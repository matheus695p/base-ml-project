{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_black\n",
      "The kedro.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext kedro.ipython\n",
      "\u001b[35m2024-01-07 20:32:40,562 - kedro_mlflow.config.kedro_mlflow_config - INFO - The 'tracking_uri' key in mlflow.yml is relative ('server.mlflow_(tracking|registry)_uri = mlruns'). It is converted to a valid uri: 'file:///Users/Matheus_Pinto/Desktop/quantumblack/titanic-dataset/mlruns'\u001b[0m\n",
      "\u001b[35m2024-01-07 20:32:40,718 - kedro.ipython - INFO - Kedro project project\u001b[0m\n",
      "\u001b[35m2024-01-07 20:32:40,719 - kedro.ipython - INFO - Defined global variable 'context', 'session', 'catalog' and 'pipelines'\u001b[0m\n",
      "\u001b[35m2024-01-07 20:32:40,730 - kedro.ipython - INFO - Registered line magic 'run_viz'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# DO NOT CHANGE THIS. YOUR PROJECT WILL NOT WORK PROPERLY OTHERWISE. Make sure that you have run `kedro install` beforehand and you don't change twice os.chdir path\n",
    "os.chdir(\"../../\")\n",
    "%load_ext kedro.ipython\n",
    "%reload_kedro .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic use case\n",
    "\n",
    "__Tutorial notebook__ for testing end-to-end the package.\n",
    "\n",
    "\n",
    "\n",
    "## Challenge Requirements\n",
    "\n",
    "### **Object-Oriented Programming (OOP)**\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b></b>\n",
    "\n",
    "> The project's codebase adheres to Object-Oriented Programming (OOP) principles. It follows the scikit-learn Transformers and Estimators schema and object injection, facilitating modularity and extensibility. This design enables compatibility with any machine learning model that adheres to the scikit-learn schema. The project's codebase is thoughtfully organized to support seamless object injection.\n",
    "\n",
    "</div>\n",
    "\n",
    "[Code Packages](https://github.com/matheus695p/titanic-dataset/tree/main/src/project/packages/README.md)\n",
    "\n",
    "\n",
    "### **Command-Line Interface (CLI)**\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b></b>\n",
    "\n",
    "> The project includes a command-line interface (CLI) that allow users to interact with the code in a streamlined manner. This CLI is based and integrated with the Kedro pipeline framework, which segregates data engineering and data science responsibilities. Leveraging Kedro, the project can be scaled in a modular way, simplifying the process of testing and evaluating numerous machine learning models. In this example, 9 different machine learning models are hypertuned, trained and evaluated using the package and scaling in a modular way using kedro modular pipelines.\n",
    "\n",
    "</div>\n",
    "\n",
    "[Pipelines Structure and Code](https://github.com/matheus695p/titanic-dataset/blob/main/src/project/pipelines/README.md)\n",
    "\n",
    "\n",
    "### **Testing and Code Coverage**\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b></b>\n",
    "\n",
    "> The project undergoes testing, encompassing both unit and integration tests, resulting in a test coverage of over 90% in the package. Continuous Integration (CI) pipelines, orchestrated by GitHub Actions, are implemented to validate the package comprehensively. These pipelines incorporate integration tests to ensure the seamless functioning of the pipelines and perform code formatting checks to maintain code quality.\n",
    "\n",
    "</div>\n",
    "\n",
    "[Test code](https://github.com/matheus695p/titanic-dataset/blob/main/src/tests/README.md)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers and model imports\n",
    "\n",
    "\n",
    "These imports are used to bring in specific classes or modules from different parts of the project's package structure. Here's a description of each import:\n",
    "\n",
    "1. `RawDataProcessor` from `project.packages.preprocessing.transformers.raw`:\n",
    "   - This import brings in the `RawDataProcessor` class, which is likely used for raw data preprocessing. It may handle tasks like data schema validation, data type validation, and initial data transformation.\n",
    "\n",
    "2. `IntermediateDataProcessor` from `project.packages.preprocessing.transformers.intermediate`:\n",
    "   - This import includes the `IntermediateDataProcessor` class, which is responsible for processing intermediate-level data. It might perform tasks like addressing outliers, data quality checks, and ensuring data consistency.\n",
    "\n",
    "3. `PrimaryDataProcessor` from `project.packages.preprocessing.transformers.primary`:\n",
    "   - The import statement fetches the `PrimaryDataProcessor` class, which is likely used for preprocessing primary-level data. It may involve tasks such as filling missing values in categorical columns and applying text normalization.\n",
    "\n",
    "4. `FeatureDataProcessor` from `project.packages.preprocessing.transformers.feature`:\n",
    "   - This import imports the `FeatureDataProcessor` class, which is designed for feature engineering. It may create new features based on existing data, perform one-hot encoding, and prepare data for modeling.\n",
    "\n",
    "5. `KMeansClusteringFeatures` from `project.packages.modelling.models.unsupervised.clustering_features`:\n",
    "   - This import includes the `KMeansClusteringFeatures` class, which is likely used for unsupervised learning tasks. It may involve generating features related to K-Means clustering for data analysis.\n",
    "\n",
    "6. `BinaryClassifierSklearnPipeline` from `project.packages.modelling.models.supervised.sklearn`:\n",
    "   - The import statement fetches the `BinaryClassifierSklearnPipeline` class, which is likely used for supervised learning tasks with scikit-learn models. It may include building pipelines for binary classification tasks using scikit-learn algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-01-07 20:32:50,948 - project.packages.modelling.reproducibility.set_seed - INFO - Seeding sklearn, numpy and random libraries with the seed 42\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from project.packages.preprocessing.transformers.raw import RawDataProcessor\n",
    "from project.packages.preprocessing.transformers.intermediate import (\n",
    "    IntermediateDataProcessor,\n",
    ")\n",
    "from project.packages.preprocessing.transformers.primary import PrimaryDataProcessor\n",
    "from project.packages.preprocessing.transformers.feature import FeatureDataProcessor\n",
    "from project.packages.modelling.models.unsupervised.clustering_features import (\n",
    "    KMeansClusteringFeatures,\n",
    ")\n",
    "from project.packages.modelling.models.supervised.sklearn import (\n",
    "    BinaryClassifierSklearnPipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Titanic dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "     PassengerId  Survived  Pclass  \\\n",
       "\u001b[1;36m0\u001b[0m              \u001b[1;36m1\u001b[0m         \u001b[1;36m0\u001b[0m       \u001b[1;36m3\u001b[0m   \n",
       "\u001b[1;36m1\u001b[0m              \u001b[1;36m2\u001b[0m         \u001b[1;36m1\u001b[0m       \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m              \u001b[1;36m3\u001b[0m         \u001b[1;36m1\u001b[0m       \u001b[1;36m3\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m              \u001b[1;36m4\u001b[0m         \u001b[1;36m1\u001b[0m       \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m              \u001b[1;36m5\u001b[0m         \u001b[1;36m0\u001b[0m       \u001b[1;36m3\u001b[0m   \n",
       "..           \u001b[33m...\u001b[0m       \u001b[33m...\u001b[0m     \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m886\u001b[0m          \u001b[1;36m887\u001b[0m         \u001b[1;36m0\u001b[0m       \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m          \u001b[1;36m888\u001b[0m         \u001b[1;36m1\u001b[0m       \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m          \u001b[1;36m889\u001b[0m         \u001b[1;36m0\u001b[0m       \u001b[1;36m3\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m          \u001b[1;36m890\u001b[0m         \u001b[1;36m1\u001b[0m       \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m          \u001b[1;36m891\u001b[0m         \u001b[1;36m0\u001b[0m       \u001b[1;36m3\u001b[0m   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "\u001b[1;36m0\u001b[0m                              Braund, Mr. Owen Harris    male  \u001b[1;36m22.0\u001b[0m      \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m1\u001b[0m    Cumings, Mrs. John Bradley \u001b[1m(\u001b[0mFlorence Briggs Th\u001b[33m...\u001b[0m  female  \u001b[1;36m38.0\u001b[0m      \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                               Heikkinen, Miss. Laina  female  \u001b[1;36m26.0\u001b[0m      \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m         Futrelle, Mrs. Jacques Heath \u001b[1m(\u001b[0mLily May Peel\u001b[1m)\u001b[0m  female  \u001b[1;36m35.0\u001b[0m      \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                             Allen, Mr. William Henry    male  \u001b[1;36m35.0\u001b[0m      \u001b[1;36m0\u001b[0m   \n",
       "..                                                 \u001b[33m...\u001b[0m     \u001b[33m...\u001b[0m   \u001b[33m...\u001b[0m    \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m886\u001b[0m                              Montvila, Rev. Juozas    male  \u001b[1;36m27.0\u001b[0m      \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                       Graham, Miss. Margaret Edith  female  \u001b[1;36m19.0\u001b[0m      \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m           Johnston, Miss. Catherine Helen \u001b[32m\"Carrie\"\u001b[0m  female   NaN      \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                              Behr, Mr. Karl Howell    male  \u001b[1;36m26.0\u001b[0m      \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                Dooley, Mr. Patrick    male  \u001b[1;36m32.0\u001b[0m      \u001b[1;36m0\u001b[0m   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "\u001b[1;36m0\u001b[0m        \u001b[1;36m0\u001b[0m         A/\u001b[1;36m5\u001b[0m \u001b[1;36m21171\u001b[0m   \u001b[1;36m7.2500\u001b[0m   NaN        S  \n",
       "\u001b[1;36m1\u001b[0m        \u001b[1;36m0\u001b[0m          PC \u001b[1;36m17599\u001b[0m  \u001b[1;36m71.2833\u001b[0m   C85        C  \n",
       "\u001b[1;36m2\u001b[0m        \u001b[1;36m0\u001b[0m  STON/O2. \u001b[1;36m3101282\u001b[0m   \u001b[1;36m7.9250\u001b[0m   NaN        S  \n",
       "\u001b[1;36m3\u001b[0m        \u001b[1;36m0\u001b[0m            \u001b[1;36m113803\u001b[0m  \u001b[1;36m53.1000\u001b[0m  C123        S  \n",
       "\u001b[1;36m4\u001b[0m        \u001b[1;36m0\u001b[0m            \u001b[1;36m373450\u001b[0m   \u001b[1;36m8.0500\u001b[0m   NaN        S  \n",
       "..     \u001b[33m...\u001b[0m               \u001b[33m...\u001b[0m      \u001b[33m...\u001b[0m   \u001b[33m...\u001b[0m      \u001b[33m...\u001b[0m  \n",
       "\u001b[1;36m886\u001b[0m      \u001b[1;36m0\u001b[0m            \u001b[1;36m211536\u001b[0m  \u001b[1;36m13.0000\u001b[0m   NaN        S  \n",
       "\u001b[1;36m887\u001b[0m      \u001b[1;36m0\u001b[0m            \u001b[1;36m112053\u001b[0m  \u001b[1;36m30.0000\u001b[0m   B42        S  \n",
       "\u001b[1;36m888\u001b[0m      \u001b[1;36m2\u001b[0m        W.\u001b[35m/\u001b[0m\u001b[95mC.\u001b[0m \u001b[1;36m6607\u001b[0m  \u001b[1;36m23.4500\u001b[0m   NaN        S  \n",
       "\u001b[1;36m889\u001b[0m      \u001b[1;36m0\u001b[0m            \u001b[1;36m111369\u001b[0m  \u001b[1;36m30.0000\u001b[0m  C148        C  \n",
       "\u001b[1;36m890\u001b[0m      \u001b[1;36m0\u001b[0m            \u001b[1;36m370376\u001b[0m   \u001b[1;36m7.7500\u001b[0m   NaN        Q  \n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m891\u001b[0m rows x \u001b[1;36m12\u001b[0m columns\u001b[1m]\u001b[0m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/01_raw/titanic_train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering\n",
    "\n",
    "### Raw data preprocessing\n",
    "\n",
    "Certainly, let's provide a more detailed explanation of the import statement:\n",
    "\n",
    "1. `RawDataProcessor` from `project.packages.preprocessing.transformers.raw`:\n",
    "\n",
    "   - `RawDataProcessor` is a class or module located in the `project.packages.preprocessing.transformers.raw` package or module.\n",
    "   - This class/module is likely designed for handling raw data preprocessing tasks in a machine learning or data science project.\n",
    "   - Raw data preprocessing typically involves tasks performed on the initial, unprocessed data that has been collected or acquired.\n",
    "   - Some common tasks that the `RawDataProcessor` class/module may handle include:\n",
    "     - **Data Schema Validation**: Ensuring that the raw data adheres to a predefined schema or structure. It checks if the expected columns and data types are present.\n",
    "     - **Data Type Validation**: Verifying that data types in the raw data match the expected types. This helps maintain consistency and prevent type-related errors.\n",
    "     - **Initial Data Transformation**: Performing basic data transformations to prepare the raw data for further processing. This may include tasks like cleaning, filtering, or reformatting data.\n",
    "   - The `RawDataProcessor` class/module is a component that aids in the initial stages of data preparation before more advanced processing or modeling steps occur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>name</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_age</th>\n",
       "      <th>passenger_siblings</th>\n",
       "      <th>passenger_parch</th>\n",
       "      <th>passenger_ticket</th>\n",
       "      <th>passenger_fare</th>\n",
       "      <th>passenger_cabin</th>\n",
       "      <th>passenger_embarked_port</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "              survived  passenger_class  \\\n",
       "passenger_id                              \n",
       "\u001b[1;36m1\u001b[0m                    \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m3\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                    \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                \u001b[33m...\u001b[0m              \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                  \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                  \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m   \n",
       "\n",
       "                                                           name passenger_sex  \\\n",
       "passenger_id                                                                    \n",
       "\u001b[1;36m1\u001b[0m                                       Braund, Mr. Owen Harris          male   \n",
       "\u001b[1;36m2\u001b[0m             Cumings, Mrs. John Bradley \u001b[1m(\u001b[0mFlorence Briggs Th\u001b[33m...\u001b[0m        female   \n",
       "\u001b[1;36m3\u001b[0m                                        Heikkinen, Miss. Laina        female   \n",
       "\u001b[1;36m4\u001b[0m                  Futrelle, Mrs. Jacques Heath \u001b[1m(\u001b[0mLily May Peel\u001b[1m)\u001b[0m        female   \n",
       "\u001b[1;36m5\u001b[0m                                      Allen, Mr. William Henry          male   \n",
       "\u001b[33m...\u001b[0m                                                         \u001b[33m...\u001b[0m           \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                       Montvila, Rev. Juozas          male   \n",
       "\u001b[1;36m888\u001b[0m                                Graham, Miss. Margaret Edith        female   \n",
       "\u001b[1;36m889\u001b[0m                    Johnston, Miss. Catherine Helen \u001b[32m\"Carrie\"\u001b[0m        female   \n",
       "\u001b[1;36m890\u001b[0m                                       Behr, Mr. Karl Howell          male   \n",
       "\u001b[1;36m891\u001b[0m                                         Dooley, Mr. Patrick          male   \n",
       "\n",
       "              passenger_age  passenger_siblings  passenger_parch  \\\n",
       "passenger_id                                                       \n",
       "\u001b[1;36m1\u001b[0m                      \u001b[1;36m22.0\u001b[0m                   \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                      \u001b[1;36m38.0\u001b[0m                   \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                      \u001b[1;36m26.0\u001b[0m                   \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                      \u001b[1;36m35.0\u001b[0m                   \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                      \u001b[1;36m35.0\u001b[0m                   \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                     \u001b[33m...\u001b[0m                 \u001b[33m...\u001b[0m              \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                    \u001b[1;36m27.0\u001b[0m                   \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                    \u001b[1;36m19.0\u001b[0m                   \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                     NaN                   \u001b[1;36m1\u001b[0m                \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                    \u001b[1;36m26.0\u001b[0m                   \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                    \u001b[1;36m32.0\u001b[0m                   \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m   \n",
       "\n",
       "              passenger_ticket  passenger_fare passenger_cabin  \\\n",
       "passenger_id                                                     \n",
       "\u001b[1;36m1\u001b[0m                    A/\u001b[1;36m5\u001b[0m \u001b[1;36m21171\u001b[0m          \u001b[1;36m7.2500\u001b[0m             NaN   \n",
       "\u001b[1;36m2\u001b[0m                     PC \u001b[1;36m17599\u001b[0m         \u001b[1;36m71.2833\u001b[0m             C85   \n",
       "\u001b[1;36m3\u001b[0m             STON/O2. \u001b[1;36m3101282\u001b[0m          \u001b[1;36m7.9250\u001b[0m             NaN   \n",
       "\u001b[1;36m4\u001b[0m                       \u001b[1;36m113803\u001b[0m         \u001b[1;36m53.1000\u001b[0m            C123   \n",
       "\u001b[1;36m5\u001b[0m                       \u001b[1;36m373450\u001b[0m          \u001b[1;36m8.0500\u001b[0m             NaN   \n",
       "\u001b[33m...\u001b[0m                        \u001b[33m...\u001b[0m             \u001b[33m...\u001b[0m             \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                     \u001b[1;36m211536\u001b[0m         \u001b[1;36m13.0000\u001b[0m             NaN   \n",
       "\u001b[1;36m888\u001b[0m                     \u001b[1;36m112053\u001b[0m         \u001b[1;36m30.0000\u001b[0m             B42   \n",
       "\u001b[1;36m889\u001b[0m                 W.\u001b[35m/\u001b[0m\u001b[95mC.\u001b[0m \u001b[1;36m6607\u001b[0m         \u001b[1;36m23.4500\u001b[0m             NaN   \n",
       "\u001b[1;36m890\u001b[0m                     \u001b[1;36m111369\u001b[0m         \u001b[1;36m30.0000\u001b[0m            C148   \n",
       "\u001b[1;36m891\u001b[0m                     \u001b[1;36m370376\u001b[0m          \u001b[1;36m7.7500\u001b[0m             NaN   \n",
       "\n",
       "             passenger_embarked_port  \n",
       "passenger_id                          \n",
       "\u001b[1;36m1\u001b[0m                                  S  \n",
       "\u001b[1;36m2\u001b[0m                                  C  \n",
       "\u001b[1;36m3\u001b[0m                                  S  \n",
       "\u001b[1;36m4\u001b[0m                                  S  \n",
       "\u001b[1;36m5\u001b[0m                                  S  \n",
       "\u001b[33m...\u001b[0m                              \u001b[33m...\u001b[0m  \n",
       "\u001b[1;36m887\u001b[0m                                S  \n",
       "\u001b[1;36m888\u001b[0m                                S  \n",
       "\u001b[1;36m889\u001b[0m                                S  \n",
       "\u001b[1;36m890\u001b[0m                                C  \n",
       "\u001b[1;36m891\u001b[0m                                Q  \n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m891\u001b[0m rows x \u001b[1;36m11\u001b[0m columns\u001b[1m]\u001b[0m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_params = {\n",
    "    \"target\": \"Survived\",\n",
    "    \"index\": \"passenger_id\",\n",
    "    \"schemas\": {\n",
    "        \"PassengerId\": {\"dtype\": \"int64\", \"name\": \"passenger_id\"},\n",
    "        \"Survived\": {\"dtype\": \"int64\", \"name\": \"survived\"},\n",
    "        \"Pclass\": {\"dtype\": \"int64\", \"name\": \"passenger_class\"},\n",
    "        \"Name\": {\"dtype\": \"object\", \"name\": \"name\"},\n",
    "        \"Sex\": {\"dtype\": \"object\", \"name\": \"passenger_sex\"},\n",
    "        \"Age\": {\"dtype\": \"float64\", \"name\": \"passenger_age\"},\n",
    "        \"Parch\": {\"dtype\": \"int64\", \"name\": \"passenger_parch\"},\n",
    "        \"Ticket\": {\"dtype\": \"object\", \"name\": \"passenger_ticket\"},\n",
    "        \"Fare\": {\"dtype\": \"float64\", \"name\": \"passenger_fare\"},\n",
    "        \"Cabin\": {\"dtype\": \"object\", \"name\": \"passenger_cabin\"},\n",
    "        \"Embarked\": {\"dtype\": \"object\", \"name\": \"passenger_embarked_port\"},\n",
    "        \"SibSp\": {\"dtype\": \"int64\", \"name\": \"passenger_siblings\"},\n",
    "    },\n",
    "}\n",
    "raw_transformer = RawDataProcessor(raw_params)\n",
    "df_raw = raw_transformer.fit_transform(df)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate data preprocessor\n",
    "\n",
    "2. `IntermediateDataProcessor` from `project.packages.preprocessing.transformers.intermediate`:\n",
    "\n",
    "   - The import statement brings in the `IntermediateDataProcessor` class, which is likely designed to handle intermediate-level data processing in a machine learning or data science project.\n",
    "   - Intermediate-level data typically refers to data that has already undergone some initial preprocessing but may still require additional refinement and quality assurance before it is used in modeling or analysis.\n",
    "   - The `IntermediateDataProcessor` class/module is responsible for several tasks related to intermediate data, including:\n",
    "     - **Outlier Handling**: Identifying and addressing outliers or unusual data points that deviate significantly from the majority of the data. This is important for ensuring that outliers do not unduly influence analysis or modeling results.\n",
    "     - **Data Quality Checks**: Verifying the quality of intermediate data by checking for missing values, data consistency, and adherence to predefined data quality standards.\n",
    "     - **Data Consistency**: Ensuring that data across various features or columns is consistent and follows expected patterns or relationships.\n",
    "   - The class/module helps in refining intermediate data and making it more suitable for subsequent modeling or analysis steps.\n",
    "   - This import statement is likely used when intermediate-level data processing is required as part of the data preparation pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_age</th>\n",
       "      <th>passenger_siblings</th>\n",
       "      <th>passenger_parch</th>\n",
       "      <th>passenger_ticket</th>\n",
       "      <th>passenger_fare</th>\n",
       "      <th>passenger_cabin</th>\n",
       "      <th>passenger_embarked_port</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "              survived  passenger_class passenger_sex  passenger_age  \\\n",
       "passenger_id                                                           \n",
       "\u001b[1;36m1\u001b[0m                    \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m22.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m38.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m3\u001b[0m        female           \u001b[1;36m26.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m35.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                    \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m35.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                \u001b[33m...\u001b[0m              \u001b[33m...\u001b[0m           \u001b[33m...\u001b[0m            \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m2\u001b[0m          male           \u001b[1;36m27.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                  \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m19.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m        female            NaN   \n",
       "\u001b[1;36m890\u001b[0m                  \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m          male           \u001b[1;36m26.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m32.0\u001b[0m   \n",
       "\n",
       "              passenger_siblings  passenger_parch  passenger_ticket  \\\n",
       "passenger_id                                                          \n",
       "\u001b[1;36m1\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m         A/\u001b[1;36m5\u001b[0m \u001b[1;36m21171\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m          PC \u001b[1;36m17599\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                              \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m  STON/O2. \u001b[1;36m3101282\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m113803\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                              \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m373450\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                          \u001b[33m...\u001b[0m              \u001b[33m...\u001b[0m               \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m211536\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m112053\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                            \u001b[1;36m1\u001b[0m                \u001b[1;36m2\u001b[0m        W.\u001b[35m/\u001b[0m\u001b[95mC.\u001b[0m \u001b[1;36m6607\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m111369\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m370376\u001b[0m   \n",
       "\n",
       "              passenger_fare passenger_cabin passenger_embarked_port  \n",
       "passenger_id                                                          \n",
       "\u001b[1;36m1\u001b[0m                     \u001b[1;36m7.2500\u001b[0m             NaN                       S  \n",
       "\u001b[1;36m2\u001b[0m                    \u001b[1;36m71.2833\u001b[0m             C85                       C  \n",
       "\u001b[1;36m3\u001b[0m                     \u001b[1;36m7.9250\u001b[0m             NaN                       S  \n",
       "\u001b[1;36m4\u001b[0m                    \u001b[1;36m53.1000\u001b[0m            C123                       S  \n",
       "\u001b[1;36m5\u001b[0m                     \u001b[1;36m8.0500\u001b[0m             NaN                       S  \n",
       "\u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m             \u001b[33m...\u001b[0m                     \u001b[33m...\u001b[0m  \n",
       "\u001b[1;36m887\u001b[0m                  \u001b[1;36m13.0000\u001b[0m             NaN                       S  \n",
       "\u001b[1;36m888\u001b[0m                  \u001b[1;36m30.0000\u001b[0m             B42                       S  \n",
       "\u001b[1;36m889\u001b[0m                  \u001b[1;36m23.4500\u001b[0m             NaN                       S  \n",
       "\u001b[1;36m890\u001b[0m                  \u001b[1;36m30.0000\u001b[0m            C148                       C  \n",
       "\u001b[1;36m891\u001b[0m                   \u001b[1;36m7.7500\u001b[0m             NaN                       Q  \n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m891\u001b[0m rows x \u001b[1;36m10\u001b[0m columns\u001b[1m]\u001b[0m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_params = {\n",
    "    \"target\": \"survived\",\n",
    "    \"outlier_params\": {\"iqr_alpha\": 2.5, \"q1_quantile\": 0.25, \"q3_quantile\": 0.75},\n",
    "    \"drop_columns\": [\"name\"],\n",
    "    \"categorical_features\": [\n",
    "        \"passenger_sex\",\n",
    "        \"passenger_ticket\",\n",
    "        \"passenger_cabin\",\n",
    "        \"passenger_embarked_port\",\n",
    "    ],\n",
    "}\n",
    "int_transformer = IntermediateDataProcessor(intermediate_params)\n",
    "df_int = int_transformer.fit_transform(df_raw)\n",
    "df_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary data preprocessing\n",
    "\n",
    "3. `PrimaryDataProcessor` from `project.packages.preprocessing.transformers.primary`:\n",
    "\n",
    "   - This import statement imports the `PrimaryDataProcessor` class/module, which is typically used for preprocessing primary-level data in a machine learning or data science project.\n",
    "   - Primary-level data refers to the initial dataset that has undergone minimal preprocessing but may still require specific transformations to make it suitable for modeling or analysis.\n",
    "   - The `PrimaryDataProcessor` class/module is responsible for various preprocessing tasks related to primary data, which may include:\n",
    "     - **Filling Missing Values**: Handling missing values in the primary data by imputing or replacing them with appropriate values. This is crucial for ensuring that missing data does not disrupt subsequent analysis or modeling.\n",
    "     - **Text Normalization**: Applying text normalization techniques to textual data within the primary dataset. Text normalization can include tasks like removing accents, converting text to lowercase, or stemming words to reduce vocabulary variations.\n",
    "     - **Categorical Data Handling**: Managing categorical variables by filling missing values, encoding them into numerical format if necessary, or applying other categorical data preprocessing techniques.\n",
    "   - The class/module is responsible for preparing primary-level data in a way that makes it more suitable and reliable for downstream analysis or modeling tasks.\n",
    "   - This import statement is likely used when specific preprocessing steps are required for primary data as part of the overall data preparation pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_age</th>\n",
       "      <th>passenger_siblings</th>\n",
       "      <th>passenger_parch</th>\n",
       "      <th>passenger_ticket</th>\n",
       "      <th>passenger_fare</th>\n",
       "      <th>passenger_cabin</th>\n",
       "      <th>passenger_embarked_port</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>c85</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>c123</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>b42</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>c148</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "              survived  passenger_class passenger_sex  passenger_age  \\\n",
       "passenger_id                                                           \n",
       "\u001b[1;36m1\u001b[0m                    \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m22.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m38.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m3\u001b[0m        female           \u001b[1;36m26.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m35.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                    \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m35.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                \u001b[33m...\u001b[0m              \u001b[33m...\u001b[0m           \u001b[33m...\u001b[0m            \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m2\u001b[0m          male           \u001b[1;36m27.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                  \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m19.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m        female            NaN   \n",
       "\u001b[1;36m890\u001b[0m                  \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m          male           \u001b[1;36m26.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m32.0\u001b[0m   \n",
       "\n",
       "              passenger_siblings  passenger_parch  passenger_ticket  \\\n",
       "passenger_id                                                          \n",
       "\u001b[1;36m1\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m         A/\u001b[1;36m5\u001b[0m \u001b[1;36m21171\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m          PC \u001b[1;36m17599\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                              \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m  STON/O2. \u001b[1;36m3101282\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m113803\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                              \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m373450\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                          \u001b[33m...\u001b[0m              \u001b[33m...\u001b[0m               \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m211536\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m112053\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                            \u001b[1;36m1\u001b[0m                \u001b[1;36m2\u001b[0m        W.\u001b[35m/\u001b[0m\u001b[95mC.\u001b[0m \u001b[1;36m6607\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m111369\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m370376\u001b[0m   \n",
       "\n",
       "              passenger_fare passenger_cabin passenger_embarked_port  \n",
       "passenger_id                                                          \n",
       "\u001b[1;36m1\u001b[0m                     \u001b[1;36m7.2500\u001b[0m         unknown                       s  \n",
       "\u001b[1;36m2\u001b[0m                    \u001b[1;36m71.2833\u001b[0m             c85                       c  \n",
       "\u001b[1;36m3\u001b[0m                     \u001b[1;36m7.9250\u001b[0m         unknown                       s  \n",
       "\u001b[1;36m4\u001b[0m                    \u001b[1;36m53.1000\u001b[0m            c123                       s  \n",
       "\u001b[1;36m5\u001b[0m                     \u001b[1;36m8.0500\u001b[0m         unknown                       s  \n",
       "\u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m             \u001b[33m...\u001b[0m                     \u001b[33m...\u001b[0m  \n",
       "\u001b[1;36m887\u001b[0m                  \u001b[1;36m13.0000\u001b[0m         unknown                       s  \n",
       "\u001b[1;36m888\u001b[0m                  \u001b[1;36m30.0000\u001b[0m             b42                       s  \n",
       "\u001b[1;36m889\u001b[0m                  \u001b[1;36m23.4500\u001b[0m         unknown                       s  \n",
       "\u001b[1;36m890\u001b[0m                  \u001b[1;36m30.0000\u001b[0m            c148                       c  \n",
       "\u001b[1;36m891\u001b[0m                   \u001b[1;36m7.7500\u001b[0m         unknown                       q  \n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m891\u001b[0m rows x \u001b[1;36m10\u001b[0m columns\u001b[1m]\u001b[0m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_params = {\n",
    "    \"target\": \"supervised\",\n",
    "    \"categorical_columns_fillna\": {\n",
    "        \"passenger_cabin\": \"unknown\",\n",
    "        \"passenger_embarked_port\": \"unknown\",\n",
    "    },\n",
    "}\n",
    "prm_transformer = PrimaryDataProcessor(primary_params)\n",
    "df_prm = prm_transformer.fit_transform(df_int)\n",
    "df_prm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering \n",
    "\n",
    "\n",
    "4. `FeatureDataProcessor` from `project.packages.preprocessing.transformers.feature`:\n",
    "\n",
    "   - This import statement brings in the `FeatureDataProcessor` class/module, which typically plays a key role in feature engineering within a machine learning or data science project.\n",
    "   - Feature engineering is a critical step in data preprocessing that involves creating new features or transforming existing ones to improve the performance of machine learning models or enhance the understanding of data patterns.\n",
    "   - The `FeatureDataProcessor` class/module is responsible for various feature engineering tasks, which may include:\n",
    "     - **Creating New Features**: Generating new features by combining or transforming existing data columns. These new features can capture valuable information or relationships within the data that may not be apparent initially.\n",
    "     - **One-Hot Encoding**: Converting categorical variables into a numerical format through one-hot encoding. This is essential for including categorical data in machine learning models that require numerical input.\n",
    "     - **Additional Data Transformation**: Carrying out additional data transformations or preprocessing steps specific to feature engineering requirements.\n",
    "   - The class/module is instrumental in preparing the dataset with engineered features, making it more informative and suitable for training machine learning models.\n",
    "   - This import statement is likely used when feature engineering steps are part of the data preparation pipeline, and new features need to be created or existing ones transformed for modeling purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_age</th>\n",
       "      <th>passenger_siblings</th>\n",
       "      <th>passenger_parch</th>\n",
       "      <th>passenger_ticket</th>\n",
       "      <th>passenger_fare</th>\n",
       "      <th>passenger_cabin</th>\n",
       "      <th>passenger_embarked_port</th>\n",
       "      <th>passenger_ticket_base</th>\n",
       "      <th>passenger_ticket_number</th>\n",
       "      <th>passenger_ticket_unknown_base</th>\n",
       "      <th>passenger_cabin_level</th>\n",
       "      <th>passenger_cabin_number</th>\n",
       "      <th>passenger_number_of_family_onboard</th>\n",
       "      <th>passenger_is_single</th>\n",
       "      <th>passenger_has_significant_other</th>\n",
       "      <th>passenger_has_childs</th>\n",
       "      <th>passenger_cabin_level_a</th>\n",
       "      <th>passenger_cabin_level_b</th>\n",
       "      <th>passenger_cabin_level_c</th>\n",
       "      <th>passenger_cabin_level_d</th>\n",
       "      <th>passenger_cabin_level_e</th>\n",
       "      <th>passenger_cabin_level_f</th>\n",
       "      <th>passenger_cabin_level_g</th>\n",
       "      <th>passenger_cabin_level_t</th>\n",
       "      <th>passenger_cabin_level_unknown</th>\n",
       "      <th>passenger_embarked_port_c</th>\n",
       "      <th>passenger_embarked_port_q</th>\n",
       "      <th>passenger_embarked_port_s</th>\n",
       "      <th>passenger_embarked_port_unknown</th>\n",
       "      <th>passenger_sex_female</th>\n",
       "      <th>passenger_sex_male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>A/5</td>\n",
       "      <td>21171.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>c85</td>\n",
       "      <td>c</td>\n",
       "      <td>PC</td>\n",
       "      <td>17599.0</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>STON/O2.</td>\n",
       "      <td>3101282.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>c123</td>\n",
       "      <td>s</td>\n",
       "      <td>unknown</td>\n",
       "      <td>113803.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>unknown</td>\n",
       "      <td>373450.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>unknown</td>\n",
       "      <td>211536.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>b42</td>\n",
       "      <td>s</td>\n",
       "      <td>unknown</td>\n",
       "      <td>112053.0</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>W./C.</td>\n",
       "      <td>6607.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>c148</td>\n",
       "      <td>c</td>\n",
       "      <td>unknown</td>\n",
       "      <td>111369.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>q</td>\n",
       "      <td>unknown</td>\n",
       "      <td>370376.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "              survived  passenger_class passenger_sex  passenger_age  \\\n",
       "passenger_id                                                           \n",
       "\u001b[1;36m1\u001b[0m                    \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m22.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m38.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m3\u001b[0m        female           \u001b[1;36m26.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m35.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                    \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m35.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                \u001b[33m...\u001b[0m              \u001b[33m...\u001b[0m           \u001b[33m...\u001b[0m            \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m2\u001b[0m          male           \u001b[1;36m27.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                  \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m19.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m        female            NaN   \n",
       "\u001b[1;36m890\u001b[0m                  \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m          male           \u001b[1;36m26.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m32.0\u001b[0m   \n",
       "\n",
       "              passenger_siblings  passenger_parch  passenger_ticket  \\\n",
       "passenger_id                                                          \n",
       "\u001b[1;36m1\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m         A/\u001b[1;36m5\u001b[0m \u001b[1;36m21171\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m          PC \u001b[1;36m17599\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                              \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m  STON/O2. \u001b[1;36m3101282\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m113803\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                              \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m373450\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                          \u001b[33m...\u001b[0m              \u001b[33m...\u001b[0m               \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m211536\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m112053\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                            \u001b[1;36m1\u001b[0m                \u001b[1;36m2\u001b[0m        W.\u001b[35m/\u001b[0m\u001b[95mC.\u001b[0m \u001b[1;36m6607\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m111369\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m370376\u001b[0m   \n",
       "\n",
       "              passenger_fare passenger_cabin passenger_embarked_port  \\\n",
       "passenger_id                                                           \n",
       "\u001b[1;36m1\u001b[0m                     \u001b[1;36m7.2500\u001b[0m         unknown                       s   \n",
       "\u001b[1;36m2\u001b[0m                    \u001b[1;36m71.2833\u001b[0m             c85                       c   \n",
       "\u001b[1;36m3\u001b[0m                     \u001b[1;36m7.9250\u001b[0m         unknown                       s   \n",
       "\u001b[1;36m4\u001b[0m                    \u001b[1;36m53.1000\u001b[0m            c123                       s   \n",
       "\u001b[1;36m5\u001b[0m                     \u001b[1;36m8.0500\u001b[0m         unknown                       s   \n",
       "\u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m             \u001b[33m...\u001b[0m                     \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                  \u001b[1;36m13.0000\u001b[0m         unknown                       s   \n",
       "\u001b[1;36m888\u001b[0m                  \u001b[1;36m30.0000\u001b[0m             b42                       s   \n",
       "\u001b[1;36m889\u001b[0m                  \u001b[1;36m23.4500\u001b[0m         unknown                       s   \n",
       "\u001b[1;36m890\u001b[0m                  \u001b[1;36m30.0000\u001b[0m            c148                       c   \n",
       "\u001b[1;36m891\u001b[0m                   \u001b[1;36m7.7500\u001b[0m         unknown                       q   \n",
       "\n",
       "             passenger_ticket_base  passenger_ticket_number  \\\n",
       "passenger_id                                                  \n",
       "\u001b[1;36m1\u001b[0m                              A/\u001b[1;36m5\u001b[0m                  \u001b[1;36m21171.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                               PC                  \u001b[1;36m17599.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                         STON/O2.                \u001b[1;36m3101282.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                          unknown                 \u001b[1;36m113803.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                          unknown                 \u001b[1;36m373450.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                            \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                        unknown                 \u001b[1;36m211536.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                        unknown                 \u001b[1;36m112053.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                          W.\u001b[35m/\u001b[0m\u001b[95mC.\u001b[0m                   \u001b[1;36m6607.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                        unknown                 \u001b[1;36m111369.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                        unknown                 \u001b[1;36m370376.0\u001b[0m   \n",
       "\n",
       "              passenger_ticket_unknown_base passenger_cabin_level  \\\n",
       "passenger_id                                                        \n",
       "\u001b[1;36m1\u001b[0m                                         \u001b[1;36m0\u001b[0m               unknown   \n",
       "\u001b[1;36m2\u001b[0m                                         \u001b[1;36m0\u001b[0m                     c   \n",
       "\u001b[1;36m3\u001b[0m                                         \u001b[1;36m0\u001b[0m               unknown   \n",
       "\u001b[1;36m4\u001b[0m                                         \u001b[1;36m1\u001b[0m                     c   \n",
       "\u001b[1;36m5\u001b[0m                                         \u001b[1;36m1\u001b[0m               unknown   \n",
       "\u001b[33m...\u001b[0m                                     \u001b[33m...\u001b[0m                   \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                       \u001b[1;36m1\u001b[0m               unknown   \n",
       "\u001b[1;36m888\u001b[0m                                       \u001b[1;36m1\u001b[0m                     b   \n",
       "\u001b[1;36m889\u001b[0m                                       \u001b[1;36m0\u001b[0m               unknown   \n",
       "\u001b[1;36m890\u001b[0m                                       \u001b[1;36m1\u001b[0m                     c   \n",
       "\u001b[1;36m891\u001b[0m                                       \u001b[1;36m1\u001b[0m               unknown   \n",
       "\n",
       "              passenger_cabin_number  passenger_number_of_family_onboard  \\\n",
       "passenger_id                                                               \n",
       "\u001b[1;36m1\u001b[0m                                NaN                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                               \u001b[1;36m85.0\u001b[0m                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                NaN                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                              \u001b[1;36m123.0\u001b[0m                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                NaN                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                              \u001b[33m...\u001b[0m                                 \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                              NaN                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                             \u001b[1;36m42.0\u001b[0m                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                              NaN                                   \u001b[1;36m3\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                            \u001b[1;36m148.0\u001b[0m                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                              NaN                                   \u001b[1;36m0\u001b[0m   \n",
       "\n",
       "              passenger_is_single  passenger_has_significant_other  \\\n",
       "passenger_id                                                         \n",
       "\u001b[1;36m1\u001b[0m                               \u001b[1;36m0\u001b[0m                                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                               \u001b[1;36m0\u001b[0m                                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                               \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                               \u001b[1;36m0\u001b[0m                                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                               \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                           \u001b[33m...\u001b[0m                              \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                             \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                             \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                             \u001b[1;36m0\u001b[0m                                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                             \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                             \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\n",
       "              passenger_has_childs  passenger_cabin_level_a  \\\n",
       "passenger_id                                                  \n",
       "\u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                            \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                              \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                              \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                              \u001b[1;36m0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                              \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                              \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_level_b  passenger_cabin_level_c  \\\n",
       "passenger_id                                                     \n",
       "\u001b[1;36m1\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                               \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                               \u001b[1;36m1.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_level_d  passenger_cabin_level_e  \\\n",
       "passenger_id                                                     \n",
       "\u001b[1;36m1\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                               \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_level_f  passenger_cabin_level_g  \\\n",
       "passenger_id                                                     \n",
       "\u001b[1;36m1\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                               \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_level_t  passenger_cabin_level_unknown  \\\n",
       "passenger_id                                                           \n",
       "\u001b[1;36m1\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                               \u001b[33m...\u001b[0m                            \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\n",
       "              passenger_embarked_port_c  passenger_embarked_port_q  \\\n",
       "passenger_id                                                         \n",
       "\u001b[1;36m1\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                 \u001b[33m...\u001b[0m                        \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                 \u001b[1;36m1.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m1.0\u001b[0m   \n",
       "\n",
       "              passenger_embarked_port_s  passenger_embarked_port_unknown  \\\n",
       "passenger_id                                                               \n",
       "\u001b[1;36m1\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                 \u001b[33m...\u001b[0m                              \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                 \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                 \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                 \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_sex_female  passenger_sex_male  \n",
       "passenger_id                                            \n",
       "\u001b[1;36m1\u001b[0m                              \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m  \n",
       "\u001b[1;36m2\u001b[0m                              \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m  \n",
       "\u001b[1;36m3\u001b[0m                              \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m  \n",
       "\u001b[1;36m4\u001b[0m                              \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m  \n",
       "\u001b[1;36m5\u001b[0m                              \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m  \n",
       "\u001b[33m...\u001b[0m                            \u001b[33m...\u001b[0m                 \u001b[33m...\u001b[0m  \n",
       "\u001b[1;36m887\u001b[0m                            \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m  \n",
       "\u001b[1;36m888\u001b[0m                            \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m  \n",
       "\u001b[1;36m889\u001b[0m                            \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m  \n",
       "\u001b[1;36m890\u001b[0m                            \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m  \n",
       "\u001b[1;36m891\u001b[0m                            \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m  \n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m891\u001b[0m rows x \u001b[1;36m34\u001b[0m columns\u001b[1m]\u001b[0m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_params = {\n",
    "    \"target\": \"survived\",\n",
    "    \"encoding_transform\": {\n",
    "        \"one_hot_encoder\": [\n",
    "            \"passenger_cabin_level\",\n",
    "            \"passenger_embarked_port\",\n",
    "            \"passenger_sex\",\n",
    "        ],\n",
    "        \"similarity_based_encoder\": None,\n",
    "    },\n",
    "}\n",
    "feat_transformer = FeatureDataProcessor(feature_params)\n",
    "df_feat = feat_transformer.fit_transform(df_prm)\n",
    "df_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. `KMeansClusteringFeatures` from `project.packages.modelling.models.unsupervised.clustering_features`:\n",
    "\n",
    "   - The `KMeansClusteringFeatures` class/module is likely designed to support unsupervised learning tasks by providing features or utilities related to K-Means clustering:\n",
    "     - **Feature Generation**: It may include methods to generate features that represent the cluster assignments or distances of data points to cluster centroids obtained through K-Means clustering. It creates new clusters features based on the parameters provided and performs K-Means clustering algorithm. The number of clusters are determined by the Elbow method.\n",
    "     - **Feature Engineering**: The class/module may offer features that can be used as input features for downstream machine learning models or analysis tasks.\n",
    "   - K-Means clustering is a popular clustering algorithm that partitions data into clusters based on similarity. The features and utilities provided by this class/module may aid in understanding the inherent patterns and structures within the data.\n",
    "\n",
    "\n",
    "New features name as __passenger_cabin_cluster_feature__, __passenger_embarked_port_cluster_feature__, __passenger_ticket_number_cluster_feature__, __passenger_family_cluster_feature__ and __passenger_social_status_cluster_feature__ will be created from these params using the features assigned on the values of these dictionary.\n",
    "The idea behind is to encode simular variables into a more descriptive feature for solving the proble.\n",
    "\n",
    "**The cluster __id__ assignment is based on a monotonically increasing mean number of the observations provide. So labels are monotonic increasing. Which allow us to also reduce the number of features, meaning we can avoid the one hot encoding of these variables.**\n",
    "\n",
    "\n",
    "```python\n",
    "cluster_feature_params = {\n",
    "    \"passenger_cabin_cluster_feature\": [\n",
    "        \"passenger_cabin_level_a\",\n",
    "        \"passenger_cabin_level_b\",\n",
    "        \"passenger_cabin_level_c\",\n",
    "        \"passenger_cabin_level_d\",\n",
    "        \"passenger_cabin_level_e\",\n",
    "        \"passenger_cabin_level_f\",\n",
    "        \"passenger_cabin_level_g\",\n",
    "        \"passenger_cabin_level_t\",\n",
    "        \"passenger_cabin_level_unknown\",\n",
    "    ],\n",
    "    \"passenger_embarked_port_cluster_feature\": [\n",
    "        \"passenger_embarked_port_c\",\n",
    "        \"passenger_embarked_port_q\",\n",
    "        \"passenger_embarked_port_s\",\n",
    "        \"passenger_embarked_port_unknown\",\n",
    "    ],\n",
    "    \"passenger_ticket_number_cluster_feature\": [\n",
    "        \"passenger_ticket_number\",\n",
    "        \"passenger_ticket_unknown_base\",\n",
    "    ],\n",
    "    \"passenger_family_cluster_feature\": [\n",
    "        \"passenger_siblings\",\n",
    "        \"passenger_parch\",\n",
    "        \"passenger_cabin_number\",\n",
    "        \"passenger_number_of_family_onboard\",\n",
    "    ],\n",
    "    \"passenger_social_status_cluster_feature\": [\n",
    "        \"passenger_class\",\n",
    "        \"passenger_age\",\n",
    "        \"passenger_sex_female\",\n",
    "    ],\n",
    "}\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-01-07 20:43:39,092 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 20:43:39,107 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 31, 'cluster_id_1': 0, 'cluster_id_2': 1}\u001b[0m\n",
      "\u001b[34m2024-01-07 20:43:40,009 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 20:43:40,024 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 1, 'cluster_id_1': 0, 'cluster_id_2': 5}\u001b[0m\n",
      "\u001b[34m2024-01-07 20:43:40,830 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 20:43:40,844 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 427, 'cluster_id_1': 594, 'cluster_id_2': 816}\u001b[0m\n",
      "\u001b[34m2024-01-07 20:43:41,952 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 20:43:41,971 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 889, 'cluster_id_1': 68, 'cluster_id_2': 128}\u001b[0m\n",
      "\u001b[34m2024-01-07 20:43:43,158 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 20:43:43,178 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 390, 'cluster_id_1': 146, 'cluster_id_2': 312}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_age</th>\n",
       "      <th>passenger_siblings</th>\n",
       "      <th>passenger_parch</th>\n",
       "      <th>passenger_ticket</th>\n",
       "      <th>passenger_fare</th>\n",
       "      <th>passenger_cabin</th>\n",
       "      <th>passenger_embarked_port</th>\n",
       "      <th>passenger_ticket_base</th>\n",
       "      <th>passenger_ticket_number</th>\n",
       "      <th>passenger_ticket_unknown_base</th>\n",
       "      <th>passenger_cabin_level</th>\n",
       "      <th>passenger_cabin_number</th>\n",
       "      <th>passenger_number_of_family_onboard</th>\n",
       "      <th>passenger_is_single</th>\n",
       "      <th>passenger_has_significant_other</th>\n",
       "      <th>passenger_has_childs</th>\n",
       "      <th>passenger_cabin_level_a</th>\n",
       "      <th>passenger_cabin_level_b</th>\n",
       "      <th>passenger_cabin_level_c</th>\n",
       "      <th>passenger_cabin_level_d</th>\n",
       "      <th>passenger_cabin_level_e</th>\n",
       "      <th>passenger_cabin_level_f</th>\n",
       "      <th>passenger_cabin_level_g</th>\n",
       "      <th>passenger_cabin_level_t</th>\n",
       "      <th>passenger_cabin_level_unknown</th>\n",
       "      <th>passenger_embarked_port_c</th>\n",
       "      <th>passenger_embarked_port_q</th>\n",
       "      <th>passenger_embarked_port_s</th>\n",
       "      <th>passenger_embarked_port_unknown</th>\n",
       "      <th>passenger_sex_female</th>\n",
       "      <th>passenger_sex_male</th>\n",
       "      <th>passenger_cabin_cluster_feature</th>\n",
       "      <th>passenger_embarked_port_cluster_feature</th>\n",
       "      <th>passenger_ticket_number_cluster_feature</th>\n",
       "      <th>passenger_family_cluster_feature</th>\n",
       "      <th>passenger_social_status_cluster_feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>A/5</td>\n",
       "      <td>21171.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>c85</td>\n",
       "      <td>c</td>\n",
       "      <td>PC</td>\n",
       "      <td>17599.0</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>STON/O2.</td>\n",
       "      <td>3101282.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>c123</td>\n",
       "      <td>s</td>\n",
       "      <td>unknown</td>\n",
       "      <td>113803.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>unknown</td>\n",
       "      <td>373450.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>unknown</td>\n",
       "      <td>211536.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>b42</td>\n",
       "      <td>s</td>\n",
       "      <td>unknown</td>\n",
       "      <td>112053.0</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>W./C.</td>\n",
       "      <td>6607.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>c148</td>\n",
       "      <td>c</td>\n",
       "      <td>unknown</td>\n",
       "      <td>111369.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>q</td>\n",
       "      <td>unknown</td>\n",
       "      <td>370376.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "              survived  passenger_class passenger_sex  passenger_age  \\\n",
       "passenger_id                                                           \n",
       "\u001b[1;36m1\u001b[0m                    \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m22.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m38.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m3\u001b[0m        female           \u001b[1;36m26.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m35.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                    \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m35.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                \u001b[33m...\u001b[0m              \u001b[33m...\u001b[0m           \u001b[33m...\u001b[0m            \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m2\u001b[0m          male           \u001b[1;36m27.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                  \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m19.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m        female            NaN   \n",
       "\u001b[1;36m890\u001b[0m                  \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m          male           \u001b[1;36m26.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m32.0\u001b[0m   \n",
       "\n",
       "              passenger_siblings  passenger_parch  passenger_ticket  \\\n",
       "passenger_id                                                          \n",
       "\u001b[1;36m1\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m         A/\u001b[1;36m5\u001b[0m \u001b[1;36m21171\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m          PC \u001b[1;36m17599\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                              \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m  STON/O2. \u001b[1;36m3101282\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m113803\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                              \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m373450\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                          \u001b[33m...\u001b[0m              \u001b[33m...\u001b[0m               \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m211536\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m112053\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                            \u001b[1;36m1\u001b[0m                \u001b[1;36m2\u001b[0m        W.\u001b[35m/\u001b[0m\u001b[95mC.\u001b[0m \u001b[1;36m6607\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m111369\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m370376\u001b[0m   \n",
       "\n",
       "              passenger_fare passenger_cabin passenger_embarked_port  \\\n",
       "passenger_id                                                           \n",
       "\u001b[1;36m1\u001b[0m                     \u001b[1;36m7.2500\u001b[0m         unknown                       s   \n",
       "\u001b[1;36m2\u001b[0m                    \u001b[1;36m71.2833\u001b[0m             c85                       c   \n",
       "\u001b[1;36m3\u001b[0m                     \u001b[1;36m7.9250\u001b[0m         unknown                       s   \n",
       "\u001b[1;36m4\u001b[0m                    \u001b[1;36m53.1000\u001b[0m            c123                       s   \n",
       "\u001b[1;36m5\u001b[0m                     \u001b[1;36m8.0500\u001b[0m         unknown                       s   \n",
       "\u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m             \u001b[33m...\u001b[0m                     \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                  \u001b[1;36m13.0000\u001b[0m         unknown                       s   \n",
       "\u001b[1;36m888\u001b[0m                  \u001b[1;36m30.0000\u001b[0m             b42                       s   \n",
       "\u001b[1;36m889\u001b[0m                  \u001b[1;36m23.4500\u001b[0m         unknown                       s   \n",
       "\u001b[1;36m890\u001b[0m                  \u001b[1;36m30.0000\u001b[0m            c148                       c   \n",
       "\u001b[1;36m891\u001b[0m                   \u001b[1;36m7.7500\u001b[0m         unknown                       q   \n",
       "\n",
       "             passenger_ticket_base  passenger_ticket_number  \\\n",
       "passenger_id                                                  \n",
       "\u001b[1;36m1\u001b[0m                              A/\u001b[1;36m5\u001b[0m                  \u001b[1;36m21171.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                               PC                  \u001b[1;36m17599.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                         STON/O2.                \u001b[1;36m3101282.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                          unknown                 \u001b[1;36m113803.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                          unknown                 \u001b[1;36m373450.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                            \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                        unknown                 \u001b[1;36m211536.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                        unknown                 \u001b[1;36m112053.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                          W.\u001b[35m/\u001b[0m\u001b[95mC.\u001b[0m                   \u001b[1;36m6607.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                        unknown                 \u001b[1;36m111369.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                        unknown                 \u001b[1;36m370376.0\u001b[0m   \n",
       "\n",
       "              passenger_ticket_unknown_base passenger_cabin_level  \\\n",
       "passenger_id                                                        \n",
       "\u001b[1;36m1\u001b[0m                                         \u001b[1;36m0\u001b[0m               unknown   \n",
       "\u001b[1;36m2\u001b[0m                                         \u001b[1;36m0\u001b[0m                     c   \n",
       "\u001b[1;36m3\u001b[0m                                         \u001b[1;36m0\u001b[0m               unknown   \n",
       "\u001b[1;36m4\u001b[0m                                         \u001b[1;36m1\u001b[0m                     c   \n",
       "\u001b[1;36m5\u001b[0m                                         \u001b[1;36m1\u001b[0m               unknown   \n",
       "\u001b[33m...\u001b[0m                                     \u001b[33m...\u001b[0m                   \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                       \u001b[1;36m1\u001b[0m               unknown   \n",
       "\u001b[1;36m888\u001b[0m                                       \u001b[1;36m1\u001b[0m                     b   \n",
       "\u001b[1;36m889\u001b[0m                                       \u001b[1;36m0\u001b[0m               unknown   \n",
       "\u001b[1;36m890\u001b[0m                                       \u001b[1;36m1\u001b[0m                     c   \n",
       "\u001b[1;36m891\u001b[0m                                       \u001b[1;36m1\u001b[0m               unknown   \n",
       "\n",
       "              passenger_cabin_number  passenger_number_of_family_onboard  \\\n",
       "passenger_id                                                               \n",
       "\u001b[1;36m1\u001b[0m                                NaN                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                               \u001b[1;36m85.0\u001b[0m                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                NaN                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                              \u001b[1;36m123.0\u001b[0m                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                NaN                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                              \u001b[33m...\u001b[0m                                 \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                              NaN                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                             \u001b[1;36m42.0\u001b[0m                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                              NaN                                   \u001b[1;36m3\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                            \u001b[1;36m148.0\u001b[0m                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                              NaN                                   \u001b[1;36m0\u001b[0m   \n",
       "\n",
       "              passenger_is_single  passenger_has_significant_other  \\\n",
       "passenger_id                                                         \n",
       "\u001b[1;36m1\u001b[0m                               \u001b[1;36m0\u001b[0m                                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                               \u001b[1;36m0\u001b[0m                                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                               \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                               \u001b[1;36m0\u001b[0m                                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                               \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                           \u001b[33m...\u001b[0m                              \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                             \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                             \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                             \u001b[1;36m0\u001b[0m                                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                             \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                             \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\n",
       "              passenger_has_childs  passenger_cabin_level_a  \\\n",
       "passenger_id                                                  \n",
       "\u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                            \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                              \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                              \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                              \u001b[1;36m0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                              \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                              \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_level_b  passenger_cabin_level_c  \\\n",
       "passenger_id                                                     \n",
       "\u001b[1;36m1\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                               \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                               \u001b[1;36m1.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_level_d  passenger_cabin_level_e  \\\n",
       "passenger_id                                                     \n",
       "\u001b[1;36m1\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                               \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_level_f  passenger_cabin_level_g  \\\n",
       "passenger_id                                                     \n",
       "\u001b[1;36m1\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                               \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_level_t  passenger_cabin_level_unknown  \\\n",
       "passenger_id                                                           \n",
       "\u001b[1;36m1\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                               \u001b[33m...\u001b[0m                            \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\n",
       "              passenger_embarked_port_c  passenger_embarked_port_q  \\\n",
       "passenger_id                                                         \n",
       "\u001b[1;36m1\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                 \u001b[33m...\u001b[0m                        \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                 \u001b[1;36m1.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m1.0\u001b[0m   \n",
       "\n",
       "              passenger_embarked_port_s  passenger_embarked_port_unknown  \\\n",
       "passenger_id                                                               \n",
       "\u001b[1;36m1\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                 \u001b[33m...\u001b[0m                              \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                 \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                 \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                 \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_sex_female  passenger_sex_male  \\\n",
       "passenger_id                                             \n",
       "\u001b[1;36m1\u001b[0m                              \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                              \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                              \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                              \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                              \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                            \u001b[33m...\u001b[0m                 \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                            \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                            \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                            \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                            \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                            \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_cluster_feature  \\\n",
       "passenger_id                                    \n",
       "\u001b[1;36m1\u001b[0m                                           \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                           \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                           \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                           \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                           \u001b[1;36m1\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                       \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                         \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                         \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                         \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                         \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                         \u001b[1;36m1\u001b[0m   \n",
       "\n",
       "              passenger_embarked_port_cluster_feature  \\\n",
       "passenger_id                                            \n",
       "\u001b[1;36m1\u001b[0m                                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                               \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                                 \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                                 \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                                 \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                                 \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                                 \u001b[1;36m2\u001b[0m   \n",
       "\n",
       "              passenger_ticket_number_cluster_feature  \\\n",
       "passenger_id                                            \n",
       "\u001b[1;36m1\u001b[0m                                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                                   \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                                   \u001b[1;36m2\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                               \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                                 \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                                 \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                                 \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                                 \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                                 \u001b[1;36m2\u001b[0m   \n",
       "\n",
       "              passenger_family_cluster_feature  \\\n",
       "passenger_id                                     \n",
       "\u001b[1;36m1\u001b[0m                                            \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                            \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                            \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                            \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                            \u001b[1;36m0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                        \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                          \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                          \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                          \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                          \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                          \u001b[1;36m0\u001b[0m   \n",
       "\n",
       "              passenger_social_status_cluster_feature  \n",
       "passenger_id                                           \n",
       "\u001b[1;36m1\u001b[0m                                                   \u001b[1;36m1\u001b[0m  \n",
       "\u001b[1;36m2\u001b[0m                                                   \u001b[1;36m2\u001b[0m  \n",
       "\u001b[1;36m3\u001b[0m                                                   \u001b[1;36m2\u001b[0m  \n",
       "\u001b[1;36m4\u001b[0m                                                   \u001b[1;36m2\u001b[0m  \n",
       "\u001b[1;36m5\u001b[0m                                                   \u001b[1;36m1\u001b[0m  \n",
       "\u001b[33m...\u001b[0m                                               \u001b[33m...\u001b[0m  \n",
       "\u001b[1;36m887\u001b[0m                                                 \u001b[1;36m0\u001b[0m  \n",
       "\u001b[1;36m888\u001b[0m                                                 \u001b[1;36m2\u001b[0m  \n",
       "\u001b[1;36m889\u001b[0m                                                 \u001b[1;36m2\u001b[0m  \n",
       "\u001b[1;36m890\u001b[0m                                                 \u001b[1;36m0\u001b[0m  \n",
       "\u001b[1;36m891\u001b[0m                                                 \u001b[1;36m1\u001b[0m  \n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m891\u001b[0m rows x \u001b[1;36m39\u001b[0m columns\u001b[1m]\u001b[0m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_model_params = {\n",
    "    \"class\": \"project.packages.modelling.models.unsupervised.segmentation.KMeansElbowSelector\",\n",
    "    \"kwargs\": {\"min_clusters\": 1, \"max_clusters\": 15},\n",
    "}\n",
    "cluster_scaler_params = {\n",
    "    \"class\": \"project.packages.modelling.transformers.scaler.ColumnsPreserverScaler\",\n",
    "    \"kwargs\": {\n",
    "        \"scaler_params\": {\"class\": \"sklearn.preprocessing.MinMaxScaler\", \"kwargs\": {}}\n",
    "    },\n",
    "}\n",
    "cluster_imputer_params = {\n",
    "    \"class\": \"project.packages.modelling.models.unsupervised.imputer.ColumnsPreserverImputer\",\n",
    "    \"kwargs\": {\n",
    "        \"imputer_params\": {\n",
    "            \"class\": \"sklearn.impute.KNNImputer\",\n",
    "            \"kwargs\": {\"n_neighbors\": 10, \"weights\": \"distance\"},\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "# cluster feature name and features used to create the cluster feature\n",
    "cluster_feature_params = {\n",
    "    \"passenger_cabin_cluster_feature\": [\n",
    "        \"passenger_cabin_level_a\",\n",
    "        \"passenger_cabin_level_b\",\n",
    "        \"passenger_cabin_level_c\",\n",
    "        \"passenger_cabin_level_d\",\n",
    "        \"passenger_cabin_level_e\",\n",
    "        \"passenger_cabin_level_f\",\n",
    "        \"passenger_cabin_level_g\",\n",
    "        \"passenger_cabin_level_t\",\n",
    "        \"passenger_cabin_level_unknown\",\n",
    "    ],\n",
    "    \"passenger_embarked_port_cluster_feature\": [\n",
    "        \"passenger_embarked_port_c\",\n",
    "        \"passenger_embarked_port_q\",\n",
    "        \"passenger_embarked_port_s\",\n",
    "        \"passenger_embarked_port_unknown\",\n",
    "    ],\n",
    "    \"passenger_ticket_number_cluster_feature\": [\n",
    "        \"passenger_ticket_number\",\n",
    "        \"passenger_ticket_unknown_base\",\n",
    "    ],\n",
    "    \"passenger_family_cluster_feature\": [\n",
    "        \"passenger_siblings\",\n",
    "        \"passenger_parch\",\n",
    "        \"passenger_cabin_number\",\n",
    "        \"passenger_number_of_family_onboard\",\n",
    "    ],\n",
    "    \"passenger_social_status_cluster_feature\": [\n",
    "        \"passenger_class\",\n",
    "        \"passenger_age\",\n",
    "        \"passenger_sex_female\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "cluster_transformer = KMeansClusteringFeatures(\n",
    "    model_params=cluster_model_params,\n",
    "    scaler_params=cluster_scaler_params,\n",
    "    feature_params=cluster_feature_params,\n",
    "    imputer_params=cluster_imputer_params,\n",
    ")\n",
    "data = cluster_transformer.fit_transform(df_feat)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data engineering in a single sklearn pipeline\n",
    "\n",
    "All data engineering transformations can be encapsulated in a single sklearn pipeline for doing all data transformations.\n",
    "\n",
    "What are the benefits of this approach: No data leakage is ensured in the process of data engineering. Data will never be leaked due to wrong data manipulations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 {color: black;background-color: white;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 pre{padding: 0;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-toggleable {background-color: white;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-estimator:hover {background-color: #d4ebff;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-item {z-index: 1;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-parallel-item:only-child::after {width: 0;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-61df5ee6-d314-4de4-a1fa-6ce8086881e0\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;raw_transformations&#x27;,\n",
       "                 RawDataProcessor(params={&#x27;index&#x27;: &#x27;passenger_id&#x27;,\n",
       "                                          &#x27;schemas&#x27;: {&#x27;Age&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                                              &#x27;name&#x27;: &#x27;passenger_age&#x27;},\n",
       "                                                      &#x27;Cabin&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                                &#x27;name&#x27;: &#x27;passenger_cabin&#x27;},\n",
       "                                                      &#x27;Embarked&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                                   &#x27;name&#x27;: &#x27;passenger_embarked_port&#x27;},\n",
       "                                                      &#x27;Fare&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                                               &#x27;name&#x27;: &#x27;passenger_fare&#x27;},\n",
       "                                                      &#x27;Name&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                               &#x27;name&#x27;: &#x27;name...\n",
       "                                                                                                   &#x27;weights&#x27;: &#x27;distance&#x27;}}}},\n",
       "                                          model_params={&#x27;class&#x27;: &#x27;project.packages.modelling.models.unsupervised.segmentation.KMeansElbowSelector&#x27;,\n",
       "                                                        &#x27;kwargs&#x27;: {&#x27;max_clusters&#x27;: 15,\n",
       "                                                                   &#x27;min_clusters&#x27;: 1}},\n",
       "                                          scaler_params={&#x27;class&#x27;: &#x27;project.packages.modelling.transformers.scaler.ColumnsPreserverScaler&#x27;,\n",
       "                                                         &#x27;kwargs&#x27;: {&#x27;scaler_params&#x27;: {&#x27;class&#x27;: &#x27;sklearn.preprocessing.MinMaxScaler&#x27;,\n",
       "                                                                                      &#x27;kwargs&#x27;: {}}}}))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3b39b3f4-831b-49a9-af4c-a6073243a9cf\" type=\"checkbox\" ><label for=\"3b39b3f4-831b-49a9-af4c-a6073243a9cf\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;raw_transformations&#x27;,\n",
       "                 RawDataProcessor(params={&#x27;index&#x27;: &#x27;passenger_id&#x27;,\n",
       "                                          &#x27;schemas&#x27;: {&#x27;Age&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                                              &#x27;name&#x27;: &#x27;passenger_age&#x27;},\n",
       "                                                      &#x27;Cabin&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                                &#x27;name&#x27;: &#x27;passenger_cabin&#x27;},\n",
       "                                                      &#x27;Embarked&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                                   &#x27;name&#x27;: &#x27;passenger_embarked_port&#x27;},\n",
       "                                                      &#x27;Fare&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                                               &#x27;name&#x27;: &#x27;passenger_fare&#x27;},\n",
       "                                                      &#x27;Name&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                               &#x27;name&#x27;: &#x27;name...\n",
       "                                                                                                   &#x27;weights&#x27;: &#x27;distance&#x27;}}}},\n",
       "                                          model_params={&#x27;class&#x27;: &#x27;project.packages.modelling.models.unsupervised.segmentation.KMeansElbowSelector&#x27;,\n",
       "                                                        &#x27;kwargs&#x27;: {&#x27;max_clusters&#x27;: 15,\n",
       "                                                                   &#x27;min_clusters&#x27;: 1}},\n",
       "                                          scaler_params={&#x27;class&#x27;: &#x27;project.packages.modelling.transformers.scaler.ColumnsPreserverScaler&#x27;,\n",
       "                                                         &#x27;kwargs&#x27;: {&#x27;scaler_params&#x27;: {&#x27;class&#x27;: &#x27;sklearn.preprocessing.MinMaxScaler&#x27;,\n",
       "                                                                                      &#x27;kwargs&#x27;: {}}}}))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"edb9f1b1-e598-4a3b-9c9b-a40255c97039\" type=\"checkbox\" ><label for=\"edb9f1b1-e598-4a3b-9c9b-a40255c97039\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RawDataProcessor</label><div class=\"sk-toggleable__content\"><pre>RawDataProcessor(params={&#x27;index&#x27;: &#x27;passenger_id&#x27;,\n",
       "                         &#x27;schemas&#x27;: {&#x27;Age&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                             &#x27;name&#x27;: &#x27;passenger_age&#x27;},\n",
       "                                     &#x27;Cabin&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                               &#x27;name&#x27;: &#x27;passenger_cabin&#x27;},\n",
       "                                     &#x27;Embarked&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                  &#x27;name&#x27;: &#x27;passenger_embarked_port&#x27;},\n",
       "                                     &#x27;Fare&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                              &#x27;name&#x27;: &#x27;passenger_fare&#x27;},\n",
       "                                     &#x27;Name&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                              &#x27;name&#x27;: &#x27;name&#x27;},\n",
       "                                     &#x27;Parch&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                               &#x27;name&#x27;: &#x27;passenger_parch&#x27;},\n",
       "                                     &#x27;PassengerId&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                                     &#x27;name&#x27;: &#x27;passenger_id&#x27;},\n",
       "                                     &#x27;Pclass&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                                &#x27;name&#x27;: &#x27;passenger_class&#x27;},\n",
       "                                     &#x27;Sex&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                             &#x27;name&#x27;: &#x27;passenger_sex&#x27;},\n",
       "                                     &#x27;SibSp&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                               &#x27;name&#x27;: &#x27;passenger_siblings&#x27;},\n",
       "                                     &#x27;Survived&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                                  &#x27;name&#x27;: &#x27;survived&#x27;},\n",
       "                                     &#x27;Ticket&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                &#x27;name&#x27;: &#x27;passenger_ticket&#x27;}},\n",
       "                         &#x27;target&#x27;: &#x27;Survived&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a30b0758-3819-4a7f-8f0a-48dcaa893f91\" type=\"checkbox\" ><label for=\"a30b0758-3819-4a7f-8f0a-48dcaa893f91\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IntermediateDataProcessor</label><div class=\"sk-toggleable__content\"><pre>IntermediateDataProcessor(params={&#x27;categorical_features&#x27;: [&#x27;passenger_sex&#x27;,\n",
       "                                                           &#x27;passenger_ticket&#x27;,\n",
       "                                                           &#x27;passenger_cabin&#x27;,\n",
       "                                                           &#x27;passenger_embarked_port&#x27;],\n",
       "                                  &#x27;drop_columns&#x27;: [&#x27;name&#x27;],\n",
       "                                  &#x27;outlier_params&#x27;: {&#x27;iqr_alpha&#x27;: 2.5,\n",
       "                                                     &#x27;q1_quantile&#x27;: 0.25,\n",
       "                                                     &#x27;q3_quantile&#x27;: 0.75},\n",
       "                                  &#x27;target&#x27;: &#x27;survived&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"815367a6-42f8-47ba-a577-fdcc49672a84\" type=\"checkbox\" ><label for=\"815367a6-42f8-47ba-a577-fdcc49672a84\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PrimaryDataProcessor</label><div class=\"sk-toggleable__content\"><pre>PrimaryDataProcessor(params={&#x27;categorical_columns_fillna&#x27;: {&#x27;passenger_cabin&#x27;: &#x27;unknown&#x27;,\n",
       "                                                            &#x27;passenger_embarked_port&#x27;: &#x27;unknown&#x27;},\n",
       "                             &#x27;target&#x27;: &#x27;supervised&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2e3d85e5-6c3a-48af-ab49-2963d434adb3\" type=\"checkbox\" ><label for=\"2e3d85e5-6c3a-48af-ab49-2963d434adb3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureDataProcessor</label><div class=\"sk-toggleable__content\"><pre>FeatureDataProcessor(params={&#x27;encoding_transform&#x27;: {&#x27;one_hot_encoder&#x27;: [&#x27;passenger_cabin_level&#x27;,\n",
       "                                                                        &#x27;passenger_embarked_port&#x27;,\n",
       "                                                                        &#x27;passenger_sex&#x27;],\n",
       "                                                    &#x27;similarity_based_encoder&#x27;: None},\n",
       "                             &#x27;target&#x27;: &#x27;survived&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"87288bd5-eea6-443e-bfb4-38cf24f3c3cb\" type=\"checkbox\" ><label for=\"87288bd5-eea6-443e-bfb4-38cf24f3c3cb\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeansClusteringFeatures</label><div class=\"sk-toggleable__content\"><pre>KMeansClusteringFeatures(feature_params={&#x27;passenger_cabin_cluster_feature&#x27;: [&#x27;passenger_cabin_level_a&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_b&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_c&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_d&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_e&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_f&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_g&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_t&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_unknown&#x27;],\n",
       "                                         &#x27;passenger_embarked_port_cluster_...\n",
       "                                                                                  &#x27;weights&#x27;: &#x27;distance&#x27;}}}},\n",
       "                         model_params={&#x27;class&#x27;: &#x27;project.packages.modelling.models.unsupervised.segmentation.KMeansElbowSelector&#x27;,\n",
       "                                       &#x27;kwargs&#x27;: {&#x27;max_clusters&#x27;: 15,\n",
       "                                                  &#x27;min_clusters&#x27;: 1}},\n",
       "                         scaler_params={&#x27;class&#x27;: &#x27;project.packages.modelling.transformers.scaler.ColumnsPreserverScaler&#x27;,\n",
       "                                        &#x27;kwargs&#x27;: {&#x27;scaler_params&#x27;: {&#x27;class&#x27;: &#x27;sklearn.preprocessing.MinMaxScaler&#x27;,\n",
       "                                                                     &#x27;kwargs&#x27;: {}}}})</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('raw_transformations',\n",
       "                 RawDataProcessor(params={'index': 'passenger_id',\n",
       "                                          'schemas': {'Age': {'dtype': 'float64',\n",
       "                                                              'name': 'passenger_age'},\n",
       "                                                      'Cabin': {'dtype': 'object',\n",
       "                                                                'name': 'passenger_cabin'},\n",
       "                                                      'Embarked': {'dtype': 'object',\n",
       "                                                                   'name': 'passenger_embarked_port'},\n",
       "                                                      'Fare': {'dtype': 'float64',\n",
       "                                                               'name': 'passenger_fare'},\n",
       "                                                      'Name': {'dtype': 'object',\n",
       "                                                               'name': 'name...\n",
       "                                                                                                   'weights': 'distance'}}}},\n",
       "                                          model_params={'class': 'project.packages.modelling.models.unsupervised.segmentation.KMeansElbowSelector',\n",
       "                                                        'kwargs': {'max_clusters': 15,\n",
       "                                                                   'min_clusters': 1}},\n",
       "                                          scaler_params={'class': 'project.packages.modelling.transformers.scaler.ColumnsPreserverScaler',\n",
       "                                                         'kwargs': {'scaler_params': {'class': 'sklearn.preprocessing.MinMaxScaler',\n",
       "                                                                                      'kwargs': {}}}}))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "data_eng_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"raw_transformations\", RawDataProcessor(raw_params)),\n",
    "        (\n",
    "            \"intermediate_transformations\",\n",
    "            IntermediateDataProcessor(intermediate_params),\n",
    "        ),\n",
    "        (\"primary_transformations\", PrimaryDataProcessor(primary_params)),\n",
    "        (\"feature_transformations\", FeatureDataProcessor(feature_params)),\n",
    "        (\n",
    "            \"cluster_feature_transformations\",\n",
    "            KMeansClusteringFeatures(\n",
    "                model_params=cluster_model_params,\n",
    "                scaler_params=cluster_scaler_params,\n",
    "                feature_params=cluster_feature_params,\n",
    "                imputer_params=cluster_imputer_params,\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "data_eng_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-01-07 20:51:18,953 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 20:51:18,969 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 31, 'cluster_id_1': 0, 'cluster_id_2': 1}\u001b[0m\n",
      "\u001b[34m2024-01-07 20:51:19,847 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 20:51:19,864 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 1, 'cluster_id_1': 0, 'cluster_id_2': 5}\u001b[0m\n",
      "\u001b[34m2024-01-07 20:51:20,687 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 20:51:20,702 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 427, 'cluster_id_1': 594, 'cluster_id_2': 816}\u001b[0m\n",
      "\u001b[34m2024-01-07 20:51:21,747 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 20:51:21,766 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 889, 'cluster_id_1': 68, 'cluster_id_2': 128}\u001b[0m\n",
      "\u001b[34m2024-01-07 20:51:22,938 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 20:51:22,956 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 390, 'cluster_id_1': 146, 'cluster_id_2': 312}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_age</th>\n",
       "      <th>passenger_siblings</th>\n",
       "      <th>passenger_parch</th>\n",
       "      <th>passenger_ticket</th>\n",
       "      <th>passenger_fare</th>\n",
       "      <th>passenger_cabin</th>\n",
       "      <th>passenger_embarked_port</th>\n",
       "      <th>passenger_ticket_base</th>\n",
       "      <th>passenger_ticket_number</th>\n",
       "      <th>passenger_ticket_unknown_base</th>\n",
       "      <th>passenger_cabin_level</th>\n",
       "      <th>passenger_cabin_number</th>\n",
       "      <th>passenger_number_of_family_onboard</th>\n",
       "      <th>passenger_is_single</th>\n",
       "      <th>passenger_has_significant_other</th>\n",
       "      <th>passenger_has_childs</th>\n",
       "      <th>passenger_cabin_level_a</th>\n",
       "      <th>passenger_cabin_level_b</th>\n",
       "      <th>passenger_cabin_level_c</th>\n",
       "      <th>passenger_cabin_level_d</th>\n",
       "      <th>passenger_cabin_level_e</th>\n",
       "      <th>passenger_cabin_level_f</th>\n",
       "      <th>passenger_cabin_level_g</th>\n",
       "      <th>passenger_cabin_level_t</th>\n",
       "      <th>passenger_cabin_level_unknown</th>\n",
       "      <th>passenger_embarked_port_c</th>\n",
       "      <th>passenger_embarked_port_q</th>\n",
       "      <th>passenger_embarked_port_s</th>\n",
       "      <th>passenger_embarked_port_unknown</th>\n",
       "      <th>passenger_sex_female</th>\n",
       "      <th>passenger_sex_male</th>\n",
       "      <th>passenger_cabin_cluster_feature</th>\n",
       "      <th>passenger_embarked_port_cluster_feature</th>\n",
       "      <th>passenger_ticket_number_cluster_feature</th>\n",
       "      <th>passenger_family_cluster_feature</th>\n",
       "      <th>passenger_social_status_cluster_feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>A/5</td>\n",
       "      <td>21171.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>c85</td>\n",
       "      <td>c</td>\n",
       "      <td>PC</td>\n",
       "      <td>17599.0</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>STON/O2.</td>\n",
       "      <td>3101282.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>c123</td>\n",
       "      <td>s</td>\n",
       "      <td>unknown</td>\n",
       "      <td>113803.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>unknown</td>\n",
       "      <td>373450.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>unknown</td>\n",
       "      <td>211536.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>b42</td>\n",
       "      <td>s</td>\n",
       "      <td>unknown</td>\n",
       "      <td>112053.0</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>s</td>\n",
       "      <td>W./C.</td>\n",
       "      <td>6607.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>c148</td>\n",
       "      <td>c</td>\n",
       "      <td>unknown</td>\n",
       "      <td>111369.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>unknown</td>\n",
       "      <td>q</td>\n",
       "      <td>unknown</td>\n",
       "      <td>370376.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "              survived  passenger_class passenger_sex  passenger_age  \\\n",
       "passenger_id                                                           \n",
       "\u001b[1;36m1\u001b[0m                    \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m22.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m38.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m3\u001b[0m        female           \u001b[1;36m26.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                    \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m35.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                    \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m35.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                \u001b[33m...\u001b[0m              \u001b[33m...\u001b[0m           \u001b[33m...\u001b[0m            \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m2\u001b[0m          male           \u001b[1;36m27.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                  \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m        female           \u001b[1;36m19.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m        female            NaN   \n",
       "\u001b[1;36m890\u001b[0m                  \u001b[1;36m1\u001b[0m                \u001b[1;36m1\u001b[0m          male           \u001b[1;36m26.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                  \u001b[1;36m0\u001b[0m                \u001b[1;36m3\u001b[0m          male           \u001b[1;36m32.0\u001b[0m   \n",
       "\n",
       "              passenger_siblings  passenger_parch  passenger_ticket  \\\n",
       "passenger_id                                                          \n",
       "\u001b[1;36m1\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m         A/\u001b[1;36m5\u001b[0m \u001b[1;36m21171\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m          PC \u001b[1;36m17599\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                              \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m  STON/O2. \u001b[1;36m3101282\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                              \u001b[1;36m1\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m113803\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                              \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m373450\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                          \u001b[33m...\u001b[0m              \u001b[33m...\u001b[0m               \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m211536\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m112053\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                            \u001b[1;36m1\u001b[0m                \u001b[1;36m2\u001b[0m        W.\u001b[35m/\u001b[0m\u001b[95mC.\u001b[0m \u001b[1;36m6607\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m111369\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                            \u001b[1;36m0\u001b[0m                \u001b[1;36m0\u001b[0m            \u001b[1;36m370376\u001b[0m   \n",
       "\n",
       "              passenger_fare passenger_cabin passenger_embarked_port  \\\n",
       "passenger_id                                                           \n",
       "\u001b[1;36m1\u001b[0m                     \u001b[1;36m7.2500\u001b[0m         unknown                       s   \n",
       "\u001b[1;36m2\u001b[0m                    \u001b[1;36m71.2833\u001b[0m             c85                       c   \n",
       "\u001b[1;36m3\u001b[0m                     \u001b[1;36m7.9250\u001b[0m         unknown                       s   \n",
       "\u001b[1;36m4\u001b[0m                    \u001b[1;36m53.1000\u001b[0m            c123                       s   \n",
       "\u001b[1;36m5\u001b[0m                     \u001b[1;36m8.0500\u001b[0m         unknown                       s   \n",
       "\u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m             \u001b[33m...\u001b[0m                     \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                  \u001b[1;36m13.0000\u001b[0m         unknown                       s   \n",
       "\u001b[1;36m888\u001b[0m                  \u001b[1;36m30.0000\u001b[0m             b42                       s   \n",
       "\u001b[1;36m889\u001b[0m                  \u001b[1;36m23.4500\u001b[0m         unknown                       s   \n",
       "\u001b[1;36m890\u001b[0m                  \u001b[1;36m30.0000\u001b[0m            c148                       c   \n",
       "\u001b[1;36m891\u001b[0m                   \u001b[1;36m7.7500\u001b[0m         unknown                       q   \n",
       "\n",
       "             passenger_ticket_base  passenger_ticket_number  \\\n",
       "passenger_id                                                  \n",
       "\u001b[1;36m1\u001b[0m                              A/\u001b[1;36m5\u001b[0m                  \u001b[1;36m21171.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                               PC                  \u001b[1;36m17599.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                         STON/O2.                \u001b[1;36m3101282.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                          unknown                 \u001b[1;36m113803.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                          unknown                 \u001b[1;36m373450.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                            \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                        unknown                 \u001b[1;36m211536.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                        unknown                 \u001b[1;36m112053.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                          W.\u001b[35m/\u001b[0m\u001b[95mC.\u001b[0m                   \u001b[1;36m6607.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                        unknown                 \u001b[1;36m111369.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                        unknown                 \u001b[1;36m370376.0\u001b[0m   \n",
       "\n",
       "              passenger_ticket_unknown_base passenger_cabin_level  \\\n",
       "passenger_id                                                        \n",
       "\u001b[1;36m1\u001b[0m                                         \u001b[1;36m0\u001b[0m               unknown   \n",
       "\u001b[1;36m2\u001b[0m                                         \u001b[1;36m0\u001b[0m                     c   \n",
       "\u001b[1;36m3\u001b[0m                                         \u001b[1;36m0\u001b[0m               unknown   \n",
       "\u001b[1;36m4\u001b[0m                                         \u001b[1;36m1\u001b[0m                     c   \n",
       "\u001b[1;36m5\u001b[0m                                         \u001b[1;36m1\u001b[0m               unknown   \n",
       "\u001b[33m...\u001b[0m                                     \u001b[33m...\u001b[0m                   \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                       \u001b[1;36m1\u001b[0m               unknown   \n",
       "\u001b[1;36m888\u001b[0m                                       \u001b[1;36m1\u001b[0m                     b   \n",
       "\u001b[1;36m889\u001b[0m                                       \u001b[1;36m0\u001b[0m               unknown   \n",
       "\u001b[1;36m890\u001b[0m                                       \u001b[1;36m1\u001b[0m                     c   \n",
       "\u001b[1;36m891\u001b[0m                                       \u001b[1;36m1\u001b[0m               unknown   \n",
       "\n",
       "              passenger_cabin_number  passenger_number_of_family_onboard  \\\n",
       "passenger_id                                                               \n",
       "\u001b[1;36m1\u001b[0m                                NaN                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                               \u001b[1;36m85.0\u001b[0m                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                NaN                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                              \u001b[1;36m123.0\u001b[0m                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                NaN                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                              \u001b[33m...\u001b[0m                                 \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                              NaN                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                             \u001b[1;36m42.0\u001b[0m                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                              NaN                                   \u001b[1;36m3\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                            \u001b[1;36m148.0\u001b[0m                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                              NaN                                   \u001b[1;36m0\u001b[0m   \n",
       "\n",
       "              passenger_is_single  passenger_has_significant_other  \\\n",
       "passenger_id                                                         \n",
       "\u001b[1;36m1\u001b[0m                               \u001b[1;36m0\u001b[0m                                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                               \u001b[1;36m0\u001b[0m                                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                               \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                               \u001b[1;36m0\u001b[0m                                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                               \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                           \u001b[33m...\u001b[0m                              \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                             \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                             \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                             \u001b[1;36m0\u001b[0m                                \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                             \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                             \u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m   \n",
       "\n",
       "              passenger_has_childs  passenger_cabin_level_a  \\\n",
       "passenger_id                                                  \n",
       "\u001b[1;36m1\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                            \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                              \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                              \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                              \u001b[1;36m0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                              \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                              \u001b[1;36m1\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_level_b  passenger_cabin_level_c  \\\n",
       "passenger_id                                                     \n",
       "\u001b[1;36m1\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                               \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                               \u001b[1;36m1.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_level_d  passenger_cabin_level_e  \\\n",
       "passenger_id                                                     \n",
       "\u001b[1;36m1\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                               \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_level_f  passenger_cabin_level_g  \\\n",
       "passenger_id                                                     \n",
       "\u001b[1;36m1\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                               \u001b[33m...\u001b[0m                      \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                               \u001b[1;36m0.0\u001b[0m                      \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_level_t  passenger_cabin_level_unknown  \\\n",
       "passenger_id                                                           \n",
       "\u001b[1;36m1\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                               \u001b[33m...\u001b[0m                            \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                               \u001b[1;36m0.0\u001b[0m                            \u001b[1;36m1.0\u001b[0m   \n",
       "\n",
       "              passenger_embarked_port_c  passenger_embarked_port_q  \\\n",
       "passenger_id                                                         \n",
       "\u001b[1;36m1\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                 \u001b[33m...\u001b[0m                        \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                 \u001b[1;36m1.0\u001b[0m                        \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                        \u001b[1;36m1.0\u001b[0m   \n",
       "\n",
       "              passenger_embarked_port_s  passenger_embarked_port_unknown  \\\n",
       "passenger_id                                                               \n",
       "\u001b[1;36m1\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                   \u001b[1;36m0.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                   \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                 \u001b[33m...\u001b[0m                              \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                 \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                 \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                 \u001b[1;36m1.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                 \u001b[1;36m0.0\u001b[0m                              \u001b[1;36m0.0\u001b[0m   \n",
       "\n",
       "              passenger_sex_female  passenger_sex_male  \\\n",
       "passenger_id                                             \n",
       "\u001b[1;36m1\u001b[0m                              \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                              \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                              \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                              \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                              \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                            \u001b[33m...\u001b[0m                 \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                            \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                            \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                            \u001b[1;36m1.0\u001b[0m                 \u001b[1;36m0.0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                            \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                            \u001b[1;36m0.0\u001b[0m                 \u001b[1;36m1.0\u001b[0m   \n",
       "\n",
       "              passenger_cabin_cluster_feature  \\\n",
       "passenger_id                                    \n",
       "\u001b[1;36m1\u001b[0m                                           \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                           \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                           \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                           \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                           \u001b[1;36m1\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                       \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                         \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                         \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                         \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                         \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                         \u001b[1;36m1\u001b[0m   \n",
       "\n",
       "              passenger_embarked_port_cluster_feature  \\\n",
       "passenger_id                                            \n",
       "\u001b[1;36m1\u001b[0m                                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                               \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                                 \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                                 \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                                 \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                                 \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                                 \u001b[1;36m2\u001b[0m   \n",
       "\n",
       "              passenger_ticket_number_cluster_feature  \\\n",
       "passenger_id                                            \n",
       "\u001b[1;36m1\u001b[0m                                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                                   \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                                   \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                                   \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                                   \u001b[1;36m2\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                               \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                                 \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                                 \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                                 \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                                 \u001b[1;36m2\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                                 \u001b[1;36m2\u001b[0m   \n",
       "\n",
       "              passenger_family_cluster_feature  \\\n",
       "passenger_id                                     \n",
       "\u001b[1;36m1\u001b[0m                                            \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m                                            \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m                                            \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                                            \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m                                            \u001b[1;36m0\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                        \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m887\u001b[0m                                          \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m888\u001b[0m                                          \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m889\u001b[0m                                          \u001b[1;36m1\u001b[0m   \n",
       "\u001b[1;36m890\u001b[0m                                          \u001b[1;36m0\u001b[0m   \n",
       "\u001b[1;36m891\u001b[0m                                          \u001b[1;36m0\u001b[0m   \n",
       "\n",
       "              passenger_social_status_cluster_feature  \n",
       "passenger_id                                           \n",
       "\u001b[1;36m1\u001b[0m                                                   \u001b[1;36m1\u001b[0m  \n",
       "\u001b[1;36m2\u001b[0m                                                   \u001b[1;36m2\u001b[0m  \n",
       "\u001b[1;36m3\u001b[0m                                                   \u001b[1;36m2\u001b[0m  \n",
       "\u001b[1;36m4\u001b[0m                                                   \u001b[1;36m2\u001b[0m  \n",
       "\u001b[1;36m5\u001b[0m                                                   \u001b[1;36m1\u001b[0m  \n",
       "\u001b[33m...\u001b[0m                                               \u001b[33m...\u001b[0m  \n",
       "\u001b[1;36m887\u001b[0m                                                 \u001b[1;36m0\u001b[0m  \n",
       "\u001b[1;36m888\u001b[0m                                                 \u001b[1;36m2\u001b[0m  \n",
       "\u001b[1;36m889\u001b[0m                                                 \u001b[1;36m2\u001b[0m  \n",
       "\u001b[1;36m890\u001b[0m                                                 \u001b[1;36m0\u001b[0m  \n",
       "\u001b[1;36m891\u001b[0m                                                 \u001b[1;36m1\u001b[0m  \n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m891\u001b[0m rows x \u001b[1;36m39\u001b[0m columns\u001b[1m]\u001b[0m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_eng_pipeline.fit_transform(df)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model hypertune and train\n",
    "\n",
    "\n",
    "For hypertuning and fit we use a `BinaryClassifierSklearnPipeline` model wrapper from `project.packages.modelling.models.supervised.sklearn`, which is used for supervised learning tasks involving binary classification. \n",
    "\n",
    "This class allows the and end to end model hypertuning, training and evaluation of a  model\n",
    "\n",
    "\n",
    "\n",
    "#### __Parameters used__\n",
    "\n",
    "Models params include the following information:\n",
    "\n",
    "The params follows an object injection structure, so each time that we need to pass and object, these one is passed as \n",
    "\n",
    "```python\n",
    "\n",
    "object_params = {\n",
    "   \"class\": path.to.the.module.ClassName\n",
    "   \"kwargs\": {\n",
    "      \"arg1\":  xx,\n",
    "      ...\n",
    "      \"argn\":  xx,\n",
    "   }\n",
    "}\n",
    "```\n",
    "\n",
    "These allow to code without hardcoding imports of models and objects.\n",
    "\n",
    "\n",
    "1. `scoring_metrics`: A list of scoring metrics used for evaluating the model's performance.\n",
    "\n",
    "2. `optuna`: Configuration for the Optuna hyperparameter optimization framework.\n",
    "   - `kwargs_study`: Arguments for creating an Optuna study.\n",
    "   - `kwargs_optimize`: Arguments for hyperparameter optimization.\n",
    "   - `sampler`: Configuration for the Optuna sampler.\n",
    "   - `pruner`: Configuration for the Optuna pruner.\n",
    "\n",
    "3. `cv_strategy`: Cross-validation strategy configuration.\n",
    "   - `class`: The class for the cross-validation strategy.\n",
    "   - `kwargs`: Additional keyword arguments for the cross-validation strategy.\n",
    "\n",
    "4. `cv_score`: Configuration for cross-validation scoring.\n",
    "   - `scoring`: The scoring metric to use during cross-validation.\n",
    "   - `class`: The class for performing cross-validation.\n",
    "   - `kwargs`: Additional keyword arguments for the cross-validation process.\n",
    "\n",
    "5. `target`: The name of the target variable in the dataset.\n",
    "\n",
    "6. `features`: A list of feature names used for modeling.\n",
    "\n",
    "\n",
    "\n",
    "1. `pipeline`: Configuration for the machine learning pipeline, which includes sub-configurations for:\n",
    "\n",
    "   Passing the entire pipeline as a unified entity enables a holistic approach to hyperparameter tuning throughout the entire modeling process. This includes optimizing various stages such as data imputation, feature scaling, feature selection, and model parameters collectively. This approach offers several advantages over optimizing these components separately.\n",
    "\n",
    "   1. **Holistic Optimization**: By optimizing the entire pipeline together, you ensure that the various stages of your modeling process work seamlessly in concert. This can lead to a more coherent and optimized end-to-end solution.\n",
    "\n",
    "   2. **Consideration of Interactions**: When hyperparameter tuning is done in isolation for each component, it may not account for interactions and dependencies between these components. Optimizing them as a whole allows for the exploration of parameter combinations that yield synergistic effects, such as the imputer vs a model hyperparam.\n",
    "\n",
    "   3. **Efficiency**: Hyperparameter tuning is an iterative and resource-intensive process. Tuning the entire pipeline in one step can be more computationally efficient than repeatedly tuning individual components separately.\n",
    "\n",
    "   4. **Reduced Risk of Overfitting**: Optimizing components separately might lead to overfitting, as each component may be tuned to perform exceptionally well on its own, but not necessarily in combination. Tuning the entire pipeline can mitigate this risk by finding a balanced configuration that works well as a whole.\n",
    "\n",
    "   5. **Consistency**: Hyperparameter tuning for the entire pipeline ensures consistency in parameter choices across different modeling runs. This consistency can make it easier to compare model performance and reproduce results.\n",
    "\n",
    "   6. **Simplified Workflow**: Managing and documenting hyperparameters for individual components can be complex and error-prone. Tuning the whole pipeline simplifies the workflow by consolidating hyperparameters into a single configuration.\n",
    "\n",
    "   7. **Domain Knowledge Integration**: In some cases, domain knowledge dictates certain relationships between preprocessing steps and model parameters. Tuning the pipeline as a whole allows for the inclusion of such domain-specific insights. So for example, defining the exploration space of each meta parameter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe {color: black;background-color: white;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe pre{padding: 0;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-toggleable {background-color: white;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-estimator:hover {background-color: #d4ebff;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-item {z-index: 1;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-parallel-item:only-child::after {width: 0;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-2c23466e-0da7-409c-b780-ba6b5afdf4fe\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BinaryClassifierSklearnPipeline(cv_score={&#x27;class&#x27;: &#x27;sklearn.model_selection.cross_val_predict&#x27;,\n",
       "                                          &#x27;kwargs&#x27;: {&#x27;X&#x27;: None, &#x27;cv&#x27;: None,\n",
       "                                                     &#x27;estimator&#x27;: None,\n",
       "                                                     &#x27;method&#x27;: &#x27;predict&#x27;,\n",
       "                                                     &#x27;n_jobs&#x27;: -1, &#x27;y&#x27;: None},\n",
       "                                          &#x27;scoring&#x27;: &#x27;f1_weighted&#x27;},\n",
       "                                cv_strategy={&#x27;class&#x27;: &#x27;sklearn.model_selection.StratifiedKFold&#x27;,\n",
       "                                             &#x27;kwargs&#x27;: {&#x27;n_splits&#x27;: 5,\n",
       "                                                        &#x27;random_state&#x27;: 42,\n",
       "                                                        &#x27;shuffle&#x27;: True}},\n",
       "                                features=[&#x27;passenger_cl...\n",
       "                                                                                           &#x27;&quot;sklearn.preprocessing.QuantileTransformer&quot;])&#x27;,\n",
       "                                                                                  &#x27;kwargs&#x27;: {}}}}},\n",
       "                                scoring_metrics=[&#x27;accuracy&#x27;,\n",
       "                                                 &#x27;balanced_accuracy&#x27;, &#x27;f1&#x27;,\n",
       "                                                 &#x27;f1_micro&#x27;, &#x27;f1_macro&#x27;,\n",
       "                                                 &#x27;f1_weighted&#x27;, &#x27;precision&#x27;,\n",
       "                                                 &#x27;precision_micro&#x27;,\n",
       "                                                 &#x27;precision_macro&#x27;,\n",
       "                                                 &#x27;precision_weighted&#x27;, &#x27;recall&#x27;,\n",
       "                                                 &#x27;recall_micro&#x27;, &#x27;recall_macro&#x27;,\n",
       "                                                 &#x27;recall_weighted&#x27;, &#x27;roc_auc&#x27;,\n",
       "                                                 &#x27;roc_auc_ovr&#x27;, &#x27;roc_auc_ovo&#x27;,\n",
       "                                                 &#x27;roc_auc_ovr_weighted&#x27;,\n",
       "                                                 &#x27;roc_auc_ovo_weighted&#x27;],\n",
       "                                target=&#x27;survived&#x27;)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c73d9522-b3a1-4948-828e-9787c918b27e\" type=\"checkbox\" checked><label for=\"c73d9522-b3a1-4948-828e-9787c918b27e\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BinaryClassifierSklearnPipeline</label><div class=\"sk-toggleable__content\"><pre>BinaryClassifierSklearnPipeline(cv_score={&#x27;class&#x27;: &#x27;sklearn.model_selection.cross_val_predict&#x27;,\n",
       "                                          &#x27;kwargs&#x27;: {&#x27;X&#x27;: None, &#x27;cv&#x27;: None,\n",
       "                                                     &#x27;estimator&#x27;: None,\n",
       "                                                     &#x27;method&#x27;: &#x27;predict&#x27;,\n",
       "                                                     &#x27;n_jobs&#x27;: -1, &#x27;y&#x27;: None},\n",
       "                                          &#x27;scoring&#x27;: &#x27;f1_weighted&#x27;},\n",
       "                                cv_strategy={&#x27;class&#x27;: &#x27;sklearn.model_selection.StratifiedKFold&#x27;,\n",
       "                                             &#x27;kwargs&#x27;: {&#x27;n_splits&#x27;: 5,\n",
       "                                                        &#x27;random_state&#x27;: 42,\n",
       "                                                        &#x27;shuffle&#x27;: True}},\n",
       "                                features=[&#x27;passenger_cl...\n",
       "                                                                                           &#x27;&quot;sklearn.preprocessing.QuantileTransformer&quot;])&#x27;,\n",
       "                                                                                  &#x27;kwargs&#x27;: {}}}}},\n",
       "                                scoring_metrics=[&#x27;accuracy&#x27;,\n",
       "                                                 &#x27;balanced_accuracy&#x27;, &#x27;f1&#x27;,\n",
       "                                                 &#x27;f1_micro&#x27;, &#x27;f1_macro&#x27;,\n",
       "                                                 &#x27;f1_weighted&#x27;, &#x27;precision&#x27;,\n",
       "                                                 &#x27;precision_micro&#x27;,\n",
       "                                                 &#x27;precision_macro&#x27;,\n",
       "                                                 &#x27;precision_weighted&#x27;, &#x27;recall&#x27;,\n",
       "                                                 &#x27;recall_micro&#x27;, &#x27;recall_macro&#x27;,\n",
       "                                                 &#x27;recall_weighted&#x27;, &#x27;roc_auc&#x27;,\n",
       "                                                 &#x27;roc_auc_ovr&#x27;, &#x27;roc_auc_ovo&#x27;,\n",
       "                                                 &#x27;roc_auc_ovr_weighted&#x27;,\n",
       "                                                 &#x27;roc_auc_ovo_weighted&#x27;],\n",
       "                                target=&#x27;survived&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BinaryClassifierSklearnPipeline(cv_score={'class': 'sklearn.model_selection.cross_val_predict',\n",
       "                                          'kwargs': {'X': None, 'cv': None,\n",
       "                                                     'estimator': None,\n",
       "                                                     'method': 'predict',\n",
       "                                                     'n_jobs': -1, 'y': None},\n",
       "                                          'scoring': 'f1_weighted'},\n",
       "                                cv_strategy={'class': 'sklearn.model_selection.StratifiedKFold',\n",
       "                                             'kwargs': {'n_splits': 5,\n",
       "                                                        'random_state': 42,\n",
       "                                                        'shuffle': True}},\n",
       "                                features=['passenger_cl...\n",
       "                                                                                           '\"sklearn.preprocessing.QuantileTransformer\"])',\n",
       "                                                                                  'kwargs': {}}}}},\n",
       "                                scoring_metrics=['accuracy',\n",
       "                                                 'balanced_accuracy', 'f1',\n",
       "                                                 'f1_micro', 'f1_macro',\n",
       "                                                 'f1_weighted', 'precision',\n",
       "                                                 'precision_micro',\n",
       "                                                 'precision_macro',\n",
       "                                                 'precision_weighted', 'recall',\n",
       "                                                 'recall_micro', 'recall_macro',\n",
       "                                                 'recall_weighted', 'roc_auc',\n",
       "                                                 'roc_auc_ovr', 'roc_auc_ovo',\n",
       "                                                 'roc_auc_ovr_weighted',\n",
       "                                                 'roc_auc_ovo_weighted'],\n",
       "                                target='survived')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = {\n",
    "    \"scoring_metrics\": [\n",
    "        \"accuracy\",\n",
    "        \"balanced_accuracy\",\n",
    "        \"f1\",\n",
    "        \"f1_micro\",\n",
    "        \"f1_macro\",\n",
    "        \"f1_weighted\",\n",
    "        \"precision\",\n",
    "        \"precision_micro\",\n",
    "        \"precision_macro\",\n",
    "        \"precision_weighted\",\n",
    "        \"recall\",\n",
    "        \"recall_micro\",\n",
    "        \"recall_macro\",\n",
    "        \"recall_weighted\",\n",
    "        \"roc_auc\",\n",
    "        \"roc_auc_ovr\",\n",
    "        \"roc_auc_ovo\",\n",
    "        \"roc_auc_ovr_weighted\",\n",
    "        \"roc_auc_ovo_weighted\",\n",
    "    ],\n",
    "    \"optuna\": {\n",
    "        \"kwargs_study\": {\n",
    "            \"direction\": \"maximize\",\n",
    "            \"study_name\": \"xgboost\",\n",
    "            \"load_if_exists\": False,\n",
    "        },\n",
    "        \"kwargs_optimize\": {\"n_trials\": 500},\n",
    "        \"sampler\": {\n",
    "            \"class\": \"optuna.samplers.TPESampler\",\n",
    "            \"kwargs\": {\"n_startup_trials\": 0, \"constant_liar\": True, \"seed\": 42},\n",
    "        },\n",
    "        \"pruner\": {\"class\": \"optuna.pruners.SuccessiveHalvingPruner\", \"kwargs\": {}},\n",
    "    },\n",
    "    \"cv_strategy\": {\n",
    "        \"class\": \"sklearn.model_selection.StratifiedKFold\",\n",
    "        \"kwargs\": {\"n_splits\": 5, \"random_state\": 42, \"shuffle\": True},\n",
    "    },\n",
    "    \"cv_score\": {\n",
    "        \"scoring\": \"f1_weighted\",\n",
    "        \"class\": \"sklearn.model_selection.cross_val_predict\",\n",
    "        \"kwargs\": {\n",
    "            \"estimator\": None,\n",
    "            \"X\": None,\n",
    "            \"y\": None,\n",
    "            \"cv\": None,\n",
    "            \"n_jobs\": -1,\n",
    "            \"method\": \"predict\",\n",
    "        },\n",
    "    },\n",
    "    \"target\": \"survived\",\n",
    "    \"features\": [\n",
    "        \"passenger_class\",\n",
    "        \"passenger_age\",\n",
    "        \"passenger_siblings\",\n",
    "        \"passenger_parch\",\n",
    "        \"passenger_fare\",\n",
    "        \"passenger_ticket_number\",\n",
    "        \"passenger_ticket_unknown_base\",\n",
    "        \"passenger_cabin_number\",\n",
    "        \"passenger_number_of_family_onboard\",\n",
    "        \"passenger_is_single\",\n",
    "        \"passenger_has_childs\",\n",
    "        \"passenger_cabin_level_a\",\n",
    "        \"passenger_cabin_level_b\",\n",
    "        \"passenger_cabin_level_c\",\n",
    "        \"passenger_cabin_level_d\",\n",
    "        \"passenger_cabin_level_e\",\n",
    "        \"passenger_cabin_level_unknown\",\n",
    "        \"passenger_embarked_port_c\",\n",
    "        \"passenger_embarked_port_q\",\n",
    "        \"passenger_embarked_port_s\",\n",
    "        \"passenger_sex_female\",\n",
    "        \"passenger_cabin_cluster_feature\",\n",
    "        \"passenger_embarked_port_cluster_feature\",\n",
    "        \"passenger_ticket_number_cluster_feature\",\n",
    "        \"passenger_family_cluster_feature\",\n",
    "        \"passenger_social_status_cluster_feature\",\n",
    "    ],\n",
    "    \"pipeline\": {\n",
    "        \"imputer\": {\n",
    "            \"class\": \"project.packages.modelling.models.unsupervised.imputer.ColumnsPreserverImputer\",\n",
    "            \"kwargs\": {\n",
    "                \"imputer_params\": {\n",
    "                    \"class\": \"sklearn.impute.KNNImputer\",\n",
    "                    \"kwargs\": {\n",
    "                        \"n_neighbors\": 'trial.suggest_int(\"knn_imputer__n_neighbors\", 2, 20, step=1)',\n",
    "                        \"weights\": 'trial.suggest_categorical(\"knn_imputer__weights\", [\"distance\", \"uniform\"])',\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        \"scaler\": {\n",
    "            \"class\": \"project.packages.modelling.transformers.scaler.ColumnsPreserverScaler\",\n",
    "            \"kwargs\": {\n",
    "                \"scaler_params\": {\n",
    "                    \"class\": 'trial.suggest_categorical(\"scaler__transformer\", [\"project.packages.modelling.transformers.scaler.NotScalerTransformer\", \"sklearn.preprocessing.PowerTransformer\", \"sklearn.preprocessing.QuantileTransformer\"])',\n",
    "                    \"kwargs\": {},\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        \"feature_selector\": {\n",
    "            \"class\": \"project.packages.modelling.feature_selection.feature_selector_pipeline.FeatureSelector\",\n",
    "            \"kwargs\": {\n",
    "                \"fs_params\": {\n",
    "                    \"selectors\": [\"model_based\"],\n",
    "                    \"model_based\": {\n",
    "                        \"bypass_features\": [\"passenger_sex_female\"],\n",
    "                        \"estimator\": {\n",
    "                            \"class\": \"xgboost.XGBClassifier\",\n",
    "                            \"kwargs\": {\n",
    "                                \"n_estimators\": 'trial.suggest_int(\"fs_mb_xgboost__n_estimators\", 10, 500, step=10)',\n",
    "                                \"max_depth\": 'trial.suggest_int(\"fs_mb_xgboost__max_depth\", 2, 10)',\n",
    "                                \"random_state\": 42,\n",
    "                            },\n",
    "                        },\n",
    "                        \"threshold\": 'trial.suggest_float(\"fs_mb__threshold\", 0.001, 0.1)',\n",
    "                        \"prefit\": False,\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        \"model\": {\n",
    "            \"class\": \"xgboost.XGBClassifier\",\n",
    "            \"kwargs\": {\n",
    "                \"n_estimators\": 'trial.suggest_int(\"xgboost__n_estimators\", 10, 500, step=5)',\n",
    "                \"learning_rate\": 'trial.suggest_float(\"xgboost__learning_rate\", 0.0001, 1)',\n",
    "                \"min_child_weight\": 'trial.suggest_int(\"xgboost__min_child_weight\", 0, 500, step=1)',\n",
    "                \"max_depth\": 'trial.suggest_int(\"xgboost__max_depth\", 1, 8)',\n",
    "                \"subsample\": 'trial.suggest_float(\"xgboost__subsample\", 0.5, 1)',\n",
    "                \"reg_lambda\": 'trial.suggest_float(\"xgboost__reg_lambda\", 0, 5)',\n",
    "                \"reg_alpha\": 'trial.suggest_float(\"xgboost__reg_alpha\", 0, 1)',\n",
    "                \"random_state\": 42,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "target = \"survived\"\n",
    "model = BinaryClassifierSklearnPipeline(model_params)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit:\n",
    "\n",
    "The provided `fit` method is part of a custom machine learning model class, which appears to be designed for hyperparameter tuning and model fitting. Here's a description of what this method does:\n",
    "\n",
    "1. `seed_file()`: It sets a random seed or initializes a seed for reproducibility. The specific implementation of `seed_file` is not provided in the code snippet.\n",
    "\n",
    "2. `self.hypertune_results = self.hypertune_cross_validated_model(...)`: This line performs hyperparameter tuning using Optuna and cross-validation. It stores the results of the hyperparameter tuning process, including the best trial parameters, in the `self.hypertune_results` attribute.\n",
    "\n",
    "3. `self.best_params = self.hypertune_results[\"best_trial_params\"]`: It extracts the best trial parameters from the hyperparameter tuning results and stores them in the `self.best_params` attribute.\n",
    "\n",
    "4. `self.model = self.build_model_pipeline(self.best_params)`: This line builds a machine learning model pipeline based on the best trial parameters obtained from hyperparameter tuning. It uses the `build_model_pipeline` method (not shown in the provided code) to create the model pipeline.\n",
    "\n",
    "5. `self.model = self.model.fit(X, y)`: It fits the machine learning model pipeline to the input features `X` and target variable `y`. This step trains the model using the best hyperparameters.\n",
    "\n",
    "6. `self.is_fitted = True`: It sets the `is_fitted` attribute to `True`, indicating that the model has been fitted.\n",
    "\n",
    "7. `self.X_train = X` and `self.y_train = y`: It stores the input features and target variable used for training in the `self.X_train` and `self.y_train` attributes, respectively.\n",
    "\n",
    "8. Finally, the method returns the instance of the class (`self`) after fitting the model, allowing for method chaining or further use of the fitted model.\n",
    "\n",
    "This `fit` method encapsulates the process of hyperparameter tuning, model creation, and model training within a single method call.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-01-07 21:02:20,664 - project.packages.modelling.reproducibility.set_seed - INFO - Seeding sklearn, numpy and random libraries with the seed 42\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 21:02:20,673] A new study created in memory with name: xgboost\n",
      "[I 2024-01-07 21:02:23,322] Trial 0 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.08718230210027886, 'xgboost__n_estimators': 20, 'xgboost__learning_rate': 0.3925136468134222, 'xgboost__min_child_weight': 450, 'xgboost__max_depth': 1, 'xgboost__subsample': 0.8391268998756262, 'xgboost__reg_lambda': 2.749217162380866, 'xgboost__reg_alpha': 0.17668140036133317}. Best is trial 0 with value: 0.46982323232323225.\n",
      "[I 2024-01-07 21:02:25,285] Trial 1 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.09380113636694212, 'xgboost__n_estimators': 10, 'xgboost__learning_rate': 0.38208404980070293, 'xgboost__min_child_weight': 482, 'xgboost__max_depth': 1, 'xgboost__subsample': 0.8384090290478076, 'xgboost__reg_lambda': 2.6981005340139887, 'xgboost__reg_alpha': 0.13158502776480327}. Best is trial 0 with value: 0.46982323232323225.\n",
      "[I 2024-01-07 21:02:25,552] Trial 2 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 140, 'fs_mb_xgboost__max_depth': 10, 'fs_mb__threshold': 0.061004164780424926, 'xgboost__n_estimators': 125, 'xgboost__learning_rate': 0.8733243417622814, 'xgboost__min_child_weight': 354, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.9874188903547395, 'xgboost__reg_lambda': 4.766112898831798, 'xgboost__reg_alpha': 0.913602585940464}. Best is trial 0 with value: 0.46982323232323225.\n",
      "[I 2024-01-07 21:02:26,094] Trial 3 finished with value: 0.7800069208288982 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.015779496404363325, 'xgboost__n_estimators': 455, 'xgboost__learning_rate': 0.04544733852500937, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5503861112186494, 'xgboost__reg_lambda': 0.8084330541961959, 'xgboost__reg_alpha': 0.09351215387535233}. Best is trial 3 with value: 0.7800069208288982.\n",
      "[I 2024-01-07 21:02:27,264] Trial 4 finished with value: 0.8413588024167761 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0018425789560252565, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.021583189959284575, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5065896071904618, 'xgboost__reg_lambda': 0.04830223610325324, 'xgboost__reg_alpha': 0.009028922472964163}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:27,735] Trial 5 finished with value: 0.7796750574528353 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.004594176509979703, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.01802189559897557, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5001952017791316, 'xgboost__reg_lambda': 0.05723293938418124, 'xgboost__reg_alpha': 0.472122575176048}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:28,014] Trial 6 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 340, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02632946441403268, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.2081591517438272, 'xgboost__min_child_weight': 184, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.638145839512903, 'xgboost__reg_lambda': 1.2586840182459347, 'xgboost__reg_alpha': 0.3989769322753984}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:28,348] Trial 7 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 330, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.032626011572554764, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.7115318813056645, 'xgboost__min_child_weight': 180, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.6533676066838329, 'xgboost__reg_lambda': 0.14823564560792188, 'xgboost__reg_alpha': 0.0005638470121471194}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:28,696] Trial 8 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 390, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.004231905875396498, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.542087215834471, 'xgboost__min_child_weight': 126, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6203538805551276, 'xgboost__reg_lambda': 1.3553024871268937, 'xgboost__reg_alpha': 0.3221359376429537}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:28,941] Trial 9 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 200, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04229864213651614, 'xgboost__n_estimators': 215, 'xgboost__learning_rate': 0.15746253681106132, 'xgboost__min_child_weight': 309, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.501170563141212, 'xgboost__reg_lambda': 1.8208878340125199, 'xgboost__reg_alpha': 0.6440462010743564}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:29,468] Trial 10 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 420, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.05730662636754405, 'xgboost__n_estimators': 210, 'xgboost__learning_rate': 0.2510642047739566, 'xgboost__min_child_weight': 102, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.739013540248122, 'xgboost__reg_lambda': 2.0120003222547718, 'xgboost__reg_alpha': 0.2825137975289682}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:30,041] Trial 11 finished with value: 0.7812045968135162 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.015824715165500554, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.005660842721502891, 'xgboost__min_child_weight': 12, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5542541483470574, 'xgboost__reg_lambda': 0.5924999861874596, 'xgboost__reg_alpha': 0.0041163567188945635}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:31,110] Trial 12 finished with value: 0.8308032291810925 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 260, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.003753012603709645, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.002795035258286264, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5808893289142647, 'xgboost__reg_lambda': 0.09496068781222433, 'xgboost__reg_alpha': 0.015054508683232045}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:31,532] Trial 13 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 240, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.010437597330985454, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.17895476181477427, 'xgboost__min_child_weight': 93, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5843517282049606, 'xgboost__reg_lambda': 0.027596547537860977, 'xgboost__reg_alpha': 0.2398120467786177}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:31,785] Trial 14 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.002238682929788773, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.10592433178880975, 'xgboost__min_child_weight': 248, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.6571580651481883, 'xgboost__reg_lambda': 0.8004838377910559, 'xgboost__reg_alpha': 0.11891956062116638}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:32,090] Trial 15 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 300, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.023817480501919695, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.2879058972572614, 'xgboost__min_child_weight': 76, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5027292876886564, 'xgboost__reg_lambda': 0.005044278267082619, 'xgboost__reg_alpha': 0.021483474167786527}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:32,538] Trial 16 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 400, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.0013749669723765415, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.0013785709153815197, 'xgboost__min_child_weight': 177, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5871319248742302, 'xgboost__reg_lambda': 0.6742041322880156, 'xgboost__reg_alpha': 0.21569913852152844}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:32,977] Trial 17 finished with value: 0.8021892735454892 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 190, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.01801495125845802, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.14872972534672188, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.6879619031245297, 'xgboost__reg_lambda': 1.0834752241589507, 'xgboost__reg_alpha': 0.38820793912377927}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:33,432] Trial 18 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 270, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.035323821756859206, 'xgboost__n_estimators': 270, 'xgboost__learning_rate': 0.3197538572713865, 'xgboost__min_child_weight': 66, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.573039207150036, 'xgboost__reg_lambda': 1.695993574738367, 'xgboost__reg_alpha': 0.12677254593379284}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:33,694] Trial 19 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.012433566504255297, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.1067719251711543, 'xgboost__min_child_weight': 149, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.7002982254737011, 'xgboost__reg_lambda': 0.536369471561255, 'xgboost__reg_alpha': 0.23422242655205705}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:34,090] Trial 20 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 440, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.02484362394973338, 'xgboost__n_estimators': 135, 'xgboost__learning_rate': 0.5147294730511498, 'xgboost__min_child_weight': 268, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.6132678622291264, 'xgboost__reg_lambda': 2.2764764950819503, 'xgboost__reg_alpha': 0.08933334027391757}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:34,416] Trial 21 finished with value: 0.6963154217692574 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 180, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.014669301728109561, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.11428846476752014, 'xgboost__min_child_weight': 51, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.6886496250940006, 'xgboost__reg_lambda': 1.1816131390693498, 'xgboost__reg_alpha': 0.36914761975252075}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:34,796] Trial 22 finished with value: 0.811783766244153 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 220, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.019972848063234728, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.103298419415503, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5517973584943614, 'xgboost__reg_lambda': 0.4478516419400229, 'xgboost__reg_alpha': 0.502219383112168}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:35,112] Trial 23 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 240, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.008684311032796068, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.07980963763839456, 'xgboost__min_child_weight': 53, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5586740000560421, 'xgboost__reg_lambda': 0.37036421417710486, 'xgboost__reg_alpha': 0.5988764510512964}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:35,395] Trial 24 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 340, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0018517800243709648, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.22076185761995487, 'xgboost__min_child_weight': 129, 'xgboost__max_depth': 2, 'xgboost__subsample': 0.5355036556887023, 'xgboost__reg_lambda': 0.4096899581394158, 'xgboost__reg_alpha': 0.28825020618703107}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:35,674] Trial 25 finished with value: 0.7012596424822131 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.02031350392418601, 'xgboost__n_estimators': 465, 'xgboost__learning_rate': 0.0032642485777751723, 'xgboost__min_child_weight': 43, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.6008966970449205, 'xgboost__reg_lambda': 0.4061816486492399, 'xgboost__reg_alpha': 0.5010063085178752}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:02:36,292] Trial 26 finished with value: 0.8429887004244362 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.010452924839967244, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.09695821118980388, 'xgboost__min_child_weight': 3, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5282116926663798, 'xgboost__reg_lambda': 0.9349623154068951, 'xgboost__reg_alpha': 0.18469376812638083}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:36,760] Trial 27 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 300, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00967725928278656, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.18624912303145144, 'xgboost__min_child_weight': 401, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.525334087331987, 'xgboost__reg_lambda': 0.851340680237374, 'xgboost__reg_alpha': 0.07208311701368508}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:37,185] Trial 28 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 360, 'fs_mb_xgboost__max_depth': 10, 'fs_mb__threshold': 0.009453924996714061, 'xgboost__n_estimators': 460, 'xgboost__learning_rate': 0.06932341348876517, 'xgboost__min_child_weight': 221, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5973329060181136, 'xgboost__reg_lambda': 1.4762034293341464, 'xgboost__reg_alpha': 0.20692980778151573}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:37,643] Trial 29 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 290, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.07060902348485489, 'xgboost__n_estimators': 120, 'xgboost__learning_rate': 0.3478863018689504, 'xgboost__min_child_weight': 95, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.532189491987094, 'xgboost__reg_lambda': 0.9281365889320669, 'xgboost__reg_alpha': 0.1956243486240699}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:37,914] Trial 30 finished with value: 0.6715094130188469 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 9, 'fs_mb__threshold': 0.04284372413081557, 'xgboost__n_estimators': 80, 'xgboost__learning_rate': 0.264087905412473, 'xgboost__min_child_weight': 38, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5759335895652518, 'xgboost__reg_lambda': 1.1134590576246999, 'xgboost__reg_alpha': 0.15591396906091895}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:38,333] Trial 31 finished with value: 0.7933100827545888 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 210, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.01968467899714859, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.08613936732511664, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5345578757825197, 'xgboost__reg_lambda': 0.32725214320777407, 'xgboost__reg_alpha': 0.03579215626219987}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:38,772] Trial 32 finished with value: 0.8295478121798622 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 160, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.007972034818125842, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.1574703613526946, 'xgboost__min_child_weight': 2, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5723569975135155, 'xgboost__reg_lambda': 0.33539746996900455, 'xgboost__reg_alpha': 0.07492823837362163}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:39,096] Trial 33 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 160, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.0075595770130936785, 'xgboost__n_estimators': 470, 'xgboost__learning_rate': 0.4326548252557329, 'xgboost__min_child_weight': 67, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6240653287601755, 'xgboost__reg_lambda': 0.03678939439261438, 'xgboost__reg_alpha': 0.15018415565474572}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:39,368] Trial 34 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.0010592450217726057, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.1493458999420411, 'xgboost__min_child_weight': 454, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5748295655645715, 'xgboost__reg_lambda': 0.6809425374088, 'xgboost__reg_alpha': 0.07005540163304}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:39,660] Trial 35 finished with value: 0.7685707448808669 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.013837033857309054, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.05870749181133461, 'xgboost__min_child_weight': 32, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5209474308429427, 'xgboost__reg_lambda': 3.0958710716965854, 'xgboost__reg_alpha': 0.06073856003865589}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:39,985] Trial 36 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 160, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.006770821793576385, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.21379045187237478, 'xgboost__min_child_weight': 127, 'xgboost__max_depth': 1, 'xgboost__subsample': 0.7964863498961815, 'xgboost__reg_lambda': 0.255570928884599, 'xgboost__reg_alpha': 0.14918229815925418}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:40,419] Trial 37 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 270, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.013331523610813592, 'xgboost__n_estimators': 440, 'xgboost__learning_rate': 0.05363103932763263, 'xgboost__min_child_weight': 354, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5545944687755313, 'xgboost__reg_lambda': 0.9457712579118638, 'xgboost__reg_alpha': 0.09102710060931962}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:40,913] Trial 38 finished with value: 0.7878658646178112 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 460, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.006566819469195532, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.046309948956956226, 'xgboost__min_child_weight': 29, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6454090401612174, 'xgboost__reg_lambda': 0.21159168895198188, 'xgboost__reg_alpha': 0.01306028148334632}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:41,215] Trial 39 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 360, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.029826681797419874, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.14065253668764427, 'xgboost__min_child_weight': 85, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5004654809287296, 'xgboost__reg_lambda': 0.6764817027815124, 'xgboost__reg_alpha': 0.1687619641003985}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:41,655] Trial 40 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 320, 'fs_mb_xgboost__max_depth': 9, 'fs_mb__threshold': 0.0257642995847268, 'xgboost__n_estimators': 260, 'xgboost__learning_rate': 0.230312824310655, 'xgboost__min_child_weight': 493, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6139304696516282, 'xgboost__reg_lambda': 0.20354165009142502, 'xgboost__reg_alpha': 0.06168622080873945}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:42,147] Trial 41 finished with value: 0.8043560406210365 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.019709023923116267, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.11904778442892265, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5518568505361754, 'xgboost__reg_lambda': 0.545136822009628, 'xgboost__reg_alpha': 0.11596778735262611}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:42,920] Trial 42 finished with value: 0.8354586886799922 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 210, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.006184121940246942, 'xgboost__n_estimators': 450, 'xgboost__learning_rate': 0.03369788320825845, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.525689335656851, 'xgboost__reg_lambda': 0.43920429417740203, 'xgboost__reg_alpha': 0.007256746728667054}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:43,275] Trial 43 finished with value: 0.7165032826893035 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 160, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.006172635503219647, 'xgboost__n_estimators': 450, 'xgboost__learning_rate': 0.02946045528017524, 'xgboost__min_child_weight': 35, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5227672692123647, 'xgboost__reg_lambda': 0.0176953592468093, 'xgboost__reg_alpha': 0.0026392367745679685}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:43,586] Trial 44 finished with value: 0.7935324950920709 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.012189448054549714, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.17451807273682798, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.570492172725747, 'xgboost__reg_lambda': 0.30858931303559217, 'xgboost__reg_alpha': 0.05070970040789198}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:43,879] Trial 45 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 260, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004944192869380757, 'xgboost__n_estimators': 220, 'xgboost__learning_rate': 0.002376979401198076, 'xgboost__min_child_weight': 59, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5989995908421104, 'xgboost__reg_lambda': 0.871912145432317, 'xgboost__reg_alpha': 0.10942485525356102}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:44,220] Trial 46 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 200, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.0011501189773531646, 'xgboost__n_estimators': 450, 'xgboost__learning_rate': 0.057038868280316624, 'xgboost__min_child_weight': 111, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5000332351173018, 'xgboost__reg_lambda': 0.6226729712963195, 'xgboost__reg_alpha': 0.0038815651856069187}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:44,575] Trial 47 finished with value: 0.7862163442693051 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.014387837055800766, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.17804920486505854, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.539660781250809, 'xgboost__reg_lambda': 0.1694172354508062, 'xgboost__reg_alpha': 0.050147902881687086}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:45,033] Trial 48 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 380, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.006718579061736793, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.033521145315927044, 'xgboost__min_child_weight': 76, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5192035601191084, 'xgboost__reg_lambda': 1.3653968305497524, 'xgboost__reg_alpha': 0.17624268259690481}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:45,303] Trial 49 finished with value: 0.8117584992659643 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 180, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.016821238128795435, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.1369800103483166, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5652246973357207, 'xgboost__reg_lambda': 0.4969469115066075, 'xgboost__reg_alpha': 0.10363704973185037}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:45,531] Trial 50 finished with value: 0.6715644416675345 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010237202921350084, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.2714586912996223, 'xgboost__min_child_weight': 54, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.6325948471328068, 'xgboost__reg_lambda': 0.014110273731066714, 'xgboost__reg_alpha': 0.035647439106766196}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:45,968] Trial 51 finished with value: 0.8037475645929483 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 220, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.02135788805511181, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.10476861193195351, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.543277532679266, 'xgboost__reg_lambda': 0.44879347063610653, 'xgboost__reg_alpha': 0.1216158307393172}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:46,463] Trial 52 finished with value: 0.8325339299822528 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 250, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.004659554323147086, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.09511184312630586, 'xgboost__min_child_weight': 2, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.587005770973366, 'xgboost__reg_lambda': 0.7433807263636762, 'xgboost__reg_alpha': 0.2433889115331292}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:46,834] Trial 53 finished with value: 0.7866882684100401 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 250, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.00477719136230287, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.0687184541160669, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5849019613572705, 'xgboost__reg_lambda': 0.7494450583889963, 'xgboost__reg_alpha': 0.25735330470583667}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:47,272] Trial 54 finished with value: 0.6966718493681404 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.010787890295906735, 'xgboost__n_estimators': 485, 'xgboost__learning_rate': 0.03130133681172803, 'xgboost__min_child_weight': 41, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5145624668961253, 'xgboost__reg_lambda': 1.0564538017050211, 'xgboost__reg_alpha': 0.1918802759758429}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:47,630] Trial 55 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 310, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.016742934105846652, 'xgboost__n_estimators': 445, 'xgboost__learning_rate': 0.002654857500227512, 'xgboost__min_child_weight': 65, 'xgboost__max_depth': 2, 'xgboost__subsample': 0.5557266598205487, 'xgboost__reg_lambda': 0.2322232402396433, 'xgboost__reg_alpha': 0.093636446507182}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:48,043] Trial 56 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 420, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.004665021105211804, 'xgboost__n_estimators': 460, 'xgboost__learning_rate': 0.09940821397517936, 'xgboost__min_child_weight': 112, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6010841207032018, 'xgboost__reg_lambda': 0.6952774434717373, 'xgboost__reg_alpha': 0.0011696836313633795}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:48,397] Trial 57 finished with value: 0.8001997466627692 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 250, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.0015248868038557064, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.19209872336491335, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5818394208788348, 'xgboost__reg_lambda': 0.9615203037658789, 'xgboost__reg_alpha': 0.14373071945855093}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:48,693] Trial 58 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 180, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.010711074910401033, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.14349422377768845, 'xgboost__min_child_weight': 155, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.6528646194019916, 'xgboost__reg_lambda': 0.5718949884043096, 'xgboost__reg_alpha': 0.04087945821724466}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:49,010] Trial 59 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.016280756660455767, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.08343602252389945, 'xgboost__min_child_weight': 295, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5387799435564415, 'xgboost__reg_lambda': 1.243499682725161, 'xgboost__reg_alpha': 0.22501956362900233}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:49,396] Trial 60 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 200, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.004342055836424161, 'xgboost__n_estimators': 495, 'xgboost__learning_rate': 0.03919824688220737, 'xgboost__min_child_weight': 215, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.5118017363162963, 'xgboost__reg_lambda': 0.1574803906591009, 'xgboost__reg_alpha': 0.08130105596976628}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:49,727] Trial 61 finished with value: 0.8042674952526491 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 210, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.00854982625639402, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.10846891871986851, 'xgboost__min_child_weight': 14, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5524468236615281, 'xgboost__reg_lambda': 0.397976029157703, 'xgboost__reg_alpha': 0.2701922059101109}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:50,104] Trial 62 finished with value: 0.7834710743801652 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.022396502997840587, 'xgboost__n_estimators': 465, 'xgboost__learning_rate': 0.08265057814391658, 'xgboost__min_child_weight': 4, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.5643301395983217, 'xgboost__reg_lambda': 0.4538450654764631, 'xgboost__reg_alpha': 0.3304728798031194}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:50,362] Trial 63 finished with value: 0.680573159356752 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 150, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.01244135820327687, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.16420029205415032, 'xgboost__min_child_weight': 46, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5358726815783836, 'xgboost__reg_lambda': 0.7883647022461272, 'xgboost__reg_alpha': 0.17819684005400496}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:50,736] Trial 64 finished with value: 0.8134557596619184 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.018356303295584558, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.12339135252130617, 'xgboost__min_child_weight': 4, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5901895533700969, 'xgboost__reg_lambda': 0.3737646792585824, 'xgboost__reg_alpha': 0.03598891611872926}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:51,051] Trial 65 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.004416634615095572, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.2097218385042754, 'xgboost__min_child_weight': 81, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.615676598497345, 'xgboost__reg_lambda': 0.16583389927248626, 'xgboost__reg_alpha': 0.035176841472679424}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:51,438] Trial 66 finished with value: 0.7259997607205729 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 260, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00851314234456364, 'xgboost__n_estimators': 470, 'xgboost__learning_rate': 0.1349735793698032, 'xgboost__min_child_weight': 38, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5885059229628221, 'xgboost__reg_lambda': 0.2914080583665652, 'xgboost__reg_alpha': 0.08148429594497394}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:51,827] Trial 67 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 330, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.017178762938009316, 'xgboost__n_estimators': 450, 'xgboost__learning_rate': 0.2425985255279689, 'xgboost__min_child_weight': 58, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5161214118439114, 'xgboost__reg_lambda': 0.005778335969591375, 'xgboost__reg_alpha': 0.1317587164572712}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:52,181] Trial 68 finished with value: 0.7989816941882802 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 180, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.013730460338220177, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.03210504012585935, 'xgboost__min_child_weight': 14, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6313730245268122, 'xgboost__reg_lambda': 0.556586192256318, 'xgboost__reg_alpha': 0.030532772863675086}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:52,635] Trial 69 finished with value: 0.7772342003021679 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0029590577709611146, 'xgboost__n_estimators': 485, 'xgboost__learning_rate': 0.07442890884022613, 'xgboost__min_child_weight': 30, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5653670921957025, 'xgboost__reg_lambda': 0.3397275305120982, 'xgboost__reg_alpha': 0.059186941325378516}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:52,946] Trial 70 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 240, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.008060186257384052, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.12355704564156837, 'xgboost__min_child_weight': 73, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6640346761127407, 'xgboost__reg_lambda': 1.0024717120456312, 'xgboost__reg_alpha': 0.13718594948826845}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:53,347] Trial 71 finished with value: 0.8038930178052333 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 210, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.019600795860615673, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.09315310831561932, 'xgboost__min_child_weight': 2, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5468608798937488, 'xgboost__reg_lambda': 0.7463445944856895, 'xgboost__reg_alpha': 0.08530158995862551}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:53,715] Trial 72 finished with value: 0.7924486559632626 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.023683463178001095, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.055138385495521344, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5313730434404595, 'xgboost__reg_lambda': 0.4232349960896449, 'xgboost__reg_alpha': 0.029780442346103487}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:54,037] Trial 73 finished with value: 0.6986925532380078 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 300, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.011722243917945274, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.015624752362376784, 'xgboost__min_child_weight': 46, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5725235868539632, 'xgboost__reg_lambda': 0.13129283152468307, 'xgboost__reg_alpha': 0.2136969148450148}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:54,315] Trial 74 finished with value: 0.7812216903838729 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 220, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.015139050848548236, 'xgboost__n_estimators': 50, 'xgboost__learning_rate': 0.19220648232990167, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.6046593954466568, 'xgboost__reg_lambda': 0.5655135703010049, 'xgboost__reg_alpha': 0.4479099122539749}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:54,635] Trial 75 finished with value: 0.8105637360798874 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 190, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.0037832670149783717, 'xgboost__n_estimators': 440, 'xgboost__learning_rate': 0.15821624861662245, 'xgboost__min_child_weight': 14, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5894493346195435, 'xgboost__reg_lambda': 0.8310133669469144, 'xgboost__reg_alpha': 0.06893349229969868}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:54,940] Trial 76 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 240, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.0074863001803212505, 'xgboost__n_estimators': 155, 'xgboost__learning_rate': 0.1124557261176794, 'xgboost__min_child_weight': 375, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.51012635028062, 'xgboost__reg_lambda': 0.3109367240220147, 'xgboost__reg_alpha': 0.11094908543404372}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:55,299] Trial 77 finished with value: 0.7053254380714565 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 140, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.010348172324609111, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.056673900634027476, 'xgboost__min_child_weight': 37, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5265214887557811, 'xgboost__reg_lambda': 0.11127404450374315, 'xgboost__reg_alpha': 0.0005027340309045752}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:55,602] Trial 78 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 170, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.0010558128775755896, 'xgboost__n_estimators': 470, 'xgboost__learning_rate': 0.0017513833854317568, 'xgboost__min_child_weight': 52, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5541651706888973, 'xgboost__reg_lambda': 1.1434866272260928, 'xgboost__reg_alpha': 0.15693285113089872}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:55,915] Trial 79 finished with value: 0.7813748046389238 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 260, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.018498103694496393, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.025969161396300226, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5776795961520191, 'xgboost__reg_lambda': 0.6225019811136354, 'xgboost__reg_alpha': 0.02385822994725011}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:56,212] Trial 80 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 350, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.029236832903506458, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.07807654594544283, 'xgboost__min_child_weight': 87, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5411956064281873, 'xgboost__reg_lambda': 0.428882707594188, 'xgboost__reg_alpha': 0.05673710673595566}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:56,667] Trial 81 finished with value: 0.8373954428871773 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 180, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.016080768478582114, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.13116349031515723, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5637416121033391, 'xgboost__reg_lambda': 0.5037803380643738, 'xgboost__reg_alpha': 0.10933186881444022}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:56,909] Trial 82 finished with value: 0.8125263643590556 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.013869847924493115, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.12831843495280276, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.563814633390657, 'xgboost__reg_lambda': 0.28195609247882997, 'xgboost__reg_alpha': 0.1305580815596914}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:57,165] Trial 83 finished with value: 0.8148126282083353 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.013259186916423242, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.16201340421636665, 'xgboost__min_child_weight': 13, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5639527142223846, 'xgboost__reg_lambda': 0.26893588837923305, 'xgboost__reg_alpha': 0.10533945226221758}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:57,444] Trial 84 finished with value: 0.816648245033724 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006735509862264435, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.1637659299491418, 'xgboost__min_child_weight': 12, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.6226163533750867, 'xgboost__reg_lambda': 0.09721986414489145, 'xgboost__reg_alpha': 0.09876970488496699}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:57,690] Trial 85 finished with value: 0.7872096232162156 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006835260541589224, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.229459516787624, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5287715438871721, 'xgboost__reg_lambda': 0.09633004177053414, 'xgboost__reg_alpha': 0.0984588400413131}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:57,882] Trial 86 finished with value: 0.7027651674149189 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0033866563401443815, 'xgboost__n_estimators': 240, 'xgboost__learning_rate': 0.17166946968899557, 'xgboost__min_child_weight': 41, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6043051423098943, 'xgboost__reg_lambda': 0.20776349539307945, 'xgboost__reg_alpha': 0.18068158447950966}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:58,144] Trial 87 finished with value: 0.8126816960122869 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006139834610837431, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.2977517594013833, 'xgboost__min_child_weight': 14, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.6226993669919783, 'xgboost__reg_lambda': 0.5162271280911654, 'xgboost__reg_alpha': 0.16014974349153344}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:58,422] Trial 88 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.009604992820438384, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.2023518248528616, 'xgboost__min_child_weight': 67, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5757901185847916, 'xgboost__reg_lambda': 0.6626478883106773, 'xgboost__reg_alpha': 0.19849803713578237}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:02:59,355] Trial 89 finished with value: 0.8305059115104432 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012066622831893577, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.15789294411972743, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5439886056665619, 'xgboost__reg_lambda': 0.9119559025955679, 'xgboost__reg_alpha': 0.11888648825831313}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:00,174] Trial 90 finished with value: 0.8338389897782109 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0029679732623081496, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.0411875585262903, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5081610735614605, 'xgboost__reg_lambda': 0.8901586261578441, 'xgboost__reg_alpha': 0.24445369673755163}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:00,391] Trial 91 finished with value: 0.7693602693602694 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003118091941542451, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.04705659735451254, 'xgboost__min_child_weight': 30, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5069581883238962, 'xgboost__reg_lambda': 0.8909725845548656, 'xgboost__reg_alpha': 0.23347478825600587}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:00,612] Trial 92 finished with value: 0.7925573540945532 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005729790405944412, 'xgboost__n_estimators': 275, 'xgboost__learning_rate': 0.08790448618465348, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5233075354219932, 'xgboost__reg_lambda': 1.0742348614990334, 'xgboost__reg_alpha': 0.06345472384597542}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:01,004] Trial 93 finished with value: 0.8400485931075474 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009019213863804196, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.02714478880339107, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.544849466412835, 'xgboost__reg_lambda': 0.8346497294425419, 'xgboost__reg_alpha': 0.2506885874967713}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:01,732] Trial 94 finished with value: 0.8322935911263063 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010548245617894731, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.015073233515108371, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5447271821004331, 'xgboost__reg_lambda': 0.8128339586735718, 'xgboost__reg_alpha': 0.29588623368215106}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:02,438] Trial 95 finished with value: 0.8390924995941588 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01107236309881927, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.021857083176411024, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5474469437486429, 'xgboost__reg_lambda': 0.8032378156443282, 'xgboost__reg_alpha': 0.2594044479035313}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:02,626] Trial 96 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009894124931407908, 'xgboost__n_estimators': 245, 'xgboost__learning_rate': 0.026505021997506612, 'xgboost__min_child_weight': 54, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5117915315660707, 'xgboost__reg_lambda': 0.7843033190800361, 'xgboost__reg_alpha': 0.2523521900444002}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:02,796] Trial 97 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015400987785516386, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.0014461450788252578, 'xgboost__min_child_weight': 40, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5038133559497314, 'xgboost__reg_lambda': 1.0070717047037263, 'xgboost__reg_alpha': 0.2420472306270971}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:03,023] Trial 98 finished with value: 0.7887606220939554 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0026657901253285257, 'xgboost__n_estimators': 260, 'xgboost__learning_rate': 0.05953818507401997, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5297341857359618, 'xgboost__reg_lambda': 1.2498858848904235, 'xgboost__reg_alpha': 0.2897693942833424}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:03,219] Trial 99 finished with value: 0.7728101208090659 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.00888889716059283, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.02323559691034341, 'xgboost__min_child_weight': 30, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5480827941538589, 'xgboost__reg_lambda': 0.6914426243147704, 'xgboost__reg_alpha': 0.2834343102863981}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:03,384] Trial 100 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004798615167721501, 'xgboost__n_estimators': 275, 'xgboost__learning_rate': 0.04973771193672388, 'xgboost__min_child_weight': 48, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5212342602810116, 'xgboost__reg_lambda': 1.153364936770646, 'xgboost__reg_alpha': 0.2204321499974159}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:03,682] Trial 101 finished with value: 0.8401671416794099 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011787413780252866, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.06845953028501071, 'xgboost__min_child_weight': 2, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.544510209358754, 'xgboost__reg_lambda': 0.8938875711561692, 'xgboost__reg_alpha': 0.19952974935454015}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:03,962] Trial 102 finished with value: 0.819214294258781 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01066640012418881, 'xgboost__n_estimators': 225, 'xgboost__learning_rate': 0.06889291631359776, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5374281166254927, 'xgboost__reg_lambda': 0.9754363124689487, 'xgboost__reg_alpha': 0.3171937927880314}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:04,815] Trial 103 finished with value: 0.8392088147427575 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011856388228632213, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.023207687460771755, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.557017320902077, 'xgboost__reg_lambda': 0.8044416777857577, 'xgboost__reg_alpha': 0.20622460906232637}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:05,023] Trial 104 finished with value: 0.7842178397733954 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01226934326818412, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.040549009674363604, 'xgboost__min_child_weight': 22, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.556487365902615, 'xgboost__reg_lambda': 0.8666501297944706, 'xgboost__reg_alpha': 0.21930560126127685}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:05,244] Trial 105 finished with value: 0.7984548038086549 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015967457121980715, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.018124530345835485, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5183768831124896, 'xgboost__reg_lambda': 0.7947445071416279, 'xgboost__reg_alpha': 0.20315537238862288}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:05,433] Trial 106 finished with value: 0.7620269289270186 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008308550496625553, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.09424190510551955, 'xgboost__min_child_weight': 34, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5474917107796456, 'xgboost__reg_lambda': 1.088140707786165, 'xgboost__reg_alpha': 0.26004848213690984}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:05,762] Trial 107 finished with value: 0.8358704241809264 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0010793640362217367, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.0680286510319928, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5361032700554857, 'xgboost__reg_lambda': 1.3243583067718994, 'xgboost__reg_alpha': 0.18535543610800848}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:05,950] Trial 108 finished with value: 0.782305825372625 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.001941064967923698, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.07047133759173595, 'xgboost__min_child_weight': 20, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5001161000540493, 'xgboost__reg_lambda': 1.310783046095909, 'xgboost__reg_alpha': 0.172647883025976}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:06,130] Trial 109 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.005693894864716545, 'xgboost__n_estimators': 265, 'xgboost__learning_rate': 0.10196609735209243, 'xgboost__min_child_weight': 62, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5244339823317133, 'xgboost__reg_lambda': 1.419803442278109, 'xgboost__reg_alpha': 0.1899943162076544}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:06,448] Trial 110 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 440, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004383783591962267, 'xgboost__n_estimators': 490, 'xgboost__learning_rate': 0.03989883600531212, 'xgboost__min_child_weight': 432, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5364964216980868, 'xgboost__reg_lambda': 0.6345264422204906, 'xgboost__reg_alpha': 0.2314516293019275}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:06,682] Trial 111 finished with value: 0.8123627144460477 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011370006119370614, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.018013293681194024, 'xgboost__min_child_weight': 7, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5588818960308941, 'xgboost__reg_lambda': 0.7464782073281211, 'xgboost__reg_alpha': 0.24223233866449584}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:07,403] Trial 112 finished with value: 0.8314615624133674 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008566354843018998, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.06332186820325321, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5303094273225931, 'xgboost__reg_lambda': 0.9161151890616623, 'xgboost__reg_alpha': 0.20229881126691773}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:07,617] Trial 113 finished with value: 0.8158751977103262 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014498530957097421, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.04241458374021852, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5147093000330795, 'xgboost__reg_lambda': 1.2106777908035138, 'xgboost__reg_alpha': 0.15939309965065313}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:07,816] Trial 114 finished with value: 0.7654031726196674 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.002971776850357422, 'xgboost__n_estimators': 250, 'xgboost__learning_rate': 0.08631379494056049, 'xgboost__min_child_weight': 34, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5481318742292343, 'xgboost__reg_lambda': 0.5217519880163107, 'xgboost__reg_alpha': 0.3044110092502297}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:08,010] Trial 115 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005845293868617517, 'xgboost__n_estimators': 235, 'xgboost__learning_rate': 0.015943023404588787, 'xgboost__min_child_weight': 21, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5404965301686333, 'xgboost__reg_lambda': 0.9944537042269209, 'xgboost__reg_alpha': 0.25892580017811323}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:08,224] Trial 116 finished with value: 0.7003033097473328 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0015043756234750514, 'xgboost__n_estimators': 270, 'xgboost__learning_rate': 0.10100862512557704, 'xgboost__min_child_weight': 45, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5685049435349091, 'xgboost__reg_lambda': 0.8336945809317998, 'xgboost__reg_alpha': 0.2150430319652019}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:08,875] Trial 117 finished with value: 0.8370600399827325 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007140167607081473, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.12463501782860002, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5570685101691655, 'xgboost__reg_lambda': 1.081490507279175, 'xgboost__reg_alpha': 0.27397163119444445}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:09,077] Trial 118 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.007728368488470772, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.12577865599738802, 'xgboost__min_child_weight': 203, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5823044575675224, 'xgboost__reg_lambda': 1.4868692634658993, 'xgboost__reg_alpha': 0.27069144789215416}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:09,321] Trial 119 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 150, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.012611908261314423, 'xgboost__n_estimators': 455, 'xgboost__learning_rate': 0.13796033530307147, 'xgboost__min_child_weight': 257, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5111797418087576, 'xgboost__reg_lambda': 0.6129625283253216, 'xgboost__reg_alpha': 0.14670906206156642}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:09,510] Trial 120 finished with value: 0.7892338374965742 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0011665437032156445, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.11475601653558656, 'xgboost__min_child_weight': 20, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5304514935505432, 'xgboost__reg_lambda': 1.0679473603252145, 'xgboost__reg_alpha': 0.18915132908946777}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:09,888] Trial 121 finished with value: 0.8352462922355396 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 380, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009994498162132597, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.07654759002758964, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5587757355015744, 'xgboost__reg_lambda': 0.7836245198275714, 'xgboost__reg_alpha': 0.33277378412638237}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:10,668] Trial 122 finished with value: 0.8349124038963612 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006654447789531205, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.06929302483102834, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5586693758005612, 'xgboost__reg_lambda': 0.9425205127180785, 'xgboost__reg_alpha': 0.2727095516673191}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:10,956] Trial 123 finished with value: 0.8105637360798874 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 370, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007255250421098237, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.06977993902540108, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5646038732282053, 'xgboost__reg_lambda': 1.1770890894159198, 'xgboost__reg_alpha': 0.27340089369331283}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:11,251] Trial 124 finished with value: 0.7795307549382281 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.017425514126456394, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.04633369085317361, 'xgboost__min_child_weight': 30, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5533279125992562, 'xgboost__reg_lambda': 0.9002569002481497, 'xgboost__reg_alpha': 0.3429943760010984}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:11,548] Trial 125 finished with value: 0.8058701213218245 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009629136450812564, 'xgboost__n_estimators': 190, 'xgboost__learning_rate': 0.07978131387863346, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.519720460763633, 'xgboost__reg_lambda': 0.6904936448780676, 'xgboost__reg_alpha': 0.25084015432990164}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:11,834] Trial 126 finished with value: 0.7859121296890962 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.021476775288328705, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.05793778484292664, 'xgboost__min_child_weight': 21, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5573183949971409, 'xgboost__reg_lambda': 1.0065188661599214, 'xgboost__reg_alpha': 0.27703753144747967}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:12,391] Trial 127 finished with value: 0.8010220219829349 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 460, 'fs_mb_xgboost__max_depth': 9, 'fs_mb__threshold': 0.01430987140067019, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.038062422511082404, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5705210106269067, 'xgboost__reg_lambda': 0.4667661725962851, 'xgboost__reg_alpha': 0.30630160225213443}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:12,683] Trial 128 finished with value: 0.7007279727586345 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 410, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0038523871025551867, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.11271189246714025, 'xgboost__min_child_weight': 39, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5349118300472421, 'xgboost__reg_lambda': 1.111110063815111, 'xgboost__reg_alpha': 0.23190804171831955}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:13,329] Trial 129 finished with value: 0.8307324920228146 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 440, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011324923100626633, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.07887305993277706, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5079537926157309, 'xgboost__reg_lambda': 1.3062984320883337, 'xgboost__reg_alpha': 0.3422343256059678}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:13,636] Trial 130 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005650946255819444, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.003503525591432341, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.577268712622058, 'xgboost__reg_lambda': 0.634691888952148, 'xgboost__reg_alpha': 0.17524655198371936}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:13,891] Trial 131 finished with value: 0.817713032248934 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007772764010724102, 'xgboost__n_estimators': 475, 'xgboost__learning_rate': 0.0998052700088293, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5432547212371166, 'xgboost__reg_lambda': 0.7075006952824888, 'xgboost__reg_alpha': 0.2442057445613054}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:14,222] Trial 132 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 400, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.00408075397234178, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.14181686167047153, 'xgboost__min_child_weight': 321, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5554821261110083, 'xgboost__reg_lambda': 0.767925286718436, 'xgboost__reg_alpha': 0.21661775731097066}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:14,439] Trial 133 finished with value: 0.7994843354738276 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006251240281429087, 'xgboost__n_estimators': 260, 'xgboost__learning_rate': 0.030931066892498665, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5970466634956187, 'xgboost__reg_lambda': 0.8890388385165517, 'xgboost__reg_alpha': 0.2947925625972008}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:15,026] Trial 134 finished with value: 0.8412421078146687 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009286390368331243, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.0898383961925743, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.526075383312836, 'xgboost__reg_lambda': 0.5506812540431445, 'xgboost__reg_alpha': 0.26822568030414673}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:15,639] Trial 135 finished with value: 0.8313427117445381 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012976603241813732, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.060330229335726, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5273946920897674, 'xgboost__reg_lambda': 0.5424614844508855, 'xgboost__reg_alpha': 0.2689181336363511}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:15,851] Trial 136 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009327431963780511, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.0014037460339173559, 'xgboost__min_child_weight': 20, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5003334745996265, 'xgboost__reg_lambda': 0.9693377237981379, 'xgboost__reg_alpha': 0.19947932495431342}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:16,063] Trial 137 finished with value: 0.8042000592910578 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 140, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.017129549146066722, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.08570899708927411, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5241109901360211, 'xgboost__reg_lambda': 0.39598087967129425, 'xgboost__reg_alpha': 0.327572677174729}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:16,255] Trial 138 finished with value: 0.7700951091672742 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011436896437076275, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.12337671110598947, 'xgboost__min_child_weight': 32, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5153138949075132, 'xgboost__reg_lambda': 0.5372565447373807, 'xgboost__reg_alpha': 0.2911309952621127}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:16,502] Trial 139 finished with value: 0.811783766244153 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 170, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015129998116238627, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.052711681747293376, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5373509516543816, 'xgboost__reg_lambda': 0.8601481447790258, 'xgboost__reg_alpha': 0.25904888212663135}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:16,865] Trial 140 finished with value: 0.7847012318513391 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 460, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.009104841210560655, 'xgboost__n_estimators': 275, 'xgboost__learning_rate': 0.023976705915834937, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5630265646500123, 'xgboost__reg_lambda': 1.03698868973178, 'xgboost__reg_alpha': 0.1402017879024977}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:17,164] Trial 141 finished with value: 0.8105637360798874 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 200, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003539877790339818, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.09386557962255314, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5484248658337575, 'xgboost__reg_lambda': 0.770086260610427, 'xgboost__reg_alpha': 0.22117331672382806}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:17,392] Trial 142 finished with value: 0.8020521706197269 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005885221135422768, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.06862929564328595, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.584832698723333, 'xgboost__reg_lambda': 0.6115241490086005, 'xgboost__reg_alpha': 0.3144990101940274}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:17,955] Trial 143 finished with value: 0.841805517409747 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007976356588350993, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.038345382110852394, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5360465804549953, 'xgboost__reg_lambda': 0.714543524361391, 'xgboost__reg_alpha': 0.2432877890133881}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:18,483] Trial 144 finished with value: 0.8328786496340432 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00818710527806147, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.04089287187666972, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5187349990120218, 'xgboost__reg_lambda': 0.4782349814109363, 'xgboost__reg_alpha': 0.1838640913593657}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:18,713] Trial 145 finished with value: 0.7015128504607095 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013088120547422252, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.026697649664492007, 'xgboost__min_child_weight': 39, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5343949315692096, 'xgboost__reg_lambda': 0.6878325648624358, 'xgboost__reg_alpha': 0.27693103655327084}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:18,887] Trial 146 finished with value: 0.7920872514528102 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0011327999203598876, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.0675311448683333, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5446104955582063, 'xgboost__reg_lambda': 1.1721162342972222, 'xgboost__reg_alpha': 0.24057362417042488}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:19,133] Trial 147 finished with value: 0.8256167082827834 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 150, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.010988250753267162, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.11029188420102434, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5070489719425385, 'xgboost__reg_lambda': 0.9507578882864456, 'xgboost__reg_alpha': 0.1664123533460142}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:19,352] Trial 148 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006618405730754787, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.05075401126530049, 'xgboost__min_child_weight': 148, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5609806263202401, 'xgboost__reg_lambda': 0.353604161635593, 'xgboost__reg_alpha': 0.20190545844449165}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:19,642] Trial 149 finished with value: 0.7824227995661613 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010029163530841002, 'xgboost__n_estimators': 255, 'xgboost__learning_rate': 0.018768275439158, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5268749039598298, 'xgboost__reg_lambda': 0.7895249544470513, 'xgboost__reg_alpha': 0.2299236549196764}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:19,839] Trial 150 finished with value: 0.6633756289176245 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.018392196309074984, 'xgboost__n_estimators': 270, 'xgboost__learning_rate': 0.1478007433793952, 'xgboost__min_child_weight': 49, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5718235394906204, 'xgboost__reg_lambda': 1.0737453866587157, 'xgboost__reg_alpha': 0.36077286768428085}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:20,187] Trial 151 finished with value: 0.8392088147427575 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.008209303899845862, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.04267921715792768, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5169895738415854, 'xgboost__reg_lambda': 0.6076001862512522, 'xgboost__reg_alpha': 0.1900746160249565}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:20,451] Trial 152 finished with value: 0.7653783156366818 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0034466835318024136, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.0012647949014405607, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5156289110673236, 'xgboost__reg_lambda': 0.5602341499858772, 'xgboost__reg_alpha': 0.2543480596634139}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:20,687] Trial 153 finished with value: 0.7881776097982062 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007275564863010534, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.038141160962920556, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5368376562279861, 'xgboost__reg_lambda': 0.8481721216890087, 'xgboost__reg_alpha': 0.209105563706654}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:20,976] Trial 154 finished with value: 0.8325339299822528 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.005273083131204998, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.06981695988560331, 'xgboost__min_child_weight': 4, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5496593969012878, 'xgboost__reg_lambda': 0.6902711997984814, 'xgboost__reg_alpha': 0.020111253406634645}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:21,616] Trial 155 finished with value: 0.8253707636039312 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.013716616870945695, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.08553747695935246, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5260178682802742, 'xgboost__reg_lambda': 0.23753246156389696, 'xgboost__reg_alpha': 0.15653684773079676}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:22,338] Trial 156 finished with value: 0.8316929234765538 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00983948570993784, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.04998629525553129, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.500546611205402, 'xgboost__reg_lambda': 0.43763866608715235, 'xgboost__reg_alpha': 0.19025222069277983}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:22,606] Trial 157 finished with value: 0.7861413909431137 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 330, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.002781734605920987, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.39299481727041724, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5415207705416921, 'xgboost__reg_lambda': 0.935775594095748, 'xgboost__reg_alpha': 0.12728838387705177}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:22,811] Trial 158 finished with value: 0.7976678855122432 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01590646356032722, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.025291831110239277, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5132925999101059, 'xgboost__reg_lambda': 0.643545945906215, 'xgboost__reg_alpha': 0.3042257941346706}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:23,093] Trial 159 finished with value: 0.720211054325194 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 430, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008041940454282066, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.12411172653926371, 'xgboost__min_child_weight': 36, 'xgboost__max_depth': 1, 'xgboost__subsample': 0.556200909262427, 'xgboost__reg_lambda': 0.7867347557372181, 'xgboost__reg_alpha': 0.23053714973882428}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:23,461] Trial 160 finished with value: 0.8193851559068951 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.004939362767832158, 'xgboost__n_estimators': 265, 'xgboost__learning_rate': 0.18620804565807186, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5323083442403738, 'xgboost__reg_lambda': 1.2420979729570945, 'xgboost__reg_alpha': 0.28256792021966115}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:24,004] Trial 161 finished with value: 0.8342789943602194 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007769048103789704, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.041963150969737885, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5186788284535033, 'xgboost__reg_lambda': 0.4747060877138816, 'xgboost__reg_alpha': 0.18114706659215823}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:24,251] Trial 162 finished with value: 0.7896518518105313 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.012337275494685896, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.08187383600287193, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5197397787591281, 'xgboost__reg_lambda': 0.36330019595542684, 'xgboost__reg_alpha': 0.17868824712467507}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:24,513] Trial 163 finished with value: 0.8116177266000588 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00912231928836255, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.053774821611847406, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.509833089161573, 'xgboost__reg_lambda': 0.4956191201820739, 'xgboost__reg_alpha': 0.20528578260395183}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:24,781] Trial 164 finished with value: 0.7945871837010827 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.006777877253860358, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.03566075048529262, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5472496555977365, 'xgboost__reg_lambda': 0.6064331306111542, 'xgboost__reg_alpha': 0.14436232961130224}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:25,421] Trial 165 finished with value: 0.8373954428871773 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.01078564809545394, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.09993725559957642, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5345564023156412, 'xgboost__reg_lambda': 0.735914166915784, 'xgboost__reg_alpha': 0.2555182177332379}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:25,956] Trial 166 finished with value: 0.8355618605618605 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.011379323534364853, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.09711762629272945, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5341606711509158, 'xgboost__reg_lambda': 0.706477920831927, 'xgboost__reg_alpha': 0.2622297802855267}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:26,187] Trial 167 finished with value: 0.7987479879484543 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.011612597746060653, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.10547696775480449, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5658091094460412, 'xgboost__reg_lambda': 0.7414273115714721, 'xgboost__reg_alpha': 0.2667689848888556}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:26,472] Trial 168 finished with value: 0.8042000592910578 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.015214474549646795, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.132589020004473, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5377616614101621, 'xgboost__reg_lambda': 0.8631651470379007, 'xgboost__reg_alpha': 0.31937087102503076}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:26,640] Trial 169 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.04217253051496733, 'xgboost__n_estimators': 10, 'xgboost__learning_rate': 0.10067384330682513, 'xgboost__min_child_weight': 34, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.7415420766444714, 'xgboost__reg_lambda': 0.5925832122343451, 'xgboost__reg_alpha': 0.2547518965709726}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:27,494] Trial 170 finished with value: 0.8286967169819097 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.010782862218698976, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.07237820976850959, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5522342476629515, 'xgboost__reg_lambda': 1.0047259484839968, 'xgboost__reg_alpha': 0.04509184400013737}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:28,028] Trial 171 finished with value: 0.8378144378144378 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.013347496723962678, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.08671912109779704, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5302883952075357, 'xgboost__reg_lambda': 0.31175756497193885, 'xgboost__reg_alpha': 0.21478678198603218}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:28,265] Trial 172 finished with value: 0.793915523120999 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.013087762938640229, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.5907491874402411, 'xgboost__min_child_weight': 13, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5285472620571924, 'xgboost__reg_lambda': 0.14571764183126473, 'xgboost__reg_alpha': 0.2241264546682709}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:28,503] Trial 173 finished with value: 0.8085986838613808 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.016226052801143434, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.09174080767634342, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5419563905215883, 'xgboost__reg_lambda': 1.9832144568634344, 'xgboost__reg_alpha': 0.2939466703051136}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:28,914] Trial 174 finished with value: 0.7892338374965742 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 380, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.019297618663794515, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.11418076258991988, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5726549018485142, 'xgboost__reg_lambda': 0.27680828636317334, 'xgboost__reg_alpha': 0.2148436135793518}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:29,170] Trial 175 finished with value: 0.7908705949302469 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.010511766721777428, 'xgboost__n_estimators': 460, 'xgboost__learning_rate': 0.06924133377509836, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5561171381368648, 'xgboost__reg_lambda': 0.705122692968297, 'xgboost__reg_alpha': 0.24243404832204157}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:29,397] Trial 176 finished with value: 0.7861413909431137 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.013058702871436872, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.1536030537449734, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5290636193447638, 'xgboost__reg_lambda': 0.39638250157498706, 'xgboost__reg_alpha': 0.27617679923631855}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:29,685] Trial 177 finished with value: 0.8217637955995697 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 10, 'fs_mb__threshold': 0.008992154890881149, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.08459834063460403, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.712559550937911, 'xgboost__reg_lambda': 0.7887227045565258, 'xgboost__reg_alpha': 0.16384076764743882}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:29,997] Trial 178 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 350, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.02270738115457746, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.0196795924105434, 'xgboost__min_child_weight': 22, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5382773073924114, 'xgboost__reg_lambda': 2.455039316184349, 'xgboost__reg_alpha': 0.0190355091524241}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:30,627] Trial 179 finished with value: 0.8282459903305827 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.011785079099043208, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.14122164333908144, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5588275438906957, 'xgboost__reg_lambda': 0.5388863142923868, 'xgboost__reg_alpha': 0.07596276083169241}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:30,898] Trial 180 finished with value: 0.8110302897809047 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.014621226776416436, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.05805516788448084, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5473028548888654, 'xgboost__reg_lambda': 0.031241842345695478, 'xgboost__reg_alpha': 0.24490453103977441}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:03:31,595] Trial 181 finished with value: 0.8430936814106018 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007080520935267898, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.03964636103580148, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5207237739239565, 'xgboost__reg_lambda': 0.4960559381392161, 'xgboost__reg_alpha': 0.19051249453054436}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:32,004] Trial 182 finished with value: 0.7800263052194589 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00559365309625885, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.002517633870496045, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5226779531224006, 'xgboost__reg_lambda': 0.6458757183345468, 'xgboost__reg_alpha': 0.1979435303407255}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:32,697] Trial 183 finished with value: 0.8258665082194494 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009527570468478385, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.06440055903333004, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.53363258291755, 'xgboost__reg_lambda': 0.2910850293209999, 'xgboost__reg_alpha': 0.22318257237180333}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:33,093] Trial 184 finished with value: 0.8187781478232847 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 450, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007356049564158338, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.10370739099416461, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5252246786829002, 'xgboost__reg_lambda': 0.9351814776200781, 'xgboost__reg_alpha': 0.26491383271294877}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:33,478] Trial 185 finished with value: 0.7873774620169777 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.005035312950855432, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.3236771019662027, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5469732820307387, 'xgboost__reg_lambda': 0.4662148538971199, 'xgboost__reg_alpha': 0.10642273341106367}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:33,741] Trial 186 finished with value: 0.7970354259972238 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011392555069658169, 'xgboost__n_estimators': 270, 'xgboost__learning_rate': 0.023863083472672752, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7924602029464155, 'xgboost__reg_lambda': 0.835724652961733, 'xgboost__reg_alpha': 0.16705336895384146}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:34,516] Trial 187 finished with value: 0.831578295761588 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014167602685073244, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.08325848803567273, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5130327550779127, 'xgboost__reg_lambda': 0.6901576497854816, 'xgboost__reg_alpha': 0.19222492458443652}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:34,828] Trial 188 finished with value: 0.8055700900518964 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008879919220556472, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.05170672024504776, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5347441664542855, 'xgboost__reg_lambda': 1.042454306844694, 'xgboost__reg_alpha': 0.12524628126345233}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:35,031] Trial 189 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.07050956084056825, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.1256224132235575, 'xgboost__min_child_weight': 32, 'xgboost__max_depth': 2, 'xgboost__subsample': 0.5647509276525292, 'xgboost__reg_lambda': 0.5771600779820154, 'xgboost__reg_alpha': 0.20967064558478277}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:35,286] Trial 190 finished with value: 0.7841037214125053 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 190, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.025946966821577114, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.24082729666099278, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5795008078785187, 'xgboost__reg_lambda': 0.3653018836646696, 'xgboost__reg_alpha': 0.22977761842773878}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:35,551] Trial 191 finished with value: 0.816648245033724 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007731662374409664, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.036936579328518584, 'xgboost__min_child_weight': 7, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5195339859574262, 'xgboost__reg_lambda': 0.4824339897895702, 'xgboost__reg_alpha': 0.17736197517145955}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:36,271] Trial 192 finished with value: 0.8307324920228146 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0065813580984450115, 'xgboost__n_estimators': 445, 'xgboost__learning_rate': 0.045978151822003634, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5195155263957234, 'xgboost__reg_lambda': 1.638640763905094, 'xgboost__reg_alpha': 0.15337746913339315}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:36,547] Trial 193 finished with value: 0.7980953128800914 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0029203178270867007, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.02290770805959834, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5072537167968878, 'xgboost__reg_lambda': 0.7158173596347503, 'xgboost__reg_alpha': 0.2521003486433405}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:37,103] Trial 194 finished with value: 0.8308426398386515 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.010056919121465136, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.07156165326738438, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5407194586795868, 'xgboost__reg_lambda': 0.48630287454046317, 'xgboost__reg_alpha': 0.17983051575029807}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:37,297] Trial 195 finished with value: 0.797369828801211 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007694820102612427, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.09100566538919233, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5262391067621929, 'xgboost__reg_lambda': 0.21186192017630118, 'xgboost__reg_alpha': 0.39643654221678576}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:37,563] Trial 196 finished with value: 0.7653783156366818 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.01196988467509794, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.0012862858487309795, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5514219034175462, 'xgboost__reg_lambda': 1.1424909862346349, 'xgboost__reg_alpha': 0.2814795263623535}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:37,889] Trial 197 finished with value: 0.7782441434430467 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.028285069461199696, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.2703161581157103, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5310893521302763, 'xgboost__reg_lambda': 0.828330722615938, 'xgboost__reg_alpha': 0.2026410918726689}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:38,081] Trial 198 finished with value: 0.7824349290287218 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03476796372222836, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.038910377343723865, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5001652472951511, 'xgboost__reg_lambda': 0.5950219973526635, 'xgboost__reg_alpha': 0.0006680897531336442}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:38,371] Trial 199 finished with value: 0.7868648656789576 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0049175532169241035, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.054990544946636716, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5162918935818765, 'xgboost__reg_lambda': 0.3739006975529982, 'xgboost__reg_alpha': 0.3043976043211016}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:38,586] Trial 200 finished with value: 0.8088460333753942 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01756405212941496, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.019415517465968892, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5424132310460824, 'xgboost__reg_lambda': 0.9428733931742839, 'xgboost__reg_alpha': 0.13373711507255853}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:38,780] Trial 201 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.001601610127777481, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.035698881020444675, 'xgboost__min_child_weight': 466, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5098675306245453, 'xgboost__reg_lambda': 0.8764450229987559, 'xgboost__reg_alpha': 0.23468992380706255}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:39,390] Trial 202 finished with value: 0.8332046981139647 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004331644701541895, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.061349404361546456, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6466499320486537, 'xgboost__reg_lambda': 0.7698490800661362, 'xgboost__reg_alpha': 0.257676041729184}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:39,908] Trial 203 finished with value: 0.8259860691507218 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0011164126222576894, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.20938745862990643, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5228082263165504, 'xgboost__reg_lambda': 0.6798073191929217, 'xgboost__reg_alpha': 0.21212651295001794}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:40,238] Trial 204 finished with value: 0.8244252915439678 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008699174068017186, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.11050530513358013, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6679458769343087, 'xgboost__reg_lambda': 0.8987623286877073, 'xgboost__reg_alpha': 0.24234077061859333}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:40,432] Trial 205 finished with value: 0.8037166422032569 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00334409621790965, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.07847501511331637, 'xgboost__min_child_weight': 26, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.8971174296293818, 'xgboost__reg_lambda': 0.9960726850683513, 'xgboost__reg_alpha': 0.2799378737267619}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:40,641] Trial 206 finished with value: 0.8016258850630973 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006766676678207484, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.04292072802680402, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.534765441570343, 'xgboost__reg_lambda': 0.5496246792979563, 'xgboost__reg_alpha': 0.22702230088478742}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:40,956] Trial 207 finished with value: 0.8122437851907783 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 170, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.01099245897123751, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.08834177565028309, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5099301961124358, 'xgboost__reg_lambda': 1.0894115808136797, 'xgboost__reg_alpha': 0.04923737682529418}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:41,491] Trial 208 finished with value: 0.8324148209994937 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012885520896030242, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.17087525419809252, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5555807357000143, 'xgboost__reg_lambda': 0.13699703906635508, 'xgboost__reg_alpha': 0.18472623811365613}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:41,817] Trial 209 finished with value: 0.7873778177760505 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006227190553245347, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.022016662743310145, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6126121538601874, 'xgboost__reg_lambda': 3.231038998779977, 'xgboost__reg_alpha': 0.2567098661348072}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:42,385] Trial 210 finished with value: 0.842016992554627 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009135912398802471, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.06102144894681829, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5188209786313331, 'xgboost__reg_lambda': 0.7955209143551796, 'xgboost__reg_alpha': 0.15495400190394354}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:42,939] Trial 211 finished with value: 0.8378144378144378 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009445657881914165, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.058444206714420875, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5174091039108232, 'xgboost__reg_lambda': 0.7532023554263942, 'xgboost__reg_alpha': 0.15319472684090876}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:43,220] Trial 212 finished with value: 0.8237623623277424 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009696327111072876, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.06567777273407405, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5275429126882542, 'xgboost__reg_lambda': 0.7151865110929473, 'xgboost__reg_alpha': 0.15074420973609926}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:43,470] Trial 213 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.008512899068323646, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.1033883774343542, 'xgboost__min_child_weight': 235, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5171308894463056, 'xgboost__reg_lambda': 0.6220328115046229, 'xgboost__reg_alpha': 0.15833389588615623}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:43,823] Trial 214 finished with value: 0.816648245033724 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 290, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.014110713451405589, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.05470775266676766, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5420600312439035, 'xgboost__reg_lambda': 0.7807039098200867, 'xgboost__reg_alpha': 0.1870100117680451}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:44,067] Trial 215 finished with value: 0.7975312513403748 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.010675015430210825, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.07603646523965402, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5322749591806765, 'xgboost__reg_lambda': 0.5130873591502731, 'xgboost__reg_alpha': 0.08953923506444944}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:44,610] Trial 216 finished with value: 0.841143726891318 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007632774266929996, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.12312491750905097, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5666607512586797, 'xgboost__reg_lambda': 0.4208931991837074, 'xgboost__reg_alpha': 0.13858206400757805}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:03:45,222] Trial 217 finished with value: 0.8441706327668782 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.012448856495061443, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.13178100232377266, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5655277836517807, 'xgboost__reg_lambda': 0.2426992798764932, 'xgboost__reg_alpha': 0.1076052096653588}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:45,521] Trial 218 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.015604577478567663, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.12563218901995454, 'xgboost__min_child_weight': 292, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5711833071012741, 'xgboost__reg_lambda': 0.2661118574627397, 'xgboost__reg_alpha': 0.12003326775665346}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:45,819] Trial 219 finished with value: 0.7899764470440789 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.012109971966934151, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.14396485846821405, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5651481232945131, 'xgboost__reg_lambda': 0.2011553162728601, 'xgboost__reg_alpha': 0.10647915264976528}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:46,165] Trial 220 finished with value: 0.8221598114348577 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.013529280214955003, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.1837386707000177, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5495695276360951, 'xgboost__reg_lambda': 0.3252695553376158, 'xgboost__reg_alpha': 0.13359771350502966}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:46,789] Trial 221 finished with value: 0.8298773245431845 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009985358572355366, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.12594182727220882, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5588168863850448, 'xgboost__reg_lambda': 0.8268942139761695, 'xgboost__reg_alpha': 0.14019006388824004}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:47,546] Trial 222 finished with value: 0.836320746795232 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 310, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00873277939974594, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.10165541777385478, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5870168362292099, 'xgboost__reg_lambda': 0.6584605232656248, 'xgboost__reg_alpha': 0.08395951006392777}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:47,942] Trial 223 finished with value: 0.7971283942905023 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 270, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.02435776370761611, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.10584000942171223, 'xgboost__min_child_weight': 12, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5928203189073409, 'xgboost__reg_lambda': 0.659302580908541, 'xgboost__reg_alpha': 0.08660503867461794}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:48,349] Trial 224 finished with value: 0.8019325823785515 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 300, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.02071332261648614, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.14747792704629129, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5841539529948823, 'xgboost__reg_lambda': 0.4325057998477156, 'xgboost__reg_alpha': 0.11567999537256056}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:48,663] Trial 225 finished with value: 0.7905395983113641 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.010907400782308703, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.9033814012149844, 'xgboost__min_child_weight': 20, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5684579794179603, 'xgboost__reg_lambda': 0.5815090588831606, 'xgboost__reg_alpha': 0.07226505136052869}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:49,034] Trial 226 finished with value: 0.8343143860458349 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00883161244857282, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.09450154596197818, 'xgboost__min_child_weight': 7, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5769549751049318, 'xgboost__reg_lambda': 0.7337510859042237, 'xgboost__reg_alpha': 0.06265458188656747}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:49,448] Trial 227 finished with value: 0.7705691213173758 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 250, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.05334635360428579, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.11197257153309886, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5462188624040863, 'xgboost__reg_lambda': 0.10009326834128818, 'xgboost__reg_alpha': 0.16575690392366582}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:49,815] Trial 228 finished with value: 0.8058345909773162 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 220, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.012409064427875198, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.3825501219109471, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5382215954277817, 'xgboost__reg_lambda': 0.41461671575101944, 'xgboost__reg_alpha': 0.5175018807159101}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:50,151] Trial 229 finished with value: 0.8181483434176061 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007683967372414358, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.09143302099845318, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5553118859845922, 'xgboost__reg_lambda': 0.6332826246256333, 'xgboost__reg_alpha': 0.028838400471877017}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:50,431] Trial 230 finished with value: 0.7887606220939554 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.014803832145147484, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.12198078723606005, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5313895629851241, 'xgboost__reg_lambda': 0.808696114783109, 'xgboost__reg_alpha': 0.09539945309147921}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:51,022] Trial 231 finished with value: 0.8424166030139313 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 320, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00561334480203614, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.2600631882030452, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5619885765801446, 'xgboost__reg_lambda': 0.9096694916771184, 'xgboost__reg_alpha': 0.1479549899308707}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:51,432] Trial 232 finished with value: 0.8301881376171062 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.005676836628039986, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.2594931505785489, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5646071583845538, 'xgboost__reg_lambda': 0.742248361073252, 'xgboost__reg_alpha': 0.1252447534112712}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:51,749] Trial 233 finished with value: 0.7890443887760493 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 310, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0404418161482457, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.15125172366807754, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5765488640940762, 'xgboost__reg_lambda': 0.8721847036377578, 'xgboost__reg_alpha': 0.14854043050109217}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:52,113] Trial 234 finished with value: 0.8265643452265937 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 330, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009846560677302767, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.19842034514171014, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5470983280209839, 'xgboost__reg_lambda': 0.026398400797590177, 'xgboost__reg_alpha': 0.16597024079797396}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:52,453] Trial 235 finished with value: 0.8069317513761957 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 310, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.005170706522620819, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.28157417439497834, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5550328105163123, 'xgboost__reg_lambda': 0.9284414550383955, 'xgboost__reg_alpha': 0.1980278250672745}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:53,014] Trial 236 finished with value: 0.8336108941149343 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 340, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.008082581133979373, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.352866023975816, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5949449922106336, 'xgboost__reg_lambda': 0.5298309062419799, 'xgboost__reg_alpha': 0.10306997020688397}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:53,366] Trial 237 finished with value: 0.8181483434176061 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 290, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.011521335744044757, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.16369126992721064, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5252408102204364, 'xgboost__reg_lambda': 0.31005104096493524, 'xgboost__reg_alpha': 0.04000989395206785}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:54,049] Trial 238 finished with value: 0.8322348731670277 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 400, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.003699254144764589, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.13364518757261173, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5396466537677269, 'xgboost__reg_lambda': 0.7023692897769808, 'xgboost__reg_alpha': 0.14334624860592513}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:54,589] Trial 239 finished with value: 0.8299829922699407 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009432536211169794, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.23614052757203757, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6364554727790718, 'xgboost__reg_lambda': 1.034016305260546, 'xgboost__reg_alpha': 0.019204432997009843}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:54,909] Trial 240 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 360, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.09536296494222007, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.06987777193070116, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5000146412491189, 'xgboost__reg_lambda': 0.8463447541831074, 'xgboost__reg_alpha': 0.16992691520342917}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:55,129] Trial 241 finished with value: 0.8125381575871466 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006663372345539977, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.2159558217599315, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5613523281957908, 'xgboost__reg_lambda': 1.0098440912527376, 'xgboost__reg_alpha': 0.20988011248472457}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:55,479] Trial 242 finished with value: 0.830450448445006 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 320, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.006975878884995731, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.08407128975960569, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5705784078682131, 'xgboost__reg_lambda': 0.9405263544267655, 'xgboost__reg_alpha': 0.3292798732587537}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:56,306] Trial 243 finished with value: 0.8430936814106018 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010910623277215068, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.04687401412359843, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5493684387514872, 'xgboost__reg_lambda': 0.8108607619064578, 'xgboost__reg_alpha': 0.36312106505123687}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:56,528] Trial 244 finished with value: 0.7836640737002963 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.031468248530167685, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.034343049023243824, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5486444700760219, 'xgboost__reg_lambda': 0.7492799999066665, 'xgboost__reg_alpha': 0.30313634039104564}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:56,810] Trial 245 finished with value: 0.8294337680869773 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012744671790122305, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.45786609360952346, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5321450295329502, 'xgboost__reg_lambda': 0.6145852606743305, 'xgboost__reg_alpha': 0.3594990116957632}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:57,032] Trial 246 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.010547692700550854, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.053175107849922604, 'xgboost__min_child_weight': 419, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5195700592026341, 'xgboost__reg_lambda': 0.8085735611281759, 'xgboost__reg_alpha': 0.9156931940386867}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:57,252] Trial 247 finished with value: 0.7793318132586108 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009185108481827405, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.015283518746350738, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5419945960138378, 'xgboost__reg_lambda': 1.3605057502951574, 'xgboost__reg_alpha': 0.18941927771692357}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:57,552] Trial 248 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 270, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.04563990687306094, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.10525994069061094, 'xgboost__min_child_weight': 181, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5811424402097959, 'xgboost__reg_lambda': 0.4147627200988209, 'xgboost__reg_alpha': 0.12035493832635775}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:58,206] Trial 249 finished with value: 0.8199046891587786 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 380, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013527902210104227, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.05681913170653289, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6854917426816498, 'xgboost__reg_lambda': 0.6556559345501773, 'xgboost__reg_alpha': 0.36672704008881446}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:58,726] Trial 250 finished with value: 0.8422206603780747 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01137302812312973, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.07519535954177065, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6102298612613218, 'xgboost__reg_lambda': 0.5319280291804067, 'xgboost__reg_alpha': 0.34230387139667023}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:58,943] Trial 251 finished with value: 0.7812216903838729 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.011802470084523857, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.027157099288057637, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5900511429262458, 'xgboost__reg_lambda': 0.515269369803175, 'xgboost__reg_alpha': 0.3920199996319459}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:59,200] Trial 252 finished with value: 0.8107217582139212 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 9, 'fs_mb__threshold': 0.016762153692022125, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.09574779713902956, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.608379443916427, 'xgboost__reg_lambda': 0.24629947049879727, 'xgboost__reg_alpha': 0.83792941959159}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:59,650] Trial 253 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008030901784821368, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.00043210186598976325, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5138925283706621, 'xgboost__reg_lambda': 0.4521652242217738, 'xgboost__reg_alpha': 0.4117254532835532}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:03:59,992] Trial 254 finished with value: 0.7854577251989087 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.004322939863824003, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.04503064291761955, 'xgboost__min_child_weight': 21, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6000120632707683, 'xgboost__reg_lambda': 0.5729472982243216, 'xgboost__reg_alpha': 0.21901677177951717}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:00,238] Trial 255 finished with value: 0.8266849834247955 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01543599708258022, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.07251355817322086, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5253185425202757, 'xgboost__reg_lambda': 0.3586785369539395, 'xgboost__reg_alpha': 0.0020131806706350005}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:00,549] Trial 256 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 210, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.011194434978893851, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.12264760518427997, 'xgboost__min_child_weight': 350, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5332588682711231, 'xgboost__reg_lambda': 0.16225020043335608, 'xgboost__reg_alpha': 0.1527049200754613}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:00,985] Trial 257 finished with value: 0.8271746126974008 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00603338395308114, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.16908832178355926, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.549140784365918, 'xgboost__reg_lambda': 0.7132332312962838, 'xgboost__reg_alpha': 0.29040627532217306}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:01,235] Trial 258 finished with value: 0.7879171507698155 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.01890035566076452, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.03392908501851056, 'xgboost__min_child_weight': 13, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5392840835077888, 'xgboost__reg_lambda': 1.2068439612311908, 'xgboost__reg_alpha': 0.24101110016654875}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:01,556] Trial 259 finished with value: 0.7763949608443991 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013687554930972377, 'xgboost__n_estimators': 455, 'xgboost__learning_rate': 0.776483084125839, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5099656702088439, 'xgboost__reg_lambda': 0.8831457246312475, 'xgboost__reg_alpha': 0.05463227328219635}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:01,780] Trial 260 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.08654501089975572, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.06224763332314075, 'xgboost__min_child_weight': 161, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5698678342493315, 'xgboost__reg_lambda': 0.5845942814960233, 'xgboost__reg_alpha': 0.17684014648583068}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:02,077] Trial 261 finished with value: 0.8117584992659643 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.008610861863614434, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.2977118336327346, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5231886789015541, 'xgboost__reg_lambda': 0.6421243327451731, 'xgboost__reg_alpha': 0.2637376051428995}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:02,376] Trial 262 finished with value: 0.7680266197086469 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0029519318192181955, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.0870380926114164, 'xgboost__min_child_weight': 34, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5571853155896472, 'xgboost__reg_lambda': 0.4922031774857398, 'xgboost__reg_alpha': 0.20423710801066822}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:02,650] Trial 263 finished with value: 0.8241668931324104 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 190, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.0106021737183383, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.11075402437126662, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5368853603052656, 'xgboost__reg_lambda': 1.0969359930820608, 'xgboost__reg_alpha': 0.0817090113279563}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:03,326] Trial 264 finished with value: 0.7980953128800914 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.023388126336685588, 'xgboost__n_estimators': 465, 'xgboost__learning_rate': 0.013712178679100732, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5787043675976488, 'xgboost__reg_lambda': 0.3187040330360263, 'xgboost__reg_alpha': 0.34417457478655333}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:03,543] Trial 265 finished with value: 0.7906392011470801 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012839793618878492, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.13455428445949613, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.54941817698787, 'xgboost__reg_lambda': 0.7596508462196684, 'xgboost__reg_alpha': 0.13678471617656085}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:03,900] Trial 266 finished with value: 0.8158751977103262 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.006980851997480077, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.05063971317612747, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5890600736310865, 'xgboost__reg_lambda': 0.9556128748509636, 'xgboost__reg_alpha': 0.10915955362344985}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:04,139] Trial 267 finished with value: 0.7919443994310305 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 150, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0051125637849104705, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.07845903135491505, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5154794283415394, 'xgboost__reg_lambda': 0.8455678977713083, 'xgboost__reg_alpha': 0.22870217423371375}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:04,765] Trial 268 finished with value: 0.8377126792460198 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009333219892574275, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.1882521109712161, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5615894810219049, 'xgboost__reg_lambda': 1.5946584782856026, 'xgboost__reg_alpha': 0.1897831171679617}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:05,351] Trial 269 finished with value: 0.8339520788661303 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00902758656994226, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.22030854535629987, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5632199891178044, 'xgboost__reg_lambda': 1.292655288973198, 'xgboost__reg_alpha': 0.19356836148318524}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:05,547] Trial 270 finished with value: 0.7854577251989087 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0010370712776251777, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.15366841290894884, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5697556740382382, 'xgboost__reg_lambda': 1.079888161827171, 'xgboost__reg_alpha': 0.16708358502856485}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:05,791] Trial 271 finished with value: 0.816294439042688 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0148281047712465, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.258033438510866, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5596014665506788, 'xgboost__reg_lambda': 1.6174763202891684, 'xgboost__reg_alpha': 0.20863479374407007}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:06,497] Trial 272 finished with value: 0.8419122361403112 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011539790789436188, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.11304242185353798, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6326441705187609, 'xgboost__reg_lambda': 1.1632177006493891, 'xgboost__reg_alpha': 0.17777052877783986}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:06,695] Trial 273 finished with value: 0.8054162864704432 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010269255866297271, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.18832714468069892, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6242777127809973, 'xgboost__reg_lambda': 1.3467082469406966, 'xgboost__reg_alpha': 0.1789115521059387}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:07,398] Trial 274 finished with value: 0.8314615624133674 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.017247163260461093, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.11956382835506629, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6162983806231607, 'xgboost__reg_lambda': 1.4820366295509446, 'xgboost__reg_alpha': 0.15452373853142257}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:07,618] Trial 275 finished with value: 0.8113012273027473 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01245944301564713, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.14010540163510646, 'xgboost__min_child_weight': 14, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.633620189408723, 'xgboost__reg_lambda': 1.194890187712644, 'xgboost__reg_alpha': 0.18998440276661577}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:07,900] Trial 276 finished with value: 0.8230983487077738 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007590599788785324, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.17519245914518952, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5951920338442888, 'xgboost__reg_lambda': 1.8624303312800525, 'xgboost__reg_alpha': 0.13526873707436698}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:08,121] Trial 277 finished with value: 0.7847609833004587 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009523848978505816, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.11051392431070588, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6081102422593029, 'xgboost__reg_lambda': 1.1549185239994486, 'xgboost__reg_alpha': 0.15614322565576247}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:08,437] Trial 278 finished with value: 0.8316929234765538 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02082908176806015, 'xgboost__n_estimators': 95, 'xgboost__learning_rate': 0.19622833377629134, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6224700021515498, 'xgboost__reg_lambda': 1.4630388144488142, 'xgboost__reg_alpha': 0.21899779260282032}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:08,818] Trial 279 finished with value: 0.698604409616048 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.0253059024193115, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.09220603799861832, 'xgboost__min_child_weight': 38, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5798282327298946, 'xgboost__reg_lambda': 1.2419844825779598, 'xgboost__reg_alpha': 0.1782677637441045}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:09,039] Trial 280 finished with value: 0.8072225594892407 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01465969788843274, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.5863883842511539, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.640096252233623, 'xgboost__reg_lambda': 0.9975730037773519, 'xgboost__reg_alpha': 0.11977149649857552}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:09,344] Trial 281 finished with value: 0.8199916193458224 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011866637185919023, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.1561385662488388, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6014913868042638, 'xgboost__reg_lambda': 1.1135167234767906, 'xgboost__reg_alpha': 0.19763263495604247}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:09,590] Trial 282 finished with value: 0.818288707177596 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008151675684346759, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.06047523530434459, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.7123529303534778, 'xgboost__reg_lambda': 1.570301126272946, 'xgboost__reg_alpha': 0.3770149823161018}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:09,796] Trial 283 finished with value: 0.7926485741831626 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003722285847005919, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.1327395431466635, 'xgboost__min_child_weight': 21, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5523440225965836, 'xgboost__reg_lambda': 0.9186530698279255, 'xgboost__reg_alpha': 0.4136550504314719}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:10,319] Trial 284 finished with value: 0.7961645174882984 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03744532120197562, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.033895313409187805, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5738872138839533, 'xgboost__reg_lambda': 2.177815526062727, 'xgboost__reg_alpha': 0.31080994800954903}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:10,511] Trial 285 finished with value: 0.7685704913749558 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.046649972012846756, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.07644330888735552, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5867804691692756, 'xgboost__reg_lambda': 2.772291738955607, 'xgboost__reg_alpha': 0.16648609082398408}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:10,705] Trial 286 finished with value: 0.7895358849776961 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005410324665028993, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.23567043340715968, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.543110053357288, 'xgboost__reg_lambda': 1.3100928703100005, 'xgboost__reg_alpha': 0.23479461489510856}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:10,958] Trial 287 finished with value: 0.8413588024167761 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010481803502830359, 'xgboost__n_estimators': 45, 'xgboost__learning_rate': 0.10809738869063583, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5620490015272609, 'xgboost__reg_lambda': 1.036462963576902, 'xgboost__reg_alpha': 0.13914339597038614}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:11,177] Trial 288 finished with value: 0.8193549518567049 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011252036311418282, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.10788072270882676, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5641927014551485, 'xgboost__reg_lambda': 0.9940279427901342, 'xgboost__reg_alpha': 0.0898490508300077}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:11,721] Trial 289 finished with value: 0.8288041288041289 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.013621586585054388, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.1372951446636852, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5677532710223696, 'xgboost__reg_lambda': 0.8439458735854385, 'xgboost__reg_alpha': 0.1295558338021007}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:11,934] Trial 290 finished with value: 0.8037475645929483 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009695533109029607, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.1224856062322622, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5534297058611787, 'xgboost__reg_lambda': 0.7958147054892434, 'xgboost__reg_alpha': 0.1463520018346043}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:12,216] Trial 291 finished with value: 0.7868648656789576 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.008316040739441071, 'xgboost__n_estimators': 145, 'xgboost__learning_rate': 0.42351313624156606, 'xgboost__min_child_weight': 29, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5854036441692182, 'xgboost__reg_lambda': 4.631246690665893, 'xgboost__reg_alpha': 0.10538718813350338}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:12,459] Trial 292 finished with value: 0.8062783562783562 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02935553769882141, 'xgboost__n_estimators': 125, 'xgboost__learning_rate': 0.3226872758444521, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5735925698352984, 'xgboost__reg_lambda': 1.0374838363309935, 'xgboost__reg_alpha': 0.4361560818495976}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:12,706] Trial 293 finished with value: 0.76699311085276 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.06304025779204867, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.9683642581373981, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6130787045976854, 'xgboost__reg_lambda': 1.810515744245055, 'xgboost__reg_alpha': 0.27898929644585274}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:13,034] Trial 294 finished with value: 0.7825352736490705 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 290, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0343705196092702, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.097338839900326, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.66189931570148, 'xgboost__reg_lambda': 0.10907223191328558, 'xgboost__reg_alpha': 0.2482855381870737}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:13,199] Trial 295 finished with value: 0.8073805470574537 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012412191788674962, 'xgboost__n_estimators': 60, 'xgboost__learning_rate': 0.1786778239942558, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6459607902443818, 'xgboost__reg_lambda': 0.6696567331260878, 'xgboost__reg_alpha': 0.33230252245539493}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:13,444] Trial 296 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.026516448491991022, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.04665770231114884, 'xgboost__min_child_weight': 195, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.559378681200603, 'xgboost__reg_lambda': 0.9293856233959119, 'xgboost__reg_alpha': 0.4856224074866434}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:13,766] Trial 297 finished with value: 0.7920877747784719 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 240, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.01623416128342146, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.49189414519632557, 'xgboost__min_child_weight': 35, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.7636671819661973, 'xgboost__reg_lambda': 0.5498870211636626, 'xgboost__reg_alpha': 0.13712563861417632}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:14,086] Trial 298 finished with value: 0.7747051016887347 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0312669542273283, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.15930431481506457, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5081281215733515, 'xgboost__reg_lambda': 0.20011371849607557, 'xgboost__reg_alpha': 0.07288076486418867}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:14,323] Trial 299 finished with value: 0.7872728299774563 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.010260436598409129, 'xgboost__n_estimators': 175, 'xgboost__learning_rate': 0.08205361585647122, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5459815176856258, 'xgboost__reg_lambda': 0.4391753921861713, 'xgboost__reg_alpha': 0.21037279806711948}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:14,653] Trial 300 finished with value: 0.8032096761263428 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006626117921869568, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.021078672022101053, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5275606067338722, 'xgboost__reg_lambda': 0.7642516042639639, 'xgboost__reg_alpha': 0.16530244729831217}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:14,824] Trial 301 finished with value: 0.7833282360534863 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.013836356878641468, 'xgboost__n_estimators': 45, 'xgboost__learning_rate': 0.29538926925930825, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5538490086933594, 'xgboost__reg_lambda': 0.8730759197713918, 'xgboost__reg_alpha': 0.22224958572679215}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:15,710] Trial 302 finished with value: 0.8309507075479371 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 140, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.011037748103663206, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.10289084422051856, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6688311341906557, 'xgboost__reg_lambda': 0.6228322018109921, 'xgboost__reg_alpha': 0.11142250410469531}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:16,029] Trial 303 finished with value: 0.8051010269042874 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 320, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008260659417731776, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.06246900715172729, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6026405251616588, 'xgboost__reg_lambda': 1.0468256761834356, 'xgboost__reg_alpha': 0.35189711590227907}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:16,458] Trial 304 finished with value: 0.7874839707995865 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.018714679942832275, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.12136159195218844, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.8415002636665916, 'xgboost__reg_lambda': 0.3469843436949646, 'xgboost__reg_alpha': 0.3138065981937931}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:16,930] Trial 305 finished with value: 0.8413588024167761 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012538830220671695, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.013504638125174159, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5805044935156658, 'xgboost__reg_lambda': 0.7570927284954254, 'xgboost__reg_alpha': 0.18987012625938904}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:17,131] Trial 306 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.016186942106493366, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.004362214171176056, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 2, 'xgboost__subsample': 0.5621782221076325, 'xgboost__reg_lambda': 0.7880234687275721, 'xgboost__reg_alpha': 0.19131616215320735}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:17,358] Trial 307 finished with value: 0.8063200967644926 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013019729519517603, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.024042447704748608, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.542534786317215, 'xgboost__reg_lambda': 0.9332158721836087, 'xgboost__reg_alpha': 0.24467845556864548}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:04:17,868] Trial 308 finished with value: 0.8483753149839316 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014786397422246855, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.042289699821556635, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5762647144791538, 'xgboost__reg_lambda': 1.1767648359962473, 'xgboost__reg_alpha': 0.17598211062914615}. Best is trial 308 with value: 0.8483753149839316.\n",
      "[I 2024-01-07 21:04:18,109] Trial 309 finished with value: 0.8175631404471531 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014573628773102443, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.03860975853795915, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6279450463703858, 'xgboost__reg_lambda': 1.1986596053459169, 'xgboost__reg_alpha': 0.1748077156217706}. Best is trial 308 with value: 0.8483753149839316.\n",
      "[I 2024-01-07 21:04:18,601] Trial 310 finished with value: 0.8494535614900911 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014895086882852264, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.01989443319536055, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5217780906850982, 'xgboost__reg_lambda': 0.01884598643476665, 'xgboost__reg_alpha': 0.15666753885860543}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:18,884] Trial 311 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.020629581874102243, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.011913145505008202, 'xgboost__min_child_weight': 99, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5771204223288919, 'xgboost__reg_lambda': 0.25857847859266986, 'xgboost__reg_alpha': 0.1606819582911032}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:19,182] Trial 312 finished with value: 0.7887689710746011 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01771804299140449, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.03398839251604778, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5063309360355646, 'xgboost__reg_lambda': 0.022593367332130385, 'xgboost__reg_alpha': 0.14876508266319208}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:19,437] Trial 313 finished with value: 0.7014478973121837 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015029830688143151, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.017605773238403448, 'xgboost__min_child_weight': 40, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5198221645138739, 'xgboost__reg_lambda': 0.05546494174594967, 'xgboost__reg_alpha': 0.1902204557153022}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:19,693] Trial 314 finished with value: 0.7819464486131154 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01548807088587929, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.04987017296184043, 'xgboost__min_child_weight': 30, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.580318658136653, 'xgboost__reg_lambda': 0.0052695767268836, 'xgboost__reg_alpha': 0.17083655834758835}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:20,066] Trial 315 finished with value: 0.7653783156366818 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012764750867125942, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.0009550794691439782, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5912686117040656, 'xgboost__reg_lambda': 0.16455830866727697, 'xgboost__reg_alpha': 0.20407940146460674}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:20,688] Trial 316 finished with value: 0.842772866949383 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01850516445652279, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.03653244038313204, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6580899747063379, 'xgboost__reg_lambda': 1.7270061505257428, 'xgboost__reg_alpha': 0.1410496144219892}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:20,930] Trial 317 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01702627911736749, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.03201045708993177, 'xgboost__min_child_weight': 125, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6457643563192975, 'xgboost__reg_lambda': 1.430979367872213, 'xgboost__reg_alpha': 0.15886261070135457}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:21,181] Trial 318 finished with value: 0.8031404535636645 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011482355997812504, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.04961017423322252, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6286506643302108, 'xgboost__reg_lambda': 1.7433285779671037, 'xgboost__reg_alpha': 0.14023930506228907}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:21,406] Trial 319 finished with value: 0.7918684719810437 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.018690224868945324, 'xgboost__n_estimators': 210, 'xgboost__learning_rate': 0.01833676854376334, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6347903066192724, 'xgboost__reg_lambda': 1.5112037993169498, 'xgboost__reg_alpha': 0.18528603945205896}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:21,990] Trial 320 finished with value: 0.8408360365388119 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01391200089081485, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.040328020964385446, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6142301614825284, 'xgboost__reg_lambda': 1.08316565883607, 'xgboost__reg_alpha': 0.13014866825404875}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:22,302] Trial 321 finished with value: 0.8389741379263068 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014117719662893526, 'xgboost__n_estimators': 100, 'xgboost__learning_rate': 0.034734137576739293, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6071896575278755, 'xgboost__reg_lambda': 1.127625553364406, 'xgboost__reg_alpha': 0.1254238672716365}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:22,543] Trial 322 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014448719733617204, 'xgboost__n_estimators': 110, 'xgboost__learning_rate': 0.00042667494124380874, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6056440807674236, 'xgboost__reg_lambda': 1.1777464188746014, 'xgboost__reg_alpha': 0.12721008253815128}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:22,765] Trial 323 finished with value: 0.7653783156366818 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.016856362831423992, 'xgboost__n_estimators': 35, 'xgboost__learning_rate': 0.030138125258075948, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6182998778359149, 'xgboost__reg_lambda': 1.020477265391678, 'xgboost__reg_alpha': 0.12516716639974387}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:23,355] Trial 324 finished with value: 0.8438492049834518 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013677707377188061, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.03720404831289152, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6086163732858537, 'xgboost__reg_lambda': 1.0890542355058588, 'xgboost__reg_alpha': 0.14711614006493057}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:23,560] Trial 325 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01967183886364995, 'xgboost__n_estimators': 60, 'xgboost__learning_rate': 0.03995690223320449, 'xgboost__min_child_weight': 22, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.609535459521988, 'xgboost__reg_lambda': 1.1475039074522553, 'xgboost__reg_alpha': 0.14174151842612873}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:23,790] Trial 326 finished with value: 0.780804034440973 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013501578160259398, 'xgboost__n_estimators': 70, 'xgboost__learning_rate': 0.02296357094719637, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6057350656917471, 'xgboost__reg_lambda': 1.2983509405069047, 'xgboost__reg_alpha': 0.11974742395365497}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:24,084] Trial 327 finished with value: 0.8085986838613808 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.021765046807067107, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.05065002534641873, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6159527049825235, 'xgboost__reg_lambda': 1.078825954390164, 'xgboost__reg_alpha': 0.14741515442087985}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:24,361] Trial 328 finished with value: 0.7826579574026585 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01605430883169054, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.023728679148590025, 'xgboost__min_child_weight': 32, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6253620106829123, 'xgboost__reg_lambda': 1.2830539961300402, 'xgboost__reg_alpha': 0.3786574946186514}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:24,569] Trial 329 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011781023763017092, 'xgboost__n_estimators': 35, 'xgboost__learning_rate': 0.0001314817271862584, 'xgboost__min_child_weight': 495, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5943531186295218, 'xgboost__reg_lambda': 1.2074421294860522, 'xgboost__reg_alpha': 0.16123067334502972}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:24,872] Trial 330 finished with value: 0.7810087406047 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.05544428546685071, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.04260466892504977, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6192736227150514, 'xgboost__reg_lambda': 1.068553784696065, 'xgboost__reg_alpha': 0.11985135831133756}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:25,161] Trial 331 finished with value: 0.8231908107142042 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015109264378214044, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.06315189640557219, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6049049318737894, 'xgboost__reg_lambda': 0.9367845873337115, 'xgboost__reg_alpha': 0.13718700113314197}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:25,712] Trial 332 finished with value: 0.847709043969658 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012342921069559814, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.018246075872017473, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6174469264940462, 'xgboost__reg_lambda': 1.1152280230600773, 'xgboost__reg_alpha': 0.10737683205319622}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:25,965] Trial 333 finished with value: 0.7984269526147151 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011756925628695453, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.022271545816076755, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6145141096851445, 'xgboost__reg_lambda': 0.9724373813869649, 'xgboost__reg_alpha': 0.05290019746931092}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:26,243] Trial 334 finished with value: 0.8164453086732879 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012634956232510819, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.014677973996866354, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6380508820770819, 'xgboost__reg_lambda': 0.8575162192015808, 'xgboost__reg_alpha': 0.45568543316224164}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:26,484] Trial 335 finished with value: 0.7774731941267188 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03226692090102471, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.06254053725128986, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6345997813565343, 'xgboost__reg_lambda': 1.3438031210559114, 'xgboost__reg_alpha': 0.17390336133966483}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:27,131] Trial 336 finished with value: 0.8303894560579054 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 460, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010197952857616412, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.3130778939485399, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.625669320970335, 'xgboost__reg_lambda': 1.953688494296242, 'xgboost__reg_alpha': 0.0983750208426758}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:27,406] Trial 337 finished with value: 0.8143705834813479 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005804727889749519, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.044273204406163495, 'xgboost__min_child_weight': 15, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.653736998956946, 'xgboost__reg_lambda': 2.154732671324502, 'xgboost__reg_alpha': 0.09189748475802303}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:27,647] Trial 338 finished with value: 0.8307162756393022 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.017687706642617634, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.071722552484179, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5966342293476035, 'xgboost__reg_lambda': 1.429417566981435, 'xgboost__reg_alpha': 0.5258959609344256}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:27,993] Trial 339 finished with value: 0.7786883458613796 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 420, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03520167092162116, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.023628055421889525, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6270446039905293, 'xgboost__reg_lambda': 1.0304182700151518, 'xgboost__reg_alpha': 0.1724158169740299}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:28,197] Trial 340 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011269938098533005, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.00221373401083055, 'xgboost__min_child_weight': 32, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6472560317415227, 'xgboost__reg_lambda': 1.1283274819005589, 'xgboost__reg_alpha': 0.35642580658671735}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:28,388] Trial 341 finished with value: 0.7845364992459607 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04922244264208889, 'xgboost__n_estimators': 270, 'xgboost__learning_rate': 0.051737405081343786, 'xgboost__min_child_weight': 20, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6152851730181519, 'xgboost__reg_lambda': 1.239049939625161, 'xgboost__reg_alpha': 0.20522737097629798}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:28,654] Trial 342 finished with value: 0.7975214730294302 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03998086871692631, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.03891685673591862, 'xgboost__min_child_weight': 15, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5940585804304168, 'xgboost__reg_lambda': 0.8803971437641809, 'xgboost__reg_alpha': 0.07249153382405057}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:28,889] Trial 343 finished with value: 0.8233561626751421 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014377782885873781, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.26611690145626765, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.9980639127854269, 'xgboost__reg_lambda': 0.109625990869252, 'xgboost__reg_alpha': 0.10597895470791478}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:29,094] Trial 344 finished with value: 0.6715094130188469 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.037497309117896865, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.06449908222201374, 'xgboost__min_child_weight': 44, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5818130203115239, 'xgboost__reg_lambda': 0.9536802673917459, 'xgboost__reg_alpha': 0.1444857942152481}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:29,449] Trial 345 finished with value: 0.7797203838600735 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04408257829810083, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.02086133879762249, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6709798608715154, 'xgboost__reg_lambda': 1.7611345070839557, 'xgboost__reg_alpha': 0.029657701271299616}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:29,662] Trial 346 finished with value: 0.7851599776733467 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007341042327352528, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.07027454428155777, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6020191335609549, 'xgboost__reg_lambda': 1.1413086623587254, 'xgboost__reg_alpha': 0.22613399634703263}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:29,946] Trial 347 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010228717590694394, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.00030120272422801825, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6789787837676109, 'xgboost__reg_lambda': 1.0024993411372363, 'xgboost__reg_alpha': 0.18438500903792907}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:30,325] Trial 348 finished with value: 0.7885189129650848 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02808621629157223, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.2204314818934126, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7112470969216472, 'xgboost__reg_lambda': 1.3843615740891115, 'xgboost__reg_alpha': 0.16152133554358059}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:30,540] Trial 349 finished with value: 0.8029822757194673 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0126826599726803, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.0430360669047643, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6383505374081672, 'xgboost__reg_lambda': 0.8326357335956224, 'xgboost__reg_alpha': 0.20176233428591106}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:30,733] Trial 350 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004014276298538239, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.07954863138191956, 'xgboost__min_child_weight': 384, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6783755691888996, 'xgboost__reg_lambda': 0.6891652876606343, 'xgboost__reg_alpha': 0.10202497972701141}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:30,982] Trial 351 finished with value: 0.812846100705431 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00844990562356882, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.03149308735305227, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7225135072904281, 'xgboost__reg_lambda': 1.2379539762349634, 'xgboost__reg_alpha': 0.1493626080867401}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:31,238] Trial 352 finished with value: 0.8102658928306273 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.022801522152070923, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.253048521660342, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6497420516467022, 'xgboost__reg_lambda': 1.9005786462931755, 'xgboost__reg_alpha': 0.40463409946329}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:31,450] Trial 353 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.016866599885454123, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.3425273767399237, 'xgboost__min_child_weight': 326, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6225134681803689, 'xgboost__reg_lambda': 2.097438892791105, 'xgboost__reg_alpha': 0.3237766378985528}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:31,700] Trial 354 finished with value: 0.7789616925097669 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.060245786197554815, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.052764758164750736, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5691778087255066, 'xgboost__reg_lambda': 0.8999294740422787, 'xgboost__reg_alpha': 0.17537079996754557}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:31,902] Trial 355 finished with value: 0.7824349290287218 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012938308650734257, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.018620274700475253, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6634790493218516, 'xgboost__reg_lambda': 1.7255903572740148, 'xgboost__reg_alpha': 0.2885601820582483}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:32,255] Trial 356 finished with value: 0.8054162864704432 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 440, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009762763522766891, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.07860156941979972, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6537365252627452, 'xgboost__reg_lambda': 1.5604676525271153, 'xgboost__reg_alpha': 0.686220208811904}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:32,503] Trial 357 finished with value: 0.8161920989962648 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.005781274565593372, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.05205161639745791, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5031004324268137, 'xgboost__reg_lambda': 0.19927182755317552, 'xgboost__reg_alpha': 0.2257641552813076}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:33,002] Trial 358 finished with value: 0.7972347107966655 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015434243922183025, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.3687029565820086, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.527869531170581, 'xgboost__reg_lambda': 0.5385797826391339, 'xgboost__reg_alpha': 0.13187072124840032}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:33,206] Trial 359 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010711234816099065, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.03324327245747095, 'xgboost__min_child_weight': 267, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.9476213855531406, 'xgboost__reg_lambda': 1.0673412494475607, 'xgboost__reg_alpha': 0.19862613920416008}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:33,474] Trial 360 finished with value: 0.7937664431418092 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 260, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007624351271174383, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.5635743175239643, 'xgboost__min_child_weight': 21, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.7003442470837631, 'xgboost__reg_lambda': 1.6590979540245145, 'xgboost__reg_alpha': 0.39058536474376426}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:33,714] Trial 361 finished with value: 0.7975276488053207 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02400817719233475, 'xgboost__n_estimators': 255, 'xgboost__learning_rate': 0.5095664748379056, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5859664607439655, 'xgboost__reg_lambda': 0.7766313283867338, 'xgboost__reg_alpha': 0.043831017598937594}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:33,930] Trial 362 finished with value: 0.7842255075173541 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.052275041132701705, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.6650880167327308, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5463896311403943, 'xgboost__reg_lambda': 0.4112502794269988, 'xgboost__reg_alpha': 0.07226102083527763}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:34,168] Trial 363 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.0029121365667962454, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.0007136417145930732, 'xgboost__min_child_weight': 36, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7597411668371109, 'xgboost__reg_lambda': 0.9721042653925117, 'xgboost__reg_alpha': 0.1560475996126038}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:34,546] Trial 364 finished with value: 0.7954168863448068 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02999951989937747, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.06930819323352137, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5156303925508091, 'xgboost__reg_lambda': 0.6882112539427042, 'xgboost__reg_alpha': 0.42261739146671606}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:34,833] Trial 365 finished with value: 0.7711471826879223 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 10, 'fs_mb__threshold': 0.02009192161971113, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.03652445573938532, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.5717403350389288, 'xgboost__reg_lambda': 0.008060929142955572, 'xgboost__reg_alpha': 0.3703583606355775}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:35,052] Trial 366 finished with value: 0.8266907716530778 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013196162049561071, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.4886525929162133, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6592580387880288, 'xgboost__reg_lambda': 0.8289755349717768, 'xgboost__reg_alpha': 0.26032405165851763}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:35,508] Trial 367 finished with value: 0.7903450085268269 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.03377420003927692, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.08709247312052035, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5377006349343301, 'xgboost__reg_lambda': 0.5739194166820643, 'xgboost__reg_alpha': 0.12273586670139469}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:35,817] Trial 368 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.08995475114300967, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.2857730601451093, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 1, 'xgboost__subsample': 0.6126939272746206, 'xgboost__reg_lambda': 1.0773690529011049, 'xgboost__reg_alpha': 0.9975959522361048}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:36,065] Trial 369 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.011414696689830956, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.015976017916771276, 'xgboost__min_child_weight': 237, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5966005591738086, 'xgboost__reg_lambda': 1.1631899646582553, 'xgboost__reg_alpha': 0.1839568589720777}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:36,269] Trial 370 finished with value: 0.8169392336059003 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00876273580317855, 'xgboost__n_estimators': 230, 'xgboost__learning_rate': 0.4564135307182422, 'xgboost__min_child_weight': 15, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5220829080212843, 'xgboost__reg_lambda': 2.062491687604142, 'xgboost__reg_alpha': 0.21423829051762702}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:36,779] Trial 371 finished with value: 0.8298773245431845 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006637546378952921, 'xgboost__n_estimators': 485, 'xgboost__learning_rate': 0.3869790215562393, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5541369926865753, 'xgboost__reg_lambda': 0.2780961129882993, 'xgboost__reg_alpha': 0.10407863613658284}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:36,959] Trial 372 finished with value: 0.7975776801974926 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04783257812967895, 'xgboost__n_estimators': 195, 'xgboost__learning_rate': 0.20754461820809578, 'xgboost__min_child_weight': 15, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6315551461739761, 'xgboost__reg_lambda': 1.852752804520542, 'xgboost__reg_alpha': 0.23513100673478332}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:37,223] Trial 373 finished with value: 0.8174108299565179 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015333612460380924, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.06316319270453015, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.577393957893666, 'xgboost__reg_lambda': 1.9532086929198518, 'xgboost__reg_alpha': 0.15218298243279224}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:37,429] Trial 374 finished with value: 0.7889696773040504 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00484618535591233, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.396869871087452, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5005516268153352, 'xgboost__reg_lambda': 0.8695130129427123, 'xgboost__reg_alpha': 0.1812968054376742}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:37,898] Trial 375 finished with value: 0.8275148716810447 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012191067396902977, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.2340225356069876, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5311414806824268, 'xgboost__reg_lambda': 0.9858034516367302, 'xgboost__reg_alpha': 0.45843083783851396}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:38,151] Trial 376 finished with value: 0.8146662261898195 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.018163552630911448, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.04925690547597453, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.545555909780188, 'xgboost__reg_lambda': 0.09246058088173725, 'xgboost__reg_alpha': 0.2957391027449086}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:38,449] Trial 377 finished with value: 0.8048087287663259 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009730903737440285, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.4080121259279034, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7405658144718987, 'xgboost__reg_lambda': 0.7555788996768114, 'xgboost__reg_alpha': 0.13649017457853405}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:38,737] Trial 378 finished with value: 0.8078441240863773 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.013372501907155101, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.025137041314202673, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5636370842523305, 'xgboost__reg_lambda': 1.3575748606554157, 'xgboost__reg_alpha': 0.16748584774414096}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:38,939] Trial 379 finished with value: 0.7194876734718031 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04190121327959192, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.08366315240592646, 'xgboost__min_child_weight': 37, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5909550858743601, 'xgboost__reg_lambda': 0.45948835597855836, 'xgboost__reg_alpha': 0.012228239606809927}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:39,757] Trial 380 finished with value: 0.8336065679627324 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007616871537572531, 'xgboost__n_estimators': 445, 'xgboost__learning_rate': 0.05195430760948036, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5115177721747464, 'xgboost__reg_lambda': 2.21277561232131, 'xgboost__reg_alpha': 0.2142531171495371}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:39,987] Trial 381 finished with value: 0.7779023233834869 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010689789686061487, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.016456140136182854, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5508474410233362, 'xgboost__reg_lambda': 0.620984550962544, 'xgboost__reg_alpha': 0.3473886639038759}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:40,217] Trial 382 finished with value: 0.8208303788194118 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014987486095022411, 'xgboost__n_estimators': 245, 'xgboost__learning_rate': 0.34923849862987255, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.617048523337726, 'xgboost__reg_lambda': 0.9051085785183752, 'xgboost__reg_alpha': 0.245009570178846}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:40,448] Trial 383 finished with value: 0.7838017311624617 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.037639738892599084, 'xgboost__n_estimators': 275, 'xgboost__learning_rate': 0.03595880084353681, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.6857953923636435, 'xgboost__reg_lambda': 0.7332232695392604, 'xgboost__reg_alpha': 0.08880222739586796}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:40,698] Trial 384 finished with value: 0.7631318487097914 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 9, 'fs_mb__threshold': 0.05161712760293857, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.28043923505825297, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.524674635264781, 'xgboost__reg_lambda': 1.6906310262570667, 'xgboost__reg_alpha': 0.06243107681801581}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:41,064] Trial 385 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 450, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.04963010383134978, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.06937549001872212, 'xgboost__min_child_weight': 481, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5377596916081928, 'xgboost__reg_lambda': 1.242512286568485, 'xgboost__reg_alpha': 0.425400355645025}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:41,259] Trial 386 finished with value: 0.7716899636091555 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0978893139355095, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.09095432376614548, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5698799372552886, 'xgboost__reg_lambda': 1.4597453244909575, 'xgboost__reg_alpha': 0.1934668449553769}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:41,500] Trial 387 finished with value: 0.8044241500852451 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04438905679409591, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.3362032077820579, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6039532167731974, 'xgboost__reg_lambda': 0.16215528384171302, 'xgboost__reg_alpha': 0.16291417852350681}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:41,704] Trial 388 finished with value: 0.7295452029262502 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009242228291198548, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.018016630989650798, 'xgboost__min_child_weight': 49, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.788909719807389, 'xgboost__reg_lambda': 1.0399073750176349, 'xgboost__reg_alpha': 0.2686176266827675}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:42,130] Trial 389 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.07104367563519659, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.7890219017068782, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6360323566726372, 'xgboost__reg_lambda': 0.34658849364871935, 'xgboost__reg_alpha': 0.11861299546550949}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:42,753] Trial 390 finished with value: 0.8440654385896077 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.002521171130845293, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.0541676651410419, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5151625616641339, 'xgboost__reg_lambda': 0.5033231724666085, 'xgboost__reg_alpha': 0.33107385768725933}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:43,297] Trial 391 finished with value: 0.8419122361403112 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005727796673308964, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.06231811687820659, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5168013427676376, 'xgboost__reg_lambda': 0.38092870661532746, 'xgboost__reg_alpha': 0.14170876550505118}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:43,543] Trial 392 finished with value: 0.8171910913846397 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0013722755672748062, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.3662684977415544, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6989471545567193, 'xgboost__reg_lambda': 0.38444302799771934, 'xgboost__reg_alpha': 0.33373819022470513}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:44,114] Trial 393 finished with value: 0.8474031538779488 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0032287739398997543, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.09417844166661929, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.508285883290043, 'xgboost__reg_lambda': 0.22124947163657022, 'xgboost__reg_alpha': 0.3363766289209027}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:44,389] Trial 394 finished with value: 0.8058345909773162 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004308612895758549, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.08452970227207589, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5117007568137777, 'xgboost__reg_lambda': 0.2450137521915663, 'xgboost__reg_alpha': 0.3192945898230074}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:44,673] Trial 395 finished with value: 0.8204214891248859 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0018087062760320715, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.11546982341394688, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5076394804388692, 'xgboost__reg_lambda': 0.24002455358061156, 'xgboost__reg_alpha': 0.3408001094865294}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:44,935] Trial 396 finished with value: 0.76334028879367 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003282687677102594, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.10365373481073697, 'xgboost__min_child_weight': 31, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5180111993785399, 'xgboost__reg_lambda': 0.4547530252405061, 'xgboost__reg_alpha': 0.36575621337455566}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:45,505] Trial 397 finished with value: 0.8410431170393942 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 350, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003076798859611507, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.15081918044528198, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5013112473199781, 'xgboost__reg_lambda': 0.14675092067607767, 'xgboost__reg_alpha': 0.3795839280768579}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:45,852] Trial 398 finished with value: 0.8058505135238087 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 330, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.002603236912684458, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.14499206975832696, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.510080717080228, 'xgboost__reg_lambda': 0.14401575568808545, 'xgboost__reg_alpha': 0.3486304273689617}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:46,437] Trial 399 finished with value: 0.8322348731670277 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 360, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0043306730287459155, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.1563207845650961, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5113116096265542, 'xgboost__reg_lambda': 0.12518527937500348, 'xgboost__reg_alpha': 0.37679011104368515}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:47,027] Trial 400 finished with value: 0.8355618605618605 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 340, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0030271743204965166, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.1295609097022458, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5083519478537231, 'xgboost__reg_lambda': 8.36503149915166e-05, 'xgboost__reg_alpha': 0.3870672159212267}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:47,327] Trial 401 finished with value: 0.8199916193458224 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004961788709021246, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.10140094962282738, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5036703687872737, 'xgboost__reg_lambda': 0.3808924339126987, 'xgboost__reg_alpha': 0.3132000507869724}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:47,650] Trial 402 finished with value: 0.7884315322994929 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 290, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.002173858330362605, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.12266080308978702, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5206275730775767, 'xgboost__reg_lambda': 0.2894697519617897, 'xgboost__reg_alpha': 0.3600785812229612}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:47,995] Trial 403 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 410, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005794489153340146, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.17296960453190885, 'xgboost__min_child_weight': 116, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5030790553708047, 'xgboost__reg_lambda': 0.19909111994016984, 'xgboost__reg_alpha': 0.13497281140197992}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:48,304] Trial 404 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 300, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003584838868786591, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.07579994460538807, 'xgboost__min_child_weight': 289, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7269293926969175, 'xgboost__reg_lambda': 0.12229751835020161, 'xgboost__reg_alpha': 0.10924414838479433}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:48,696] Trial 405 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.0011028323487191423, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.10630114688514988, 'xgboost__min_child_weight': 140, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5210825216426387, 'xgboost__reg_lambda': 0.2992495430166132, 'xgboost__reg_alpha': 0.3263212827800344}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:48,987] Trial 406 finished with value: 0.8014401000799581 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.025692021040163722, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.14711775744746833, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.51758899512184, 'xgboost__reg_lambda': 0.4769219217764169, 'xgboost__reg_alpha': 0.39727251143662223}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:49,306] Trial 407 finished with value: 0.7948244868366892 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 270, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005667258058273693, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.06463850089870143, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5017172914629434, 'xgboost__reg_lambda': 0.2375242258007783, 'xgboost__reg_alpha': 0.3384767988031069}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:49,752] Trial 408 finished with value: 0.8319159077887337 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0062470224853368094, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.42958258257017146, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5270606380454002, 'xgboost__reg_lambda': 0.4105231866396034, 'xgboost__reg_alpha': 0.35404504591863}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:50,037] Trial 409 finished with value: 0.8026581306681119 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.027247222692540936, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.09038313737205966, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6233534987968252, 'xgboost__reg_lambda': 0.3295160124313187, 'xgboost__reg_alpha': 0.13683307161079164}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:50,374] Trial 410 finished with value: 0.7264134624261489 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 390, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0037385467798249986, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.11684417575869072, 'xgboost__min_child_weight': 34, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5291457947928458, 'xgboost__reg_lambda': 0.08097481569417886, 'xgboost__reg_alpha': 0.29968369110156523}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:50,685] Trial 411 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 320, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006665124580513603, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.06462226547044261, 'xgboost__min_child_weight': 163, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6515435757879275, 'xgboost__reg_lambda': 0.5144945642546122, 'xgboost__reg_alpha': 0.03197153972887422}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:51,293] Trial 412 finished with value: 0.7893163064052107 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.018539978009458124, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.09026841247351686, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5002866096044071, 'xgboost__reg_lambda': 1.1429558397811828, 'xgboost__reg_alpha': 0.37911424920849557}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:51,606] Trial 413 finished with value: 0.7870487729045014 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.032700683611820845, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.21826664329235518, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6137229776258013, 'xgboost__reg_lambda': 2.303661125282903, 'xgboost__reg_alpha': 0.0858063095195983}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:51,956] Trial 414 finished with value: 0.7890788003823456 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 350, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0010842383307033238, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.6247792596767632, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5986348017167458, 'xgboost__reg_lambda': 0.00011221366877113559, 'xgboost__reg_alpha': 0.14396980985795624}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:52,246] Trial 415 finished with value: 0.8167954510043351 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.004782702692742713, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.2045147416506926, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5181135261074012, 'xgboost__reg_lambda': 0.2015187404284933, 'xgboost__reg_alpha': 0.11374144332601}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:52,945] Trial 416 finished with value: 0.8464290293934451 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.00677867288202685, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.1656549862659517, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8406945181625209, 'xgboost__reg_lambda': 1.5687002267031263, 'xgboost__reg_alpha': 0.15743707577849123}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:53,351] Trial 417 finished with value: 0.8333657434530016 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.002985143436956077, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.16595408128403194, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6727391314181843, 'xgboost__reg_lambda': 1.381801579802935, 'xgboost__reg_alpha': 0.15375994026288947}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:54,147] Trial 418 finished with value: 0.8372856750500254 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.006519255518713438, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.1367966193745351, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7991712492229511, 'xgboost__reg_lambda': 1.8419877865923342, 'xgboost__reg_alpha': 0.12249941947921657}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:54,534] Trial 419 finished with value: 0.8209094018201942 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.007723333454272926, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.3179564391156555, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.9615300924921812, 'xgboost__reg_lambda': 2.0184251250506726, 'xgboost__reg_alpha': 0.09430642358104671}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:54,940] Trial 420 finished with value: 0.8100852572440833 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.02123866304603226, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.1719903171558833, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.860038548370866, 'xgboost__reg_lambda': 1.297916969963996, 'xgboost__reg_alpha': 0.1575707924198102}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:55,257] Trial 421 finished with value: 0.793915523120999 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 450, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004776075455424586, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.10856864138800346, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6871308102943007, 'xgboost__reg_lambda': 2.7266427270673783, 'xgboost__reg_alpha': 0.002578884547478769}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:55,592] Trial 422 finished with value: 0.7789770516018327 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.028234172340892746, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.18634897556523877, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.6413179760535505, 'xgboost__reg_lambda': 2.4194330786728204, 'xgboost__reg_alpha': 0.3188694011998149}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:56,032] Trial 423 finished with value: 0.759341490549321 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.04794653333157578, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.2549623583645914, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5879694451557956, 'xgboost__reg_lambda': 1.323193475968198, 'xgboost__reg_alpha': 0.1370620055591674}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:56,674] Trial 424 finished with value: 0.8085309335309335 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.016476405658083355, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.14491332377532504, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.772745714784584, 'xgboost__reg_lambda': 1.209461790454628, 'xgboost__reg_alpha': 0.16909974987336776}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:57,016] Trial 425 finished with value: 0.8229660563229467 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007267832700968685, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.13321064258313978, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7484191534036269, 'xgboost__reg_lambda': 0.12425268943261533, 'xgboost__reg_alpha': 0.40431479134278986}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:57,264] Trial 426 finished with value: 0.783488823126009 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00239875412225415, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.5296352017588648, 'xgboost__min_child_weight': 36, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8203859315630622, 'xgboost__reg_lambda': 3.078391497323703, 'xgboost__reg_alpha': 0.11609510211040931}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:57,677] Trial 427 finished with value: 0.8054979357062689 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 350, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.005154909371259412, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.24094671352524005, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7698184896849174, 'xgboost__reg_lambda': 1.4293830157413656, 'xgboost__reg_alpha': 0.06459415162920953}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:57,982] Trial 428 finished with value: 0.8268273806364874 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 300, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.008312542120562531, 'xgboost__n_estimators': 165, 'xgboost__learning_rate': 0.29249860433596797, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6286601592098539, 'xgboost__reg_lambda': 1.455952048791202, 'xgboost__reg_alpha': 0.3419023444388201}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:58,616] Trial 429 finished with value: 0.8422206603780747 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004176654610802289, 'xgboost__n_estimators': 495, 'xgboost__learning_rate': 0.1581666385541394, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8031183963139876, 'xgboost__reg_lambda': 1.6780373724821627, 'xgboost__reg_alpha': 0.44114837169370463}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:59,005] Trial 430 finished with value: 0.8143201139265568 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 250, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003602617308079406, 'xgboost__n_estimators': 495, 'xgboost__learning_rate': 0.19182417195930743, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8821398139902554, 'xgboost__reg_lambda': 1.576001672247564, 'xgboost__reg_alpha': 0.4533843580738168}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:04:59,390] Trial 431 finished with value: 0.8271053382232415 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006034165014283704, 'xgboost__n_estimators': 490, 'xgboost__learning_rate': 0.16041755266726057, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8467876267097518, 'xgboost__reg_lambda': 1.6647092620492088, 'xgboost__reg_alpha': 0.40872493747144145}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:00,027] Trial 432 finished with value: 0.8255855757210772 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0014000866388465456, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.15336985775130588, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5132053378867427, 'xgboost__reg_lambda': 1.6610373838943489, 'xgboost__reg_alpha': 0.4200402308979201}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:00,444] Trial 433 finished with value: 0.8031404535636645 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.004341366928949277, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.5617829749687088, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.809246577044009, 'xgboost__reg_lambda': 1.9425391282459847, 'xgboost__reg_alpha': 0.48941117417029656}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:00,813] Trial 434 finished with value: 0.8227748775644926 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006727080894740665, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.3080014395437322, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7354112494432896, 'xgboost__reg_lambda': 1.5986771062755945, 'xgboost__reg_alpha': 0.37334373059911585}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:01,097] Trial 435 finished with value: 0.7490679541867842 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 190, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.022318294734313748, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.12562524825593588, 'xgboost__min_child_weight': 46, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.7699092204897281, 'xgboost__reg_lambda': 0.37112441191327783, 'xgboost__reg_alpha': 0.43971555417992836}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:01,927] Trial 436 finished with value: 0.8465307927673519 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 170, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00897145574396178, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.14404597560830273, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8220697291488875, 'xgboost__reg_lambda': 1.919734912050462, 'xgboost__reg_alpha': 0.38278918255818173}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:02,254] Trial 437 finished with value: 0.7688374473893754 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 170, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.03602625396287615, 'xgboost__n_estimators': 465, 'xgboost__learning_rate': 0.26689358228817783, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8187451760980051, 'xgboost__reg_lambda': 1.91498995858112, 'xgboost__reg_alpha': 0.4784223111381582}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:02,509] Trial 438 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 180, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009225082817879869, 'xgboost__n_estimators': 495, 'xgboost__learning_rate': 0.10481137330133977, 'xgboost__min_child_weight': 217, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.860012588438951, 'xgboost__reg_lambda': 1.840091834695434, 'xgboost__reg_alpha': 0.4421482278066167}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:02,803] Trial 439 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 160, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010134000930206938, 'xgboost__n_estimators': 485, 'xgboost__learning_rate': 0.41418616652685025, 'xgboost__min_child_weight': 441, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8227473952312717, 'xgboost__reg_lambda': 1.748677700010777, 'xgboost__reg_alpha': 0.045775694419472115}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:03,119] Trial 440 finished with value: 0.7967237981561263 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 220, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.025057822777439315, 'xgboost__n_estimators': 485, 'xgboost__learning_rate': 0.1750484418687343, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7500932839601757, 'xgboost__reg_lambda': 1.551824546972363, 'xgboost__reg_alpha': 0.3548431148789036}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:03,463] Trial 441 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.031973295547193414, 'xgboost__n_estimators': 465, 'xgboost__learning_rate': 0.19804114500747544, 'xgboost__min_child_weight': 87, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.837658449714763, 'xgboost__reg_lambda': 1.8807628438814614, 'xgboost__reg_alpha': 0.17133869803333784}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:03,729] Trial 442 finished with value: 0.8090139694518717 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 150, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008042789113362757, 'xgboost__n_estimators': 455, 'xgboost__learning_rate': 0.12802784918154575, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8059180093404705, 'xgboost__reg_lambda': 1.6759694995963024, 'xgboost__reg_alpha': 0.3940693583965638}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:04,555] Trial 443 finished with value: 0.8387884094796694 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 210, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.011141763369988724, 'xgboost__n_estimators': 485, 'xgboost__learning_rate': 0.07626909559768452, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8273583061708762, 'xgboost__reg_lambda': 1.555123670768693, 'xgboost__reg_alpha': 0.15060641954577492}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:04,912] Trial 444 finished with value: 0.7610742721682778 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.055910788244709866, 'xgboost__n_estimators': 470, 'xgboost__learning_rate': 0.08962564209521366, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8158969195498614, 'xgboost__reg_lambda': 1.684578833922342, 'xgboost__reg_alpha': 0.29993754102086306}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:05,178] Trial 445 finished with value: 0.7827354187720035 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 140, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.04508247125070647, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.44049864201246, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.804802652754722, 'xgboost__reg_lambda': 1.768237873358033, 'xgboost__reg_alpha': 0.5354388755374224}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:05,456] Trial 446 finished with value: 0.7794295615476956 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 240, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008842510325875571, 'xgboost__n_estimators': 440, 'xgboost__learning_rate': 0.5255602408585054, 'xgboost__min_child_weight': 35, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.781472472124534, 'xgboost__reg_lambda': 1.8164667754849058, 'xgboost__reg_alpha': 0.32798844017629214}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:05,779] Trial 447 finished with value: 0.8305059115104432 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 200, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006585360156867813, 'xgboost__n_estimators': 470, 'xgboost__learning_rate': 0.22584424251314303, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8069383358408556, 'xgboost__reg_lambda': 1.5656850680417729, 'xgboost__reg_alpha': 0.672391181442081}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:06,568] Trial 448 finished with value: 0.8489826320761573 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012034862193472334, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.05297428580541784, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.810239011031228, 'xgboost__reg_lambda': 0.5441384392468354, 'xgboost__reg_alpha': 0.42974588677200287}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:06,842] Trial 449 finished with value: 0.7978461867350758 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012862357475739564, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.05252688147824316, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8102548708735572, 'xgboost__reg_lambda': 1.5221603781385886, 'xgboost__reg_alpha': 0.39383113846221857}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:07,228] Trial 450 finished with value: 0.8229660563229467 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015109446661130344, 'xgboost__n_estimators': 475, 'xgboost__learning_rate': 0.04934749633126069, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8330570178973189, 'xgboost__reg_lambda': 0.5429834746700338, 'xgboost__reg_alpha': 0.4290623537908563}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:07,647] Trial 451 finished with value: 0.806630970381257 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.019753683939898507, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.06665897050378207, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7917062579893016, 'xgboost__reg_lambda': 1.7860599839314177, 'xgboost__reg_alpha': 0.4601009683652987}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:07,994] Trial 452 finished with value: 0.8276342884844975 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.029865089531844972, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.041434504891151996, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.8144902062560792, 'xgboost__reg_lambda': 1.9879893272586093, 'xgboost__reg_alpha': 0.3644931038607279}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:08,323] Trial 453 finished with value: 0.8095023573501426 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01172111325754225, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.0810583716444533, 'xgboost__min_child_weight': 22, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8287711232060306, 'xgboost__reg_lambda': 2.1220542600028702, 'xgboost__reg_alpha': 0.4119785824796522}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:09,020] Trial 454 finished with value: 0.8419122361403112 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.016363194845968564, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.05248855192291661, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8268276397408365, 'xgboost__reg_lambda': 0.5911982968628058, 'xgboost__reg_alpha': 0.4656720031974771}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:09,705] Trial 455 finished with value: 0.7653163634304182 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01922624929718744, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.0013854741318752375, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8278278959198442, 'xgboost__reg_lambda': 2.5803315142438237, 'xgboost__reg_alpha': 0.46273669024070396}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:09,962] Trial 456 finished with value: 0.8125381575871466 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01709864919008509, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.36867163205563325, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8341199431531566, 'xgboost__reg_lambda': 0.6402435906577091, 'xgboost__reg_alpha': 0.17732306677405282}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:05:10,758] Trial 457 finished with value: 0.8498666160259712 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014506382657943451, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.05778333213062965, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8404353004405407, 'xgboost__reg_lambda': 2.10503360161923, 'xgboost__reg_alpha': 0.48740033703104}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:11,364] Trial 458 finished with value: 0.8461122599836918 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01631696661872629, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.05664951801129591, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8415255677170282, 'xgboost__reg_lambda': 2.2809266397140653, 'xgboost__reg_alpha': 0.5038070229224714}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:11,635] Trial 459 finished with value: 0.7867926615575213 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.016057691535473, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.4883374590270426, 'xgboost__min_child_weight': 31, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8458031178248968, 'xgboost__reg_lambda': 2.032920547493833, 'xgboost__reg_alpha': 0.4894117251598074}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:11,921] Trial 460 finished with value: 0.8295140719540057 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01810236814661036, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.05295600136673907, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8422329367093615, 'xgboost__reg_lambda': 1.8940780850762136, 'xgboost__reg_alpha': 0.4737506588611171}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:12,585] Trial 461 finished with value: 0.8419122361403112 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02292764724607782, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.06218819081304285, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.830243808176751, 'xgboost__reg_lambda': 1.7700128286299404, 'xgboost__reg_alpha': 0.5035314506732268}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:12,999] Trial 462 finished with value: 0.8122052341501838 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.021107441839859437, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.0644383223054098, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8216017288713625, 'xgboost__reg_lambda': 2.3331893450283956, 'xgboost__reg_alpha': 0.5044464795069025}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:13,668] Trial 463 finished with value: 0.8396538395137442 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01692815005816456, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.05948926839335072, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.83171073221273, 'xgboost__reg_lambda': 1.9844272971234778, 'xgboost__reg_alpha': 0.4941963053058755}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:14,044] Trial 464 finished with value: 0.8290788555263442 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01792617492815952, 'xgboost__n_estimators': 440, 'xgboost__learning_rate': 0.07527042816348141, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8393356299928464, 'xgboost__reg_lambda': 2.1581212871410287, 'xgboost__reg_alpha': 0.47115908482537333}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:14,363] Trial 465 finished with value: 0.810411171115466 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.022884512281302324, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.34444217535657384, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8566862929275029, 'xgboost__reg_lambda': 2.06105355474409, 'xgboost__reg_alpha': 0.5072542820500179}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:14,698] Trial 466 finished with value: 0.8094772112032455 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.019019156136304283, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.7614204488990758, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8240459955982647, 'xgboost__reg_lambda': 2.2031199250178415, 'xgboost__reg_alpha': 0.5378449430392158}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:15,203] Trial 467 finished with value: 0.8333092833092834 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01484879699107677, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.3971791997366901, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.815712347997652, 'xgboost__reg_lambda': 2.0101276978073663, 'xgboost__reg_alpha': 0.44465146036662295}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:15,543] Trial 468 finished with value: 0.825325410847382 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.020530954763025105, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.03944906098495236, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7970367483165639, 'xgboost__reg_lambda': 1.74735434392878, 'xgboost__reg_alpha': 0.4940868481462815}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:15,913] Trial 469 finished with value: 0.7822748907172601 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 250, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.016338707971156944, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.060092046503238475, 'xgboost__min_child_weight': 38, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8518936711301689, 'xgboost__reg_lambda': 2.1021685175368705, 'xgboost__reg_alpha': 0.5168380813875243}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:16,189] Trial 470 finished with value: 0.8261717461262633 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013990189774423185, 'xgboost__n_estimators': 440, 'xgboost__learning_rate': 0.09130193293257709, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8389076253467019, 'xgboost__reg_lambda': 2.20951898991592, 'xgboost__reg_alpha': 0.5499825693394665}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:16,767] Trial 471 finished with value: 0.8353535027762874 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.014895825868185416, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.3297351678378755, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8524415854443773, 'xgboost__reg_lambda': 2.2894952035082645, 'xgboost__reg_alpha': 0.4716224712366672}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:16,995] Trial 472 finished with value: 0.7881776097982062 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.027159588326548918, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.6948607333236224, 'xgboost__min_child_weight': 26, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8322073036018862, 'xgboost__reg_lambda': 1.7252585811445886, 'xgboost__reg_alpha': 0.4331911613140172}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:17,236] Trial 473 finished with value: 0.818475426959044 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.017483669666919086, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.03583546033324149, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8159259274881009, 'xgboost__reg_lambda': 1.8314376786287747, 'xgboost__reg_alpha': 0.5060955001526449}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:17,583] Trial 474 finished with value: 0.8356328761951377 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.024427741559183695, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.07671880910102438, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8464059539813259, 'xgboost__reg_lambda': 4.390443726249137, 'xgboost__reg_alpha': 0.45839808057876613}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:17,851] Trial 475 finished with value: 0.8271053382232415 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.019710736612954822, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.0531439189482054, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.7834458275003819, 'xgboost__reg_lambda': 1.9199823181227387, 'xgboost__reg_alpha': 0.4776498317118943}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:18,153] Trial 476 finished with value: 0.8084272832895052 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013714540690706491, 'xgboost__n_estimators': 450, 'xgboost__learning_rate': 0.6279764737211979, 'xgboost__min_child_weight': 21, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8259012992610504, 'xgboost__reg_lambda': 2.327171153158762, 'xgboost__reg_alpha': 0.4282515511357844}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:18,854] Trial 477 finished with value: 0.8322348731670277 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015505028302050793, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.302926557273099, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8422439710275806, 'xgboost__reg_lambda': 3.8079321386596328, 'xgboost__reg_alpha': 0.44538084686908747}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:19,247] Trial 478 finished with value: 0.7737497403099242 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 260, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0753122782044342, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.029337821127786802, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7965719288859432, 'xgboost__reg_lambda': 1.6412373529323812, 'xgboost__reg_alpha': 0.5540528692065865}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:19,596] Trial 479 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01293457289672582, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.20441832420419073, 'xgboost__min_child_weight': 200, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8025728130510824, 'xgboost__reg_lambda': 2.143765367736446, 'xgboost__reg_alpha': 0.522864728972355}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:19,824] Trial 480 finished with value: 0.7971467104808033 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.03935264505239296, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.8133276991670046, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8266896449033837, 'xgboost__reg_lambda': 2.5887409859255146, 'xgboost__reg_alpha': 0.4620933861507906}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:20,093] Trial 481 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02279127530578855, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.276785975275546, 'xgboost__min_child_weight': 356, 'xgboost__max_depth': 2, 'xgboost__subsample': 0.783576206951414, 'xgboost__reg_lambda': 2.4501836525448977, 'xgboost__reg_alpha': 0.4857515624142177}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:20,328] Trial 482 finished with value: 0.807993628074108 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0167656058936117, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.24407169054639882, 'xgboost__min_child_weight': 29, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8631049838599878, 'xgboost__reg_lambda': 1.7981784663993259, 'xgboost__reg_alpha': 0.44955761443102205}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:20,592] Trial 483 finished with value: 0.7847340856534633 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04063549141979267, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.09968081586039539, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8115115726624401, 'xgboost__reg_lambda': 2.0485288305830567, 'xgboost__reg_alpha': 0.5057130100373368}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:21,303] Trial 484 finished with value: 0.842016992554627 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013847981921031864, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.0753244484486097, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8405604635736912, 'xgboost__reg_lambda': 0.5159611339146439, 'xgboost__reg_alpha': 0.5599188745850596}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:21,755] Trial 485 finished with value: 0.827885491837318 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014058453345479859, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.08147211142309614, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8359190519723804, 'xgboost__reg_lambda': 0.48826550879003133, 'xgboost__reg_alpha': 0.5962834622168038}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:22,039] Trial 486 finished with value: 0.8016221960311848 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03865313394884087, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.06862273951363602, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8391598938281017, 'xgboost__reg_lambda': 2.2493858544233922, 'xgboost__reg_alpha': 0.5568131063287681}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:22,479] Trial 487 finished with value: 0.822155880544294 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.018350349213469685, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.9363803460778297, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8501732522549268, 'xgboost__reg_lambda': 0.4264735149392428, 'xgboost__reg_alpha': 0.42181225498406194}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:22,882] Trial 488 finished with value: 0.7894801186467854 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 10, 'fs_mb__threshold': 0.015945609064403295, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.47458833821136304, 'xgboost__min_child_weight': 40, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8217379480080226, 'xgboost__reg_lambda': 0.524342160907104, 'xgboost__reg_alpha': 0.5136337393717221}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:23,259] Trial 489 finished with value: 0.8336065679627324 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012200271488560241, 'xgboost__n_estimators': 445, 'xgboost__learning_rate': 0.09794317568761002, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8742622829452188, 'xgboost__reg_lambda': 4.8143581771709485, 'xgboost__reg_alpha': 0.48658261731720814}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:23,615] Trial 490 finished with value: 0.7763130894349799 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.055237775368485835, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.053921499437926027, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.8506340279554065, 'xgboost__reg_lambda': 1.505575211736158, 'xgboost__reg_alpha': 0.5592490617803696}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:23,967] Trial 491 finished with value: 0.7614219387981903 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0789180953226469, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.5310036829190526, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8382299133813017, 'xgboost__reg_lambda': 0.3313810232008661, 'xgboost__reg_alpha': 0.5251501844491939}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:24,280] Trial 492 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.049221855488831984, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.17552001867354394, 'xgboost__min_child_weight': 410, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8292540141547676, 'xgboost__reg_lambda': 2.3921537259684924, 'xgboost__reg_alpha': 0.5680912865956373}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:24,597] Trial 493 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.060738359215624184, 'xgboost__n_estimators': 450, 'xgboost__learning_rate': 0.5486511807647825, 'xgboost__min_child_weight': 70, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6574114349779923, 'xgboost__reg_lambda': 1.6651120858245467, 'xgboost__reg_alpha': 0.5821941563143126}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:24,988] Trial 494 finished with value: 0.8155837767741358 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.014037910794639927, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.1190219754231662, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8707588634367288, 'xgboost__reg_lambda': 0.5744064112949149, 'xgboost__reg_alpha': 0.6151059767989773}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:25,619] Trial 495 finished with value: 0.8197629470001856 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 200, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01943785476860161, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.08683656667764089, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8450976766973956, 'xgboost__reg_lambda': 1.9128949821715222, 'xgboost__reg_alpha': 0.5380143334656552}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:26,034] Trial 496 finished with value: 0.7843817352651274 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03248098509520933, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.07169054984273843, 'xgboost__min_child_weight': 32, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6951020302211487, 'xgboost__reg_lambda': 1.7976417392441149, 'xgboost__reg_alpha': 0.4722761510850056}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:26,343] Trial 497 finished with value: 0.7960949514711082 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.04552278871966443, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.14141178828637402, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8110026168354595, 'xgboost__reg_lambda': 0.4582994336429656, 'xgboost__reg_alpha': 0.39706969149204857}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:26,726] Trial 498 finished with value: 0.811783766244153 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 270, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011433617594268097, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.044128645090439865, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8610278088434911, 'xgboost__reg_lambda': 1.377266254458147, 'xgboost__reg_alpha': 0.438917872499998}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:05:27,470] Trial 499 finished with value: 0.8084108018876622 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 170, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.016647145242973477, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.11296574315432267, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8301393905141536, 'xgboost__reg_lambda': 2.5135953303809684, 'xgboost__reg_alpha': 0.49734683564327076}. Best is trial 457 with value: 0.8498666160259712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-01-07 21:05:28,844 - project.packages.modelling.models.supervised.sklearn - INFO - final estimator: Pipeline(steps=[('columns_selector',\n",
      "                 ColumnsSelector(columns=['passenger_class', 'passenger_age',\n",
      "                                          'passenger_siblings',\n",
      "                                          'passenger_parch', 'passenger_fare',\n",
      "                                          'passenger_ticket_number',\n",
      "                                          'passenger_ticket_unknown_base',\n",
      "                                          'passenger_cabin_number',\n",
      "                                          'passenger_number_of_family_onboard',\n",
      "                                          'passenger_is_single',\n",
      "                                          'passenger_has_childs',\n",
      "                                          'passenger_cabin_level_a',\n",
      "                                          'passeng...\n",
      "                               feature_types=None, gamma=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.05778333213062965, max_bin=None,\n",
      "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               max_leaves=None, min_child_weight=0, missing=nan,\n",
      "                               monotone_constraints=None, multi_strategy=None,\n",
      "                               n_estimators=430, n_jobs=None,\n",
      "                               num_parallel_tree=None, random_state=42, ...))])\u001b[0m\n",
      "\u001b[34m2024-01-07 21:05:28,845 - project.packages.modelling.models.supervised.sklearn - INFO - final estimator f1_weighted: 0.8498666160259712\u001b[0m\n",
      "\u001b[34m2024-01-07 21:05:29,162 - project.packages.modelling.feature_selection.feature_selectors.model_based - INFO - Model based feature selection drops the following features: ['passenger_ticket_unknown_base', 'passenger_is_single', 'passenger_cabin_level_d', 'passenger_embarked_port_cluster_feature', 'passenger_family_cluster_feature', 'passenger_embarked_port_c', 'passenger_embarked_port_q', 'passenger_cabin_level_b', 'passenger_ticket_number_cluster_feature', 'passenger_cabin_level_c', 'passenger_cabin_level_a', 'passenger_has_childs', 'passenger_parch', 'passenger_social_status_cluster_feature']\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-e1a400bb-e609-48e6-aa41-531ca703493a {color: black;background-color: white;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a pre{padding: 0;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-toggleable {background-color: white;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-estimator:hover {background-color: #d4ebff;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-item {z-index: 1;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-parallel-item:only-child::after {width: 0;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-e1a400bb-e609-48e6-aa41-531ca703493a div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-e1a400bb-e609-48e6-aa41-531ca703493a\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BinaryClassifierSklearnPipeline(cv_score={&#x27;class&#x27;: &#x27;sklearn.model_selection.cross_val_predict&#x27;,\n",
       "                                          &#x27;kwargs&#x27;: {&#x27;X&#x27;: None, &#x27;cv&#x27;: None,\n",
       "                                                     &#x27;estimator&#x27;: None,\n",
       "                                                     &#x27;method&#x27;: &#x27;predict&#x27;,\n",
       "                                                     &#x27;n_jobs&#x27;: -1, &#x27;y&#x27;: None},\n",
       "                                          &#x27;scoring&#x27;: &#x27;f1_weighted&#x27;},\n",
       "                                cv_strategy={&#x27;class&#x27;: &#x27;sklearn.model_selection.StratifiedKFold&#x27;,\n",
       "                                             &#x27;kwargs&#x27;: {&#x27;n_splits&#x27;: 5,\n",
       "                                                        &#x27;random_state&#x27;: 42,\n",
       "                                                        &#x27;shuffle&#x27;: True}},\n",
       "                                features=[&#x27;passenger_cl...\n",
       "                                                                                           &#x27;&quot;sklearn.preprocessing.QuantileTransformer&quot;])&#x27;,\n",
       "                                                                                  &#x27;kwargs&#x27;: {}}}}},\n",
       "                                scoring_metrics=[&#x27;accuracy&#x27;,\n",
       "                                                 &#x27;balanced_accuracy&#x27;, &#x27;f1&#x27;,\n",
       "                                                 &#x27;f1_micro&#x27;, &#x27;f1_macro&#x27;,\n",
       "                                                 &#x27;f1_weighted&#x27;, &#x27;precision&#x27;,\n",
       "                                                 &#x27;precision_micro&#x27;,\n",
       "                                                 &#x27;precision_macro&#x27;,\n",
       "                                                 &#x27;precision_weighted&#x27;, &#x27;recall&#x27;,\n",
       "                                                 &#x27;recall_micro&#x27;, &#x27;recall_macro&#x27;,\n",
       "                                                 &#x27;recall_weighted&#x27;, &#x27;roc_auc&#x27;,\n",
       "                                                 &#x27;roc_auc_ovr&#x27;, &#x27;roc_auc_ovo&#x27;,\n",
       "                                                 &#x27;roc_auc_ovr_weighted&#x27;,\n",
       "                                                 &#x27;roc_auc_ovo_weighted&#x27;],\n",
       "                                target=&#x27;survived&#x27;)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5e0f7298-432b-41d1-b7bc-f20a80c65131\" type=\"checkbox\" checked><label for=\"5e0f7298-432b-41d1-b7bc-f20a80c65131\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BinaryClassifierSklearnPipeline</label><div class=\"sk-toggleable__content\"><pre>BinaryClassifierSklearnPipeline(cv_score={&#x27;class&#x27;: &#x27;sklearn.model_selection.cross_val_predict&#x27;,\n",
       "                                          &#x27;kwargs&#x27;: {&#x27;X&#x27;: None, &#x27;cv&#x27;: None,\n",
       "                                                     &#x27;estimator&#x27;: None,\n",
       "                                                     &#x27;method&#x27;: &#x27;predict&#x27;,\n",
       "                                                     &#x27;n_jobs&#x27;: -1, &#x27;y&#x27;: None},\n",
       "                                          &#x27;scoring&#x27;: &#x27;f1_weighted&#x27;},\n",
       "                                cv_strategy={&#x27;class&#x27;: &#x27;sklearn.model_selection.StratifiedKFold&#x27;,\n",
       "                                             &#x27;kwargs&#x27;: {&#x27;n_splits&#x27;: 5,\n",
       "                                                        &#x27;random_state&#x27;: 42,\n",
       "                                                        &#x27;shuffle&#x27;: True}},\n",
       "                                features=[&#x27;passenger_cl...\n",
       "                                                                                           &#x27;&quot;sklearn.preprocessing.QuantileTransformer&quot;])&#x27;,\n",
       "                                                                                  &#x27;kwargs&#x27;: {}}}}},\n",
       "                                scoring_metrics=[&#x27;accuracy&#x27;,\n",
       "                                                 &#x27;balanced_accuracy&#x27;, &#x27;f1&#x27;,\n",
       "                                                 &#x27;f1_micro&#x27;, &#x27;f1_macro&#x27;,\n",
       "                                                 &#x27;f1_weighted&#x27;, &#x27;precision&#x27;,\n",
       "                                                 &#x27;precision_micro&#x27;,\n",
       "                                                 &#x27;precision_macro&#x27;,\n",
       "                                                 &#x27;precision_weighted&#x27;, &#x27;recall&#x27;,\n",
       "                                                 &#x27;recall_micro&#x27;, &#x27;recall_macro&#x27;,\n",
       "                                                 &#x27;recall_weighted&#x27;, &#x27;roc_auc&#x27;,\n",
       "                                                 &#x27;roc_auc_ovr&#x27;, &#x27;roc_auc_ovo&#x27;,\n",
       "                                                 &#x27;roc_auc_ovr_weighted&#x27;,\n",
       "                                                 &#x27;roc_auc_ovo_weighted&#x27;],\n",
       "                                target=&#x27;survived&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BinaryClassifierSklearnPipeline(cv_score={'class': 'sklearn.model_selection.cross_val_predict',\n",
       "                                          'kwargs': {'X': None, 'cv': None,\n",
       "                                                     'estimator': None,\n",
       "                                                     'method': 'predict',\n",
       "                                                     'n_jobs': -1, 'y': None},\n",
       "                                          'scoring': 'f1_weighted'},\n",
       "                                cv_strategy={'class': 'sklearn.model_selection.StratifiedKFold',\n",
       "                                             'kwargs': {'n_splits': 5,\n",
       "                                                        'random_state': 42,\n",
       "                                                        'shuffle': True}},\n",
       "                                features=['passenger_cl...\n",
       "                                                                                           '\"sklearn.preprocessing.QuantileTransformer\"])',\n",
       "                                                                                  'kwargs': {}}}}},\n",
       "                                scoring_metrics=['accuracy',\n",
       "                                                 'balanced_accuracy', 'f1',\n",
       "                                                 'f1_micro', 'f1_macro',\n",
       "                                                 'f1_weighted', 'precision',\n",
       "                                                 'precision_micro',\n",
       "                                                 'precision_macro',\n",
       "                                                 'precision_weighted', 'recall',\n",
       "                                                 'recall_micro', 'recall_macro',\n",
       "                                                 'recall_weighted', 'roc_auc',\n",
       "                                                 'roc_auc_ovr', 'roc_auc_ovo',\n",
       "                                                 'roc_auc_ovr_weighted',\n",
       "                                                 'roc_auc_ovo_weighted'],\n",
       "                                target='survived')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and Test datasets\n",
    "y_train = data[[target]]\n",
    "X_train = data[[col for col in data.columns if col != target]]\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-d87d32e7-c60b-4513-841a-58f6faf83aff {color: black;background-color: white;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff pre{padding: 0;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-toggleable {background-color: white;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-estimator:hover {background-color: #d4ebff;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-item {z-index: 1;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-parallel-item:only-child::after {width: 0;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-d87d32e7-c60b-4513-841a-58f6faf83aff div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-d87d32e7-c60b-4513-841a-58f6faf83aff\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columns_selector&#x27;,\n",
       "                 ColumnsSelector(columns=[&#x27;passenger_class&#x27;, &#x27;passenger_age&#x27;,\n",
       "                                          &#x27;passenger_siblings&#x27;,\n",
       "                                          &#x27;passenger_parch&#x27;, &#x27;passenger_fare&#x27;,\n",
       "                                          &#x27;passenger_ticket_number&#x27;,\n",
       "                                          &#x27;passenger_ticket_unknown_base&#x27;,\n",
       "                                          &#x27;passenger_cabin_number&#x27;,\n",
       "                                          &#x27;passenger_number_of_family_onboard&#x27;,\n",
       "                                          &#x27;passenger_is_single&#x27;,\n",
       "                                          &#x27;passenger_has_childs&#x27;,\n",
       "                                          &#x27;passenger_cabin_level_a&#x27;,\n",
       "                                          &#x27;passeng...\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.05778333213062965, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=6,\n",
       "                               max_leaves=None, min_child_weight=0, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=430, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=42, ...))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"497f0263-5542-432c-aabf-9b97b30cbfdf\" type=\"checkbox\" ><label for=\"497f0263-5542-432c-aabf-9b97b30cbfdf\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columns_selector&#x27;,\n",
       "                 ColumnsSelector(columns=[&#x27;passenger_class&#x27;, &#x27;passenger_age&#x27;,\n",
       "                                          &#x27;passenger_siblings&#x27;,\n",
       "                                          &#x27;passenger_parch&#x27;, &#x27;passenger_fare&#x27;,\n",
       "                                          &#x27;passenger_ticket_number&#x27;,\n",
       "                                          &#x27;passenger_ticket_unknown_base&#x27;,\n",
       "                                          &#x27;passenger_cabin_number&#x27;,\n",
       "                                          &#x27;passenger_number_of_family_onboard&#x27;,\n",
       "                                          &#x27;passenger_is_single&#x27;,\n",
       "                                          &#x27;passenger_has_childs&#x27;,\n",
       "                                          &#x27;passenger_cabin_level_a&#x27;,\n",
       "                                          &#x27;passeng...\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.05778333213062965, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=6,\n",
       "                               max_leaves=None, min_child_weight=0, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=430, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=42, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"38b46a57-bdad-4a09-90cf-4a0a64382e9f\" type=\"checkbox\" ><label for=\"38b46a57-bdad-4a09-90cf-4a0a64382e9f\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnsSelector</label><div class=\"sk-toggleable__content\"><pre>ColumnsSelector(columns=[&#x27;passenger_class&#x27;, &#x27;passenger_age&#x27;,\n",
       "                         &#x27;passenger_siblings&#x27;, &#x27;passenger_parch&#x27;,\n",
       "                         &#x27;passenger_fare&#x27;, &#x27;passenger_ticket_number&#x27;,\n",
       "                         &#x27;passenger_ticket_unknown_base&#x27;,\n",
       "                         &#x27;passenger_cabin_number&#x27;,\n",
       "                         &#x27;passenger_number_of_family_onboard&#x27;,\n",
       "                         &#x27;passenger_is_single&#x27;, &#x27;passenger_has_childs&#x27;,\n",
       "                         &#x27;passenger_cabin_level_a&#x27;, &#x27;passenger_cabin_level_b&#x27;,\n",
       "                         &#x27;passenger_cabin_l...\n",
       "                         &#x27;passenger_cabin_level_e&#x27;,\n",
       "                         &#x27;passenger_cabin_level_unknown&#x27;,\n",
       "                         &#x27;passenger_embarked_port_c&#x27;,\n",
       "                         &#x27;passenger_embarked_port_q&#x27;,\n",
       "                         &#x27;passenger_embarked_port_s&#x27;, &#x27;passenger_sex_female&#x27;,\n",
       "                         &#x27;passenger_cabin_cluster_feature&#x27;,\n",
       "                         &#x27;passenger_embarked_port_cluster_feature&#x27;,\n",
       "                         &#x27;passenger_ticket_number_cluster_feature&#x27;,\n",
       "                         &#x27;passenger_family_cluster_feature&#x27;,\n",
       "                         &#x27;passenger_social_status_cluster_feature&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2d2b09c3-dc19-400b-99fb-a5b2385eb127\" type=\"checkbox\" ><label for=\"2d2b09c3-dc19-400b-99fb-a5b2385eb127\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnsPreserverImputer</label><div class=\"sk-toggleable__content\"><pre>ColumnsPreserverImputer(imputer_params={&#x27;class&#x27;: &#x27;sklearn.impute.KNNImputer&#x27;,\n",
       "                                        &#x27;kwargs&#x27;: {&#x27;n_neighbors&#x27;: 20,\n",
       "                                                   &#x27;weights&#x27;: &#x27;uniform&#x27;}})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"721d07f0-3df0-44a9-9744-d783e83b9d0c\" type=\"checkbox\" ><label for=\"721d07f0-3df0-44a9-9744-d783e83b9d0c\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnsPreserverScaler</label><div class=\"sk-toggleable__content\"><pre>ColumnsPreserverScaler(scaler_params={&#x27;class&#x27;: &#x27;project.packages.modelling.transformers.scaler.NotScalerTransformer&#x27;,\n",
       "                                      &#x27;kwargs&#x27;: {}})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7c5fe5e4-7910-49ff-aa2f-a3119380ca0f\" type=\"checkbox\" ><label for=\"7c5fe5e4-7910-49ff-aa2f-a3119380ca0f\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureSelector</label><div class=\"sk-toggleable__content\"><pre>FeatureSelector(fs_params={&#x27;model_based&#x27;: {&#x27;estimator&#x27;: {&#x27;class&#x27;: &#x27;xgboost.XGBClassifier&#x27;,\n",
       "                                                         &#x27;kwargs&#x27;: {&#x27;max_depth&#x27;: 2,\n",
       "                                                                    &#x27;n_estimators&#x27;: 30,\n",
       "                                                                    &#x27;random_state&#x27;: 42}},\n",
       "                                           &#x27;prefit&#x27;: False,\n",
       "                                           &#x27;threshold&#x27;: 0.014506382657943451},\n",
       "                           &#x27;selectors&#x27;: [&#x27;model_based&#x27;]})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"94626018-679a-47fd-b21e-bade6e8d66f0\" type=\"checkbox\" ><label for=\"94626018-679a-47fd-b21e-bade6e8d66f0\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05778333213062965,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=0, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=430, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columns_selector',\n",
       "                 ColumnsSelector(columns=['passenger_class', 'passenger_age',\n",
       "                                          'passenger_siblings',\n",
       "                                          'passenger_parch', 'passenger_fare',\n",
       "                                          'passenger_ticket_number',\n",
       "                                          'passenger_ticket_unknown_base',\n",
       "                                          'passenger_cabin_number',\n",
       "                                          'passenger_number_of_family_onboard',\n",
       "                                          'passenger_is_single',\n",
       "                                          'passenger_has_childs',\n",
       "                                          'passenger_cabin_level_a',\n",
       "                                          'passeng...\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.05778333213062965, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=6,\n",
       "                               max_leaves=None, min_child_weight=0, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=430, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=42, ...))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model hypertuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'study'\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95moptuna.study.study.Study\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x286db33a0\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[32m'best_trial_params'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'scoring_metrics'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'accuracy'\u001b[0m,\n",
       "            \u001b[32m'balanced_accuracy'\u001b[0m,\n",
       "            \u001b[32m'f1'\u001b[0m,\n",
       "            \u001b[32m'f1_micro'\u001b[0m,\n",
       "            \u001b[32m'f1_macro'\u001b[0m,\n",
       "            \u001b[32m'f1_weighted'\u001b[0m,\n",
       "            \u001b[32m'precision'\u001b[0m,\n",
       "            \u001b[32m'precision_micro'\u001b[0m,\n",
       "            \u001b[32m'precision_macro'\u001b[0m,\n",
       "            \u001b[32m'precision_weighted'\u001b[0m,\n",
       "            \u001b[32m'recall'\u001b[0m,\n",
       "            \u001b[32m'recall_micro'\u001b[0m,\n",
       "            \u001b[32m'recall_macro'\u001b[0m,\n",
       "            \u001b[32m'recall_weighted'\u001b[0m,\n",
       "            \u001b[32m'roc_auc'\u001b[0m,\n",
       "            \u001b[32m'roc_auc_ovr'\u001b[0m,\n",
       "            \u001b[32m'roc_auc_ovo'\u001b[0m,\n",
       "            \u001b[32m'roc_auc_ovr_weighted'\u001b[0m,\n",
       "            \u001b[32m'roc_auc_ovo_weighted'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'optuna'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'kwargs_study'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'direction'\u001b[0m: \u001b[32m'maximize'\u001b[0m,\n",
       "                \u001b[32m'study_name'\u001b[0m: \u001b[32m'xgboost'\u001b[0m,\n",
       "                \u001b[32m'load_if_exists'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'kwargs_optimize'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'n_trials'\u001b[0m: \u001b[1;36m500\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'sampler'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'class'\u001b[0m: \u001b[32m'optuna.samplers.TPESampler'\u001b[0m,\n",
       "                \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'n_startup_trials'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'constant_liar'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'seed'\u001b[0m: \u001b[1;36m42\u001b[0m\u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'pruner'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'class'\u001b[0m: \u001b[32m'optuna.pruners.SuccessiveHalvingPruner'\u001b[0m, \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'cv_strategy'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'class'\u001b[0m: \u001b[32m'sklearn.model_selection.StratifiedKFold'\u001b[0m,\n",
       "            \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'n_splits'\u001b[0m: \u001b[1;36m5\u001b[0m, \u001b[32m'random_state'\u001b[0m: \u001b[1;36m42\u001b[0m, \u001b[32m'shuffle'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'cv_score'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'scoring'\u001b[0m: \u001b[32m'f1_weighted'\u001b[0m,\n",
       "            \u001b[32m'class'\u001b[0m: \u001b[32m'sklearn.model_selection.cross_val_predict'\u001b[0m,\n",
       "            \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'estimator'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[32m'X'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[32m'y'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[32m'cv'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[32m'n_jobs'\u001b[0m: \u001b[1;36m-1\u001b[0m,\n",
       "                \u001b[32m'method'\u001b[0m: \u001b[32m'predict'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'target'\u001b[0m: \u001b[32m'survived'\u001b[0m,\n",
       "        \u001b[32m'features'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'passenger_class'\u001b[0m,\n",
       "            \u001b[32m'passenger_age'\u001b[0m,\n",
       "            \u001b[32m'passenger_siblings'\u001b[0m,\n",
       "            \u001b[32m'passenger_parch'\u001b[0m,\n",
       "            \u001b[32m'passenger_fare'\u001b[0m,\n",
       "            \u001b[32m'passenger_ticket_number'\u001b[0m,\n",
       "            \u001b[32m'passenger_ticket_unknown_base'\u001b[0m,\n",
       "            \u001b[32m'passenger_cabin_number'\u001b[0m,\n",
       "            \u001b[32m'passenger_number_of_family_onboard'\u001b[0m,\n",
       "            \u001b[32m'passenger_is_single'\u001b[0m,\n",
       "            \u001b[32m'passenger_has_childs'\u001b[0m,\n",
       "            \u001b[32m'passenger_cabin_level_a'\u001b[0m,\n",
       "            \u001b[32m'passenger_cabin_level_b'\u001b[0m,\n",
       "            \u001b[32m'passenger_cabin_level_c'\u001b[0m,\n",
       "            \u001b[32m'passenger_cabin_level_d'\u001b[0m,\n",
       "            \u001b[32m'passenger_cabin_level_e'\u001b[0m,\n",
       "            \u001b[32m'passenger_cabin_level_unknown'\u001b[0m,\n",
       "            \u001b[32m'passenger_embarked_port_c'\u001b[0m,\n",
       "            \u001b[32m'passenger_embarked_port_q'\u001b[0m,\n",
       "            \u001b[32m'passenger_embarked_port_s'\u001b[0m,\n",
       "            \u001b[32m'passenger_sex_female'\u001b[0m,\n",
       "            \u001b[32m'passenger_cabin_cluster_feature'\u001b[0m,\n",
       "            \u001b[32m'passenger_embarked_port_cluster_feature'\u001b[0m,\n",
       "            \u001b[32m'passenger_ticket_number_cluster_feature'\u001b[0m,\n",
       "            \u001b[32m'passenger_family_cluster_feature'\u001b[0m,\n",
       "            \u001b[32m'passenger_social_status_cluster_feature'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'pipeline'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'imputer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'class'\u001b[0m: \u001b[32m'project.packages.modelling.models.unsupervised.imputer.ColumnsPreserverImputer'\u001b[0m,\n",
       "                \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'imputer_params'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'class'\u001b[0m: \u001b[32m'sklearn.impute.KNNImputer'\u001b[0m,\n",
       "                        \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'n_neighbors'\u001b[0m: \u001b[1;36m20\u001b[0m, \u001b[32m'weights'\u001b[0m: \u001b[32m'uniform'\u001b[0m\u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'scaler'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'class'\u001b[0m: \u001b[32m'project.packages.modelling.transformers.scaler.ColumnsPreserverScaler'\u001b[0m,\n",
       "                \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'scaler_params'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'class'\u001b[0m: \u001b[32m'project.packages.modelling.transformers.scaler.NotScalerTransformer'\u001b[0m,\n",
       "                        \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'feature_selector'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'class'\u001b[0m: \u001b[32m'project.packages.modelling.feature_selection.feature_selector_pipeline.FeatureSelector'\u001b[0m,\n",
       "                \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'fs_params'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'selectors'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'model_based'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                        \u001b[32m'model_based'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'estimator'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                \u001b[32m'class'\u001b[0m: \u001b[32m'xgboost.XGBClassifier'\u001b[0m,\n",
       "                                \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m30\u001b[0m, \u001b[32m'max_depth'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'random_state'\u001b[0m: \u001b[1;36m42\u001b[0m\u001b[1m}\u001b[0m\n",
       "                            \u001b[1m}\u001b[0m,\n",
       "                            \u001b[32m'threshold'\u001b[0m: \u001b[1;36m0.014506382657943451\u001b[0m,\n",
       "                            \u001b[32m'prefit'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'model'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'class'\u001b[0m: \u001b[32m'xgboost.XGBClassifier'\u001b[0m,\n",
       "                \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m430\u001b[0m,\n",
       "                    \u001b[32m'learning_rate'\u001b[0m: \u001b[1;36m0.05778333213062965\u001b[0m,\n",
       "                    \u001b[32m'min_child_weight'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                    \u001b[32m'max_depth'\u001b[0m: \u001b[1;36m6\u001b[0m,\n",
       "                    \u001b[32m'subsample'\u001b[0m: \u001b[1;36m0.8404353004405407\u001b[0m,\n",
       "                    \u001b[32m'reg_lambda'\u001b[0m: \u001b[1;36m2.10503360161923\u001b[0m,\n",
       "                    \u001b[32m'reg_alpha'\u001b[0m: \u001b[1;36m0.48740033703104\u001b[0m,\n",
       "                    \u001b[32m'random_state'\u001b[0m: \u001b[1;36m42\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'cross_validation_metrics'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'accuracy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8507295173961841\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'balanced_accuracy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.836976320582878\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'f1'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.7999999999999999\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'f1_micro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8507295173961841\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'f1_macro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8404655326768128\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'f1_weighted'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8498666160259712\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'precision'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8235294117647058\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'precision_micro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8507295173961841\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'precision_macro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8448632974316487\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'precision_weighted'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8498196547078072\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'recall'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.7777777777777778\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'recall_micro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8507295173961841\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'recall_macro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.836976320582878\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'recall_weighted'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8507295173961841\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'matthews_corrcoef'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.6817940013599288\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'roc_auc'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8812620500857486\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'roc_auc_ovr'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8812620500857486\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'roc_auc_ovo'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8812620500857486\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'roc_auc_ovr_weighted'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8812620500857486\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'roc_auc_ovo_weighted'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8812620500857486\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hypertune_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validation results\n",
    "\n",
    "It shows the hypertuning results of the best model and the most important binary classification metrics, results will be analyzed later on.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'accuracy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8507295173961841\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'balanced_accuracy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.836976320582878\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'f1'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.7999999999999999\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'f1_micro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8507295173961841\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'f1_macro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8404655326768128\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'f1_weighted'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8498666160259712\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'precision'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8235294117647058\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'precision_micro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8507295173961841\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'precision_macro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8448632974316487\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'precision_weighted'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8498196547078072\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'recall'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.7777777777777778\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'recall_micro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8507295173961841\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'recall_macro'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.836976320582878\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'recall_weighted'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8507295173961841\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'matthews_corrcoef'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.6817940013599288\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'roc_auc'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8812620500857486\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'roc_auc_ovr'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8812620500857486\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'roc_auc_ovo'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8812620500857486\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'roc_auc_ovr_weighted'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8812620500857486\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'roc_auc_ovo_weighted'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'value'\u001b[0m: \u001b[1;36m0.8812620500857486\u001b[0m, \u001b[32m'step'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hypertune_results[\"cross_validation_metrics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best trial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'scoring_metrics'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'accuracy'\u001b[0m,\n",
       "        \u001b[32m'balanced_accuracy'\u001b[0m,\n",
       "        \u001b[32m'f1'\u001b[0m,\n",
       "        \u001b[32m'f1_micro'\u001b[0m,\n",
       "        \u001b[32m'f1_macro'\u001b[0m,\n",
       "        \u001b[32m'f1_weighted'\u001b[0m,\n",
       "        \u001b[32m'precision'\u001b[0m,\n",
       "        \u001b[32m'precision_micro'\u001b[0m,\n",
       "        \u001b[32m'precision_macro'\u001b[0m,\n",
       "        \u001b[32m'precision_weighted'\u001b[0m,\n",
       "        \u001b[32m'recall'\u001b[0m,\n",
       "        \u001b[32m'recall_micro'\u001b[0m,\n",
       "        \u001b[32m'recall_macro'\u001b[0m,\n",
       "        \u001b[32m'recall_weighted'\u001b[0m,\n",
       "        \u001b[32m'roc_auc'\u001b[0m,\n",
       "        \u001b[32m'roc_auc_ovr'\u001b[0m,\n",
       "        \u001b[32m'roc_auc_ovo'\u001b[0m,\n",
       "        \u001b[32m'roc_auc_ovr_weighted'\u001b[0m,\n",
       "        \u001b[32m'roc_auc_ovo_weighted'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'optuna'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'kwargs_study'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'direction'\u001b[0m: \u001b[32m'maximize'\u001b[0m, \u001b[32m'study_name'\u001b[0m: \u001b[32m'xgboost'\u001b[0m, \u001b[32m'load_if_exists'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'kwargs_optimize'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'n_trials'\u001b[0m: \u001b[1;36m500\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'sampler'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'class'\u001b[0m: \u001b[32m'optuna.samplers.TPESampler'\u001b[0m,\n",
       "            \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'n_startup_trials'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'constant_liar'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'seed'\u001b[0m: \u001b[1;36m42\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'pruner'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'class'\u001b[0m: \u001b[32m'optuna.pruners.SuccessiveHalvingPruner'\u001b[0m, \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'cv_strategy'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'class'\u001b[0m: \u001b[32m'sklearn.model_selection.StratifiedKFold'\u001b[0m,\n",
       "        \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'n_splits'\u001b[0m: \u001b[1;36m5\u001b[0m, \u001b[32m'random_state'\u001b[0m: \u001b[1;36m42\u001b[0m, \u001b[32m'shuffle'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'cv_score'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'scoring'\u001b[0m: \u001b[32m'f1_weighted'\u001b[0m,\n",
       "        \u001b[32m'class'\u001b[0m: \u001b[32m'sklearn.model_selection.cross_val_predict'\u001b[0m,\n",
       "        \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'estimator'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'X'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'y'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'cv'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'n_jobs'\u001b[0m: \u001b[1;36m-1\u001b[0m,\n",
       "            \u001b[32m'method'\u001b[0m: \u001b[32m'predict'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'target'\u001b[0m: \u001b[32m'survived'\u001b[0m,\n",
       "    \u001b[32m'features'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[32m'passenger_class'\u001b[0m,\n",
       "        \u001b[32m'passenger_age'\u001b[0m,\n",
       "        \u001b[32m'passenger_siblings'\u001b[0m,\n",
       "        \u001b[32m'passenger_parch'\u001b[0m,\n",
       "        \u001b[32m'passenger_fare'\u001b[0m,\n",
       "        \u001b[32m'passenger_ticket_number'\u001b[0m,\n",
       "        \u001b[32m'passenger_ticket_unknown_base'\u001b[0m,\n",
       "        \u001b[32m'passenger_cabin_number'\u001b[0m,\n",
       "        \u001b[32m'passenger_number_of_family_onboard'\u001b[0m,\n",
       "        \u001b[32m'passenger_is_single'\u001b[0m,\n",
       "        \u001b[32m'passenger_has_childs'\u001b[0m,\n",
       "        \u001b[32m'passenger_cabin_level_a'\u001b[0m,\n",
       "        \u001b[32m'passenger_cabin_level_b'\u001b[0m,\n",
       "        \u001b[32m'passenger_cabin_level_c'\u001b[0m,\n",
       "        \u001b[32m'passenger_cabin_level_d'\u001b[0m,\n",
       "        \u001b[32m'passenger_cabin_level_e'\u001b[0m,\n",
       "        \u001b[32m'passenger_cabin_level_unknown'\u001b[0m,\n",
       "        \u001b[32m'passenger_embarked_port_c'\u001b[0m,\n",
       "        \u001b[32m'passenger_embarked_port_q'\u001b[0m,\n",
       "        \u001b[32m'passenger_embarked_port_s'\u001b[0m,\n",
       "        \u001b[32m'passenger_sex_female'\u001b[0m,\n",
       "        \u001b[32m'passenger_cabin_cluster_feature'\u001b[0m,\n",
       "        \u001b[32m'passenger_embarked_port_cluster_feature'\u001b[0m,\n",
       "        \u001b[32m'passenger_ticket_number_cluster_feature'\u001b[0m,\n",
       "        \u001b[32m'passenger_family_cluster_feature'\u001b[0m,\n",
       "        \u001b[32m'passenger_social_status_cluster_feature'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'pipeline'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'imputer'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'class'\u001b[0m: \u001b[32m'project.packages.modelling.models.unsupervised.imputer.ColumnsPreserverImputer'\u001b[0m,\n",
       "            \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'imputer_params'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'class'\u001b[0m: \u001b[32m'sklearn.impute.KNNImputer'\u001b[0m,\n",
       "                    \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'n_neighbors'\u001b[0m: \u001b[1;36m20\u001b[0m, \u001b[32m'weights'\u001b[0m: \u001b[32m'uniform'\u001b[0m\u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'scaler'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'class'\u001b[0m: \u001b[32m'project.packages.modelling.transformers.scaler.ColumnsPreserverScaler'\u001b[0m,\n",
       "            \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'scaler_params'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'class'\u001b[0m: \u001b[32m'project.packages.modelling.transformers.scaler.NotScalerTransformer'\u001b[0m,\n",
       "                    \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'feature_selector'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'class'\u001b[0m: \u001b[32m'project.packages.modelling.feature_selection.feature_selector_pipeline.FeatureSelector'\u001b[0m,\n",
       "            \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'fs_params'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'selectors'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'model_based'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                    \u001b[32m'model_based'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'estimator'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'class'\u001b[0m: \u001b[32m'xgboost.XGBClassifier'\u001b[0m,\n",
       "                            \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m30\u001b[0m, \u001b[32m'max_depth'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'random_state'\u001b[0m: \u001b[1;36m42\u001b[0m\u001b[1m}\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m,\n",
       "                        \u001b[32m'threshold'\u001b[0m: \u001b[1;36m0.014506382657943451\u001b[0m,\n",
       "                        \u001b[32m'prefit'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'class'\u001b[0m: \u001b[32m'xgboost.XGBClassifier'\u001b[0m,\n",
       "            \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m430\u001b[0m,\n",
       "                \u001b[32m'learning_rate'\u001b[0m: \u001b[1;36m0.05778333213062965\u001b[0m,\n",
       "                \u001b[32m'min_child_weight'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'max_depth'\u001b[0m: \u001b[1;36m6\u001b[0m,\n",
       "                \u001b[32m'subsample'\u001b[0m: \u001b[1;36m0.8404353004405407\u001b[0m,\n",
       "                \u001b[32m'reg_lambda'\u001b[0m: \u001b[1;36m2.10503360161923\u001b[0m,\n",
       "                \u001b[32m'reg_alpha'\u001b[0m: \u001b[1;36m0.48740033703104\u001b[0m,\n",
       "                \u001b[32m'random_state'\u001b[0m: \u001b[1;36m42\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hypertune_results[\"best_trial_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hypertuning study results\n",
    "\n",
    "1. Optimization history\n",
    "2. More important hypertuning parameters during the optimization\n",
    "3. Parallel plot to visualize optimization decision boundaries\n",
    "4. Slice plots to visualize decision boundaries vs the objective function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95moptuna.study.study.Study\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x286db33a0\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = model.hypertune_results[\"study\"]\n",
    "study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;36m0.8498666160259712\u001b[0m"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8413588024167761,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8429887004244362,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8430936814106018,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8441706327668782,
          0.8483753149839316,
          0.8483753149839316,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8494535614900911,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712,
          0.8498666160259712
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna\n",
    "import optuna.visualization as optuna_visualization\n",
    "\n",
    "fig = optuna_visualization.plot_optimization_history(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "scaler__transformer (CategoricalDistribution): 4.371553227068812e-06<extra></extra>",
          "knn_imputer__n_neighbors (IntDistribution): 7.132478958077418e-06<extra></extra>",
          "fs_mb_xgboost__n_estimators (IntDistribution): 1.8250448775982616e-05<extra></extra>",
          "fs_mb_xgboost__max_depth (IntDistribution): 2.8979691979448996e-05<extra></extra>",
          "xgboost__n_estimators (IntDistribution): 4.16734490814305e-05<extra></extra>",
          "knn_imputer__weights (CategoricalDistribution): 6.935637574573085e-05<extra></extra>",
          "fs_mb__threshold (FloatDistribution): 7.400448107528526e-05<extra></extra>",
          "xgboost__max_depth (IntDistribution): 9.140949630421839e-05<extra></extra>",
          "xgboost__learning_rate (FloatDistribution): 0.000102807744686566<extra></extra>",
          "xgboost__subsample (FloatDistribution): 0.00020065451223225976<extra></extra>",
          "xgboost__reg_alpha (FloatDistribution): 0.0002120749508418214<extra></extra>",
          "xgboost__reg_lambda (FloatDistribution): 0.0026774475102098426<extra></extra>",
          "xgboost__min_child_weight (IntDistribution): 0.9964718373068823<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "1.00"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.000004371553227068812,
          0.000007132478958077418,
          0.000018250448775982616,
          0.000028979691979448996,
          0.0000416734490814305,
          0.00006935637574573085,
          0.00007400448107528526,
          0.00009140949630421839,
          0.000102807744686566,
          0.00020065451223225976,
          0.0002120749508418214,
          0.0026774475102098426,
          0.9964718373068823
         ],
         "y": [
          "scaler__transformer",
          "knn_imputer__n_neighbors",
          "fs_mb_xgboost__n_estimators",
          "fs_mb_xgboost__max_depth",
          "xgboost__n_estimators",
          "knn_imputer__weights",
          "fs_mb__threshold",
          "xgboost__max_depth",
          "xgboost__learning_rate",
          "xgboost__subsample",
          "xgboost__reg_alpha",
          "xgboost__reg_lambda",
          "xgboost__min_child_weight"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the parameter importance\n",
    "fig = optuna_visualization.plot_param_importances(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "Objective Value",
           "range": [
            0.46982323232323225,
            0.8498666160259712
           ],
           "values": [
            0.46982323232323225,
            0.46982323232323225,
            0.46982323232323225,
            0.7800069208288982,
            0.8413588024167761,
            0.7796750574528353,
            0.46982323232323225,
            0.46982323232323225,
            0.46982323232323225,
            0.46982323232323225,
            0.46982323232323225,
            0.7812045968135162,
            0.8308032291810925,
            0.46982323232323225,
            0.46982323232323225,
            0.46982323232323225,
            0.46982323232323225,
            0.8021892735454892,
            0.46982323232323225,
            0.46982323232323225,
            0.46982323232323225,
            0.6963154217692574,
            0.811783766244153,
            0.46982323232323225,
            0.46982323232323225,
            0.7012596424822131,
            0.8429887004244362,
            0.46982323232323225,
            0.46982323232323225,
            0.46982323232323225,
            0.6715094130188469,
            0.7933100827545888,
            0.8295478121798622,
            0.46982323232323225,
            0.46982323232323225,
            0.7685707448808669,
            0.46982323232323225,
            0.46982323232323225,
            0.7878658646178112,
            0.46982323232323225,
            0.46982323232323225,
            0.8043560406210365,
            0.8354586886799922,
            0.7165032826893035,
            0.7935324950920709,
            0.46982323232323225,
            0.46982323232323225,
            0.7862163442693051,
            0.46982323232323225,
            0.8117584992659643,
            0.6715644416675345,
            0.8037475645929483,
            0.8325339299822528,
            0.7866882684100401,
            0.6966718493681404,
            0.46982323232323225,
            0.46982323232323225,
            0.8001997466627692,
            0.46982323232323225,
            0.46982323232323225,
            0.46982323232323225,
            0.8042674952526491,
            0.7834710743801652,
            0.680573159356752,
            0.8134557596619184,
            0.46982323232323225,
            0.7259997607205729,
            0.46982323232323225,
            0.7989816941882802,
            0.7772342003021679,
            0.46982323232323225,
            0.8038930178052333,
            0.7924486559632626,
            0.6986925532380078,
            0.7812216903838729,
            0.8105637360798874,
            0.46982323232323225,
            0.7053254380714565,
            0.46982323232323225,
            0.7813748046389238,
            0.46982323232323225,
            0.8373954428871773,
            0.8125263643590556,
            0.8148126282083353,
            0.816648245033724,
            0.7872096232162156,
            0.7027651674149189,
            0.8126816960122869,
            0.46982323232323225,
            0.8305059115104432,
            0.8338389897782109,
            0.7693602693602694,
            0.7925573540945532,
            0.8400485931075474,
            0.8322935911263063,
            0.8390924995941588,
            0.46982323232323225,
            0.46982323232323225,
            0.7887606220939554,
            0.7728101208090659,
            0.46982323232323225,
            0.8401671416794099,
            0.819214294258781,
            0.8392088147427575,
            0.7842178397733954,
            0.7984548038086549,
            0.7620269289270186,
            0.8358704241809264,
            0.782305825372625,
            0.46982323232323225,
            0.46982323232323225,
            0.8123627144460477,
            0.8314615624133674,
            0.8158751977103262,
            0.7654031726196674,
            0.7848568647966473,
            0.7003033097473328,
            0.8370600399827325,
            0.46982323232323225,
            0.46982323232323225,
            0.7892338374965742,
            0.8352462922355396,
            0.8349124038963612,
            0.8105637360798874,
            0.7795307549382281,
            0.8058701213218245,
            0.7859121296890962,
            0.8010220219829349,
            0.7007279727586345,
            0.8307324920228146,
            0.7848568647966473,
            0.817713032248934,
            0.46982323232323225,
            0.7994843354738276,
            0.8412421078146687,
            0.8313427117445381,
            0.7848568647966473,
            0.8042000592910578,
            0.7700951091672742,
            0.811783766244153,
            0.7847012318513391,
            0.8105637360798874,
            0.8020521706197269,
            0.841805517409747,
            0.8328786496340432,
            0.7015128504607095,
            0.7920872514528102,
            0.8256167082827834,
            0.46982323232323225,
            0.7824227995661613,
            0.6633756289176245,
            0.8392088147427575,
            0.7653783156366818,
            0.7881776097982062,
            0.8325339299822528,
            0.8253707636039312,
            0.8316929234765538,
            0.7861413909431137,
            0.7976678855122432,
            0.720211054325194,
            0.8193851559068951,
            0.8342789943602194,
            0.7896518518105313,
            0.8116177266000588,
            0.7945871837010827,
            0.8373954428871773,
            0.8355618605618605,
            0.7987479879484543,
            0.8042000592910578,
            0.7848568647966473,
            0.8286967169819097,
            0.8378144378144378,
            0.793915523120999,
            0.8085986838613808,
            0.7892338374965742,
            0.7908705949302469,
            0.7861413909431137,
            0.8217637955995697,
            0.7848568647966473,
            0.8282459903305827,
            0.8110302897809047,
            0.8430936814106018,
            0.7800263052194589,
            0.8258665082194494,
            0.8187781478232847,
            0.7873774620169777,
            0.7970354259972238,
            0.831578295761588,
            0.8055700900518964,
            0.7848568647966473,
            0.7841037214125053,
            0.816648245033724,
            0.8307324920228146,
            0.7980953128800914,
            0.8308426398386515,
            0.797369828801211,
            0.7653783156366818,
            0.7782441434430467,
            0.7824349290287218,
            0.7868648656789576,
            0.8088460333753942,
            0.46982323232323225,
            0.8332046981139647,
            0.8259860691507218,
            0.8244252915439678,
            0.8037166422032569,
            0.8016258850630973,
            0.8122437851907783,
            0.8324148209994937,
            0.7873778177760505,
            0.842016992554627,
            0.8378144378144378,
            0.8237623623277424,
            0.46982323232323225,
            0.816648245033724,
            0.7975312513403748,
            0.841143726891318,
            0.8441706327668782,
            0.46982323232323225,
            0.7899764470440789,
            0.8221598114348577,
            0.8298773245431845,
            0.836320746795232,
            0.7971283942905023,
            0.8019325823785515,
            0.7905395983113641,
            0.8343143860458349,
            0.7705691213173758,
            0.8058345909773162,
            0.8181483434176061,
            0.7887606220939554,
            0.8424166030139313,
            0.8301881376171062,
            0.7890443887760493,
            0.8265643452265937,
            0.8069317513761957,
            0.8336108941149343,
            0.8181483434176061,
            0.8322348731670277,
            0.8299829922699407,
            0.7848568647966473,
            0.8125381575871466,
            0.830450448445006,
            0.8430936814106018,
            0.7836640737002963,
            0.8294337680869773,
            0.46982323232323225,
            0.7793318132586108,
            0.46982323232323225,
            0.8199046891587786,
            0.8422206603780747,
            0.7812216903838729,
            0.8107217582139212,
            0.46982323232323225,
            0.7854577251989087,
            0.8266849834247955,
            0.46982323232323225,
            0.8271746126974008,
            0.7879171507698155,
            0.7763949608443991,
            0.46982323232323225,
            0.8117584992659643,
            0.7680266197086469,
            0.8241668931324104,
            0.7980953128800914,
            0.7906392011470801,
            0.8158751977103262,
            0.7919443994310305,
            0.8377126792460198,
            0.8339520788661303,
            0.7854577251989087,
            0.816294439042688,
            0.8419122361403112,
            0.8054162864704432,
            0.8314615624133674,
            0.8113012273027473,
            0.8230983487077738,
            0.7847609833004587,
            0.8316929234765538,
            0.698604409616048,
            0.8072225594892407,
            0.8199916193458224,
            0.818288707177596,
            0.7926485741831626,
            0.7961645174882984,
            0.7685704913749558,
            0.7895358849776961,
            0.8413588024167761,
            0.8193549518567049,
            0.8288041288041289,
            0.8037475645929483,
            0.7868648656789576,
            0.8062783562783562,
            0.76699311085276,
            0.7825352736490705,
            0.8073805470574537,
            0.46982323232323225,
            0.7920877747784719,
            0.7747051016887347,
            0.7872728299774563,
            0.8032096761263428,
            0.7833282360534863,
            0.8309507075479371,
            0.8051010269042874,
            0.7874839707995865,
            0.8413588024167761,
            0.7848568647966473,
            0.8063200967644926,
            0.8483753149839316,
            0.8175631404471531,
            0.8494535614900911,
            0.46982323232323225,
            0.7887689710746011,
            0.7014478973121837,
            0.7819464486131154,
            0.7653783156366818,
            0.842772866949383,
            0.46982323232323225,
            0.8031404535636645,
            0.7918684719810437,
            0.8408360365388119,
            0.8389741379263068,
            0.46982323232323225,
            0.7653783156366818,
            0.8438492049834518,
            0.7848568647966473,
            0.780804034440973,
            0.8085986838613808,
            0.7826579574026585,
            0.46982323232323225,
            0.7810087406047,
            0.8231908107142042,
            0.847709043969658,
            0.7984269526147151,
            0.8164453086732879,
            0.7774731941267188,
            0.8303894560579054,
            0.8143705834813479,
            0.8307162756393022,
            0.7786883458613796,
            0.7848568647966473,
            0.7845364992459607,
            0.7975214730294302,
            0.8233561626751421,
            0.6715094130188469,
            0.7797203838600735,
            0.7851599776733467,
            0.46982323232323225,
            0.7885189129650848,
            0.8029822757194673,
            0.46982323232323225,
            0.812846100705431,
            0.8102658928306273,
            0.46982323232323225,
            0.7789616925097669,
            0.7824349290287218,
            0.8054162864704432,
            0.8161920989962648,
            0.7972347107966655,
            0.46982323232323225,
            0.7937664431418092,
            0.7975276488053207,
            0.7842255075173541,
            0.46982323232323225,
            0.7954168863448068,
            0.7711471826879223,
            0.8266907716530778,
            0.7903450085268269,
            0.7848568647966473,
            0.46982323232323225,
            0.8169392336059003,
            0.8298773245431845,
            0.7975776801974926,
            0.8174108299565179,
            0.7889696773040504,
            0.8275148716810447,
            0.8146662261898195,
            0.8048087287663259,
            0.8078441240863773,
            0.7194876734718031,
            0.8336065679627324,
            0.7779023233834869,
            0.8208303788194118,
            0.7838017311624617,
            0.7631318487097914,
            0.46982323232323225,
            0.7716899636091555,
            0.8044241500852451,
            0.7295452029262502,
            0.7848568647966473,
            0.8440654385896077,
            0.8419122361403112,
            0.8171910913846397,
            0.8474031538779488,
            0.8058345909773162,
            0.8204214891248859,
            0.76334028879367,
            0.8410431170393942,
            0.8058505135238087,
            0.8322348731670277,
            0.8355618605618605,
            0.8199916193458224,
            0.7884315322994929,
            0.46982323232323225,
            0.46982323232323225,
            0.46982323232323225,
            0.8014401000799581,
            0.7948244868366892,
            0.8319159077887337,
            0.8026581306681119,
            0.7264134624261489,
            0.46982323232323225,
            0.7893163064052107,
            0.7870487729045014,
            0.7890788003823456,
            0.8167954510043351,
            0.8464290293934451,
            0.8333657434530016,
            0.8372856750500254,
            0.8209094018201942,
            0.8100852572440833,
            0.793915523120999,
            0.7789770516018327,
            0.759341490549321,
            0.8085309335309335,
            0.8229660563229467,
            0.783488823126009,
            0.8054979357062689,
            0.8268273806364874,
            0.8422206603780747,
            0.8143201139265568,
            0.8271053382232415,
            0.8255855757210772,
            0.8031404535636645,
            0.8227748775644926,
            0.7490679541867842,
            0.8465307927673519,
            0.7688374473893754,
            0.46982323232323225,
            0.46982323232323225,
            0.7967237981561263,
            0.46982323232323225,
            0.8090139694518717,
            0.8387884094796694,
            0.7610742721682778,
            0.7827354187720035,
            0.7794295615476956,
            0.8305059115104432,
            0.8489826320761573,
            0.7978461867350758,
            0.8229660563229467,
            0.806630970381257,
            0.8276342884844975,
            0.8095023573501426,
            0.8419122361403112,
            0.7653163634304182,
            0.8125381575871466,
            0.8498666160259712,
            0.8461122599836918,
            0.7867926615575213,
            0.8295140719540057,
            0.8419122361403112,
            0.8122052341501838,
            0.8396538395137442,
            0.8290788555263442,
            0.810411171115466,
            0.8094772112032455,
            0.8333092833092834,
            0.825325410847382,
            0.7822748907172601,
            0.8261717461262633,
            0.8353535027762874,
            0.7881776097982062,
            0.818475426959044,
            0.8356328761951377,
            0.8271053382232415,
            0.8084272832895052,
            0.8322348731670277,
            0.7737497403099242,
            0.46982323232323225,
            0.7971467104808033,
            0.46982323232323225,
            0.807993628074108,
            0.7847340856534633,
            0.842016992554627,
            0.827885491837318,
            0.8016221960311848,
            0.822155880544294,
            0.7894801186467854,
            0.8336065679627324,
            0.7763130894349799,
            0.7614219387981903,
            0.46982323232323225,
            0.46982323232323225,
            0.8155837767741358,
            0.8197629470001856,
            0.7843817352651274,
            0.7960949514711082,
            0.811783766244153,
            0.8084108018876622
           ]
          },
          {
           "label": "fs_mb__threshold",
           "range": [
            0.0010370712776251777,
            0.0978893139355095
           ],
           "values": [
            0.08718230210027886,
            0.09380113636694212,
            0.061004164780424926,
            0.015779496404363325,
            0.0018425789560252565,
            0.004594176509979703,
            0.02632946441403268,
            0.032626011572554764,
            0.004231905875396498,
            0.04229864213651614,
            0.05730662636754405,
            0.015824715165500554,
            0.003753012603709645,
            0.010437597330985454,
            0.002238682929788773,
            0.023817480501919695,
            0.0013749669723765415,
            0.01801495125845802,
            0.035323821756859206,
            0.012433566504255297,
            0.02484362394973338,
            0.014669301728109561,
            0.019972848063234728,
            0.008684311032796068,
            0.0018517800243709648,
            0.02031350392418601,
            0.010452924839967244,
            0.00967725928278656,
            0.009453924996714061,
            0.07060902348485489,
            0.04284372413081557,
            0.01968467899714859,
            0.007972034818125842,
            0.0075595770130936785,
            0.0010592450217726057,
            0.013837033857309054,
            0.006770821793576385,
            0.013331523610813592,
            0.006566819469195532,
            0.029826681797419874,
            0.0257642995847268,
            0.019709023923116267,
            0.006184121940246942,
            0.006172635503219647,
            0.012189448054549714,
            0.004944192869380757,
            0.0011501189773531646,
            0.014387837055800766,
            0.006718579061736793,
            0.016821238128795435,
            0.010237202921350084,
            0.02135788805511181,
            0.004659554323147086,
            0.00477719136230287,
            0.010787890295906735,
            0.016742934105846652,
            0.004665021105211804,
            0.0015248868038557064,
            0.010711074910401033,
            0.016280756660455767,
            0.004342055836424161,
            0.00854982625639402,
            0.022396502997840587,
            0.01244135820327687,
            0.018356303295584558,
            0.004416634615095572,
            0.00851314234456364,
            0.017178762938009316,
            0.013730460338220177,
            0.0029590577709611146,
            0.008060186257384052,
            0.019600795860615673,
            0.023683463178001095,
            0.011722243917945274,
            0.015139050848548236,
            0.0037832670149783717,
            0.0074863001803212505,
            0.010348172324609111,
            0.0010558128775755896,
            0.018498103694496393,
            0.029236832903506458,
            0.016080768478582114,
            0.013869847924493115,
            0.013259186916423242,
            0.006735509862264435,
            0.006835260541589224,
            0.0033866563401443815,
            0.006139834610837431,
            0.009604992820438384,
            0.012066622831893577,
            0.0029679732623081496,
            0.003118091941542451,
            0.005729790405944412,
            0.009019213863804196,
            0.010548245617894731,
            0.01107236309881927,
            0.009894124931407908,
            0.015400987785516386,
            0.0026657901253285257,
            0.00888889716059283,
            0.004798615167721501,
            0.011787413780252866,
            0.01066640012418881,
            0.011856388228632213,
            0.01226934326818412,
            0.015967457121980715,
            0.008308550496625553,
            0.0010793640362217367,
            0.001941064967923698,
            0.005693894864716545,
            0.004383783591962267,
            0.011370006119370614,
            0.008566354843018998,
            0.014498530957097421,
            0.002971776850357422,
            0.005845293868617517,
            0.0015043756234750514,
            0.007140167607081473,
            0.007728368488470772,
            0.012611908261314423,
            0.0011665437032156445,
            0.009994498162132597,
            0.006654447789531205,
            0.007255250421098237,
            0.017425514126456394,
            0.009629136450812564,
            0.021476775288328705,
            0.01430987140067019,
            0.0038523871025551867,
            0.011324923100626633,
            0.005650946255819444,
            0.007772764010724102,
            0.00408075397234178,
            0.006251240281429087,
            0.009286390368331243,
            0.012976603241813732,
            0.009327431963780511,
            0.017129549146066722,
            0.011436896437076275,
            0.015129998116238627,
            0.009104841210560655,
            0.003539877790339818,
            0.005885221135422768,
            0.007976356588350993,
            0.00818710527806147,
            0.013088120547422252,
            0.0011327999203598876,
            0.010988250753267162,
            0.006618405730754787,
            0.010029163530841002,
            0.018392196309074984,
            0.008209303899845862,
            0.0034466835318024136,
            0.007275564863010534,
            0.005273083131204998,
            0.013716616870945695,
            0.00983948570993784,
            0.002781734605920987,
            0.01590646356032722,
            0.008041940454282066,
            0.004939362767832158,
            0.007769048103789704,
            0.012337275494685896,
            0.00912231928836255,
            0.006777877253860358,
            0.01078564809545394,
            0.011379323534364853,
            0.011612597746060653,
            0.015214474549646795,
            0.04217253051496733,
            0.010782862218698976,
            0.013347496723962678,
            0.013087762938640229,
            0.016226052801143434,
            0.019297618663794515,
            0.010511766721777428,
            0.013058702871436872,
            0.008992154890881149,
            0.02270738115457746,
            0.011785079099043208,
            0.014621226776416436,
            0.007080520935267898,
            0.00559365309625885,
            0.009527570468478385,
            0.007356049564158338,
            0.005035312950855432,
            0.011392555069658169,
            0.014167602685073244,
            0.008879919220556472,
            0.07050956084056825,
            0.025946966821577114,
            0.007731662374409664,
            0.0065813580984450115,
            0.0029203178270867007,
            0.010056919121465136,
            0.007694820102612427,
            0.01196988467509794,
            0.028285069461199696,
            0.03476796372222836,
            0.0049175532169241035,
            0.01756405212941496,
            0.001601610127777481,
            0.004331644701541895,
            0.0011164126222576894,
            0.008699174068017186,
            0.00334409621790965,
            0.006766676678207484,
            0.01099245897123751,
            0.012885520896030242,
            0.006227190553245347,
            0.009135912398802471,
            0.009445657881914165,
            0.009696327111072876,
            0.008512899068323646,
            0.014110713451405589,
            0.010675015430210825,
            0.007632774266929996,
            0.012448856495061443,
            0.015604577478567663,
            0.012109971966934151,
            0.013529280214955003,
            0.009985358572355366,
            0.00873277939974594,
            0.02435776370761611,
            0.02071332261648614,
            0.010907400782308703,
            0.00883161244857282,
            0.05334635360428579,
            0.012409064427875198,
            0.007683967372414358,
            0.014803832145147484,
            0.00561334480203614,
            0.005676836628039986,
            0.0404418161482457,
            0.009846560677302767,
            0.005170706522620819,
            0.008082581133979373,
            0.011521335744044757,
            0.003699254144764589,
            0.009432536211169794,
            0.09536296494222007,
            0.006663372345539977,
            0.006975878884995731,
            0.010910623277215068,
            0.031468248530167685,
            0.012744671790122305,
            0.010547692700550854,
            0.009185108481827405,
            0.04563990687306094,
            0.013527902210104227,
            0.01137302812312973,
            0.011802470084523857,
            0.016762153692022125,
            0.008030901784821368,
            0.004322939863824003,
            0.01543599708258022,
            0.011194434978893851,
            0.00603338395308114,
            0.01890035566076452,
            0.013687554930972377,
            0.08654501089975572,
            0.008610861863614434,
            0.0029519318192181955,
            0.0106021737183383,
            0.023388126336685588,
            0.012839793618878492,
            0.006980851997480077,
            0.0051125637849104705,
            0.009333219892574275,
            0.00902758656994226,
            0.0010370712776251777,
            0.0148281047712465,
            0.011539790789436188,
            0.010269255866297271,
            0.017247163260461093,
            0.01245944301564713,
            0.007590599788785324,
            0.009523848978505816,
            0.02082908176806015,
            0.0253059024193115,
            0.01465969788843274,
            0.011866637185919023,
            0.008151675684346759,
            0.003722285847005919,
            0.03744532120197562,
            0.046649972012846756,
            0.005410324665028993,
            0.010481803502830359,
            0.011252036311418282,
            0.013621586585054388,
            0.009695533109029607,
            0.008316040739441071,
            0.02935553769882141,
            0.06304025779204867,
            0.0343705196092702,
            0.012412191788674962,
            0.026516448491991022,
            0.01623416128342146,
            0.0312669542273283,
            0.010260436598409129,
            0.006626117921869568,
            0.013836356878641468,
            0.011037748103663206,
            0.008260659417731776,
            0.018714679942832275,
            0.012538830220671695,
            0.016186942106493366,
            0.013019729519517603,
            0.014786397422246855,
            0.014573628773102443,
            0.014895086882852264,
            0.020629581874102243,
            0.01771804299140449,
            0.015029830688143151,
            0.01548807088587929,
            0.012764750867125942,
            0.01850516445652279,
            0.01702627911736749,
            0.011482355997812504,
            0.018690224868945324,
            0.01391200089081485,
            0.014117719662893526,
            0.014448719733617204,
            0.016856362831423992,
            0.013677707377188061,
            0.01967183886364995,
            0.013501578160259398,
            0.021765046807067107,
            0.01605430883169054,
            0.011781023763017092,
            0.05544428546685071,
            0.015109264378214044,
            0.012342921069559814,
            0.011756925628695453,
            0.012634956232510819,
            0.03226692090102471,
            0.010197952857616412,
            0.005804727889749519,
            0.017687706642617634,
            0.03520167092162116,
            0.011269938098533005,
            0.04922244264208889,
            0.03998086871692631,
            0.014377782885873781,
            0.037497309117896865,
            0.04408257829810083,
            0.007341042327352528,
            0.010228717590694394,
            0.02808621629157223,
            0.0126826599726803,
            0.004014276298538239,
            0.00844990562356882,
            0.022801522152070923,
            0.016866599885454123,
            0.060245786197554815,
            0.012938308650734257,
            0.009762763522766891,
            0.005781274565593372,
            0.015434243922183025,
            0.010711234816099065,
            0.007624351271174383,
            0.02400817719233475,
            0.052275041132701705,
            0.0029121365667962454,
            0.02999951989937747,
            0.02009192161971113,
            0.013196162049561071,
            0.03377420003927692,
            0.08995475114300967,
            0.011414696689830956,
            0.00876273580317855,
            0.006637546378952921,
            0.04783257812967895,
            0.015333612460380924,
            0.00484618535591233,
            0.012191067396902977,
            0.018163552630911448,
            0.009730903737440285,
            0.013372501907155101,
            0.04190121327959192,
            0.007616871537572531,
            0.010689789686061487,
            0.014987486095022411,
            0.037639738892599084,
            0.05161712760293857,
            0.04963010383134978,
            0.0978893139355095,
            0.04438905679409591,
            0.009242228291198548,
            0.07104367563519659,
            0.002521171130845293,
            0.005727796673308964,
            0.0013722755672748062,
            0.0032287739398997543,
            0.004308612895758549,
            0.0018087062760320715,
            0.003282687677102594,
            0.003076798859611507,
            0.002603236912684458,
            0.0043306730287459155,
            0.0030271743204965166,
            0.004961788709021246,
            0.002173858330362605,
            0.005794489153340146,
            0.003584838868786591,
            0.0011028323487191423,
            0.025692021040163722,
            0.005667258058273693,
            0.0062470224853368094,
            0.027247222692540936,
            0.0037385467798249986,
            0.006665124580513603,
            0.018539978009458124,
            0.032700683611820845,
            0.0010842383307033238,
            0.004782702692742713,
            0.00677867288202685,
            0.002985143436956077,
            0.006519255518713438,
            0.007723333454272926,
            0.02123866304603226,
            0.004776075455424586,
            0.028234172340892746,
            0.04794653333157578,
            0.016476405658083355,
            0.007267832700968685,
            0.00239875412225415,
            0.005154909371259412,
            0.008312542120562531,
            0.004176654610802289,
            0.003602617308079406,
            0.006034165014283704,
            0.0014000866388465456,
            0.004341366928949277,
            0.006727080894740665,
            0.022318294734313748,
            0.00897145574396178,
            0.03602625396287615,
            0.009225082817879869,
            0.010134000930206938,
            0.025057822777439315,
            0.031973295547193414,
            0.008042789113362757,
            0.011141763369988724,
            0.055910788244709866,
            0.04508247125070647,
            0.008842510325875571,
            0.006585360156867813,
            0.012034862193472334,
            0.012862357475739564,
            0.015109446661130344,
            0.019753683939898507,
            0.029865089531844972,
            0.01172111325754225,
            0.016363194845968564,
            0.01922624929718744,
            0.01709864919008509,
            0.014506382657943451,
            0.01631696661872629,
            0.016057691535473,
            0.01810236814661036,
            0.02292764724607782,
            0.021107441839859437,
            0.01692815005816456,
            0.01792617492815952,
            0.022884512281302324,
            0.019019156136304283,
            0.01484879699107677,
            0.020530954763025105,
            0.016338707971156944,
            0.013990189774423185,
            0.014895825868185416,
            0.027159588326548918,
            0.017483669666919086,
            0.024427741559183695,
            0.019710736612954822,
            0.013714540690706491,
            0.015505028302050793,
            0.0753122782044342,
            0.01293457289672582,
            0.03935264505239296,
            0.02279127530578855,
            0.0167656058936117,
            0.04063549141979267,
            0.013847981921031864,
            0.014058453345479859,
            0.03865313394884087,
            0.018350349213469685,
            0.015945609064403295,
            0.012200271488560241,
            0.055237775368485835,
            0.0789180953226469,
            0.049221855488831984,
            0.060738359215624184,
            0.014037910794639927,
            0.01943785476860161,
            0.03248098509520933,
            0.04552278871966443,
            0.011433617594268097,
            0.016647145242973477
           ]
          },
          {
           "label": "fs_mb_xgboost__ma...",
           "range": [
            2,
            10
           ],
           "values": [
            4,
            4,
            10,
            3,
            2,
            8,
            2,
            6,
            6,
            2,
            8,
            4,
            4,
            5,
            2,
            3,
            3,
            5,
            7,
            5,
            3,
            5,
            4,
            4,
            2,
            3,
            7,
            7,
            10,
            8,
            9,
            7,
            4,
            6,
            4,
            5,
            6,
            3,
            7,
            2,
            9,
            4,
            4,
            5,
            4,
            2,
            6,
            3,
            4,
            3,
            2,
            4,
            5,
            5,
            6,
            5,
            3,
            4,
            8,
            5,
            6,
            4,
            4,
            3,
            5,
            5,
            7,
            6,
            5,
            7,
            5,
            4,
            4,
            3,
            4,
            5,
            6,
            8,
            4,
            3,
            2,
            3,
            3,
            3,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            3,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            3,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            9,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            7,
            2,
            2,
            3,
            2,
            2,
            2,
            7,
            7,
            7,
            8,
            7,
            2,
            2,
            2,
            2,
            3,
            7,
            7,
            7,
            6,
            7,
            7,
            8,
            7,
            7,
            6,
            7,
            7,
            7,
            8,
            7,
            7,
            10,
            6,
            8,
            7,
            7,
            7,
            7,
            7,
            7,
            2,
            2,
            2,
            7,
            2,
            7,
            7,
            7,
            7,
            2,
            7,
            2,
            2,
            7,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            7,
            2,
            2,
            7,
            7,
            7,
            7,
            7,
            7,
            7,
            7,
            7,
            8,
            7,
            7,
            7,
            7,
            7,
            6,
            7,
            7,
            7,
            7,
            7,
            7,
            7,
            7,
            7,
            7,
            7,
            7,
            8,
            7,
            7,
            2,
            6,
            2,
            7,
            2,
            7,
            2,
            7,
            2,
            2,
            7,
            9,
            2,
            7,
            2,
            7,
            2,
            7,
            2,
            6,
            7,
            2,
            3,
            7,
            2,
            7,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            8,
            2,
            2,
            2,
            2,
            2,
            7,
            2,
            2,
            2,
            7,
            2,
            7,
            2,
            6,
            7,
            2,
            8,
            7,
            2,
            7,
            2,
            3,
            7,
            2,
            7,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            10,
            2,
            6,
            2,
            8,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            9,
            6,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            5,
            3,
            3,
            4,
            3,
            3,
            2,
            2,
            8,
            2,
            2,
            2,
            6,
            4,
            2,
            2,
            2,
            7,
            3,
            2,
            2,
            2,
            7,
            2,
            2,
            5,
            2,
            2,
            8,
            7,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            6,
            10,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            4,
            2,
            7
           ]
          },
          {
           "label": "fs_mb_xgboost__n_...",
           "range": [
            10,
            500
           ],
           "values": [
            30,
            10,
            140,
            480,
            470,
            500,
            340,
            330,
            390,
            200,
            420,
            480,
            260,
            240,
            110,
            300,
            400,
            190,
            270,
            70,
            440,
            180,
            220,
            240,
            340,
            130,
            280,
            300,
            360,
            290,
            60,
            210,
            160,
            160,
            90,
            30,
            160,
            270,
            460,
            360,
            320,
            230,
            210,
            160,
            130,
            260,
            200,
            500,
            380,
            180,
            110,
            220,
            250,
            250,
            280,
            310,
            420,
            250,
            180,
            230,
            200,
            210,
            280,
            150,
            230,
            230,
            260,
            330,
            180,
            470,
            240,
            210,
            280,
            300,
            220,
            190,
            240,
            140,
            170,
            260,
            350,
            180,
            120,
            80,
            90,
            70,
            10,
            90,
            50,
            90,
            110,
            100,
            120,
            50,
            50,
            40,
            40,
            10,
            60,
            20,
            40,
            60,
            30,
            60,
            60,
            50,
            70,
            20,
            30,
            20,
            440,
            50,
            20,
            40,
            70,
            80,
            60,
            110,
            110,
            150,
            40,
            380,
            500,
            370,
            490,
            490,
            480,
            460,
            410,
            440,
            500,
            80,
            400,
            100,
            130,
            120,
            130,
            140,
            100,
            170,
            460,
            200,
            10,
            60,
            80,
            60,
            20,
            150,
            30,
            110,
            50,
            70,
            70,
            40,
            60,
            80,
            100,
            330,
            130,
            430,
            470,
            90,
            90,
            70,
            110,
            90,
            50,
            50,
            60,
            50,
            30,
            90,
            70,
            80,
            380,
            60,
            40,
            30,
            350,
            70,
            90,
            500,
            500,
            490,
            450,
            480,
            100,
            500,
            480,
            40,
            190,
            80,
            90,
            120,
            60,
            50,
            90,
            470,
            80,
            100,
            70,
            110,
            130,
            110,
            490,
            50,
            20,
            170,
            120,
            70,
            100,
            100,
            100,
            90,
            290,
            80,
            60,
            40,
            50,
            30,
            60,
            40,
            310,
            270,
            300,
            40,
            60,
            250,
            220,
            50,
            70,
            320,
            280,
            310,
            330,
            310,
            340,
            290,
            400,
            10,
            360,
            50,
            320,
            500,
            60,
            100,
            70,
            40,
            270,
            380,
            30,
            30,
            30,
            20,
            80,
            40,
            210,
            50,
            60,
            500,
            30,
            90,
            20,
            190,
            110,
            70,
            120,
            150,
            50,
            50,
            40,
            80,
            60,
            60,
            70,
            100,
            10,
            60,
            40,
            490,
            90,
            480,
            80,
            70,
            60,
            40,
            30,
            50,
            60,
            50,
            90,
            50,
            70,
            100,
            290,
            50,
            120,
            240,
            110,
            80,
            60,
            70,
            140,
            320,
            500,
            40,
            40,
            30,
            50,
            40,
            50,
            50,
            50,
            30,
            40,
            60,
            60,
            60,
            50,
            60,
            70,
            70,
            70,
            70,
            40,
            20,
            40,
            30,
            60,
            50,
            40,
            60,
            30,
            20,
            30,
            40,
            460,
            30,
            10,
            420,
            20,
            40,
            50,
            30,
            50,
            490,
            40,
            60,
            470,
            50,
            30,
            50,
            60,
            70,
            40,
            20,
            440,
            80,
            490,
            60,
            260,
            50,
            40,
            30,
            70,
            60,
            50,
            500,
            480,
            40,
            80,
            70,
            20,
            10,
            50,
            30,
            60,
            40,
            60,
            40,
            50,
            80,
            70,
            30,
            50,
            450,
            20,
            60,
            40,
            500,
            70,
            80,
            80,
            80,
            80,
            80,
            70,
            350,
            330,
            360,
            340,
            90,
            290,
            410,
            300,
            480,
            80,
            270,
            70,
            70,
            390,
            320,
            470,
            280,
            350,
            60,
            500,
            500,
            490,
            490,
            480,
            450,
            490,
            500,
            500,
            480,
            90,
            350,
            300,
            230,
            250,
            470,
            20,
            500,
            280,
            190,
            170,
            170,
            180,
            160,
            220,
            490,
            150,
            210,
            130,
            140,
            240,
            200,
            40,
            30,
            30,
            40,
            20,
            10,
            50,
            50,
            40,
            30,
            30,
            30,
            10,
            20,
            230,
            10,
            20,
            20,
            30,
            20,
            10,
            250,
            30,
            30,
            40,
            20,
            30,
            50,
            10,
            40,
            260,
            50,
            30,
            20,
            40,
            230,
            60,
            30,
            40,
            60,
            50,
            20,
            40,
            60,
            50,
            20,
            90,
            200,
            80,
            10,
            270,
            170
           ]
          },
          {
           "label": "knn_imputer__n_ne...",
           "range": [
            2,
            20
           ],
           "values": [
            10,
            10,
            16,
            2,
            2,
            2,
            6,
            20,
            7,
            15,
            6,
            2,
            2,
            5,
            4,
            8,
            14,
            4,
            13,
            8,
            20,
            4,
            4,
            3,
            2,
            5,
            8,
            12,
            9,
            7,
            11,
            3,
            5,
            6,
            10,
            3,
            5,
            18,
            2,
            7,
            9,
            3,
            4,
            6,
            5,
            2,
            3,
            4,
            6,
            8,
            5,
            4,
            4,
            2,
            7,
            3,
            4,
            2,
            6,
            9,
            5,
            4,
            3,
            4,
            3,
            2,
            3,
            11,
            3,
            5,
            8,
            4,
            2,
            5,
            3,
            2,
            4,
            7,
            6,
            4,
            12,
            8,
            9,
            9,
            8,
            8,
            9,
            10,
            7,
            8,
            10,
            10,
            8,
            12,
            13,
            11,
            13,
            12,
            15,
            13,
            11,
            14,
            14,
            12,
            12,
            14,
            15,
            12,
            11,
            10,
            12,
            13,
            13,
            12,
            11,
            14,
            12,
            15,
            15,
            17,
            10,
            14,
            16,
            18,
            16,
            16,
            16,
            17,
            14,
            15,
            11,
            14,
            15,
            17,
            12,
            12,
            13,
            11,
            13,
            12,
            16,
            11,
            10,
            14,
            14,
            14,
            15,
            13,
            12,
            13,
            15,
            14,
            14,
            11,
            14,
            12,
            16,
            15,
            13,
            10,
            14,
            14,
            13,
            14,
            12,
            9,
            7,
            8,
            7,
            9,
            8,
            7,
            7,
            7,
            6,
            9,
            6,
            8,
            7,
            11,
            15,
            14,
            15,
            13,
            7,
            9,
            14,
            12,
            16,
            8,
            13,
            14,
            14,
            15,
            13,
            12,
            11,
            14,
            14,
            8,
            14,
            10,
            10,
            11,
            15,
            9,
            9,
            10,
            13,
            17,
            20,
            19,
            19,
            20,
            20,
            19,
            18,
            19,
            19,
            19,
            18,
            20,
            18,
            19,
            19,
            18,
            18,
            18,
            19,
            20,
            20,
            17,
            17,
            18,
            18,
            17,
            19,
            12,
            18,
            19,
            20,
            17,
            16,
            17,
            17,
            6,
            7,
            12,
            18,
            8,
            19,
            18,
            19,
            19,
            5,
            20,
            19,
            2,
            11,
            12,
            12,
            17,
            18,
            19,
            8,
            7,
            13,
            20,
            18,
            18,
            18,
            17,
            11,
            11,
            12,
            11,
            19,
            11,
            18,
            19,
            17,
            12,
            18,
            13,
            11,
            20,
            16,
            9,
            9,
            9,
            10,
            9,
            15,
            8,
            19,
            10,
            14,
            18,
            9,
            17,
            13,
            19,
            20,
            16,
            17,
            18,
            14,
            15,
            19,
            19,
            19,
            19,
            20,
            19,
            19,
            19,
            18,
            18,
            18,
            18,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            19,
            20,
            19,
            20,
            19,
            20,
            19,
            19,
            12,
            17,
            13,
            11,
            20,
            18,
            19,
            12,
            20,
            11,
            13,
            19,
            14,
            18,
            17,
            20,
            19,
            16,
            10,
            18,
            12,
            20,
            14,
            13,
            19,
            19,
            18,
            20,
            12,
            17,
            19,
            11,
            10,
            15,
            14,
            18,
            20,
            13,
            16,
            11,
            20,
            19,
            17,
            18,
            19,
            12,
            14,
            20,
            12,
            19,
            19,
            19,
            19,
            19,
            19,
            19,
            19,
            19,
            18,
            19,
            18,
            19,
            20,
            19,
            19,
            18,
            20,
            19,
            20,
            18,
            19,
            20,
            19,
            18,
            20,
            19,
            19,
            19,
            18,
            19,
            20,
            19,
            18,
            20,
            19,
            19,
            18,
            3,
            20,
            19,
            17,
            20,
            18,
            19,
            20,
            19,
            18,
            19,
            17,
            20,
            18,
            19,
            20,
            5,
            6,
            19,
            16,
            18,
            20,
            19,
            17,
            18,
            19,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            20,
            19,
            20,
            19,
            20,
            19,
            20,
            19,
            20,
            19,
            20,
            19,
            19,
            20,
            20,
            20,
            20,
            20,
            20,
            19,
            19,
            20,
            19,
            20,
            19,
            20,
            19,
            20,
            20
           ]
          },
          {
           "label": "knn_imputer__weig...",
           "range": [
            0,
            1
           ],
           "ticktext": [
            "distance",
            "uniform"
           ],
           "tickvals": [
            0,
            1
           ],
           "values": [
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            1,
            0,
            0,
            1,
            0,
            1,
            0,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1
           ]
          },
          {
           "label": "scaler__transformer",
           "range": [
            0,
            2
           ],
           "ticktext": [
            "sklearn.preprocessing.QuantileTransformer",
            "project.packages.modelling.transformers.scaler.NotScalerTransformer",
            "sklearn.preprocessing.PowerTransformer"
           ],
           "tickvals": [
            0,
            1,
            2
           ],
           "values": [
            0,
            0,
            1,
            0,
            2,
            2,
            2,
            2,
            1,
            2,
            2,
            0,
            0,
            0,
            1,
            2,
            0,
            2,
            0,
            1,
            0,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            1,
            0,
            0,
            2,
            2,
            2,
            2,
            0,
            2,
            2,
            1,
            2,
            0,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            0,
            1,
            2,
            2,
            2,
            2,
            2,
            2,
            0,
            2,
            1,
            2,
            0,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            0,
            2,
            2,
            2,
            2,
            2,
            2,
            1,
            2,
            0,
            2,
            2,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            2,
            1,
            1,
            2,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            2,
            0,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            0,
            2,
            1,
            1,
            1,
            1,
            2,
            1,
            0,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            1,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            0,
            2,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            1,
            2,
            1,
            0,
            1,
            1,
            1,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            0,
            2,
            2,
            2,
            1,
            1,
            0,
            1,
            2,
            1,
            1,
            2,
            1,
            1,
            1,
            2,
            1,
            1,
            0,
            1,
            2,
            1,
            1,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1
           ]
          },
          {
           "label": "xgboost__learning...",
           "range": [
            0.0001314817271862584,
            0.9683642581373981
           ],
           "values": [
            0.3925136468134222,
            0.38208404980070293,
            0.8733243417622814,
            0.04544733852500937,
            0.021583189959284575,
            0.01802189559897557,
            0.2081591517438272,
            0.7115318813056645,
            0.542087215834471,
            0.15746253681106132,
            0.2510642047739566,
            0.005660842721502891,
            0.002795035258286264,
            0.17895476181477427,
            0.10592433178880975,
            0.2879058972572614,
            0.0013785709153815197,
            0.14872972534672188,
            0.3197538572713865,
            0.1067719251711543,
            0.5147294730511498,
            0.11428846476752014,
            0.103298419415503,
            0.07980963763839456,
            0.22076185761995487,
            0.0032642485777751723,
            0.09695821118980388,
            0.18624912303145144,
            0.06932341348876517,
            0.3478863018689504,
            0.264087905412473,
            0.08613936732511664,
            0.1574703613526946,
            0.4326548252557329,
            0.1493458999420411,
            0.05870749181133461,
            0.21379045187237478,
            0.05363103932763263,
            0.046309948956956226,
            0.14065253668764427,
            0.230312824310655,
            0.11904778442892265,
            0.03369788320825845,
            0.02946045528017524,
            0.17451807273682798,
            0.002376979401198076,
            0.057038868280316624,
            0.17804920486505854,
            0.033521145315927044,
            0.1369800103483166,
            0.2714586912996223,
            0.10476861193195351,
            0.09511184312630586,
            0.0687184541160669,
            0.03130133681172803,
            0.002654857500227512,
            0.09940821397517936,
            0.19209872336491335,
            0.14349422377768845,
            0.08343602252389945,
            0.03919824688220737,
            0.10846891871986851,
            0.08265057814391658,
            0.16420029205415032,
            0.12339135252130617,
            0.2097218385042754,
            0.1349735793698032,
            0.2425985255279689,
            0.03210504012585935,
            0.07442890884022613,
            0.12355704564156837,
            0.09315310831561932,
            0.055138385495521344,
            0.015624752362376784,
            0.19220648232990167,
            0.15821624861662245,
            0.1124557261176794,
            0.056673900634027476,
            0.0017513833854317568,
            0.025969161396300226,
            0.07807654594544283,
            0.13116349031515723,
            0.12831843495280276,
            0.16201340421636665,
            0.1637659299491418,
            0.229459516787624,
            0.17166946968899557,
            0.2977517594013833,
            0.2023518248528616,
            0.15789294411972743,
            0.0411875585262903,
            0.04705659735451254,
            0.08790448618465348,
            0.02714478880339107,
            0.015073233515108371,
            0.021857083176411024,
            0.026505021997506612,
            0.0014461450788252578,
            0.05953818507401997,
            0.02323559691034341,
            0.04973771193672388,
            0.06845953028501071,
            0.06889291631359776,
            0.023207687460771755,
            0.040549009674363604,
            0.018124530345835485,
            0.09424190510551955,
            0.0680286510319928,
            0.07047133759173595,
            0.10196609735209243,
            0.03989883600531212,
            0.018013293681194024,
            0.06332186820325321,
            0.04241458374021852,
            0.08631379494056049,
            0.015943023404588787,
            0.10100862512557704,
            0.12463501782860002,
            0.12577865599738802,
            0.13796033530307147,
            0.11475601653558656,
            0.07654759002758964,
            0.06929302483102834,
            0.06977993902540108,
            0.04633369085317361,
            0.07978131387863346,
            0.05793778484292664,
            0.038062422511082404,
            0.11271189246714025,
            0.07887305993277706,
            0.003503525591432341,
            0.0998052700088293,
            0.14181686167047153,
            0.030931066892498665,
            0.0898383961925743,
            0.060330229335726,
            0.0014037460339173559,
            0.08570899708927411,
            0.12337671110598947,
            0.052711681747293376,
            0.023976705915834937,
            0.09386557962255314,
            0.06862929564328595,
            0.038345382110852394,
            0.04089287187666972,
            0.026697649664492007,
            0.0675311448683333,
            0.11029188420102434,
            0.05075401126530049,
            0.018768275439158,
            0.1478007433793952,
            0.04267921715792768,
            0.0012647949014405607,
            0.038141160962920556,
            0.06981695988560331,
            0.08553747695935246,
            0.04998629525553129,
            0.39299481727041724,
            0.025291831110239277,
            0.12411172653926371,
            0.18620804565807186,
            0.041963150969737885,
            0.08187383600287193,
            0.053774821611847406,
            0.03566075048529262,
            0.09993725559957642,
            0.09711762629272945,
            0.10547696775480449,
            0.132589020004473,
            0.10067384330682513,
            0.07237820976850959,
            0.08671912109779704,
            0.5907491874402411,
            0.09174080767634342,
            0.11418076258991988,
            0.06924133377509836,
            0.1536030537449734,
            0.08459834063460403,
            0.0196795924105434,
            0.14122164333908144,
            0.05805516788448084,
            0.03964636103580148,
            0.002517633870496045,
            0.06440055903333004,
            0.10370739099416461,
            0.3236771019662027,
            0.023863083472672752,
            0.08325848803567273,
            0.05170672024504776,
            0.1256224132235575,
            0.24082729666099278,
            0.036936579328518584,
            0.045978151822003634,
            0.02290770805959834,
            0.07156165326738438,
            0.09100566538919233,
            0.0012862858487309795,
            0.2703161581157103,
            0.038910377343723865,
            0.054990544946636716,
            0.019415517465968892,
            0.035698881020444675,
            0.061349404361546456,
            0.20938745862990643,
            0.11050530513358013,
            0.07847501511331637,
            0.04292072802680402,
            0.08834177565028309,
            0.17087525419809252,
            0.022016662743310145,
            0.06102144894681829,
            0.058444206714420875,
            0.06567777273407405,
            0.1033883774343542,
            0.05470775266676766,
            0.07603646523965402,
            0.12312491750905097,
            0.13178100232377266,
            0.12563218901995454,
            0.14396485846821405,
            0.1837386707000177,
            0.12594182727220882,
            0.10165541777385478,
            0.10584000942171223,
            0.14747792704629129,
            0.9033814012149844,
            0.09450154596197818,
            0.11197257153309886,
            0.3825501219109471,
            0.09143302099845318,
            0.12198078723606005,
            0.2600631882030452,
            0.2594931505785489,
            0.15125172366807754,
            0.19842034514171014,
            0.28157417439497834,
            0.352866023975816,
            0.16369126992721064,
            0.13364518757261173,
            0.23614052757203757,
            0.06987777193070116,
            0.2159558217599315,
            0.08407128975960569,
            0.04687401412359843,
            0.034343049023243824,
            0.45786609360952346,
            0.053175107849922604,
            0.015283518746350738,
            0.10525994069061094,
            0.05681913170653289,
            0.07519535954177065,
            0.027157099288057637,
            0.09574779713902956,
            0.00043210186598976325,
            0.04503064291761955,
            0.07251355817322086,
            0.12264760518427997,
            0.16908832178355926,
            0.03392908501851056,
            0.776483084125839,
            0.06224763332314075,
            0.2977118336327346,
            0.0870380926114164,
            0.11075402437126662,
            0.013712178679100732,
            0.13455428445949613,
            0.05063971317612747,
            0.07845903135491505,
            0.1882521109712161,
            0.22030854535629987,
            0.15366841290894884,
            0.258033438510866,
            0.11304242185353798,
            0.18832714468069892,
            0.11956382835506629,
            0.14010540163510646,
            0.17519245914518952,
            0.11051392431070588,
            0.19622833377629134,
            0.09220603799861832,
            0.5863883842511539,
            0.1561385662488388,
            0.06047523530434459,
            0.1327395431466635,
            0.033895313409187805,
            0.07644330888735552,
            0.23567043340715968,
            0.10809738869063583,
            0.10788072270882676,
            0.1372951446636852,
            0.1224856062322622,
            0.42351313624156606,
            0.3226872758444521,
            0.9683642581373981,
            0.097338839900326,
            0.1786778239942558,
            0.04665770231114884,
            0.49189414519632557,
            0.15930431481506457,
            0.08205361585647122,
            0.021078672022101053,
            0.29538926925930825,
            0.10289084422051856,
            0.06246900715172729,
            0.12136159195218844,
            0.013504638125174159,
            0.004362214171176056,
            0.024042447704748608,
            0.042289699821556635,
            0.03860975853795915,
            0.01989443319536055,
            0.011913145505008202,
            0.03398839251604778,
            0.017605773238403448,
            0.04987017296184043,
            0.0009550794691439782,
            0.03653244038313204,
            0.03201045708993177,
            0.04961017423322252,
            0.01833676854376334,
            0.040328020964385446,
            0.034734137576739293,
            0.00042667494124380874,
            0.030138125258075948,
            0.03720404831289152,
            0.03995690223320449,
            0.02296357094719637,
            0.05065002534641873,
            0.023728679148590025,
            0.0001314817271862584,
            0.04260466892504977,
            0.06315189640557219,
            0.018246075872017473,
            0.022271545816076755,
            0.014677973996866354,
            0.06254053725128986,
            0.3130778939485399,
            0.044273204406163495,
            0.071722552484179,
            0.023628055421889525,
            0.00221373401083055,
            0.051737405081343786,
            0.03891685673591862,
            0.26611690145626765,
            0.06449908222201374,
            0.02086133879762249,
            0.07027454428155777,
            0.00030120272422801825,
            0.2204314818934126,
            0.0430360669047643,
            0.07954863138191956,
            0.03149308735305227,
            0.253048521660342,
            0.3425273767399237,
            0.052764758164750736,
            0.018620274700475253,
            0.07860156941979972,
            0.05205161639745791,
            0.3687029565820086,
            0.03324327245747095,
            0.5635743175239643,
            0.5095664748379056,
            0.6650880167327308,
            0.0007136417145930732,
            0.06930819323352137,
            0.03652445573938532,
            0.4886525929162133,
            0.08709247312052035,
            0.2857730601451093,
            0.015976017916771276,
            0.4564135307182422,
            0.3869790215562393,
            0.20754461820809578,
            0.06316319270453015,
            0.396869871087452,
            0.2340225356069876,
            0.04925690547597453,
            0.4080121259279034,
            0.025137041314202673,
            0.08366315240592646,
            0.05195430760948036,
            0.016456140136182854,
            0.34923849862987255,
            0.03595880084353681,
            0.28043923505825297,
            0.06937549001872212,
            0.09095432376614548,
            0.3362032077820579,
            0.018016630989650798,
            0.7890219017068782,
            0.0541676651410419,
            0.06231811687820659,
            0.3662684977415544,
            0.09417844166661929,
            0.08452970227207589,
            0.11546982341394688,
            0.10365373481073697,
            0.15081918044528198,
            0.14499206975832696,
            0.1563207845650961,
            0.1295609097022458,
            0.10140094962282738,
            0.12266080308978702,
            0.17296960453190885,
            0.07579994460538807,
            0.10630114688514988,
            0.14711775744746833,
            0.06463850089870143,
            0.42958258257017146,
            0.09038313737205966,
            0.11684417575869072,
            0.06462226547044261,
            0.09026841247351686,
            0.21826664329235518,
            0.6247792596767632,
            0.2045147416506926,
            0.1656549862659517,
            0.16595408128403194,
            0.1367966193745351,
            0.3179564391156555,
            0.1719903171558833,
            0.10856864138800346,
            0.18634897556523877,
            0.2549623583645914,
            0.14491332377532504,
            0.13321064258313978,
            0.5296352017588648,
            0.24094671352524005,
            0.29249860433596797,
            0.1581666385541394,
            0.19182417195930743,
            0.16041755266726057,
            0.15336985775130588,
            0.5617829749687088,
            0.3080014395437322,
            0.12562524825593588,
            0.14404597560830273,
            0.26689358228817783,
            0.10481137330133977,
            0.41418616652685025,
            0.1750484418687343,
            0.19804114500747544,
            0.12802784918154575,
            0.07626909559768452,
            0.08962564209521366,
            0.44049864201246,
            0.5255602408585054,
            0.22584424251314303,
            0.05297428580541784,
            0.05252688147824316,
            0.04934749633126069,
            0.06665897050378207,
            0.041434504891151996,
            0.0810583716444533,
            0.05248855192291661,
            0.0013854741318752375,
            0.36867163205563325,
            0.05778333213062965,
            0.05664951801129591,
            0.4883374590270426,
            0.05295600136673907,
            0.06218819081304285,
            0.0644383223054098,
            0.05948926839335072,
            0.07527042816348141,
            0.34444217535657384,
            0.7614204488990758,
            0.3971791997366901,
            0.03944906098495236,
            0.060092046503238475,
            0.09130193293257709,
            0.3297351678378755,
            0.6948607333236224,
            0.03583546033324149,
            0.07671880910102438,
            0.0531439189482054,
            0.6279764737211979,
            0.302926557273099,
            0.029337821127786802,
            0.20441832420419073,
            0.8133276991670046,
            0.276785975275546,
            0.24407169054639882,
            0.09968081586039539,
            0.0753244484486097,
            0.08147211142309614,
            0.06862273951363602,
            0.9363803460778297,
            0.47458833821136304,
            0.09794317568761002,
            0.053921499437926027,
            0.5310036829190526,
            0.17552001867354394,
            0.5486511807647825,
            0.1190219754231662,
            0.08683656667764089,
            0.07169054984273843,
            0.14141178828637402,
            0.044128645090439865,
            0.11296574315432267
           ]
          },
          {
           "label": "xgboost__max_depth",
           "range": [
            1,
            8
           ],
           "values": [
            1,
            1,
            3,
            8,
            8,
            8,
            6,
            5,
            6,
            3,
            7,
            8,
            8,
            7,
            4,
            7,
            6,
            5,
            8,
            7,
            3,
            5,
            4,
            4,
            2,
            4,
            6,
            7,
            6,
            8,
            7,
            5,
            6,
            6,
            8,
            7,
            1,
            8,
            6,
            7,
            6,
            4,
            5,
            5,
            5,
            6,
            8,
            8,
            6,
            5,
            3,
            4,
            4,
            7,
            5,
            2,
            7,
            5,
            4,
            6,
            3,
            4,
            3,
            4,
            5,
            5,
            6,
            5,
            8,
            5,
            7,
            4,
            4,
            4,
            3,
            5,
            8,
            6,
            5,
            4,
            8,
            5,
            5,
            5,
            5,
            6,
            6,
            5,
            5,
            7,
            7,
            7,
            8,
            7,
            7,
            7,
            7,
            7,
            8,
            7,
            7,
            7,
            7,
            8,
            8,
            7,
            7,
            8,
            8,
            8,
            8,
            7,
            8,
            7,
            8,
            7,
            6,
            8,
            8,
            8,
            8,
            7,
            8,
            8,
            8,
            8,
            7,
            6,
            8,
            7,
            8,
            7,
            8,
            6,
            7,
            7,
            7,
            7,
            8,
            7,
            8,
            7,
            7,
            6,
            6,
            6,
            8,
            7,
            6,
            8,
            6,
            6,
            6,
            7,
            6,
            7,
            8,
            7,
            6,
            1,
            8,
            6,
            6,
            6,
            6,
            7,
            6,
            5,
            7,
            8,
            7,
            6,
            6,
            6,
            5,
            6,
            6,
            7,
            8,
            6,
            8,
            6,
            6,
            6,
            6,
            7,
            6,
            7,
            5,
            2,
            8,
            6,
            6,
            6,
            6,
            7,
            6,
            6,
            7,
            8,
            6,
            7,
            7,
            7,
            7,
            5,
            7,
            8,
            7,
            8,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            5,
            6,
            6,
            6,
            6,
            5,
            8,
            6,
            8,
            6,
            8,
            6,
            8,
            7,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            5,
            8,
            6,
            8,
            6,
            5,
            6,
            8,
            6,
            6,
            6,
            8,
            8,
            8,
            8,
            8,
            8,
            8,
            8,
            8,
            8,
            8,
            8,
            7,
            8,
            8,
            7,
            8,
            7,
            7,
            8,
            8,
            6,
            6,
            8,
            6,
            7,
            8,
            6,
            6,
            7,
            6,
            8,
            6,
            8,
            7,
            6,
            7,
            6,
            2,
            8,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            7,
            6,
            6,
            7,
            6,
            6,
            6,
            6,
            7,
            6,
            6,
            5,
            6,
            7,
            6,
            6,
            3,
            6,
            8,
            1,
            7,
            6,
            6,
            8,
            6,
            6,
            7,
            8,
            6,
            6,
            6,
            7,
            6,
            8,
            5,
            6,
            8,
            6,
            7,
            6,
            6,
            7,
            6,
            8,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            5,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            5,
            6,
            6,
            6,
            6,
            6,
            6,
            4,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            5,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            5,
            6,
            6,
            6,
            6,
            6,
            6,
            8,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            5,
            6,
            6,
            6,
            6,
            6,
            2,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            5,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6,
            6
           ]
          },
          {
           "label": "xgboost__min_chil...",
           "range": [
            0,
            495
           ],
           "values": [
            450,
            482,
            354,
            24,
            0,
            24,
            184,
            180,
            126,
            309,
            102,
            12,
            0,
            93,
            248,
            76,
            177,
            1,
            66,
            149,
            268,
            51,
            1,
            53,
            129,
            43,
            3,
            401,
            221,
            95,
            38,
            10,
            2,
            67,
            454,
            32,
            127,
            354,
            29,
            85,
            493,
            0,
            0,
            35,
            25,
            59,
            111,
            19,
            76,
            17,
            54,
            0,
            2,
            23,
            41,
            65,
            112,
            18,
            155,
            295,
            215,
            14,
            4,
            46,
            4,
            81,
            38,
            58,
            14,
            30,
            73,
            2,
            1,
            46,
            25,
            14,
            375,
            37,
            52,
            28,
            87,
            0,
            11,
            13,
            12,
            25,
            41,
            14,
            67,
            0,
            0,
            30,
            23,
            1,
            0,
            0,
            54,
            40,
            18,
            30,
            48,
            2,
            8,
            0,
            22,
            10,
            34,
            1,
            20,
            62,
            432,
            7,
            0,
            10,
            34,
            21,
            45,
            0,
            203,
            257,
            20,
            1,
            0,
            10,
            30,
            11,
            21,
            0,
            39,
            0,
            28,
            11,
            321,
            16,
            0,
            0,
            20,
            9,
            32,
            9,
            25,
            10,
            18,
            0,
            0,
            39,
            18,
            9,
            148,
            28,
            49,
            1,
            9,
            18,
            4,
            0,
            0,
            28,
            16,
            36,
            11,
            0,
            24,
            8,
            16,
            0,
            0,
            23,
            11,
            34,
            0,
            0,
            13,
            9,
            0,
            24,
            17,
            9,
            22,
            0,
            10,
            0,
            16,
            0,
            9,
            28,
            18,
            0,
            9,
            32,
            19,
            7,
            0,
            9,
            0,
            17,
            9,
            0,
            24,
            17,
            10,
            466,
            0,
            0,
            10,
            26,
            16,
            9,
            0,
            19,
            0,
            0,
            9,
            235,
            9,
            18,
            0,
            0,
            292,
            28,
            9,
            0,
            0,
            12,
            10,
            20,
            7,
            0,
            17,
            10,
            24,
            0,
            1,
            9,
            8,
            17,
            0,
            9,
            0,
            0,
            18,
            9,
            8,
            0,
            16,
            1,
            419,
            16,
            181,
            0,
            0,
            28,
            10,
            0,
            21,
            11,
            350,
            0,
            13,
            25,
            161,
            11,
            34,
            9,
            0,
            19,
            9,
            19,
            0,
            0,
            28,
            9,
            0,
            18,
            0,
            14,
            9,
            27,
            0,
            38,
            17,
            10,
            9,
            21,
            0,
            9,
            23,
            0,
            10,
            0,
            16,
            29,
            0,
            9,
            18,
            9,
            195,
            35,
            0,
            18,
            9,
            25,
            0,
            16,
            9,
            0,
            24,
            11,
            0,
            9,
            0,
            99,
            17,
            40,
            30,
            8,
            0,
            125,
            18,
            10,
            0,
            0,
            23,
            11,
            0,
            22,
            8,
            16,
            32,
            495,
            0,
            10,
            0,
            17,
            8,
            24,
            0,
            15,
            8,
            0,
            32,
            20,
            15,
            10,
            44,
            0,
            27,
            9,
            0,
            18,
            384,
            10,
            10,
            326,
            0,
            27,
            18,
            9,
            0,
            267,
            21,
            10,
            8,
            36,
            0,
            19,
            9,
            0,
            27,
            237,
            15,
            0,
            15,
            9,
            25,
            0,
            9,
            19,
            9,
            37,
            0,
            17,
            9,
            27,
            0,
            481,
            17,
            9,
            49,
            24,
            0,
            0,
            9,
            0,
            17,
            9,
            31,
            0,
            17,
            0,
            0,
            9,
            23,
            116,
            289,
            140,
            9,
            17,
            0,
            9,
            34,
            163,
            0,
            16,
            25,
            10,
            0,
            9,
            0,
            17,
            8,
            27,
            0,
            17,
            0,
            9,
            36,
            19,
            10,
            0,
            27,
            10,
            0,
            18,
            9,
            46,
            0,
            19,
            217,
            441,
            11,
            87,
            25,
            0,
            9,
            16,
            35,
            9,
            0,
            24,
            9,
            16,
            8,
            22,
            0,
            0,
            16,
            0,
            0,
            31,
            9,
            0,
            16,
            0,
            8,
            25,
            10,
            0,
            17,
            38,
            10,
            0,
            26,
            17,
            9,
            9,
            21,
            0,
            0,
            200,
            17,
            356,
            29,
            8,
            0,
            9,
            17,
            0,
            40,
            9,
            23,
            9,
            410,
            70,
            17,
            0,
            32,
            9,
            17,
            0
           ]
          },
          {
           "label": "xgboost__n_estima...",
           "range": [
            10,
            500
           ],
           "values": [
            20,
            10,
            125,
            455,
            480,
            500,
            340,
            300,
            385,
            215,
            210,
            500,
            420,
            390,
            420,
            315,
            435,
            370,
            270,
            480,
            135,
            360,
            420,
            435,
            400,
            465,
            420,
            340,
            460,
            120,
            80,
            425,
            405,
            470,
            345,
            400,
            300,
            440,
            500,
            380,
            260,
            410,
            450,
            450,
            480,
            220,
            450,
            320,
            480,
            370,
            405,
            415,
            500,
            500,
            485,
            445,
            460,
            430,
            390,
            355,
            495,
            420,
            465,
            435,
            390,
            385,
            470,
            450,
            325,
            485,
            370,
            425,
            395,
            405,
            50,
            440,
            155,
            290,
            470,
            420,
            370,
            380,
            355,
            355,
            340,
            340,
            240,
            380,
            330,
            305,
            310,
            310,
            275,
            315,
            285,
            280,
            245,
            285,
            260,
            290,
            275,
            315,
            225,
            300,
            300,
            315,
            280,
            295,
            330,
            265,
            490,
            290,
            320,
            300,
            250,
            235,
            270,
            310,
            310,
            455,
            330,
            300,
            295,
            295,
            310,
            190,
            320,
            300,
            335,
            280,
            345,
            475,
            500,
            260,
            310,
            320,
            305,
            295,
            315,
            350,
            275,
            290,
            325,
            310,
            305,
            335,
            285,
            310,
            365,
            255,
            270,
            300,
            320,
            300,
            290,
            310,
            280,
            295,
            330,
            315,
            265,
            305,
            300,
            345,
            280,
            320,
            325,
            325,
            335,
            10,
            435,
            305,
            320,
            295,
            310,
            460,
            290,
            325,
            300,
            315,
            340,
            300,
            280,
            305,
            290,
            315,
            270,
            410,
            300,
            330,
            290,
            310,
            445,
            305,
            325,
            300,
            285,
            315,
            305,
            295,
            320,
            310,
            280,
            305,
            335,
            295,
            320,
            310,
            285,
            480,
            350,
            345,
            340,
            350,
            365,
            355,
            380,
            390,
            385,
            370,
            400,
            380,
            390,
            395,
            375,
            415,
            400,
            390,
            425,
            380,
            365,
            325,
            355,
            330,
            345,
            325,
            320,
            410,
            385,
            335,
            320,
            300,
            315,
            395,
            390,
            400,
            365,
            380,
            395,
            410,
            375,
            380,
            375,
            345,
            430,
            365,
            355,
            390,
            330,
            455,
            375,
            405,
            310,
            325,
            465,
            340,
            390,
            360,
            310,
            315,
            305,
            325,
            315,
            295,
            315,
            305,
            295,
            375,
            95,
            335,
            315,
            285,
            350,
            305,
            395,
            310,
            370,
            45,
            330,
            385,
            345,
            145,
            125,
            415,
            320,
            60,
            365,
            400,
            335,
            175,
            360,
            45,
            385,
            315,
            300,
            325,
            325,
            340,
            325,
            330,
            350,
            350,
            355,
            350,
            340,
            330,
            360,
            360,
            345,
            210,
            355,
            100,
            110,
            35,
            370,
            60,
            70,
            370,
            360,
            35,
            370,
            375,
            355,
            355,
            360,
            370,
            350,
            355,
            340,
            375,
            360,
            270,
            365,
            380,
            340,
            330,
            350,
            290,
            380,
            320,
            360,
            335,
            280,
            370,
            320,
            390,
            345,
            295,
            425,
            310,
            330,
            255,
            350,
            405,
            365,
            380,
            300,
            320,
            335,
            310,
            230,
            485,
            195,
            370,
            285,
            325,
            395,
            355,
            340,
            300,
            445,
            315,
            245,
            275,
            360,
            385,
            325,
            290,
            305,
            350,
            375,
            375,
            375,
            385,
            385,
            395,
            375,
            370,
            370,
            385,
            405,
            365,
            380,
            395,
            365,
            375,
            415,
            380,
            390,
            360,
            370,
            355,
            390,
            400,
            375,
            345,
            365,
            365,
            355,
            380,
            365,
            385,
            355,
            370,
            405,
            345,
            375,
            390,
            165,
            495,
            495,
            490,
            480,
            500,
            500,
            415,
            480,
            465,
            495,
            485,
            485,
            465,
            455,
            485,
            470,
            480,
            440,
            470,
            400,
            405,
            475,
            415,
            420,
            385,
            395,
            395,
            395,
            430,
            400,
            410,
            430,
            430,
            430,
            425,
            440,
            425,
            410,
            400,
            420,
            405,
            440,
            400,
            415,
            400,
            390,
            410,
            450,
            385,
            420,
            435,
            395,
            400,
            385,
            405,
            435,
            425,
            430,
            415,
            435,
            445,
            380,
            410,
            430,
            450,
            390,
            420,
            375,
            365,
            390,
            375
           ]
          },
          {
           "label": "xgboost__reg_alpha",
           "range": [
            0.0005027340309045752,
            0.9975959522361048
           ],
           "values": [
            0.17668140036133317,
            0.13158502776480327,
            0.913602585940464,
            0.09351215387535233,
            0.009028922472964163,
            0.472122575176048,
            0.3989769322753984,
            0.0005638470121471194,
            0.3221359376429537,
            0.6440462010743564,
            0.2825137975289682,
            0.0041163567188945635,
            0.015054508683232045,
            0.2398120467786177,
            0.11891956062116638,
            0.021483474167786527,
            0.21569913852152844,
            0.38820793912377927,
            0.12677254593379284,
            0.23422242655205705,
            0.08933334027391757,
            0.36914761975252075,
            0.502219383112168,
            0.5988764510512964,
            0.28825020618703107,
            0.5010063085178752,
            0.18469376812638083,
            0.07208311701368508,
            0.20692980778151573,
            0.1956243486240699,
            0.15591396906091895,
            0.03579215626219987,
            0.07492823837362163,
            0.15018415565474572,
            0.07005540163304,
            0.06073856003865589,
            0.14918229815925418,
            0.09102710060931962,
            0.01306028148334632,
            0.1687619641003985,
            0.06168622080873945,
            0.11596778735262611,
            0.007256746728667054,
            0.0026392367745679685,
            0.05070970040789198,
            0.10942485525356102,
            0.0038815651856069187,
            0.050147902881687086,
            0.17624268259690481,
            0.10363704973185037,
            0.035647439106766196,
            0.1216158307393172,
            0.2433889115331292,
            0.25735330470583667,
            0.1918802759758429,
            0.093636446507182,
            0.0011696836313633795,
            0.14373071945855093,
            0.04087945821724466,
            0.22501956362900233,
            0.08130105596976628,
            0.2701922059101109,
            0.3304728798031194,
            0.17819684005400496,
            0.03598891611872926,
            0.035176841472679424,
            0.08148429594497394,
            0.1317587164572712,
            0.030532772863675086,
            0.059186941325378516,
            0.13718594948826845,
            0.08530158995862551,
            0.029780442346103487,
            0.2136969148450148,
            0.4479099122539749,
            0.06893349229969868,
            0.11094908543404372,
            0.0005027340309045752,
            0.15693285113089872,
            0.02385822994725011,
            0.05673710673595566,
            0.10933186881444022,
            0.1305580815596914,
            0.10533945226221758,
            0.09876970488496699,
            0.0984588400413131,
            0.18068158447950966,
            0.16014974349153344,
            0.19849803713578237,
            0.11888648825831313,
            0.24445369673755163,
            0.23347478825600587,
            0.06345472384597542,
            0.2506885874967713,
            0.29588623368215106,
            0.2594044479035313,
            0.2523521900444002,
            0.2420472306270971,
            0.2897693942833424,
            0.2834343102863981,
            0.2204321499974159,
            0.19952974935454015,
            0.3171937927880314,
            0.20622460906232637,
            0.21930560126127685,
            0.20315537238862288,
            0.26004848213690984,
            0.18535543610800848,
            0.172647883025976,
            0.1899943162076544,
            0.2314516293019275,
            0.24223233866449584,
            0.20229881126691773,
            0.15939309965065313,
            0.3044110092502297,
            0.25892580017811323,
            0.2150430319652019,
            0.27397163119444445,
            0.27069144789215416,
            0.14670906206156642,
            0.18915132908946777,
            0.33277378412638237,
            0.2727095516673191,
            0.27340089369331283,
            0.3429943760010984,
            0.25084015432990164,
            0.27703753144747967,
            0.30630160225213443,
            0.23190804171831955,
            0.3422343256059678,
            0.17524655198371936,
            0.2442057445613054,
            0.21661775731097066,
            0.2947925625972008,
            0.26822568030414673,
            0.2689181336363511,
            0.19947932495431342,
            0.327572677174729,
            0.2911309952621127,
            0.25904888212663135,
            0.1402017879024977,
            0.22117331672382806,
            0.3144990101940274,
            0.2432877890133881,
            0.1838640913593657,
            0.27693103655327084,
            0.24057362417042488,
            0.1664123533460142,
            0.20190545844449165,
            0.2299236549196764,
            0.36077286768428085,
            0.1900746160249565,
            0.2543480596634139,
            0.209105563706654,
            0.020111253406634645,
            0.15653684773079676,
            0.19025222069277983,
            0.12728838387705177,
            0.3042257941346706,
            0.23053714973882428,
            0.28256792021966115,
            0.18114706659215823,
            0.17868824712467507,
            0.20528578260395183,
            0.14436232961130224,
            0.2555182177332379,
            0.2622297802855267,
            0.2667689848888556,
            0.31937087102503076,
            0.2547518965709726,
            0.04509184400013737,
            0.21478678198603218,
            0.2241264546682709,
            0.2939466703051136,
            0.2148436135793518,
            0.24243404832204157,
            0.27617679923631855,
            0.16384076764743882,
            0.0190355091524241,
            0.07596276083169241,
            0.24490453103977441,
            0.19051249453054436,
            0.1979435303407255,
            0.22318257237180333,
            0.26491383271294877,
            0.10642273341106367,
            0.16705336895384146,
            0.19222492458443652,
            0.12524628126345233,
            0.20967064558478277,
            0.22977761842773878,
            0.17736197517145955,
            0.15337746913339315,
            0.2521003486433405,
            0.17983051575029807,
            0.39643654221678576,
            0.2814795263623535,
            0.2026410918726689,
            0.0006680897531336442,
            0.3043976043211016,
            0.13373711507255853,
            0.23468992380706255,
            0.257676041729184,
            0.21212651295001794,
            0.24234077061859333,
            0.2799378737267619,
            0.22702230088478742,
            0.04923737682529418,
            0.18472623811365613,
            0.2567098661348072,
            0.15495400190394354,
            0.15319472684090876,
            0.15074420973609926,
            0.15833389588615623,
            0.1870100117680451,
            0.08953923506444944,
            0.13858206400757805,
            0.1076052096653588,
            0.12003326775665346,
            0.10647915264976528,
            0.13359771350502966,
            0.14019006388824004,
            0.08395951006392777,
            0.08660503867461794,
            0.11567999537256056,
            0.07226505136052869,
            0.06265458188656747,
            0.16575690392366582,
            0.5175018807159101,
            0.028838400471877017,
            0.09539945309147921,
            0.1479549899308707,
            0.1252447534112712,
            0.14854043050109217,
            0.16597024079797396,
            0.1980278250672745,
            0.10306997020688397,
            0.04000989395206785,
            0.14334624860592513,
            0.019204432997009843,
            0.16992691520342917,
            0.20988011248472457,
            0.3292798732587537,
            0.36312106505123687,
            0.30313634039104564,
            0.3594990116957632,
            0.9156931940386867,
            0.18941927771692357,
            0.12035493832635775,
            0.36672704008881446,
            0.34230387139667023,
            0.3920199996319459,
            0.83792941959159,
            0.4117254532835532,
            0.21901677177951717,
            0.0020131806706350005,
            0.1527049200754613,
            0.29040627532217306,
            0.24101110016654875,
            0.05463227328219635,
            0.17684014648583068,
            0.2637376051428995,
            0.20423710801066822,
            0.0817090113279563,
            0.34417457478655333,
            0.13678471617656085,
            0.10915955362344985,
            0.22870217423371375,
            0.1897831171679617,
            0.19356836148318524,
            0.16708358502856485,
            0.20863479374407007,
            0.17777052877783986,
            0.1789115521059387,
            0.15452373853142257,
            0.18998440276661577,
            0.13526873707436698,
            0.15614322565576247,
            0.21899779260282032,
            0.1782677637441045,
            0.11977149649857552,
            0.19763263495604247,
            0.3770149823161018,
            0.4136550504314719,
            0.31080994800954903,
            0.16648609082398408,
            0.23479461489510856,
            0.13914339597038614,
            0.0898490508300077,
            0.1295558338021007,
            0.1463520018346043,
            0.10538718813350338,
            0.4361560818495976,
            0.27898929644585274,
            0.2482855381870737,
            0.33230252245539493,
            0.4856224074866434,
            0.13712563861417632,
            0.07288076486418867,
            0.21037279806711948,
            0.16530244729831217,
            0.22224958572679215,
            0.11142250410469531,
            0.35189711590227907,
            0.3138065981937931,
            0.18987012625938904,
            0.19131616215320735,
            0.24467845556864548,
            0.17598211062914615,
            0.1748077156217706,
            0.15666753885860543,
            0.1606819582911032,
            0.14876508266319208,
            0.1902204557153022,
            0.17083655834758835,
            0.20407940146460674,
            0.1410496144219892,
            0.15886261070135457,
            0.14023930506228907,
            0.18528603945205896,
            0.13014866825404875,
            0.1254238672716365,
            0.12721008253815128,
            0.12516716639974387,
            0.14711614006493057,
            0.14174151842612873,
            0.11974742395365497,
            0.14741515442087985,
            0.3786574946186514,
            0.16123067334502972,
            0.11985135831133756,
            0.13718700113314197,
            0.10737683205319622,
            0.05290019746931092,
            0.45568543316224164,
            0.17390336133966483,
            0.0983750208426758,
            0.09189748475802303,
            0.5258959609344256,
            0.1724158169740299,
            0.35642580658671735,
            0.20522737097629798,
            0.07249153382405057,
            0.10597895470791478,
            0.1444857942152481,
            0.029657701271299616,
            0.22613399634703263,
            0.18438500903792907,
            0.16152133554358059,
            0.20176233428591106,
            0.10202497972701141,
            0.1493626080867401,
            0.40463409946329,
            0.3237766378985528,
            0.17537079996754557,
            0.2885601820582483,
            0.686220208811904,
            0.2257641552813076,
            0.13187072124840032,
            0.19862613920416008,
            0.39058536474376426,
            0.043831017598937594,
            0.07226102083527763,
            0.1560475996126038,
            0.42261739146671606,
            0.3703583606355775,
            0.26032405165851763,
            0.12273586670139469,
            0.9975959522361048,
            0.1839568589720777,
            0.21423829051762702,
            0.10407863613658284,
            0.23513100673478332,
            0.15218298243279224,
            0.1812968054376742,
            0.45843083783851396,
            0.2957391027449086,
            0.13649017457853405,
            0.16748584774414096,
            0.012228239606809927,
            0.2142531171495371,
            0.3473886639038759,
            0.245009570178846,
            0.08880222739586796,
            0.06243107681801581,
            0.425400355645025,
            0.1934668449553769,
            0.16291417852350681,
            0.2686176266827675,
            0.11861299546550949,
            0.33107385768725933,
            0.14170876550505118,
            0.33373819022470513,
            0.3363766289209027,
            0.3192945898230074,
            0.3408001094865294,
            0.36575621337455566,
            0.3795839280768579,
            0.3486304273689617,
            0.37679011104368515,
            0.3870672159212267,
            0.3132000507869724,
            0.3600785812229612,
            0.13497281140197992,
            0.10924414838479433,
            0.3263212827800344,
            0.39727251143662223,
            0.3384767988031069,
            0.35404504591863,
            0.13683307161079164,
            0.29968369110156523,
            0.03197153972887422,
            0.37911424920849557,
            0.0858063095195983,
            0.14396980985795624,
            0.11374144332601,
            0.15743707577849123,
            0.15375994026288947,
            0.12249941947921657,
            0.09430642358104671,
            0.1575707924198102,
            0.002578884547478769,
            0.3188694011998149,
            0.1370620055591674,
            0.16909974987336776,
            0.40431479134278986,
            0.11609510211040931,
            0.06459415162920953,
            0.3419023444388201,
            0.44114837169370463,
            0.4533843580738168,
            0.40872493747144145,
            0.4200402308979201,
            0.48941117417029656,
            0.37334373059911585,
            0.43971555417992836,
            0.38278918255818173,
            0.4784223111381582,
            0.4421482278066167,
            0.045775694419472115,
            0.3548431148789036,
            0.17133869803333784,
            0.3940693583965638,
            0.15060641954577492,
            0.29993754102086306,
            0.5354388755374224,
            0.32798844017629214,
            0.672391181442081,
            0.42974588677200287,
            0.39383113846221857,
            0.4290623537908563,
            0.4601009683652987,
            0.3644931038607279,
            0.4119785824796522,
            0.4656720031974771,
            0.46273669024070396,
            0.17732306677405282,
            0.48740033703104,
            0.5038070229224714,
            0.4894117251598074,
            0.4737506588611171,
            0.5035314506732268,
            0.5044464795069025,
            0.4941963053058755,
            0.47115908482537333,
            0.5072542820500179,
            0.5378449430392158,
            0.44465146036662295,
            0.4940868481462815,
            0.5168380813875243,
            0.5499825693394665,
            0.4716224712366672,
            0.4331911613140172,
            0.5060955001526449,
            0.45839808057876613,
            0.4776498317118943,
            0.4282515511357844,
            0.44538084686908747,
            0.5540528692065865,
            0.522864728972355,
            0.4620933861507906,
            0.4857515624142177,
            0.44955761443102205,
            0.5057130100373368,
            0.5599188745850596,
            0.5962834622168038,
            0.5568131063287681,
            0.42181225498406194,
            0.5136337393717221,
            0.48658261731720814,
            0.5592490617803696,
            0.5251501844491939,
            0.5680912865956373,
            0.5821941563143126,
            0.6151059767989773,
            0.5380143334656552,
            0.4722761510850056,
            0.39706969149204857,
            0.438917872499998,
            0.49734683564327076
           ]
          },
          {
           "label": "xgboost__reg_lambda",
           "range": [
            0.0000836503149915166,
            4.8143581771709485
           ],
           "values": [
            2.749217162380866,
            2.6981005340139887,
            4.766112898831798,
            0.8084330541961959,
            0.04830223610325324,
            0.05723293938418124,
            1.2586840182459347,
            0.14823564560792188,
            1.3553024871268937,
            1.8208878340125199,
            2.0120003222547718,
            0.5924999861874596,
            0.09496068781222433,
            0.027596547537860977,
            0.8004838377910559,
            0.005044278267082619,
            0.6742041322880156,
            1.0834752241589507,
            1.695993574738367,
            0.536369471561255,
            2.2764764950819503,
            1.1816131390693498,
            0.4478516419400229,
            0.37036421417710486,
            0.4096899581394158,
            0.4061816486492399,
            0.9349623154068951,
            0.851340680237374,
            1.4762034293341464,
            0.9281365889320669,
            1.1134590576246999,
            0.32725214320777407,
            0.33539746996900455,
            0.03678939439261438,
            0.6809425374088,
            3.0958710716965854,
            0.255570928884599,
            0.9457712579118638,
            0.21159168895198188,
            0.6764817027815124,
            0.20354165009142502,
            0.545136822009628,
            0.43920429417740203,
            0.0176953592468093,
            0.30858931303559217,
            0.871912145432317,
            0.6226729712963195,
            0.1694172354508062,
            1.3653968305497524,
            0.4969469115066075,
            0.014110273731066714,
            0.44879347063610653,
            0.7433807263636762,
            0.7494450583889963,
            1.0564538017050211,
            0.2322232402396433,
            0.6952774434717373,
            0.9615203037658789,
            0.5718949884043096,
            1.243499682725161,
            0.1574803906591009,
            0.397976029157703,
            0.4538450654764631,
            0.7883647022461272,
            0.3737646792585824,
            0.16583389927248626,
            0.2914080583665652,
            0.005778335969591375,
            0.556586192256318,
            0.3397275305120982,
            1.0024717120456312,
            0.7463445944856895,
            0.4232349960896449,
            0.13129283152468307,
            0.5655135703010049,
            0.8310133669469144,
            0.3109367240220147,
            0.11127404450374315,
            1.1434866272260928,
            0.6225019811136354,
            0.428882707594188,
            0.5037803380643738,
            0.28195609247882997,
            0.26893588837923305,
            0.09721986414489145,
            0.09633004177053414,
            0.20776349539307945,
            0.5162271280911654,
            0.6626478883106773,
            0.9119559025955679,
            0.8901586261578441,
            0.8909725845548656,
            1.0742348614990334,
            0.8346497294425419,
            0.8128339586735718,
            0.8032378156443282,
            0.7843033190800361,
            1.0070717047037263,
            1.2498858848904235,
            0.6914426243147704,
            1.153364936770646,
            0.8938875711561692,
            0.9754363124689487,
            0.8044416777857577,
            0.8666501297944706,
            0.7947445071416279,
            1.088140707786165,
            1.3243583067718994,
            1.310783046095909,
            1.419803442278109,
            0.6345264422204906,
            0.7464782073281211,
            0.9161151890616623,
            1.2106777908035138,
            0.5217519880163107,
            0.9944537042269209,
            0.8336945809317998,
            1.081490507279175,
            1.4868692634658993,
            0.6129625283253216,
            1.0679473603252145,
            0.7836245198275714,
            0.9425205127180785,
            1.1770890894159198,
            0.9002569002481497,
            0.6904936448780676,
            1.0065188661599214,
            0.4667661725962851,
            1.111110063815111,
            1.3062984320883337,
            0.634691888952148,
            0.7075006952824888,
            0.767925286718436,
            0.8890388385165517,
            0.5506812540431445,
            0.5424614844508855,
            0.9693377237981379,
            0.39598087967129425,
            0.5372565447373807,
            0.8601481447790258,
            1.03698868973178,
            0.770086260610427,
            0.6115241490086005,
            0.714543524361391,
            0.4782349814109363,
            0.6878325648624358,
            1.1721162342972222,
            0.9507578882864456,
            0.353604161635593,
            0.7895249544470513,
            1.0737453866587157,
            0.6076001862512522,
            0.5602341499858772,
            0.8481721216890087,
            0.6902711997984814,
            0.23753246156389696,
            0.43763866608715235,
            0.935775594095748,
            0.643545945906215,
            0.7867347557372181,
            1.2420979729570945,
            0.4747060877138816,
            0.36330019595542684,
            0.4956191201820739,
            0.6064331306111542,
            0.735914166915784,
            0.706477920831927,
            0.7414273115714721,
            0.8631651470379007,
            0.5925832122343451,
            1.0047259484839968,
            0.31175756497193885,
            0.14571764183126473,
            1.9832144568634344,
            0.27680828636317334,
            0.705122692968297,
            0.39638250157498706,
            0.7887227045565258,
            2.455039316184349,
            0.5388863142923868,
            0.031241842345695478,
            0.4960559381392161,
            0.6458757183345468,
            0.2910850293209999,
            0.9351814776200781,
            0.4662148538971199,
            0.835724652961733,
            0.6901576497854816,
            1.042454306844694,
            0.5771600779820154,
            0.3653018836646696,
            0.4824339897895702,
            1.638640763905094,
            0.7158173596347503,
            0.48630287454046317,
            0.21186192017630118,
            1.1424909862346349,
            0.828330722615938,
            0.5950219973526635,
            0.3739006975529982,
            0.9428733931742839,
            0.8764450229987559,
            0.7698490800661362,
            0.6798073191929217,
            0.8987623286877073,
            0.9960726850683513,
            0.5496246792979563,
            1.0894115808136797,
            0.13699703906635508,
            3.231038998779977,
            0.7955209143551796,
            0.7532023554263942,
            0.7151865110929473,
            0.6220328115046229,
            0.7807039098200867,
            0.5130873591502731,
            0.4208931991837074,
            0.2426992798764932,
            0.2661118574627397,
            0.2011553162728601,
            0.3252695553376158,
            0.8268942139761695,
            0.6584605232656248,
            0.659302580908541,
            0.4325057998477156,
            0.5815090588831606,
            0.7337510859042237,
            0.10009326834128818,
            0.41461671575101944,
            0.6332826246256333,
            0.808696114783109,
            0.9096694916771184,
            0.742248361073252,
            0.8721847036377578,
            0.026398400797590177,
            0.9284414550383955,
            0.5298309062419799,
            0.31005104096493524,
            0.7023692897769808,
            1.034016305260546,
            0.8463447541831074,
            1.0098440912527376,
            0.9405263544267655,
            0.8108607619064578,
            0.7492799999066665,
            0.6145852606743305,
            0.8085735611281759,
            1.3605057502951574,
            0.4147627200988209,
            0.6556559345501773,
            0.5319280291804067,
            0.515269369803175,
            0.24629947049879727,
            0.4521652242217738,
            0.5729472982243216,
            0.3586785369539395,
            0.16225020043335608,
            0.7132332312962838,
            1.2068439612311908,
            0.8831457246312475,
            0.5845942814960233,
            0.6421243327451731,
            0.4922031774857398,
            1.0969359930820608,
            0.3187040330360263,
            0.7596508462196684,
            0.9556128748509636,
            0.8455678977713083,
            1.5946584782856026,
            1.292655288973198,
            1.079888161827171,
            1.6174763202891684,
            1.1632177006493891,
            1.3467082469406966,
            1.4820366295509446,
            1.194890187712644,
            1.8624303312800525,
            1.1549185239994486,
            1.4630388144488142,
            1.2419844825779598,
            0.9975730037773519,
            1.1135167234767906,
            1.570301126272946,
            0.9186530698279255,
            2.177815526062727,
            2.772291738955607,
            1.3100928703100005,
            1.036462963576902,
            0.9940279427901342,
            0.8439458735854385,
            0.7958147054892434,
            4.631246690665893,
            1.0374838363309935,
            1.810515744245055,
            0.10907223191328558,
            0.6696567331260878,
            0.9293856233959119,
            0.5498870211636626,
            0.20011371849607557,
            0.4391753921861713,
            0.7642516042639639,
            0.8730759197713918,
            0.6228322018109921,
            1.0468256761834356,
            0.3469843436949646,
            0.7570927284954254,
            0.7880234687275721,
            0.9332158721836087,
            1.1767648359962473,
            1.1986596053459169,
            0.01884598643476665,
            0.25857847859266986,
            0.022593367332130385,
            0.05546494174594967,
            0.0052695767268836,
            0.16455830866727697,
            1.7270061505257428,
            1.430979367872213,
            1.7433285779671037,
            1.5112037993169498,
            1.08316565883607,
            1.127625553364406,
            1.1777464188746014,
            1.020477265391678,
            1.0890542355058588,
            1.1475039074522553,
            1.2983509405069047,
            1.078825954390164,
            1.2830539961300402,
            1.2074421294860522,
            1.068553784696065,
            0.9367845873337115,
            1.1152280230600773,
            0.9724373813869649,
            0.8575162192015808,
            1.3438031210559114,
            1.953688494296242,
            2.154732671324502,
            1.429417566981435,
            1.0304182700151518,
            1.1283274819005589,
            1.239049939625161,
            0.8803971437641809,
            0.109625990869252,
            0.9536802673917459,
            1.7611345070839557,
            1.1413086623587254,
            1.0024993411372363,
            1.3843615740891115,
            0.8326357335956224,
            0.6891652876606343,
            1.2379539762349634,
            1.9005786462931755,
            2.097438892791105,
            0.8999294740422787,
            1.7255903572740148,
            1.5604676525271153,
            0.19927182755317552,
            0.5385797826391339,
            1.0673412494475607,
            1.6590979540245145,
            0.7766313283867338,
            0.4112502794269988,
            0.9721042653925117,
            0.6882112539427042,
            0.008060929142955572,
            0.8289755349717768,
            0.5739194166820643,
            1.0773690529011049,
            1.1631899646582553,
            2.062491687604142,
            0.2780961129882993,
            1.852752804520542,
            1.9532086929198518,
            0.8695130129427123,
            0.9858034516367302,
            0.09246058088173725,
            0.7555788996768114,
            1.3575748606554157,
            0.45948835597855836,
            2.21277561232131,
            0.620984550962544,
            0.9051085785183752,
            0.7332232695392604,
            1.6906310262570667,
            1.242512286568485,
            1.4597453244909575,
            0.16215528384171302,
            1.0399073750176349,
            0.34658849364871935,
            0.5033231724666085,
            0.38092870661532746,
            0.38444302799771934,
            0.22124947163657022,
            0.2450137521915663,
            0.24002455358061156,
            0.4547530252405061,
            0.14675092067607767,
            0.14401575568808545,
            0.12518527937500348,
            0.0000836503149915166,
            0.3808924339126987,
            0.2894697519617897,
            0.19909111994016984,
            0.12229751835020161,
            0.2992495430166132,
            0.4769219217764169,
            0.2375242258007783,
            0.4105231866396034,
            0.3295160124313187,
            0.08097481569417886,
            0.5144945642546122,
            1.1429558397811828,
            2.303661125282903,
            0.00011221366877113559,
            0.2015187404284933,
            1.5687002267031263,
            1.381801579802935,
            1.8419877865923342,
            2.0184251250506726,
            1.297916969963996,
            2.7266427270673783,
            2.4194330786728204,
            1.323193475968198,
            1.209461790454628,
            0.12425268943261533,
            3.078391497323703,
            1.4293830157413656,
            1.455952048791202,
            1.6780373724821627,
            1.576001672247564,
            1.6647092620492088,
            1.6610373838943489,
            1.9425391282459847,
            1.5986771062755945,
            0.37112441191327783,
            1.919734912050462,
            1.91498995858112,
            1.840091834695434,
            1.748677700010777,
            1.551824546972363,
            1.8807628438814614,
            1.6759694995963024,
            1.555123670768693,
            1.684578833922342,
            1.768237873358033,
            1.8164667754849058,
            1.5656850680417729,
            0.5441384392468354,
            1.5221603781385886,
            0.5429834746700338,
            1.7860599839314177,
            1.9879893272586093,
            2.1220542600028702,
            0.5911982968628058,
            2.5803315142438237,
            0.6402435906577091,
            2.10503360161923,
            2.2809266397140653,
            2.032920547493833,
            1.8940780850762136,
            1.7700128286299404,
            2.3331893450283956,
            1.9844272971234778,
            2.1581212871410287,
            2.06105355474409,
            2.2031199250178415,
            2.0101276978073663,
            1.74735434392878,
            2.1021685175368705,
            2.20951898991592,
            2.2894952035082645,
            1.7252585811445886,
            1.8314376786287747,
            4.390443726249137,
            1.9199823181227387,
            2.327171153158762,
            3.8079321386596328,
            1.6412373529323812,
            2.143765367736446,
            2.5887409859255146,
            2.4501836525448977,
            1.7981784663993259,
            2.0485288305830567,
            0.5159611339146439,
            0.48826550879003133,
            2.2493858544233922,
            0.4264735149392428,
            0.524342160907104,
            4.8143581771709485,
            1.505575211736158,
            0.3313810232008661,
            2.3921537259684924,
            1.6651120858245467,
            0.5744064112949149,
            1.9128949821715222,
            1.7976417392441149,
            0.4582994336429656,
            1.377266254458147,
            2.5135953303809684
           ]
          },
          {
           "label": "xgboost__subsample",
           "range": [
            0.5000146412491189,
            0.9980639127854269
           ],
           "values": [
            0.8391268998756262,
            0.8384090290478076,
            0.9874188903547395,
            0.5503861112186494,
            0.5065896071904618,
            0.5001952017791316,
            0.638145839512903,
            0.6533676066838329,
            0.6203538805551276,
            0.501170563141212,
            0.739013540248122,
            0.5542541483470574,
            0.5808893289142647,
            0.5843517282049606,
            0.6571580651481883,
            0.5027292876886564,
            0.5871319248742302,
            0.6879619031245297,
            0.573039207150036,
            0.7002982254737011,
            0.6132678622291264,
            0.6886496250940006,
            0.5517973584943614,
            0.5586740000560421,
            0.5355036556887023,
            0.6008966970449205,
            0.5282116926663798,
            0.525334087331987,
            0.5973329060181136,
            0.532189491987094,
            0.5759335895652518,
            0.5345578757825197,
            0.5723569975135155,
            0.6240653287601755,
            0.5748295655645715,
            0.5209474308429427,
            0.7964863498961815,
            0.5545944687755313,
            0.6454090401612174,
            0.5004654809287296,
            0.6139304696516282,
            0.5518568505361754,
            0.525689335656851,
            0.5227672692123647,
            0.570492172725747,
            0.5989995908421104,
            0.5000332351173018,
            0.539660781250809,
            0.5192035601191084,
            0.5652246973357207,
            0.6325948471328068,
            0.543277532679266,
            0.587005770973366,
            0.5849019613572705,
            0.5145624668961253,
            0.5557266598205487,
            0.6010841207032018,
            0.5818394208788348,
            0.6528646194019916,
            0.5387799435564415,
            0.5118017363162963,
            0.5524468236615281,
            0.5643301395983217,
            0.5358726815783836,
            0.5901895533700969,
            0.615676598497345,
            0.5885059229628221,
            0.5161214118439114,
            0.6313730245268122,
            0.5653670921957025,
            0.6640346761127407,
            0.5468608798937488,
            0.5313730434404595,
            0.5725235868539632,
            0.6046593954466568,
            0.5894493346195435,
            0.51012635028062,
            0.5265214887557811,
            0.5541651706888973,
            0.5776795961520191,
            0.5411956064281873,
            0.5637416121033391,
            0.563814633390657,
            0.5639527142223846,
            0.6226163533750867,
            0.5287715438871721,
            0.6043051423098943,
            0.6226993669919783,
            0.5757901185847916,
            0.5439886056665619,
            0.5081610735614605,
            0.5069581883238962,
            0.5233075354219932,
            0.544849466412835,
            0.5447271821004331,
            0.5474469437486429,
            0.5117915315660707,
            0.5038133559497314,
            0.5297341857359618,
            0.5480827941538589,
            0.5212342602810116,
            0.544510209358754,
            0.5374281166254927,
            0.557017320902077,
            0.556487365902615,
            0.5183768831124896,
            0.5474917107796456,
            0.5361032700554857,
            0.5001161000540493,
            0.5244339823317133,
            0.5364964216980868,
            0.5588818960308941,
            0.5303094273225931,
            0.5147093000330795,
            0.5481318742292343,
            0.5404965301686333,
            0.5685049435349091,
            0.5570685101691655,
            0.5823044575675224,
            0.5111797418087576,
            0.5304514935505432,
            0.5587757355015744,
            0.5586693758005612,
            0.5646038732282053,
            0.5533279125992562,
            0.519720460763633,
            0.5573183949971409,
            0.5705210106269067,
            0.5349118300472421,
            0.5079537926157309,
            0.577268712622058,
            0.5432547212371166,
            0.5554821261110083,
            0.5970466634956187,
            0.526075383312836,
            0.5273946920897674,
            0.5003334745996265,
            0.5241109901360211,
            0.5153138949075132,
            0.5373509516543816,
            0.5630265646500123,
            0.5484248658337575,
            0.584832698723333,
            0.5360465804549953,
            0.5187349990120218,
            0.5343949315692096,
            0.5446104955582063,
            0.5070489719425385,
            0.5609806263202401,
            0.5268749039598298,
            0.5718235394906204,
            0.5169895738415854,
            0.5156289110673236,
            0.5368376562279861,
            0.5496593969012878,
            0.5260178682802742,
            0.500546611205402,
            0.5415207705416921,
            0.5132925999101059,
            0.556200909262427,
            0.5323083442403738,
            0.5186788284535033,
            0.5197397787591281,
            0.509833089161573,
            0.5472496555977365,
            0.5345564023156412,
            0.5341606711509158,
            0.5658091094460412,
            0.5377616614101621,
            0.7415420766444714,
            0.5522342476629515,
            0.5302883952075357,
            0.5285472620571924,
            0.5419563905215883,
            0.5726549018485142,
            0.5561171381368648,
            0.5290636193447638,
            0.712559550937911,
            0.5382773073924114,
            0.5588275438906957,
            0.5473028548888654,
            0.5207237739239565,
            0.5226779531224006,
            0.53363258291755,
            0.5252246786829002,
            0.5469732820307387,
            0.7924602029464155,
            0.5130327550779127,
            0.5347441664542855,
            0.5647509276525292,
            0.5795008078785187,
            0.5195339859574262,
            0.5195155263957234,
            0.5072537167968878,
            0.5407194586795868,
            0.5262391067621929,
            0.5514219034175462,
            0.5310893521302763,
            0.5001652472951511,
            0.5162918935818765,
            0.5424132310460824,
            0.5098675306245453,
            0.6466499320486537,
            0.5228082263165504,
            0.6679458769343087,
            0.8971174296293818,
            0.534765441570343,
            0.5099301961124358,
            0.5555807357000143,
            0.6126121538601874,
            0.5188209786313331,
            0.5174091039108232,
            0.5275429126882542,
            0.5171308894463056,
            0.5420600312439035,
            0.5322749591806765,
            0.5666607512586797,
            0.5655277836517807,
            0.5711833071012741,
            0.5651481232945131,
            0.5495695276360951,
            0.5588168863850448,
            0.5870168362292099,
            0.5928203189073409,
            0.5841539529948823,
            0.5684579794179603,
            0.5769549751049318,
            0.5462188624040863,
            0.5382215954277817,
            0.5553118859845922,
            0.5313895629851241,
            0.5619885765801446,
            0.5646071583845538,
            0.5765488640940762,
            0.5470983280209839,
            0.5550328105163123,
            0.5949449922106336,
            0.5252408102204364,
            0.5396466537677269,
            0.6364554727790718,
            0.5000146412491189,
            0.5613523281957908,
            0.5705784078682131,
            0.5493684387514872,
            0.5486444700760219,
            0.5321450295329502,
            0.5195700592026341,
            0.5419945960138378,
            0.5811424402097959,
            0.6854917426816498,
            0.6102298612613218,
            0.5900511429262458,
            0.608379443916427,
            0.5138925283706621,
            0.6000120632707683,
            0.5253185425202757,
            0.5332588682711231,
            0.549140784365918,
            0.5392840835077888,
            0.5099656702088439,
            0.5698678342493315,
            0.5231886789015541,
            0.5571853155896472,
            0.5368853603052656,
            0.5787043675976488,
            0.54941817698787,
            0.5890600736310865,
            0.5154794283415394,
            0.5615894810219049,
            0.5632199891178044,
            0.5697556740382382,
            0.5596014665506788,
            0.6326441705187609,
            0.6242777127809973,
            0.6162983806231607,
            0.633620189408723,
            0.5951920338442888,
            0.6081102422593029,
            0.6224700021515498,
            0.5798282327298946,
            0.640096252233623,
            0.6014913868042638,
            0.7123529303534778,
            0.5523440225965836,
            0.5738872138839533,
            0.5867804691692756,
            0.543110053357288,
            0.5620490015272609,
            0.5641927014551485,
            0.5677532710223696,
            0.5534297058611787,
            0.5854036441692182,
            0.5735925698352984,
            0.6130787045976854,
            0.66189931570148,
            0.6459607902443818,
            0.559378681200603,
            0.7636671819661973,
            0.5081281215733515,
            0.5459815176856258,
            0.5275606067338722,
            0.5538490086933594,
            0.6688311341906557,
            0.6026405251616588,
            0.8415002636665916,
            0.5805044935156658,
            0.5621782221076325,
            0.542534786317215,
            0.5762647144791538,
            0.6279450463703858,
            0.5217780906850982,
            0.5771204223288919,
            0.5063309360355646,
            0.5198221645138739,
            0.580318658136653,
            0.5912686117040656,
            0.6580899747063379,
            0.6457643563192975,
            0.6286506643302108,
            0.6347903066192724,
            0.6142301614825284,
            0.6071896575278755,
            0.6056440807674236,
            0.6182998778359149,
            0.6086163732858537,
            0.609535459521988,
            0.6057350656917471,
            0.6159527049825235,
            0.6253620106829123,
            0.5943531186295218,
            0.6192736227150514,
            0.6049049318737894,
            0.6174469264940462,
            0.6145141096851445,
            0.6380508820770819,
            0.6345997813565343,
            0.625669320970335,
            0.653736998956946,
            0.5966342293476035,
            0.6270446039905293,
            0.6472560317415227,
            0.6152851730181519,
            0.5940585804304168,
            0.9980639127854269,
            0.5818130203115239,
            0.6709798608715154,
            0.6020191335609549,
            0.6789787837676109,
            0.7112470969216472,
            0.6383505374081672,
            0.6783755691888996,
            0.7225135072904281,
            0.6497420516467022,
            0.6225134681803689,
            0.5691778087255066,
            0.6634790493218516,
            0.6537365252627452,
            0.5031004324268137,
            0.527869531170581,
            0.9476213855531406,
            0.7003442470837631,
            0.5859664607439655,
            0.5463896311403943,
            0.7597411668371109,
            0.5156303925508091,
            0.5717403350389288,
            0.6592580387880288,
            0.5377006349343301,
            0.6126939272746206,
            0.5966005591738086,
            0.5220829080212843,
            0.5541369926865753,
            0.6315551461739761,
            0.577393957893666,
            0.5005516268153352,
            0.5311414806824268,
            0.545555909780188,
            0.7405658144718987,
            0.5636370842523305,
            0.5909550858743601,
            0.5115177721747464,
            0.5508474410233362,
            0.617048523337726,
            0.6857953923636435,
            0.524674635264781,
            0.5377596916081928,
            0.5698799372552886,
            0.6039532167731974,
            0.788909719807389,
            0.6360323566726372,
            0.5151625616641339,
            0.5168013427676376,
            0.6989471545567193,
            0.508285883290043,
            0.5117007568137777,
            0.5076394804388692,
            0.5180111993785399,
            0.5013112473199781,
            0.510080717080228,
            0.5113116096265542,
            0.5083519478537231,
            0.5036703687872737,
            0.5206275730775767,
            0.5030790553708047,
            0.7269293926969175,
            0.5210825216426387,
            0.51758899512184,
            0.5017172914629434,
            0.5270606380454002,
            0.6233534987968252,
            0.5291457947928458,
            0.6515435757879275,
            0.5002866096044071,
            0.6137229776258013,
            0.5986348017167458,
            0.5181135261074012,
            0.8406945181625209,
            0.6727391314181843,
            0.7991712492229511,
            0.9615300924921812,
            0.860038548370866,
            0.6871308102943007,
            0.6413179760535505,
            0.5879694451557956,
            0.772745714784584,
            0.7484191534036269,
            0.8203859315630622,
            0.7698184896849174,
            0.6286601592098539,
            0.8031183963139876,
            0.8821398139902554,
            0.8467876267097518,
            0.5132053378867427,
            0.809246577044009,
            0.7354112494432896,
            0.7699092204897281,
            0.8220697291488875,
            0.8187451760980051,
            0.860012588438951,
            0.8227473952312717,
            0.7500932839601757,
            0.837658449714763,
            0.8059180093404705,
            0.8273583061708762,
            0.8158969195498614,
            0.804802652754722,
            0.781472472124534,
            0.8069383358408556,
            0.810239011031228,
            0.8102548708735572,
            0.8330570178973189,
            0.7917062579893016,
            0.8144902062560792,
            0.8287711232060306,
            0.8268276397408365,
            0.8278278959198442,
            0.8341199431531566,
            0.8404353004405407,
            0.8415255677170282,
            0.8458031178248968,
            0.8422329367093615,
            0.830243808176751,
            0.8216017288713625,
            0.83171073221273,
            0.8393356299928464,
            0.8566862929275029,
            0.8240459955982647,
            0.815712347997652,
            0.7970367483165639,
            0.8518936711301689,
            0.8389076253467019,
            0.8524415854443773,
            0.8322073036018862,
            0.8159259274881009,
            0.8464059539813259,
            0.7834458275003819,
            0.8259012992610504,
            0.8422439710275806,
            0.7965719288859432,
            0.8025728130510824,
            0.8266896449033837,
            0.783576206951414,
            0.8631049838599878,
            0.8115115726624401,
            0.8405604635736912,
            0.8359190519723804,
            0.8391598938281017,
            0.8501732522549268,
            0.8217379480080226,
            0.8742622829452188,
            0.8506340279554065,
            0.8382299133813017,
            0.8292540141547676,
            0.6574114349779923,
            0.8707588634367288,
            0.8450976766973956,
            0.6951020302211487,
            0.8110026168354595,
            0.8610278088434911,
            0.8301393905141536
           ]
          }
         ],
         "labelangle": 30,
         "labelside": "bottom",
         "line": {
          "color": [
           0.46982323232323225,
           0.46982323232323225,
           0.46982323232323225,
           0.7800069208288982,
           0.8413588024167761,
           0.7796750574528353,
           0.46982323232323225,
           0.46982323232323225,
           0.46982323232323225,
           0.46982323232323225,
           0.46982323232323225,
           0.7812045968135162,
           0.8308032291810925,
           0.46982323232323225,
           0.46982323232323225,
           0.46982323232323225,
           0.46982323232323225,
           0.8021892735454892,
           0.46982323232323225,
           0.46982323232323225,
           0.46982323232323225,
           0.6963154217692574,
           0.811783766244153,
           0.46982323232323225,
           0.46982323232323225,
           0.7012596424822131,
           0.8429887004244362,
           0.46982323232323225,
           0.46982323232323225,
           0.46982323232323225,
           0.6715094130188469,
           0.7933100827545888,
           0.8295478121798622,
           0.46982323232323225,
           0.46982323232323225,
           0.7685707448808669,
           0.46982323232323225,
           0.46982323232323225,
           0.7878658646178112,
           0.46982323232323225,
           0.46982323232323225,
           0.8043560406210365,
           0.8354586886799922,
           0.7165032826893035,
           0.7935324950920709,
           0.46982323232323225,
           0.46982323232323225,
           0.7862163442693051,
           0.46982323232323225,
           0.8117584992659643,
           0.6715644416675345,
           0.8037475645929483,
           0.8325339299822528,
           0.7866882684100401,
           0.6966718493681404,
           0.46982323232323225,
           0.46982323232323225,
           0.8001997466627692,
           0.46982323232323225,
           0.46982323232323225,
           0.46982323232323225,
           0.8042674952526491,
           0.7834710743801652,
           0.680573159356752,
           0.8134557596619184,
           0.46982323232323225,
           0.7259997607205729,
           0.46982323232323225,
           0.7989816941882802,
           0.7772342003021679,
           0.46982323232323225,
           0.8038930178052333,
           0.7924486559632626,
           0.6986925532380078,
           0.7812216903838729,
           0.8105637360798874,
           0.46982323232323225,
           0.7053254380714565,
           0.46982323232323225,
           0.7813748046389238,
           0.46982323232323225,
           0.8373954428871773,
           0.8125263643590556,
           0.8148126282083353,
           0.816648245033724,
           0.7872096232162156,
           0.7027651674149189,
           0.8126816960122869,
           0.46982323232323225,
           0.8305059115104432,
           0.8338389897782109,
           0.7693602693602694,
           0.7925573540945532,
           0.8400485931075474,
           0.8322935911263063,
           0.8390924995941588,
           0.46982323232323225,
           0.46982323232323225,
           0.7887606220939554,
           0.7728101208090659,
           0.46982323232323225,
           0.8401671416794099,
           0.819214294258781,
           0.8392088147427575,
           0.7842178397733954,
           0.7984548038086549,
           0.7620269289270186,
           0.8358704241809264,
           0.782305825372625,
           0.46982323232323225,
           0.46982323232323225,
           0.8123627144460477,
           0.8314615624133674,
           0.8158751977103262,
           0.7654031726196674,
           0.7848568647966473,
           0.7003033097473328,
           0.8370600399827325,
           0.46982323232323225,
           0.46982323232323225,
           0.7892338374965742,
           0.8352462922355396,
           0.8349124038963612,
           0.8105637360798874,
           0.7795307549382281,
           0.8058701213218245,
           0.7859121296890962,
           0.8010220219829349,
           0.7007279727586345,
           0.8307324920228146,
           0.7848568647966473,
           0.817713032248934,
           0.46982323232323225,
           0.7994843354738276,
           0.8412421078146687,
           0.8313427117445381,
           0.7848568647966473,
           0.8042000592910578,
           0.7700951091672742,
           0.811783766244153,
           0.7847012318513391,
           0.8105637360798874,
           0.8020521706197269,
           0.841805517409747,
           0.8328786496340432,
           0.7015128504607095,
           0.7920872514528102,
           0.8256167082827834,
           0.46982323232323225,
           0.7824227995661613,
           0.6633756289176245,
           0.8392088147427575,
           0.7653783156366818,
           0.7881776097982062,
           0.8325339299822528,
           0.8253707636039312,
           0.8316929234765538,
           0.7861413909431137,
           0.7976678855122432,
           0.720211054325194,
           0.8193851559068951,
           0.8342789943602194,
           0.7896518518105313,
           0.8116177266000588,
           0.7945871837010827,
           0.8373954428871773,
           0.8355618605618605,
           0.7987479879484543,
           0.8042000592910578,
           0.7848568647966473,
           0.8286967169819097,
           0.8378144378144378,
           0.793915523120999,
           0.8085986838613808,
           0.7892338374965742,
           0.7908705949302469,
           0.7861413909431137,
           0.8217637955995697,
           0.7848568647966473,
           0.8282459903305827,
           0.8110302897809047,
           0.8430936814106018,
           0.7800263052194589,
           0.8258665082194494,
           0.8187781478232847,
           0.7873774620169777,
           0.7970354259972238,
           0.831578295761588,
           0.8055700900518964,
           0.7848568647966473,
           0.7841037214125053,
           0.816648245033724,
           0.8307324920228146,
           0.7980953128800914,
           0.8308426398386515,
           0.797369828801211,
           0.7653783156366818,
           0.7782441434430467,
           0.7824349290287218,
           0.7868648656789576,
           0.8088460333753942,
           0.46982323232323225,
           0.8332046981139647,
           0.8259860691507218,
           0.8244252915439678,
           0.8037166422032569,
           0.8016258850630973,
           0.8122437851907783,
           0.8324148209994937,
           0.7873778177760505,
           0.842016992554627,
           0.8378144378144378,
           0.8237623623277424,
           0.46982323232323225,
           0.816648245033724,
           0.7975312513403748,
           0.841143726891318,
           0.8441706327668782,
           0.46982323232323225,
           0.7899764470440789,
           0.8221598114348577,
           0.8298773245431845,
           0.836320746795232,
           0.7971283942905023,
           0.8019325823785515,
           0.7905395983113641,
           0.8343143860458349,
           0.7705691213173758,
           0.8058345909773162,
           0.8181483434176061,
           0.7887606220939554,
           0.8424166030139313,
           0.8301881376171062,
           0.7890443887760493,
           0.8265643452265937,
           0.8069317513761957,
           0.8336108941149343,
           0.8181483434176061,
           0.8322348731670277,
           0.8299829922699407,
           0.7848568647966473,
           0.8125381575871466,
           0.830450448445006,
           0.8430936814106018,
           0.7836640737002963,
           0.8294337680869773,
           0.46982323232323225,
           0.7793318132586108,
           0.46982323232323225,
           0.8199046891587786,
           0.8422206603780747,
           0.7812216903838729,
           0.8107217582139212,
           0.46982323232323225,
           0.7854577251989087,
           0.8266849834247955,
           0.46982323232323225,
           0.8271746126974008,
           0.7879171507698155,
           0.7763949608443991,
           0.46982323232323225,
           0.8117584992659643,
           0.7680266197086469,
           0.8241668931324104,
           0.7980953128800914,
           0.7906392011470801,
           0.8158751977103262,
           0.7919443994310305,
           0.8377126792460198,
           0.8339520788661303,
           0.7854577251989087,
           0.816294439042688,
           0.8419122361403112,
           0.8054162864704432,
           0.8314615624133674,
           0.8113012273027473,
           0.8230983487077738,
           0.7847609833004587,
           0.8316929234765538,
           0.698604409616048,
           0.8072225594892407,
           0.8199916193458224,
           0.818288707177596,
           0.7926485741831626,
           0.7961645174882984,
           0.7685704913749558,
           0.7895358849776961,
           0.8413588024167761,
           0.8193549518567049,
           0.8288041288041289,
           0.8037475645929483,
           0.7868648656789576,
           0.8062783562783562,
           0.76699311085276,
           0.7825352736490705,
           0.8073805470574537,
           0.46982323232323225,
           0.7920877747784719,
           0.7747051016887347,
           0.7872728299774563,
           0.8032096761263428,
           0.7833282360534863,
           0.8309507075479371,
           0.8051010269042874,
           0.7874839707995865,
           0.8413588024167761,
           0.7848568647966473,
           0.8063200967644926,
           0.8483753149839316,
           0.8175631404471531,
           0.8494535614900911,
           0.46982323232323225,
           0.7887689710746011,
           0.7014478973121837,
           0.7819464486131154,
           0.7653783156366818,
           0.842772866949383,
           0.46982323232323225,
           0.8031404535636645,
           0.7918684719810437,
           0.8408360365388119,
           0.8389741379263068,
           0.46982323232323225,
           0.7653783156366818,
           0.8438492049834518,
           0.7848568647966473,
           0.780804034440973,
           0.8085986838613808,
           0.7826579574026585,
           0.46982323232323225,
           0.7810087406047,
           0.8231908107142042,
           0.847709043969658,
           0.7984269526147151,
           0.8164453086732879,
           0.7774731941267188,
           0.8303894560579054,
           0.8143705834813479,
           0.8307162756393022,
           0.7786883458613796,
           0.7848568647966473,
           0.7845364992459607,
           0.7975214730294302,
           0.8233561626751421,
           0.6715094130188469,
           0.7797203838600735,
           0.7851599776733467,
           0.46982323232323225,
           0.7885189129650848,
           0.8029822757194673,
           0.46982323232323225,
           0.812846100705431,
           0.8102658928306273,
           0.46982323232323225,
           0.7789616925097669,
           0.7824349290287218,
           0.8054162864704432,
           0.8161920989962648,
           0.7972347107966655,
           0.46982323232323225,
           0.7937664431418092,
           0.7975276488053207,
           0.7842255075173541,
           0.46982323232323225,
           0.7954168863448068,
           0.7711471826879223,
           0.8266907716530778,
           0.7903450085268269,
           0.7848568647966473,
           0.46982323232323225,
           0.8169392336059003,
           0.8298773245431845,
           0.7975776801974926,
           0.8174108299565179,
           0.7889696773040504,
           0.8275148716810447,
           0.8146662261898195,
           0.8048087287663259,
           0.8078441240863773,
           0.7194876734718031,
           0.8336065679627324,
           0.7779023233834869,
           0.8208303788194118,
           0.7838017311624617,
           0.7631318487097914,
           0.46982323232323225,
           0.7716899636091555,
           0.8044241500852451,
           0.7295452029262502,
           0.7848568647966473,
           0.8440654385896077,
           0.8419122361403112,
           0.8171910913846397,
           0.8474031538779488,
           0.8058345909773162,
           0.8204214891248859,
           0.76334028879367,
           0.8410431170393942,
           0.8058505135238087,
           0.8322348731670277,
           0.8355618605618605,
           0.8199916193458224,
           0.7884315322994929,
           0.46982323232323225,
           0.46982323232323225,
           0.46982323232323225,
           0.8014401000799581,
           0.7948244868366892,
           0.8319159077887337,
           0.8026581306681119,
           0.7264134624261489,
           0.46982323232323225,
           0.7893163064052107,
           0.7870487729045014,
           0.7890788003823456,
           0.8167954510043351,
           0.8464290293934451,
           0.8333657434530016,
           0.8372856750500254,
           0.8209094018201942,
           0.8100852572440833,
           0.793915523120999,
           0.7789770516018327,
           0.759341490549321,
           0.8085309335309335,
           0.8229660563229467,
           0.783488823126009,
           0.8054979357062689,
           0.8268273806364874,
           0.8422206603780747,
           0.8143201139265568,
           0.8271053382232415,
           0.8255855757210772,
           0.8031404535636645,
           0.8227748775644926,
           0.7490679541867842,
           0.8465307927673519,
           0.7688374473893754,
           0.46982323232323225,
           0.46982323232323225,
           0.7967237981561263,
           0.46982323232323225,
           0.8090139694518717,
           0.8387884094796694,
           0.7610742721682778,
           0.7827354187720035,
           0.7794295615476956,
           0.8305059115104432,
           0.8489826320761573,
           0.7978461867350758,
           0.8229660563229467,
           0.806630970381257,
           0.8276342884844975,
           0.8095023573501426,
           0.8419122361403112,
           0.7653163634304182,
           0.8125381575871466,
           0.8498666160259712,
           0.8461122599836918,
           0.7867926615575213,
           0.8295140719540057,
           0.8419122361403112,
           0.8122052341501838,
           0.8396538395137442,
           0.8290788555263442,
           0.810411171115466,
           0.8094772112032455,
           0.8333092833092834,
           0.825325410847382,
           0.7822748907172601,
           0.8261717461262633,
           0.8353535027762874,
           0.7881776097982062,
           0.818475426959044,
           0.8356328761951377,
           0.8271053382232415,
           0.8084272832895052,
           0.8322348731670277,
           0.7737497403099242,
           0.46982323232323225,
           0.7971467104808033,
           0.46982323232323225,
           0.807993628074108,
           0.7847340856534633,
           0.842016992554627,
           0.827885491837318,
           0.8016221960311848,
           0.822155880544294,
           0.7894801186467854,
           0.8336065679627324,
           0.7763130894349799,
           0.7614219387981903,
           0.46982323232323225,
           0.46982323232323225,
           0.8155837767741358,
           0.8197629470001856,
           0.7843817352651274,
           0.7960949514711082,
           0.811783766244153,
           0.8084108018876622
          ],
          "colorbar": {
           "title": {
            "text": "Objective Value"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "reversescale": false,
          "showscale": true
         },
         "type": "parcoords"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Parallel Coordinate Plot"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = optuna_visualization.plot_parallel_coordinate(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": true
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.08718230210027886,
          0.09380113636694212,
          0.061004164780424926,
          0.015779496404363325,
          0.0018425789560252565,
          0.004594176509979703,
          0.02632946441403268,
          0.032626011572554764,
          0.004231905875396498,
          0.04229864213651614,
          0.05730662636754405,
          0.015824715165500554,
          0.003753012603709645,
          0.010437597330985454,
          0.002238682929788773,
          0.023817480501919695,
          0.0013749669723765415,
          0.01801495125845802,
          0.035323821756859206,
          0.012433566504255297,
          0.02484362394973338,
          0.014669301728109561,
          0.019972848063234728,
          0.008684311032796068,
          0.0018517800243709648,
          0.02031350392418601,
          0.010452924839967244,
          0.00967725928278656,
          0.009453924996714061,
          0.07060902348485489,
          0.04284372413081557,
          0.01968467899714859,
          0.007972034818125842,
          0.0075595770130936785,
          0.0010592450217726057,
          0.013837033857309054,
          0.006770821793576385,
          0.013331523610813592,
          0.006566819469195532,
          0.029826681797419874,
          0.0257642995847268,
          0.019709023923116267,
          0.006184121940246942,
          0.006172635503219647,
          0.012189448054549714,
          0.004944192869380757,
          0.0011501189773531646,
          0.014387837055800766,
          0.006718579061736793,
          0.016821238128795435,
          0.010237202921350084,
          0.02135788805511181,
          0.004659554323147086,
          0.00477719136230287,
          0.010787890295906735,
          0.016742934105846652,
          0.004665021105211804,
          0.0015248868038557064,
          0.010711074910401033,
          0.016280756660455767,
          0.004342055836424161,
          0.00854982625639402,
          0.022396502997840587,
          0.01244135820327687,
          0.018356303295584558,
          0.004416634615095572,
          0.00851314234456364,
          0.017178762938009316,
          0.013730460338220177,
          0.0029590577709611146,
          0.008060186257384052,
          0.019600795860615673,
          0.023683463178001095,
          0.011722243917945274,
          0.015139050848548236,
          0.0037832670149783717,
          0.0074863001803212505,
          0.010348172324609111,
          0.0010558128775755896,
          0.018498103694496393,
          0.029236832903506458,
          0.016080768478582114,
          0.013869847924493115,
          0.013259186916423242,
          0.006735509862264435,
          0.006835260541589224,
          0.0033866563401443815,
          0.006139834610837431,
          0.009604992820438384,
          0.012066622831893577,
          0.0029679732623081496,
          0.003118091941542451,
          0.005729790405944412,
          0.009019213863804196,
          0.010548245617894731,
          0.01107236309881927,
          0.009894124931407908,
          0.015400987785516386,
          0.0026657901253285257,
          0.00888889716059283,
          0.004798615167721501,
          0.011787413780252866,
          0.01066640012418881,
          0.011856388228632213,
          0.01226934326818412,
          0.015967457121980715,
          0.008308550496625553,
          0.0010793640362217367,
          0.001941064967923698,
          0.005693894864716545,
          0.004383783591962267,
          0.011370006119370614,
          0.008566354843018998,
          0.014498530957097421,
          0.002971776850357422,
          0.005845293868617517,
          0.0015043756234750514,
          0.007140167607081473,
          0.007728368488470772,
          0.012611908261314423,
          0.0011665437032156445,
          0.009994498162132597,
          0.006654447789531205,
          0.007255250421098237,
          0.017425514126456394,
          0.009629136450812564,
          0.021476775288328705,
          0.01430987140067019,
          0.0038523871025551867,
          0.011324923100626633,
          0.005650946255819444,
          0.007772764010724102,
          0.00408075397234178,
          0.006251240281429087,
          0.009286390368331243,
          0.012976603241813732,
          0.009327431963780511,
          0.017129549146066722,
          0.011436896437076275,
          0.015129998116238627,
          0.009104841210560655,
          0.003539877790339818,
          0.005885221135422768,
          0.007976356588350993,
          0.00818710527806147,
          0.013088120547422252,
          0.0011327999203598876,
          0.010988250753267162,
          0.006618405730754787,
          0.010029163530841002,
          0.018392196309074984,
          0.008209303899845862,
          0.0034466835318024136,
          0.007275564863010534,
          0.005273083131204998,
          0.013716616870945695,
          0.00983948570993784,
          0.002781734605920987,
          0.01590646356032722,
          0.008041940454282066,
          0.004939362767832158,
          0.007769048103789704,
          0.012337275494685896,
          0.00912231928836255,
          0.006777877253860358,
          0.01078564809545394,
          0.011379323534364853,
          0.011612597746060653,
          0.015214474549646795,
          0.04217253051496733,
          0.010782862218698976,
          0.013347496723962678,
          0.013087762938640229,
          0.016226052801143434,
          0.019297618663794515,
          0.010511766721777428,
          0.013058702871436872,
          0.008992154890881149,
          0.02270738115457746,
          0.011785079099043208,
          0.014621226776416436,
          0.007080520935267898,
          0.00559365309625885,
          0.009527570468478385,
          0.007356049564158338,
          0.005035312950855432,
          0.011392555069658169,
          0.014167602685073244,
          0.008879919220556472,
          0.07050956084056825,
          0.025946966821577114,
          0.007731662374409664,
          0.0065813580984450115,
          0.0029203178270867007,
          0.010056919121465136,
          0.007694820102612427,
          0.01196988467509794,
          0.028285069461199696,
          0.03476796372222836,
          0.0049175532169241035,
          0.01756405212941496,
          0.001601610127777481,
          0.004331644701541895,
          0.0011164126222576894,
          0.008699174068017186,
          0.00334409621790965,
          0.006766676678207484,
          0.01099245897123751,
          0.012885520896030242,
          0.006227190553245347,
          0.009135912398802471,
          0.009445657881914165,
          0.009696327111072876,
          0.008512899068323646,
          0.014110713451405589,
          0.010675015430210825,
          0.007632774266929996,
          0.012448856495061443,
          0.015604577478567663,
          0.012109971966934151,
          0.013529280214955003,
          0.009985358572355366,
          0.00873277939974594,
          0.02435776370761611,
          0.02071332261648614,
          0.010907400782308703,
          0.00883161244857282,
          0.05334635360428579,
          0.012409064427875198,
          0.007683967372414358,
          0.014803832145147484,
          0.00561334480203614,
          0.005676836628039986,
          0.0404418161482457,
          0.009846560677302767,
          0.005170706522620819,
          0.008082581133979373,
          0.011521335744044757,
          0.003699254144764589,
          0.009432536211169794,
          0.09536296494222007,
          0.006663372345539977,
          0.006975878884995731,
          0.010910623277215068,
          0.031468248530167685,
          0.012744671790122305,
          0.010547692700550854,
          0.009185108481827405,
          0.04563990687306094,
          0.013527902210104227,
          0.01137302812312973,
          0.011802470084523857,
          0.016762153692022125,
          0.008030901784821368,
          0.004322939863824003,
          0.01543599708258022,
          0.011194434978893851,
          0.00603338395308114,
          0.01890035566076452,
          0.013687554930972377,
          0.08654501089975572,
          0.008610861863614434,
          0.0029519318192181955,
          0.0106021737183383,
          0.023388126336685588,
          0.012839793618878492,
          0.006980851997480077,
          0.0051125637849104705,
          0.009333219892574275,
          0.00902758656994226,
          0.0010370712776251777,
          0.0148281047712465,
          0.011539790789436188,
          0.010269255866297271,
          0.017247163260461093,
          0.01245944301564713,
          0.007590599788785324,
          0.009523848978505816,
          0.02082908176806015,
          0.0253059024193115,
          0.01465969788843274,
          0.011866637185919023,
          0.008151675684346759,
          0.003722285847005919,
          0.03744532120197562,
          0.046649972012846756,
          0.005410324665028993,
          0.010481803502830359,
          0.011252036311418282,
          0.013621586585054388,
          0.009695533109029607,
          0.008316040739441071,
          0.02935553769882141,
          0.06304025779204867,
          0.0343705196092702,
          0.012412191788674962,
          0.026516448491991022,
          0.01623416128342146,
          0.0312669542273283,
          0.010260436598409129,
          0.006626117921869568,
          0.013836356878641468,
          0.011037748103663206,
          0.008260659417731776,
          0.018714679942832275,
          0.012538830220671695,
          0.016186942106493366,
          0.013019729519517603,
          0.014786397422246855,
          0.014573628773102443,
          0.014895086882852264,
          0.020629581874102243,
          0.01771804299140449,
          0.015029830688143151,
          0.01548807088587929,
          0.012764750867125942,
          0.01850516445652279,
          0.01702627911736749,
          0.011482355997812504,
          0.018690224868945324,
          0.01391200089081485,
          0.014117719662893526,
          0.014448719733617204,
          0.016856362831423992,
          0.013677707377188061,
          0.01967183886364995,
          0.013501578160259398,
          0.021765046807067107,
          0.01605430883169054,
          0.011781023763017092,
          0.05544428546685071,
          0.015109264378214044,
          0.012342921069559814,
          0.011756925628695453,
          0.012634956232510819,
          0.03226692090102471,
          0.010197952857616412,
          0.005804727889749519,
          0.017687706642617634,
          0.03520167092162116,
          0.011269938098533005,
          0.04922244264208889,
          0.03998086871692631,
          0.014377782885873781,
          0.037497309117896865,
          0.04408257829810083,
          0.007341042327352528,
          0.010228717590694394,
          0.02808621629157223,
          0.0126826599726803,
          0.004014276298538239,
          0.00844990562356882,
          0.022801522152070923,
          0.016866599885454123,
          0.060245786197554815,
          0.012938308650734257,
          0.009762763522766891,
          0.005781274565593372,
          0.015434243922183025,
          0.010711234816099065,
          0.007624351271174383,
          0.02400817719233475,
          0.052275041132701705,
          0.0029121365667962454,
          0.02999951989937747,
          0.02009192161971113,
          0.013196162049561071,
          0.03377420003927692,
          0.08995475114300967,
          0.011414696689830956,
          0.00876273580317855,
          0.006637546378952921,
          0.04783257812967895,
          0.015333612460380924,
          0.00484618535591233,
          0.012191067396902977,
          0.018163552630911448,
          0.009730903737440285,
          0.013372501907155101,
          0.04190121327959192,
          0.007616871537572531,
          0.010689789686061487,
          0.014987486095022411,
          0.037639738892599084,
          0.05161712760293857,
          0.04963010383134978,
          0.0978893139355095,
          0.04438905679409591,
          0.009242228291198548,
          0.07104367563519659,
          0.002521171130845293,
          0.005727796673308964,
          0.0013722755672748062,
          0.0032287739398997543,
          0.004308612895758549,
          0.0018087062760320715,
          0.003282687677102594,
          0.003076798859611507,
          0.002603236912684458,
          0.0043306730287459155,
          0.0030271743204965166,
          0.004961788709021246,
          0.002173858330362605,
          0.005794489153340146,
          0.003584838868786591,
          0.0011028323487191423,
          0.025692021040163722,
          0.005667258058273693,
          0.0062470224853368094,
          0.027247222692540936,
          0.0037385467798249986,
          0.006665124580513603,
          0.018539978009458124,
          0.032700683611820845,
          0.0010842383307033238,
          0.004782702692742713,
          0.00677867288202685,
          0.002985143436956077,
          0.006519255518713438,
          0.007723333454272926,
          0.02123866304603226,
          0.004776075455424586,
          0.028234172340892746,
          0.04794653333157578,
          0.016476405658083355,
          0.007267832700968685,
          0.00239875412225415,
          0.005154909371259412,
          0.008312542120562531,
          0.004176654610802289,
          0.003602617308079406,
          0.006034165014283704,
          0.0014000866388465456,
          0.004341366928949277,
          0.006727080894740665,
          0.022318294734313748,
          0.00897145574396178,
          0.03602625396287615,
          0.009225082817879869,
          0.010134000930206938,
          0.025057822777439315,
          0.031973295547193414,
          0.008042789113362757,
          0.011141763369988724,
          0.055910788244709866,
          0.04508247125070647,
          0.008842510325875571,
          0.006585360156867813,
          0.012034862193472334,
          0.012862357475739564,
          0.015109446661130344,
          0.019753683939898507,
          0.029865089531844972,
          0.01172111325754225,
          0.016363194845968564,
          0.01922624929718744,
          0.01709864919008509,
          0.014506382657943451,
          0.01631696661872629,
          0.016057691535473,
          0.01810236814661036,
          0.02292764724607782,
          0.021107441839859437,
          0.01692815005816456,
          0.01792617492815952,
          0.022884512281302324,
          0.019019156136304283,
          0.01484879699107677,
          0.020530954763025105,
          0.016338707971156944,
          0.013990189774423185,
          0.014895825868185416,
          0.027159588326548918,
          0.017483669666919086,
          0.024427741559183695,
          0.019710736612954822,
          0.013714540690706491,
          0.015505028302050793,
          0.0753122782044342,
          0.01293457289672582,
          0.03935264505239296,
          0.02279127530578855,
          0.0167656058936117,
          0.04063549141979267,
          0.013847981921031864,
          0.014058453345479859,
          0.03865313394884087,
          0.018350349213469685,
          0.015945609064403295,
          0.012200271488560241,
          0.055237775368485835,
          0.0789180953226469,
          0.049221855488831984,
          0.060738359215624184,
          0.014037910794639927,
          0.01943785476860161,
          0.03248098509520933,
          0.04552278871966443,
          0.011433617594268097,
          0.016647145242973477
         ],
         "xaxis": "x",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          4,
          4,
          10,
          3,
          2,
          8,
          2,
          6,
          6,
          2,
          8,
          4,
          4,
          5,
          2,
          3,
          3,
          5,
          7,
          5,
          3,
          5,
          4,
          4,
          2,
          3,
          7,
          7,
          10,
          8,
          9,
          7,
          4,
          6,
          4,
          5,
          6,
          3,
          7,
          2,
          9,
          4,
          4,
          5,
          4,
          2,
          6,
          3,
          4,
          3,
          2,
          4,
          5,
          5,
          6,
          5,
          3,
          4,
          8,
          5,
          6,
          4,
          4,
          3,
          5,
          5,
          7,
          6,
          5,
          7,
          5,
          4,
          4,
          3,
          4,
          5,
          6,
          8,
          4,
          3,
          2,
          3,
          3,
          3,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          3,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          9,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          7,
          2,
          2,
          3,
          2,
          2,
          2,
          7,
          7,
          7,
          8,
          7,
          2,
          2,
          2,
          2,
          3,
          7,
          7,
          7,
          6,
          7,
          7,
          8,
          7,
          7,
          6,
          7,
          7,
          7,
          8,
          7,
          7,
          10,
          6,
          8,
          7,
          7,
          7,
          7,
          7,
          7,
          2,
          2,
          2,
          7,
          2,
          7,
          7,
          7,
          7,
          2,
          7,
          2,
          2,
          7,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          7,
          2,
          2,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          7,
          7,
          7,
          7,
          7,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          7,
          7,
          2,
          6,
          2,
          7,
          2,
          7,
          2,
          7,
          2,
          2,
          7,
          9,
          2,
          7,
          2,
          7,
          2,
          7,
          2,
          6,
          7,
          2,
          3,
          7,
          2,
          7,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          8,
          2,
          2,
          2,
          2,
          2,
          7,
          2,
          2,
          2,
          7,
          2,
          7,
          2,
          6,
          7,
          2,
          8,
          7,
          2,
          7,
          2,
          3,
          7,
          2,
          7,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          10,
          2,
          6,
          2,
          8,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          9,
          6,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          5,
          3,
          3,
          4,
          3,
          3,
          2,
          2,
          8,
          2,
          2,
          2,
          6,
          4,
          2,
          2,
          2,
          7,
          3,
          2,
          2,
          2,
          7,
          2,
          2,
          5,
          2,
          2,
          8,
          7,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          6,
          10,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          4,
          2,
          7
         ],
         "xaxis": "x2",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          30,
          10,
          140,
          480,
          470,
          500,
          340,
          330,
          390,
          200,
          420,
          480,
          260,
          240,
          110,
          300,
          400,
          190,
          270,
          70,
          440,
          180,
          220,
          240,
          340,
          130,
          280,
          300,
          360,
          290,
          60,
          210,
          160,
          160,
          90,
          30,
          160,
          270,
          460,
          360,
          320,
          230,
          210,
          160,
          130,
          260,
          200,
          500,
          380,
          180,
          110,
          220,
          250,
          250,
          280,
          310,
          420,
          250,
          180,
          230,
          200,
          210,
          280,
          150,
          230,
          230,
          260,
          330,
          180,
          470,
          240,
          210,
          280,
          300,
          220,
          190,
          240,
          140,
          170,
          260,
          350,
          180,
          120,
          80,
          90,
          70,
          10,
          90,
          50,
          90,
          110,
          100,
          120,
          50,
          50,
          40,
          40,
          10,
          60,
          20,
          40,
          60,
          30,
          60,
          60,
          50,
          70,
          20,
          30,
          20,
          440,
          50,
          20,
          40,
          70,
          80,
          60,
          110,
          110,
          150,
          40,
          380,
          500,
          370,
          490,
          490,
          480,
          460,
          410,
          440,
          500,
          80,
          400,
          100,
          130,
          120,
          130,
          140,
          100,
          170,
          460,
          200,
          10,
          60,
          80,
          60,
          20,
          150,
          30,
          110,
          50,
          70,
          70,
          40,
          60,
          80,
          100,
          330,
          130,
          430,
          470,
          90,
          90,
          70,
          110,
          90,
          50,
          50,
          60,
          50,
          30,
          90,
          70,
          80,
          380,
          60,
          40,
          30,
          350,
          70,
          90,
          500,
          500,
          490,
          450,
          480,
          100,
          500,
          480,
          40,
          190,
          80,
          90,
          120,
          60,
          50,
          90,
          470,
          80,
          100,
          70,
          110,
          130,
          110,
          490,
          50,
          20,
          170,
          120,
          70,
          100,
          100,
          100,
          90,
          290,
          80,
          60,
          40,
          50,
          30,
          60,
          40,
          310,
          270,
          300,
          40,
          60,
          250,
          220,
          50,
          70,
          320,
          280,
          310,
          330,
          310,
          340,
          290,
          400,
          10,
          360,
          50,
          320,
          500,
          60,
          100,
          70,
          40,
          270,
          380,
          30,
          30,
          30,
          20,
          80,
          40,
          210,
          50,
          60,
          500,
          30,
          90,
          20,
          190,
          110,
          70,
          120,
          150,
          50,
          50,
          40,
          80,
          60,
          60,
          70,
          100,
          10,
          60,
          40,
          490,
          90,
          480,
          80,
          70,
          60,
          40,
          30,
          50,
          60,
          50,
          90,
          50,
          70,
          100,
          290,
          50,
          120,
          240,
          110,
          80,
          60,
          70,
          140,
          320,
          500,
          40,
          40,
          30,
          50,
          40,
          50,
          50,
          50,
          30,
          40,
          60,
          60,
          60,
          50,
          60,
          70,
          70,
          70,
          70,
          40,
          20,
          40,
          30,
          60,
          50,
          40,
          60,
          30,
          20,
          30,
          40,
          460,
          30,
          10,
          420,
          20,
          40,
          50,
          30,
          50,
          490,
          40,
          60,
          470,
          50,
          30,
          50,
          60,
          70,
          40,
          20,
          440,
          80,
          490,
          60,
          260,
          50,
          40,
          30,
          70,
          60,
          50,
          500,
          480,
          40,
          80,
          70,
          20,
          10,
          50,
          30,
          60,
          40,
          60,
          40,
          50,
          80,
          70,
          30,
          50,
          450,
          20,
          60,
          40,
          500,
          70,
          80,
          80,
          80,
          80,
          80,
          70,
          350,
          330,
          360,
          340,
          90,
          290,
          410,
          300,
          480,
          80,
          270,
          70,
          70,
          390,
          320,
          470,
          280,
          350,
          60,
          500,
          500,
          490,
          490,
          480,
          450,
          490,
          500,
          500,
          480,
          90,
          350,
          300,
          230,
          250,
          470,
          20,
          500,
          280,
          190,
          170,
          170,
          180,
          160,
          220,
          490,
          150,
          210,
          130,
          140,
          240,
          200,
          40,
          30,
          30,
          40,
          20,
          10,
          50,
          50,
          40,
          30,
          30,
          30,
          10,
          20,
          230,
          10,
          20,
          20,
          30,
          20,
          10,
          250,
          30,
          30,
          40,
          20,
          30,
          50,
          10,
          40,
          260,
          50,
          30,
          20,
          40,
          230,
          60,
          30,
          40,
          60,
          50,
          20,
          40,
          60,
          50,
          20,
          90,
          200,
          80,
          10,
          270,
          170
         ],
         "xaxis": "x3",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          10,
          10,
          16,
          2,
          2,
          2,
          6,
          20,
          7,
          15,
          6,
          2,
          2,
          5,
          4,
          8,
          14,
          4,
          13,
          8,
          20,
          4,
          4,
          3,
          2,
          5,
          8,
          12,
          9,
          7,
          11,
          3,
          5,
          6,
          10,
          3,
          5,
          18,
          2,
          7,
          9,
          3,
          4,
          6,
          5,
          2,
          3,
          4,
          6,
          8,
          5,
          4,
          4,
          2,
          7,
          3,
          4,
          2,
          6,
          9,
          5,
          4,
          3,
          4,
          3,
          2,
          3,
          11,
          3,
          5,
          8,
          4,
          2,
          5,
          3,
          2,
          4,
          7,
          6,
          4,
          12,
          8,
          9,
          9,
          8,
          8,
          9,
          10,
          7,
          8,
          10,
          10,
          8,
          12,
          13,
          11,
          13,
          12,
          15,
          13,
          11,
          14,
          14,
          12,
          12,
          14,
          15,
          12,
          11,
          10,
          12,
          13,
          13,
          12,
          11,
          14,
          12,
          15,
          15,
          17,
          10,
          14,
          16,
          18,
          16,
          16,
          16,
          17,
          14,
          15,
          11,
          14,
          15,
          17,
          12,
          12,
          13,
          11,
          13,
          12,
          16,
          11,
          10,
          14,
          14,
          14,
          15,
          13,
          12,
          13,
          15,
          14,
          14,
          11,
          14,
          12,
          16,
          15,
          13,
          10,
          14,
          14,
          13,
          14,
          12,
          9,
          7,
          8,
          7,
          9,
          8,
          7,
          7,
          7,
          6,
          9,
          6,
          8,
          7,
          11,
          15,
          14,
          15,
          13,
          7,
          9,
          14,
          12,
          16,
          8,
          13,
          14,
          14,
          15,
          13,
          12,
          11,
          14,
          14,
          8,
          14,
          10,
          10,
          11,
          15,
          9,
          9,
          10,
          13,
          17,
          20,
          19,
          19,
          20,
          20,
          19,
          18,
          19,
          19,
          19,
          18,
          20,
          18,
          19,
          19,
          18,
          18,
          18,
          19,
          20,
          20,
          17,
          17,
          18,
          18,
          17,
          19,
          12,
          18,
          19,
          20,
          17,
          16,
          17,
          17,
          6,
          7,
          12,
          18,
          8,
          19,
          18,
          19,
          19,
          5,
          20,
          19,
          2,
          11,
          12,
          12,
          17,
          18,
          19,
          8,
          7,
          13,
          20,
          18,
          18,
          18,
          17,
          11,
          11,
          12,
          11,
          19,
          11,
          18,
          19,
          17,
          12,
          18,
          13,
          11,
          20,
          16,
          9,
          9,
          9,
          10,
          9,
          15,
          8,
          19,
          10,
          14,
          18,
          9,
          17,
          13,
          19,
          20,
          16,
          17,
          18,
          14,
          15,
          19,
          19,
          19,
          19,
          20,
          19,
          19,
          19,
          18,
          18,
          18,
          18,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          19,
          20,
          19,
          20,
          19,
          20,
          19,
          19,
          12,
          17,
          13,
          11,
          20,
          18,
          19,
          12,
          20,
          11,
          13,
          19,
          14,
          18,
          17,
          20,
          19,
          16,
          10,
          18,
          12,
          20,
          14,
          13,
          19,
          19,
          18,
          20,
          12,
          17,
          19,
          11,
          10,
          15,
          14,
          18,
          20,
          13,
          16,
          11,
          20,
          19,
          17,
          18,
          19,
          12,
          14,
          20,
          12,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          18,
          19,
          18,
          19,
          20,
          19,
          19,
          18,
          20,
          19,
          20,
          18,
          19,
          20,
          19,
          18,
          20,
          19,
          19,
          19,
          18,
          19,
          20,
          19,
          18,
          20,
          19,
          19,
          18,
          3,
          20,
          19,
          17,
          20,
          18,
          19,
          20,
          19,
          18,
          19,
          17,
          20,
          18,
          19,
          20,
          5,
          6,
          19,
          16,
          18,
          20,
          19,
          17,
          18,
          19,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          19,
          20,
          19,
          20,
          19,
          20,
          19,
          20,
          19,
          20,
          19,
          19,
          20,
          20,
          20,
          20,
          20,
          20,
          19,
          19,
          20,
          19,
          20,
          19,
          20,
          19,
          20,
          20
         ],
         "xaxis": "x4",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "distance",
          "distance",
          "distance",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "distance",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "distance",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "distance",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "distance",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "uniform",
          "distance",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "uniform",
          "distance",
          "distance",
          "distance",
          "uniform",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "uniform",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "distance",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "distance",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "uniform",
          "distance",
          "uniform",
          "distance",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform",
          "uniform"
         ],
         "xaxis": "x5",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.QuantileTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "project.packages.modelling.transformers.scaler.NotScalerTransformer"
         ],
         "xaxis": "x6",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.3925136468134222,
          0.38208404980070293,
          0.8733243417622814,
          0.04544733852500937,
          0.021583189959284575,
          0.01802189559897557,
          0.2081591517438272,
          0.7115318813056645,
          0.542087215834471,
          0.15746253681106132,
          0.2510642047739566,
          0.005660842721502891,
          0.002795035258286264,
          0.17895476181477427,
          0.10592433178880975,
          0.2879058972572614,
          0.0013785709153815197,
          0.14872972534672188,
          0.3197538572713865,
          0.1067719251711543,
          0.5147294730511498,
          0.11428846476752014,
          0.103298419415503,
          0.07980963763839456,
          0.22076185761995487,
          0.0032642485777751723,
          0.09695821118980388,
          0.18624912303145144,
          0.06932341348876517,
          0.3478863018689504,
          0.264087905412473,
          0.08613936732511664,
          0.1574703613526946,
          0.4326548252557329,
          0.1493458999420411,
          0.05870749181133461,
          0.21379045187237478,
          0.05363103932763263,
          0.046309948956956226,
          0.14065253668764427,
          0.230312824310655,
          0.11904778442892265,
          0.03369788320825845,
          0.02946045528017524,
          0.17451807273682798,
          0.002376979401198076,
          0.057038868280316624,
          0.17804920486505854,
          0.033521145315927044,
          0.1369800103483166,
          0.2714586912996223,
          0.10476861193195351,
          0.09511184312630586,
          0.0687184541160669,
          0.03130133681172803,
          0.002654857500227512,
          0.09940821397517936,
          0.19209872336491335,
          0.14349422377768845,
          0.08343602252389945,
          0.03919824688220737,
          0.10846891871986851,
          0.08265057814391658,
          0.16420029205415032,
          0.12339135252130617,
          0.2097218385042754,
          0.1349735793698032,
          0.2425985255279689,
          0.03210504012585935,
          0.07442890884022613,
          0.12355704564156837,
          0.09315310831561932,
          0.055138385495521344,
          0.015624752362376784,
          0.19220648232990167,
          0.15821624861662245,
          0.1124557261176794,
          0.056673900634027476,
          0.0017513833854317568,
          0.025969161396300226,
          0.07807654594544283,
          0.13116349031515723,
          0.12831843495280276,
          0.16201340421636665,
          0.1637659299491418,
          0.229459516787624,
          0.17166946968899557,
          0.2977517594013833,
          0.2023518248528616,
          0.15789294411972743,
          0.0411875585262903,
          0.04705659735451254,
          0.08790448618465348,
          0.02714478880339107,
          0.015073233515108371,
          0.021857083176411024,
          0.026505021997506612,
          0.0014461450788252578,
          0.05953818507401997,
          0.02323559691034341,
          0.04973771193672388,
          0.06845953028501071,
          0.06889291631359776,
          0.023207687460771755,
          0.040549009674363604,
          0.018124530345835485,
          0.09424190510551955,
          0.0680286510319928,
          0.07047133759173595,
          0.10196609735209243,
          0.03989883600531212,
          0.018013293681194024,
          0.06332186820325321,
          0.04241458374021852,
          0.08631379494056049,
          0.015943023404588787,
          0.10100862512557704,
          0.12463501782860002,
          0.12577865599738802,
          0.13796033530307147,
          0.11475601653558656,
          0.07654759002758964,
          0.06929302483102834,
          0.06977993902540108,
          0.04633369085317361,
          0.07978131387863346,
          0.05793778484292664,
          0.038062422511082404,
          0.11271189246714025,
          0.07887305993277706,
          0.003503525591432341,
          0.0998052700088293,
          0.14181686167047153,
          0.030931066892498665,
          0.0898383961925743,
          0.060330229335726,
          0.0014037460339173559,
          0.08570899708927411,
          0.12337671110598947,
          0.052711681747293376,
          0.023976705915834937,
          0.09386557962255314,
          0.06862929564328595,
          0.038345382110852394,
          0.04089287187666972,
          0.026697649664492007,
          0.0675311448683333,
          0.11029188420102434,
          0.05075401126530049,
          0.018768275439158,
          0.1478007433793952,
          0.04267921715792768,
          0.0012647949014405607,
          0.038141160962920556,
          0.06981695988560331,
          0.08553747695935246,
          0.04998629525553129,
          0.39299481727041724,
          0.025291831110239277,
          0.12411172653926371,
          0.18620804565807186,
          0.041963150969737885,
          0.08187383600287193,
          0.053774821611847406,
          0.03566075048529262,
          0.09993725559957642,
          0.09711762629272945,
          0.10547696775480449,
          0.132589020004473,
          0.10067384330682513,
          0.07237820976850959,
          0.08671912109779704,
          0.5907491874402411,
          0.09174080767634342,
          0.11418076258991988,
          0.06924133377509836,
          0.1536030537449734,
          0.08459834063460403,
          0.0196795924105434,
          0.14122164333908144,
          0.05805516788448084,
          0.03964636103580148,
          0.002517633870496045,
          0.06440055903333004,
          0.10370739099416461,
          0.3236771019662027,
          0.023863083472672752,
          0.08325848803567273,
          0.05170672024504776,
          0.1256224132235575,
          0.24082729666099278,
          0.036936579328518584,
          0.045978151822003634,
          0.02290770805959834,
          0.07156165326738438,
          0.09100566538919233,
          0.0012862858487309795,
          0.2703161581157103,
          0.038910377343723865,
          0.054990544946636716,
          0.019415517465968892,
          0.035698881020444675,
          0.061349404361546456,
          0.20938745862990643,
          0.11050530513358013,
          0.07847501511331637,
          0.04292072802680402,
          0.08834177565028309,
          0.17087525419809252,
          0.022016662743310145,
          0.06102144894681829,
          0.058444206714420875,
          0.06567777273407405,
          0.1033883774343542,
          0.05470775266676766,
          0.07603646523965402,
          0.12312491750905097,
          0.13178100232377266,
          0.12563218901995454,
          0.14396485846821405,
          0.1837386707000177,
          0.12594182727220882,
          0.10165541777385478,
          0.10584000942171223,
          0.14747792704629129,
          0.9033814012149844,
          0.09450154596197818,
          0.11197257153309886,
          0.3825501219109471,
          0.09143302099845318,
          0.12198078723606005,
          0.2600631882030452,
          0.2594931505785489,
          0.15125172366807754,
          0.19842034514171014,
          0.28157417439497834,
          0.352866023975816,
          0.16369126992721064,
          0.13364518757261173,
          0.23614052757203757,
          0.06987777193070116,
          0.2159558217599315,
          0.08407128975960569,
          0.04687401412359843,
          0.034343049023243824,
          0.45786609360952346,
          0.053175107849922604,
          0.015283518746350738,
          0.10525994069061094,
          0.05681913170653289,
          0.07519535954177065,
          0.027157099288057637,
          0.09574779713902956,
          0.00043210186598976325,
          0.04503064291761955,
          0.07251355817322086,
          0.12264760518427997,
          0.16908832178355926,
          0.03392908501851056,
          0.776483084125839,
          0.06224763332314075,
          0.2977118336327346,
          0.0870380926114164,
          0.11075402437126662,
          0.013712178679100732,
          0.13455428445949613,
          0.05063971317612747,
          0.07845903135491505,
          0.1882521109712161,
          0.22030854535629987,
          0.15366841290894884,
          0.258033438510866,
          0.11304242185353798,
          0.18832714468069892,
          0.11956382835506629,
          0.14010540163510646,
          0.17519245914518952,
          0.11051392431070588,
          0.19622833377629134,
          0.09220603799861832,
          0.5863883842511539,
          0.1561385662488388,
          0.06047523530434459,
          0.1327395431466635,
          0.033895313409187805,
          0.07644330888735552,
          0.23567043340715968,
          0.10809738869063583,
          0.10788072270882676,
          0.1372951446636852,
          0.1224856062322622,
          0.42351313624156606,
          0.3226872758444521,
          0.9683642581373981,
          0.097338839900326,
          0.1786778239942558,
          0.04665770231114884,
          0.49189414519632557,
          0.15930431481506457,
          0.08205361585647122,
          0.021078672022101053,
          0.29538926925930825,
          0.10289084422051856,
          0.06246900715172729,
          0.12136159195218844,
          0.013504638125174159,
          0.004362214171176056,
          0.024042447704748608,
          0.042289699821556635,
          0.03860975853795915,
          0.01989443319536055,
          0.011913145505008202,
          0.03398839251604778,
          0.017605773238403448,
          0.04987017296184043,
          0.0009550794691439782,
          0.03653244038313204,
          0.03201045708993177,
          0.04961017423322252,
          0.01833676854376334,
          0.040328020964385446,
          0.034734137576739293,
          0.00042667494124380874,
          0.030138125258075948,
          0.03720404831289152,
          0.03995690223320449,
          0.02296357094719637,
          0.05065002534641873,
          0.023728679148590025,
          0.0001314817271862584,
          0.04260466892504977,
          0.06315189640557219,
          0.018246075872017473,
          0.022271545816076755,
          0.014677973996866354,
          0.06254053725128986,
          0.3130778939485399,
          0.044273204406163495,
          0.071722552484179,
          0.023628055421889525,
          0.00221373401083055,
          0.051737405081343786,
          0.03891685673591862,
          0.26611690145626765,
          0.06449908222201374,
          0.02086133879762249,
          0.07027454428155777,
          0.00030120272422801825,
          0.2204314818934126,
          0.0430360669047643,
          0.07954863138191956,
          0.03149308735305227,
          0.253048521660342,
          0.3425273767399237,
          0.052764758164750736,
          0.018620274700475253,
          0.07860156941979972,
          0.05205161639745791,
          0.3687029565820086,
          0.03324327245747095,
          0.5635743175239643,
          0.5095664748379056,
          0.6650880167327308,
          0.0007136417145930732,
          0.06930819323352137,
          0.03652445573938532,
          0.4886525929162133,
          0.08709247312052035,
          0.2857730601451093,
          0.015976017916771276,
          0.4564135307182422,
          0.3869790215562393,
          0.20754461820809578,
          0.06316319270453015,
          0.396869871087452,
          0.2340225356069876,
          0.04925690547597453,
          0.4080121259279034,
          0.025137041314202673,
          0.08366315240592646,
          0.05195430760948036,
          0.016456140136182854,
          0.34923849862987255,
          0.03595880084353681,
          0.28043923505825297,
          0.06937549001872212,
          0.09095432376614548,
          0.3362032077820579,
          0.018016630989650798,
          0.7890219017068782,
          0.0541676651410419,
          0.06231811687820659,
          0.3662684977415544,
          0.09417844166661929,
          0.08452970227207589,
          0.11546982341394688,
          0.10365373481073697,
          0.15081918044528198,
          0.14499206975832696,
          0.1563207845650961,
          0.1295609097022458,
          0.10140094962282738,
          0.12266080308978702,
          0.17296960453190885,
          0.07579994460538807,
          0.10630114688514988,
          0.14711775744746833,
          0.06463850089870143,
          0.42958258257017146,
          0.09038313737205966,
          0.11684417575869072,
          0.06462226547044261,
          0.09026841247351686,
          0.21826664329235518,
          0.6247792596767632,
          0.2045147416506926,
          0.1656549862659517,
          0.16595408128403194,
          0.1367966193745351,
          0.3179564391156555,
          0.1719903171558833,
          0.10856864138800346,
          0.18634897556523877,
          0.2549623583645914,
          0.14491332377532504,
          0.13321064258313978,
          0.5296352017588648,
          0.24094671352524005,
          0.29249860433596797,
          0.1581666385541394,
          0.19182417195930743,
          0.16041755266726057,
          0.15336985775130588,
          0.5617829749687088,
          0.3080014395437322,
          0.12562524825593588,
          0.14404597560830273,
          0.26689358228817783,
          0.10481137330133977,
          0.41418616652685025,
          0.1750484418687343,
          0.19804114500747544,
          0.12802784918154575,
          0.07626909559768452,
          0.08962564209521366,
          0.44049864201246,
          0.5255602408585054,
          0.22584424251314303,
          0.05297428580541784,
          0.05252688147824316,
          0.04934749633126069,
          0.06665897050378207,
          0.041434504891151996,
          0.0810583716444533,
          0.05248855192291661,
          0.0013854741318752375,
          0.36867163205563325,
          0.05778333213062965,
          0.05664951801129591,
          0.4883374590270426,
          0.05295600136673907,
          0.06218819081304285,
          0.0644383223054098,
          0.05948926839335072,
          0.07527042816348141,
          0.34444217535657384,
          0.7614204488990758,
          0.3971791997366901,
          0.03944906098495236,
          0.060092046503238475,
          0.09130193293257709,
          0.3297351678378755,
          0.6948607333236224,
          0.03583546033324149,
          0.07671880910102438,
          0.0531439189482054,
          0.6279764737211979,
          0.302926557273099,
          0.029337821127786802,
          0.20441832420419073,
          0.8133276991670046,
          0.276785975275546,
          0.24407169054639882,
          0.09968081586039539,
          0.0753244484486097,
          0.08147211142309614,
          0.06862273951363602,
          0.9363803460778297,
          0.47458833821136304,
          0.09794317568761002,
          0.053921499437926027,
          0.5310036829190526,
          0.17552001867354394,
          0.5486511807647825,
          0.1190219754231662,
          0.08683656667764089,
          0.07169054984273843,
          0.14141178828637402,
          0.044128645090439865,
          0.11296574315432267
         ],
         "xaxis": "x7",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          1,
          3,
          8,
          8,
          8,
          6,
          5,
          6,
          3,
          7,
          8,
          8,
          7,
          4,
          7,
          6,
          5,
          8,
          7,
          3,
          5,
          4,
          4,
          2,
          4,
          6,
          7,
          6,
          8,
          7,
          5,
          6,
          6,
          8,
          7,
          1,
          8,
          6,
          7,
          6,
          4,
          5,
          5,
          5,
          6,
          8,
          8,
          6,
          5,
          3,
          4,
          4,
          7,
          5,
          2,
          7,
          5,
          4,
          6,
          3,
          4,
          3,
          4,
          5,
          5,
          6,
          5,
          8,
          5,
          7,
          4,
          4,
          4,
          3,
          5,
          8,
          6,
          5,
          4,
          8,
          5,
          5,
          5,
          5,
          6,
          6,
          5,
          5,
          7,
          7,
          7,
          8,
          7,
          7,
          7,
          7,
          7,
          8,
          7,
          7,
          7,
          7,
          8,
          8,
          7,
          7,
          8,
          8,
          8,
          8,
          7,
          8,
          7,
          8,
          7,
          6,
          8,
          8,
          8,
          8,
          7,
          8,
          8,
          8,
          8,
          7,
          6,
          8,
          7,
          8,
          7,
          8,
          6,
          7,
          7,
          7,
          7,
          8,
          7,
          8,
          7,
          7,
          6,
          6,
          6,
          8,
          7,
          6,
          8,
          6,
          6,
          6,
          7,
          6,
          7,
          8,
          7,
          6,
          1,
          8,
          6,
          6,
          6,
          6,
          7,
          6,
          5,
          7,
          8,
          7,
          6,
          6,
          6,
          5,
          6,
          6,
          7,
          8,
          6,
          8,
          6,
          6,
          6,
          6,
          7,
          6,
          7,
          5,
          2,
          8,
          6,
          6,
          6,
          6,
          7,
          6,
          6,
          7,
          8,
          6,
          7,
          7,
          7,
          7,
          5,
          7,
          8,
          7,
          8,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          5,
          8,
          6,
          8,
          6,
          8,
          6,
          8,
          7,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          8,
          6,
          8,
          6,
          5,
          6,
          8,
          6,
          6,
          6,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          7,
          8,
          8,
          7,
          8,
          7,
          7,
          8,
          8,
          6,
          6,
          8,
          6,
          7,
          8,
          6,
          6,
          7,
          6,
          8,
          6,
          8,
          7,
          6,
          7,
          6,
          2,
          8,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          6,
          6,
          7,
          6,
          6,
          6,
          6,
          7,
          6,
          6,
          5,
          6,
          7,
          6,
          6,
          3,
          6,
          8,
          1,
          7,
          6,
          6,
          8,
          6,
          6,
          7,
          8,
          6,
          6,
          6,
          7,
          6,
          8,
          5,
          6,
          8,
          6,
          7,
          6,
          6,
          7,
          6,
          8,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          4,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          8,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          6,
          2,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6
         ],
         "xaxis": "x8",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y8"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          450,
          482,
          354,
          24,
          0,
          24,
          184,
          180,
          126,
          309,
          102,
          12,
          0,
          93,
          248,
          76,
          177,
          1,
          66,
          149,
          268,
          51,
          1,
          53,
          129,
          43,
          3,
          401,
          221,
          95,
          38,
          10,
          2,
          67,
          454,
          32,
          127,
          354,
          29,
          85,
          493,
          0,
          0,
          35,
          25,
          59,
          111,
          19,
          76,
          17,
          54,
          0,
          2,
          23,
          41,
          65,
          112,
          18,
          155,
          295,
          215,
          14,
          4,
          46,
          4,
          81,
          38,
          58,
          14,
          30,
          73,
          2,
          1,
          46,
          25,
          14,
          375,
          37,
          52,
          28,
          87,
          0,
          11,
          13,
          12,
          25,
          41,
          14,
          67,
          0,
          0,
          30,
          23,
          1,
          0,
          0,
          54,
          40,
          18,
          30,
          48,
          2,
          8,
          0,
          22,
          10,
          34,
          1,
          20,
          62,
          432,
          7,
          0,
          10,
          34,
          21,
          45,
          0,
          203,
          257,
          20,
          1,
          0,
          10,
          30,
          11,
          21,
          0,
          39,
          0,
          28,
          11,
          321,
          16,
          0,
          0,
          20,
          9,
          32,
          9,
          25,
          10,
          18,
          0,
          0,
          39,
          18,
          9,
          148,
          28,
          49,
          1,
          9,
          18,
          4,
          0,
          0,
          28,
          16,
          36,
          11,
          0,
          24,
          8,
          16,
          0,
          0,
          23,
          11,
          34,
          0,
          0,
          13,
          9,
          0,
          24,
          17,
          9,
          22,
          0,
          10,
          0,
          16,
          0,
          9,
          28,
          18,
          0,
          9,
          32,
          19,
          7,
          0,
          9,
          0,
          17,
          9,
          0,
          24,
          17,
          10,
          466,
          0,
          0,
          10,
          26,
          16,
          9,
          0,
          19,
          0,
          0,
          9,
          235,
          9,
          18,
          0,
          0,
          292,
          28,
          9,
          0,
          0,
          12,
          10,
          20,
          7,
          0,
          17,
          10,
          24,
          0,
          1,
          9,
          8,
          17,
          0,
          9,
          0,
          0,
          18,
          9,
          8,
          0,
          16,
          1,
          419,
          16,
          181,
          0,
          0,
          28,
          10,
          0,
          21,
          11,
          350,
          0,
          13,
          25,
          161,
          11,
          34,
          9,
          0,
          19,
          9,
          19,
          0,
          0,
          28,
          9,
          0,
          18,
          0,
          14,
          9,
          27,
          0,
          38,
          17,
          10,
          9,
          21,
          0,
          9,
          23,
          0,
          10,
          0,
          16,
          29,
          0,
          9,
          18,
          9,
          195,
          35,
          0,
          18,
          9,
          25,
          0,
          16,
          9,
          0,
          24,
          11,
          0,
          9,
          0,
          99,
          17,
          40,
          30,
          8,
          0,
          125,
          18,
          10,
          0,
          0,
          23,
          11,
          0,
          22,
          8,
          16,
          32,
          495,
          0,
          10,
          0,
          17,
          8,
          24,
          0,
          15,
          8,
          0,
          32,
          20,
          15,
          10,
          44,
          0,
          27,
          9,
          0,
          18,
          384,
          10,
          10,
          326,
          0,
          27,
          18,
          9,
          0,
          267,
          21,
          10,
          8,
          36,
          0,
          19,
          9,
          0,
          27,
          237,
          15,
          0,
          15,
          9,
          25,
          0,
          9,
          19,
          9,
          37,
          0,
          17,
          9,
          27,
          0,
          481,
          17,
          9,
          49,
          24,
          0,
          0,
          9,
          0,
          17,
          9,
          31,
          0,
          17,
          0,
          0,
          9,
          23,
          116,
          289,
          140,
          9,
          17,
          0,
          9,
          34,
          163,
          0,
          16,
          25,
          10,
          0,
          9,
          0,
          17,
          8,
          27,
          0,
          17,
          0,
          9,
          36,
          19,
          10,
          0,
          27,
          10,
          0,
          18,
          9,
          46,
          0,
          19,
          217,
          441,
          11,
          87,
          25,
          0,
          9,
          16,
          35,
          9,
          0,
          24,
          9,
          16,
          8,
          22,
          0,
          0,
          16,
          0,
          0,
          31,
          9,
          0,
          16,
          0,
          8,
          25,
          10,
          0,
          17,
          38,
          10,
          0,
          26,
          17,
          9,
          9,
          21,
          0,
          0,
          200,
          17,
          356,
          29,
          8,
          0,
          9,
          17,
          0,
          40,
          9,
          23,
          9,
          410,
          70,
          17,
          0,
          32,
          9,
          17,
          0
         ],
         "xaxis": "x9",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y9"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          20,
          10,
          125,
          455,
          480,
          500,
          340,
          300,
          385,
          215,
          210,
          500,
          420,
          390,
          420,
          315,
          435,
          370,
          270,
          480,
          135,
          360,
          420,
          435,
          400,
          465,
          420,
          340,
          460,
          120,
          80,
          425,
          405,
          470,
          345,
          400,
          300,
          440,
          500,
          380,
          260,
          410,
          450,
          450,
          480,
          220,
          450,
          320,
          480,
          370,
          405,
          415,
          500,
          500,
          485,
          445,
          460,
          430,
          390,
          355,
          495,
          420,
          465,
          435,
          390,
          385,
          470,
          450,
          325,
          485,
          370,
          425,
          395,
          405,
          50,
          440,
          155,
          290,
          470,
          420,
          370,
          380,
          355,
          355,
          340,
          340,
          240,
          380,
          330,
          305,
          310,
          310,
          275,
          315,
          285,
          280,
          245,
          285,
          260,
          290,
          275,
          315,
          225,
          300,
          300,
          315,
          280,
          295,
          330,
          265,
          490,
          290,
          320,
          300,
          250,
          235,
          270,
          310,
          310,
          455,
          330,
          300,
          295,
          295,
          310,
          190,
          320,
          300,
          335,
          280,
          345,
          475,
          500,
          260,
          310,
          320,
          305,
          295,
          315,
          350,
          275,
          290,
          325,
          310,
          305,
          335,
          285,
          310,
          365,
          255,
          270,
          300,
          320,
          300,
          290,
          310,
          280,
          295,
          330,
          315,
          265,
          305,
          300,
          345,
          280,
          320,
          325,
          325,
          335,
          10,
          435,
          305,
          320,
          295,
          310,
          460,
          290,
          325,
          300,
          315,
          340,
          300,
          280,
          305,
          290,
          315,
          270,
          410,
          300,
          330,
          290,
          310,
          445,
          305,
          325,
          300,
          285,
          315,
          305,
          295,
          320,
          310,
          280,
          305,
          335,
          295,
          320,
          310,
          285,
          480,
          350,
          345,
          340,
          350,
          365,
          355,
          380,
          390,
          385,
          370,
          400,
          380,
          390,
          395,
          375,
          415,
          400,
          390,
          425,
          380,
          365,
          325,
          355,
          330,
          345,
          325,
          320,
          410,
          385,
          335,
          320,
          300,
          315,
          395,
          390,
          400,
          365,
          380,
          395,
          410,
          375,
          380,
          375,
          345,
          430,
          365,
          355,
          390,
          330,
          455,
          375,
          405,
          310,
          325,
          465,
          340,
          390,
          360,
          310,
          315,
          305,
          325,
          315,
          295,
          315,
          305,
          295,
          375,
          95,
          335,
          315,
          285,
          350,
          305,
          395,
          310,
          370,
          45,
          330,
          385,
          345,
          145,
          125,
          415,
          320,
          60,
          365,
          400,
          335,
          175,
          360,
          45,
          385,
          315,
          300,
          325,
          325,
          340,
          325,
          330,
          350,
          350,
          355,
          350,
          340,
          330,
          360,
          360,
          345,
          210,
          355,
          100,
          110,
          35,
          370,
          60,
          70,
          370,
          360,
          35,
          370,
          375,
          355,
          355,
          360,
          370,
          350,
          355,
          340,
          375,
          360,
          270,
          365,
          380,
          340,
          330,
          350,
          290,
          380,
          320,
          360,
          335,
          280,
          370,
          320,
          390,
          345,
          295,
          425,
          310,
          330,
          255,
          350,
          405,
          365,
          380,
          300,
          320,
          335,
          310,
          230,
          485,
          195,
          370,
          285,
          325,
          395,
          355,
          340,
          300,
          445,
          315,
          245,
          275,
          360,
          385,
          325,
          290,
          305,
          350,
          375,
          375,
          375,
          385,
          385,
          395,
          375,
          370,
          370,
          385,
          405,
          365,
          380,
          395,
          365,
          375,
          415,
          380,
          390,
          360,
          370,
          355,
          390,
          400,
          375,
          345,
          365,
          365,
          355,
          380,
          365,
          385,
          355,
          370,
          405,
          345,
          375,
          390,
          165,
          495,
          495,
          490,
          480,
          500,
          500,
          415,
          480,
          465,
          495,
          485,
          485,
          465,
          455,
          485,
          470,
          480,
          440,
          470,
          400,
          405,
          475,
          415,
          420,
          385,
          395,
          395,
          395,
          430,
          400,
          410,
          430,
          430,
          430,
          425,
          440,
          425,
          410,
          400,
          420,
          405,
          440,
          400,
          415,
          400,
          390,
          410,
          450,
          385,
          420,
          435,
          395,
          400,
          385,
          405,
          435,
          425,
          430,
          415,
          435,
          445,
          380,
          410,
          430,
          450,
          390,
          420,
          375,
          365,
          390,
          375
         ],
         "xaxis": "x10",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y10"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.17668140036133317,
          0.13158502776480327,
          0.913602585940464,
          0.09351215387535233,
          0.009028922472964163,
          0.472122575176048,
          0.3989769322753984,
          0.0005638470121471194,
          0.3221359376429537,
          0.6440462010743564,
          0.2825137975289682,
          0.0041163567188945635,
          0.015054508683232045,
          0.2398120467786177,
          0.11891956062116638,
          0.021483474167786527,
          0.21569913852152844,
          0.38820793912377927,
          0.12677254593379284,
          0.23422242655205705,
          0.08933334027391757,
          0.36914761975252075,
          0.502219383112168,
          0.5988764510512964,
          0.28825020618703107,
          0.5010063085178752,
          0.18469376812638083,
          0.07208311701368508,
          0.20692980778151573,
          0.1956243486240699,
          0.15591396906091895,
          0.03579215626219987,
          0.07492823837362163,
          0.15018415565474572,
          0.07005540163304,
          0.06073856003865589,
          0.14918229815925418,
          0.09102710060931962,
          0.01306028148334632,
          0.1687619641003985,
          0.06168622080873945,
          0.11596778735262611,
          0.007256746728667054,
          0.0026392367745679685,
          0.05070970040789198,
          0.10942485525356102,
          0.0038815651856069187,
          0.050147902881687086,
          0.17624268259690481,
          0.10363704973185037,
          0.035647439106766196,
          0.1216158307393172,
          0.2433889115331292,
          0.25735330470583667,
          0.1918802759758429,
          0.093636446507182,
          0.0011696836313633795,
          0.14373071945855093,
          0.04087945821724466,
          0.22501956362900233,
          0.08130105596976628,
          0.2701922059101109,
          0.3304728798031194,
          0.17819684005400496,
          0.03598891611872926,
          0.035176841472679424,
          0.08148429594497394,
          0.1317587164572712,
          0.030532772863675086,
          0.059186941325378516,
          0.13718594948826845,
          0.08530158995862551,
          0.029780442346103487,
          0.2136969148450148,
          0.4479099122539749,
          0.06893349229969868,
          0.11094908543404372,
          0.0005027340309045752,
          0.15693285113089872,
          0.02385822994725011,
          0.05673710673595566,
          0.10933186881444022,
          0.1305580815596914,
          0.10533945226221758,
          0.09876970488496699,
          0.0984588400413131,
          0.18068158447950966,
          0.16014974349153344,
          0.19849803713578237,
          0.11888648825831313,
          0.24445369673755163,
          0.23347478825600587,
          0.06345472384597542,
          0.2506885874967713,
          0.29588623368215106,
          0.2594044479035313,
          0.2523521900444002,
          0.2420472306270971,
          0.2897693942833424,
          0.2834343102863981,
          0.2204321499974159,
          0.19952974935454015,
          0.3171937927880314,
          0.20622460906232637,
          0.21930560126127685,
          0.20315537238862288,
          0.26004848213690984,
          0.18535543610800848,
          0.172647883025976,
          0.1899943162076544,
          0.2314516293019275,
          0.24223233866449584,
          0.20229881126691773,
          0.15939309965065313,
          0.3044110092502297,
          0.25892580017811323,
          0.2150430319652019,
          0.27397163119444445,
          0.27069144789215416,
          0.14670906206156642,
          0.18915132908946777,
          0.33277378412638237,
          0.2727095516673191,
          0.27340089369331283,
          0.3429943760010984,
          0.25084015432990164,
          0.27703753144747967,
          0.30630160225213443,
          0.23190804171831955,
          0.3422343256059678,
          0.17524655198371936,
          0.2442057445613054,
          0.21661775731097066,
          0.2947925625972008,
          0.26822568030414673,
          0.2689181336363511,
          0.19947932495431342,
          0.327572677174729,
          0.2911309952621127,
          0.25904888212663135,
          0.1402017879024977,
          0.22117331672382806,
          0.3144990101940274,
          0.2432877890133881,
          0.1838640913593657,
          0.27693103655327084,
          0.24057362417042488,
          0.1664123533460142,
          0.20190545844449165,
          0.2299236549196764,
          0.36077286768428085,
          0.1900746160249565,
          0.2543480596634139,
          0.209105563706654,
          0.020111253406634645,
          0.15653684773079676,
          0.19025222069277983,
          0.12728838387705177,
          0.3042257941346706,
          0.23053714973882428,
          0.28256792021966115,
          0.18114706659215823,
          0.17868824712467507,
          0.20528578260395183,
          0.14436232961130224,
          0.2555182177332379,
          0.2622297802855267,
          0.2667689848888556,
          0.31937087102503076,
          0.2547518965709726,
          0.04509184400013737,
          0.21478678198603218,
          0.2241264546682709,
          0.2939466703051136,
          0.2148436135793518,
          0.24243404832204157,
          0.27617679923631855,
          0.16384076764743882,
          0.0190355091524241,
          0.07596276083169241,
          0.24490453103977441,
          0.19051249453054436,
          0.1979435303407255,
          0.22318257237180333,
          0.26491383271294877,
          0.10642273341106367,
          0.16705336895384146,
          0.19222492458443652,
          0.12524628126345233,
          0.20967064558478277,
          0.22977761842773878,
          0.17736197517145955,
          0.15337746913339315,
          0.2521003486433405,
          0.17983051575029807,
          0.39643654221678576,
          0.2814795263623535,
          0.2026410918726689,
          0.0006680897531336442,
          0.3043976043211016,
          0.13373711507255853,
          0.23468992380706255,
          0.257676041729184,
          0.21212651295001794,
          0.24234077061859333,
          0.2799378737267619,
          0.22702230088478742,
          0.04923737682529418,
          0.18472623811365613,
          0.2567098661348072,
          0.15495400190394354,
          0.15319472684090876,
          0.15074420973609926,
          0.15833389588615623,
          0.1870100117680451,
          0.08953923506444944,
          0.13858206400757805,
          0.1076052096653588,
          0.12003326775665346,
          0.10647915264976528,
          0.13359771350502966,
          0.14019006388824004,
          0.08395951006392777,
          0.08660503867461794,
          0.11567999537256056,
          0.07226505136052869,
          0.06265458188656747,
          0.16575690392366582,
          0.5175018807159101,
          0.028838400471877017,
          0.09539945309147921,
          0.1479549899308707,
          0.1252447534112712,
          0.14854043050109217,
          0.16597024079797396,
          0.1980278250672745,
          0.10306997020688397,
          0.04000989395206785,
          0.14334624860592513,
          0.019204432997009843,
          0.16992691520342917,
          0.20988011248472457,
          0.3292798732587537,
          0.36312106505123687,
          0.30313634039104564,
          0.3594990116957632,
          0.9156931940386867,
          0.18941927771692357,
          0.12035493832635775,
          0.36672704008881446,
          0.34230387139667023,
          0.3920199996319459,
          0.83792941959159,
          0.4117254532835532,
          0.21901677177951717,
          0.0020131806706350005,
          0.1527049200754613,
          0.29040627532217306,
          0.24101110016654875,
          0.05463227328219635,
          0.17684014648583068,
          0.2637376051428995,
          0.20423710801066822,
          0.0817090113279563,
          0.34417457478655333,
          0.13678471617656085,
          0.10915955362344985,
          0.22870217423371375,
          0.1897831171679617,
          0.19356836148318524,
          0.16708358502856485,
          0.20863479374407007,
          0.17777052877783986,
          0.1789115521059387,
          0.15452373853142257,
          0.18998440276661577,
          0.13526873707436698,
          0.15614322565576247,
          0.21899779260282032,
          0.1782677637441045,
          0.11977149649857552,
          0.19763263495604247,
          0.3770149823161018,
          0.4136550504314719,
          0.31080994800954903,
          0.16648609082398408,
          0.23479461489510856,
          0.13914339597038614,
          0.0898490508300077,
          0.1295558338021007,
          0.1463520018346043,
          0.10538718813350338,
          0.4361560818495976,
          0.27898929644585274,
          0.2482855381870737,
          0.33230252245539493,
          0.4856224074866434,
          0.13712563861417632,
          0.07288076486418867,
          0.21037279806711948,
          0.16530244729831217,
          0.22224958572679215,
          0.11142250410469531,
          0.35189711590227907,
          0.3138065981937931,
          0.18987012625938904,
          0.19131616215320735,
          0.24467845556864548,
          0.17598211062914615,
          0.1748077156217706,
          0.15666753885860543,
          0.1606819582911032,
          0.14876508266319208,
          0.1902204557153022,
          0.17083655834758835,
          0.20407940146460674,
          0.1410496144219892,
          0.15886261070135457,
          0.14023930506228907,
          0.18528603945205896,
          0.13014866825404875,
          0.1254238672716365,
          0.12721008253815128,
          0.12516716639974387,
          0.14711614006493057,
          0.14174151842612873,
          0.11974742395365497,
          0.14741515442087985,
          0.3786574946186514,
          0.16123067334502972,
          0.11985135831133756,
          0.13718700113314197,
          0.10737683205319622,
          0.05290019746931092,
          0.45568543316224164,
          0.17390336133966483,
          0.0983750208426758,
          0.09189748475802303,
          0.5258959609344256,
          0.1724158169740299,
          0.35642580658671735,
          0.20522737097629798,
          0.07249153382405057,
          0.10597895470791478,
          0.1444857942152481,
          0.029657701271299616,
          0.22613399634703263,
          0.18438500903792907,
          0.16152133554358059,
          0.20176233428591106,
          0.10202497972701141,
          0.1493626080867401,
          0.40463409946329,
          0.3237766378985528,
          0.17537079996754557,
          0.2885601820582483,
          0.686220208811904,
          0.2257641552813076,
          0.13187072124840032,
          0.19862613920416008,
          0.39058536474376426,
          0.043831017598937594,
          0.07226102083527763,
          0.1560475996126038,
          0.42261739146671606,
          0.3703583606355775,
          0.26032405165851763,
          0.12273586670139469,
          0.9975959522361048,
          0.1839568589720777,
          0.21423829051762702,
          0.10407863613658284,
          0.23513100673478332,
          0.15218298243279224,
          0.1812968054376742,
          0.45843083783851396,
          0.2957391027449086,
          0.13649017457853405,
          0.16748584774414096,
          0.012228239606809927,
          0.2142531171495371,
          0.3473886639038759,
          0.245009570178846,
          0.08880222739586796,
          0.06243107681801581,
          0.425400355645025,
          0.1934668449553769,
          0.16291417852350681,
          0.2686176266827675,
          0.11861299546550949,
          0.33107385768725933,
          0.14170876550505118,
          0.33373819022470513,
          0.3363766289209027,
          0.3192945898230074,
          0.3408001094865294,
          0.36575621337455566,
          0.3795839280768579,
          0.3486304273689617,
          0.37679011104368515,
          0.3870672159212267,
          0.3132000507869724,
          0.3600785812229612,
          0.13497281140197992,
          0.10924414838479433,
          0.3263212827800344,
          0.39727251143662223,
          0.3384767988031069,
          0.35404504591863,
          0.13683307161079164,
          0.29968369110156523,
          0.03197153972887422,
          0.37911424920849557,
          0.0858063095195983,
          0.14396980985795624,
          0.11374144332601,
          0.15743707577849123,
          0.15375994026288947,
          0.12249941947921657,
          0.09430642358104671,
          0.1575707924198102,
          0.002578884547478769,
          0.3188694011998149,
          0.1370620055591674,
          0.16909974987336776,
          0.40431479134278986,
          0.11609510211040931,
          0.06459415162920953,
          0.3419023444388201,
          0.44114837169370463,
          0.4533843580738168,
          0.40872493747144145,
          0.4200402308979201,
          0.48941117417029656,
          0.37334373059911585,
          0.43971555417992836,
          0.38278918255818173,
          0.4784223111381582,
          0.4421482278066167,
          0.045775694419472115,
          0.3548431148789036,
          0.17133869803333784,
          0.3940693583965638,
          0.15060641954577492,
          0.29993754102086306,
          0.5354388755374224,
          0.32798844017629214,
          0.672391181442081,
          0.42974588677200287,
          0.39383113846221857,
          0.4290623537908563,
          0.4601009683652987,
          0.3644931038607279,
          0.4119785824796522,
          0.4656720031974771,
          0.46273669024070396,
          0.17732306677405282,
          0.48740033703104,
          0.5038070229224714,
          0.4894117251598074,
          0.4737506588611171,
          0.5035314506732268,
          0.5044464795069025,
          0.4941963053058755,
          0.47115908482537333,
          0.5072542820500179,
          0.5378449430392158,
          0.44465146036662295,
          0.4940868481462815,
          0.5168380813875243,
          0.5499825693394665,
          0.4716224712366672,
          0.4331911613140172,
          0.5060955001526449,
          0.45839808057876613,
          0.4776498317118943,
          0.4282515511357844,
          0.44538084686908747,
          0.5540528692065865,
          0.522864728972355,
          0.4620933861507906,
          0.4857515624142177,
          0.44955761443102205,
          0.5057130100373368,
          0.5599188745850596,
          0.5962834622168038,
          0.5568131063287681,
          0.42181225498406194,
          0.5136337393717221,
          0.48658261731720814,
          0.5592490617803696,
          0.5251501844491939,
          0.5680912865956373,
          0.5821941563143126,
          0.6151059767989773,
          0.5380143334656552,
          0.4722761510850056,
          0.39706969149204857,
          0.438917872499998,
          0.49734683564327076
         ],
         "xaxis": "x11",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y11"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          2.749217162380866,
          2.6981005340139887,
          4.766112898831798,
          0.8084330541961959,
          0.04830223610325324,
          0.05723293938418124,
          1.2586840182459347,
          0.14823564560792188,
          1.3553024871268937,
          1.8208878340125199,
          2.0120003222547718,
          0.5924999861874596,
          0.09496068781222433,
          0.027596547537860977,
          0.8004838377910559,
          0.005044278267082619,
          0.6742041322880156,
          1.0834752241589507,
          1.695993574738367,
          0.536369471561255,
          2.2764764950819503,
          1.1816131390693498,
          0.4478516419400229,
          0.37036421417710486,
          0.4096899581394158,
          0.4061816486492399,
          0.9349623154068951,
          0.851340680237374,
          1.4762034293341464,
          0.9281365889320669,
          1.1134590576246999,
          0.32725214320777407,
          0.33539746996900455,
          0.03678939439261438,
          0.6809425374088,
          3.0958710716965854,
          0.255570928884599,
          0.9457712579118638,
          0.21159168895198188,
          0.6764817027815124,
          0.20354165009142502,
          0.545136822009628,
          0.43920429417740203,
          0.0176953592468093,
          0.30858931303559217,
          0.871912145432317,
          0.6226729712963195,
          0.1694172354508062,
          1.3653968305497524,
          0.4969469115066075,
          0.014110273731066714,
          0.44879347063610653,
          0.7433807263636762,
          0.7494450583889963,
          1.0564538017050211,
          0.2322232402396433,
          0.6952774434717373,
          0.9615203037658789,
          0.5718949884043096,
          1.243499682725161,
          0.1574803906591009,
          0.397976029157703,
          0.4538450654764631,
          0.7883647022461272,
          0.3737646792585824,
          0.16583389927248626,
          0.2914080583665652,
          0.005778335969591375,
          0.556586192256318,
          0.3397275305120982,
          1.0024717120456312,
          0.7463445944856895,
          0.4232349960896449,
          0.13129283152468307,
          0.5655135703010049,
          0.8310133669469144,
          0.3109367240220147,
          0.11127404450374315,
          1.1434866272260928,
          0.6225019811136354,
          0.428882707594188,
          0.5037803380643738,
          0.28195609247882997,
          0.26893588837923305,
          0.09721986414489145,
          0.09633004177053414,
          0.20776349539307945,
          0.5162271280911654,
          0.6626478883106773,
          0.9119559025955679,
          0.8901586261578441,
          0.8909725845548656,
          1.0742348614990334,
          0.8346497294425419,
          0.8128339586735718,
          0.8032378156443282,
          0.7843033190800361,
          1.0070717047037263,
          1.2498858848904235,
          0.6914426243147704,
          1.153364936770646,
          0.8938875711561692,
          0.9754363124689487,
          0.8044416777857577,
          0.8666501297944706,
          0.7947445071416279,
          1.088140707786165,
          1.3243583067718994,
          1.310783046095909,
          1.419803442278109,
          0.6345264422204906,
          0.7464782073281211,
          0.9161151890616623,
          1.2106777908035138,
          0.5217519880163107,
          0.9944537042269209,
          0.8336945809317998,
          1.081490507279175,
          1.4868692634658993,
          0.6129625283253216,
          1.0679473603252145,
          0.7836245198275714,
          0.9425205127180785,
          1.1770890894159198,
          0.9002569002481497,
          0.6904936448780676,
          1.0065188661599214,
          0.4667661725962851,
          1.111110063815111,
          1.3062984320883337,
          0.634691888952148,
          0.7075006952824888,
          0.767925286718436,
          0.8890388385165517,
          0.5506812540431445,
          0.5424614844508855,
          0.9693377237981379,
          0.39598087967129425,
          0.5372565447373807,
          0.8601481447790258,
          1.03698868973178,
          0.770086260610427,
          0.6115241490086005,
          0.714543524361391,
          0.4782349814109363,
          0.6878325648624358,
          1.1721162342972222,
          0.9507578882864456,
          0.353604161635593,
          0.7895249544470513,
          1.0737453866587157,
          0.6076001862512522,
          0.5602341499858772,
          0.8481721216890087,
          0.6902711997984814,
          0.23753246156389696,
          0.43763866608715235,
          0.935775594095748,
          0.643545945906215,
          0.7867347557372181,
          1.2420979729570945,
          0.4747060877138816,
          0.36330019595542684,
          0.4956191201820739,
          0.6064331306111542,
          0.735914166915784,
          0.706477920831927,
          0.7414273115714721,
          0.8631651470379007,
          0.5925832122343451,
          1.0047259484839968,
          0.31175756497193885,
          0.14571764183126473,
          1.9832144568634344,
          0.27680828636317334,
          0.705122692968297,
          0.39638250157498706,
          0.7887227045565258,
          2.455039316184349,
          0.5388863142923868,
          0.031241842345695478,
          0.4960559381392161,
          0.6458757183345468,
          0.2910850293209999,
          0.9351814776200781,
          0.4662148538971199,
          0.835724652961733,
          0.6901576497854816,
          1.042454306844694,
          0.5771600779820154,
          0.3653018836646696,
          0.4824339897895702,
          1.638640763905094,
          0.7158173596347503,
          0.48630287454046317,
          0.21186192017630118,
          1.1424909862346349,
          0.828330722615938,
          0.5950219973526635,
          0.3739006975529982,
          0.9428733931742839,
          0.8764450229987559,
          0.7698490800661362,
          0.6798073191929217,
          0.8987623286877073,
          0.9960726850683513,
          0.5496246792979563,
          1.0894115808136797,
          0.13699703906635508,
          3.231038998779977,
          0.7955209143551796,
          0.7532023554263942,
          0.7151865110929473,
          0.6220328115046229,
          0.7807039098200867,
          0.5130873591502731,
          0.4208931991837074,
          0.2426992798764932,
          0.2661118574627397,
          0.2011553162728601,
          0.3252695553376158,
          0.8268942139761695,
          0.6584605232656248,
          0.659302580908541,
          0.4325057998477156,
          0.5815090588831606,
          0.7337510859042237,
          0.10009326834128818,
          0.41461671575101944,
          0.6332826246256333,
          0.808696114783109,
          0.9096694916771184,
          0.742248361073252,
          0.8721847036377578,
          0.026398400797590177,
          0.9284414550383955,
          0.5298309062419799,
          0.31005104096493524,
          0.7023692897769808,
          1.034016305260546,
          0.8463447541831074,
          1.0098440912527376,
          0.9405263544267655,
          0.8108607619064578,
          0.7492799999066665,
          0.6145852606743305,
          0.8085735611281759,
          1.3605057502951574,
          0.4147627200988209,
          0.6556559345501773,
          0.5319280291804067,
          0.515269369803175,
          0.24629947049879727,
          0.4521652242217738,
          0.5729472982243216,
          0.3586785369539395,
          0.16225020043335608,
          0.7132332312962838,
          1.2068439612311908,
          0.8831457246312475,
          0.5845942814960233,
          0.6421243327451731,
          0.4922031774857398,
          1.0969359930820608,
          0.3187040330360263,
          0.7596508462196684,
          0.9556128748509636,
          0.8455678977713083,
          1.5946584782856026,
          1.292655288973198,
          1.079888161827171,
          1.6174763202891684,
          1.1632177006493891,
          1.3467082469406966,
          1.4820366295509446,
          1.194890187712644,
          1.8624303312800525,
          1.1549185239994486,
          1.4630388144488142,
          1.2419844825779598,
          0.9975730037773519,
          1.1135167234767906,
          1.570301126272946,
          0.9186530698279255,
          2.177815526062727,
          2.772291738955607,
          1.3100928703100005,
          1.036462963576902,
          0.9940279427901342,
          0.8439458735854385,
          0.7958147054892434,
          4.631246690665893,
          1.0374838363309935,
          1.810515744245055,
          0.10907223191328558,
          0.6696567331260878,
          0.9293856233959119,
          0.5498870211636626,
          0.20011371849607557,
          0.4391753921861713,
          0.7642516042639639,
          0.8730759197713918,
          0.6228322018109921,
          1.0468256761834356,
          0.3469843436949646,
          0.7570927284954254,
          0.7880234687275721,
          0.9332158721836087,
          1.1767648359962473,
          1.1986596053459169,
          0.01884598643476665,
          0.25857847859266986,
          0.022593367332130385,
          0.05546494174594967,
          0.0052695767268836,
          0.16455830866727697,
          1.7270061505257428,
          1.430979367872213,
          1.7433285779671037,
          1.5112037993169498,
          1.08316565883607,
          1.127625553364406,
          1.1777464188746014,
          1.020477265391678,
          1.0890542355058588,
          1.1475039074522553,
          1.2983509405069047,
          1.078825954390164,
          1.2830539961300402,
          1.2074421294860522,
          1.068553784696065,
          0.9367845873337115,
          1.1152280230600773,
          0.9724373813869649,
          0.8575162192015808,
          1.3438031210559114,
          1.953688494296242,
          2.154732671324502,
          1.429417566981435,
          1.0304182700151518,
          1.1283274819005589,
          1.239049939625161,
          0.8803971437641809,
          0.109625990869252,
          0.9536802673917459,
          1.7611345070839557,
          1.1413086623587254,
          1.0024993411372363,
          1.3843615740891115,
          0.8326357335956224,
          0.6891652876606343,
          1.2379539762349634,
          1.9005786462931755,
          2.097438892791105,
          0.8999294740422787,
          1.7255903572740148,
          1.5604676525271153,
          0.19927182755317552,
          0.5385797826391339,
          1.0673412494475607,
          1.6590979540245145,
          0.7766313283867338,
          0.4112502794269988,
          0.9721042653925117,
          0.6882112539427042,
          0.008060929142955572,
          0.8289755349717768,
          0.5739194166820643,
          1.0773690529011049,
          1.1631899646582553,
          2.062491687604142,
          0.2780961129882993,
          1.852752804520542,
          1.9532086929198518,
          0.8695130129427123,
          0.9858034516367302,
          0.09246058088173725,
          0.7555788996768114,
          1.3575748606554157,
          0.45948835597855836,
          2.21277561232131,
          0.620984550962544,
          0.9051085785183752,
          0.7332232695392604,
          1.6906310262570667,
          1.242512286568485,
          1.4597453244909575,
          0.16215528384171302,
          1.0399073750176349,
          0.34658849364871935,
          0.5033231724666085,
          0.38092870661532746,
          0.38444302799771934,
          0.22124947163657022,
          0.2450137521915663,
          0.24002455358061156,
          0.4547530252405061,
          0.14675092067607767,
          0.14401575568808545,
          0.12518527937500348,
          0.0000836503149915166,
          0.3808924339126987,
          0.2894697519617897,
          0.19909111994016984,
          0.12229751835020161,
          0.2992495430166132,
          0.4769219217764169,
          0.2375242258007783,
          0.4105231866396034,
          0.3295160124313187,
          0.08097481569417886,
          0.5144945642546122,
          1.1429558397811828,
          2.303661125282903,
          0.00011221366877113559,
          0.2015187404284933,
          1.5687002267031263,
          1.381801579802935,
          1.8419877865923342,
          2.0184251250506726,
          1.297916969963996,
          2.7266427270673783,
          2.4194330786728204,
          1.323193475968198,
          1.209461790454628,
          0.12425268943261533,
          3.078391497323703,
          1.4293830157413656,
          1.455952048791202,
          1.6780373724821627,
          1.576001672247564,
          1.6647092620492088,
          1.6610373838943489,
          1.9425391282459847,
          1.5986771062755945,
          0.37112441191327783,
          1.919734912050462,
          1.91498995858112,
          1.840091834695434,
          1.748677700010777,
          1.551824546972363,
          1.8807628438814614,
          1.6759694995963024,
          1.555123670768693,
          1.684578833922342,
          1.768237873358033,
          1.8164667754849058,
          1.5656850680417729,
          0.5441384392468354,
          1.5221603781385886,
          0.5429834746700338,
          1.7860599839314177,
          1.9879893272586093,
          2.1220542600028702,
          0.5911982968628058,
          2.5803315142438237,
          0.6402435906577091,
          2.10503360161923,
          2.2809266397140653,
          2.032920547493833,
          1.8940780850762136,
          1.7700128286299404,
          2.3331893450283956,
          1.9844272971234778,
          2.1581212871410287,
          2.06105355474409,
          2.2031199250178415,
          2.0101276978073663,
          1.74735434392878,
          2.1021685175368705,
          2.20951898991592,
          2.2894952035082645,
          1.7252585811445886,
          1.8314376786287747,
          4.390443726249137,
          1.9199823181227387,
          2.327171153158762,
          3.8079321386596328,
          1.6412373529323812,
          2.143765367736446,
          2.5887409859255146,
          2.4501836525448977,
          1.7981784663993259,
          2.0485288305830567,
          0.5159611339146439,
          0.48826550879003133,
          2.2493858544233922,
          0.4264735149392428,
          0.524342160907104,
          4.8143581771709485,
          1.505575211736158,
          0.3313810232008661,
          2.3921537259684924,
          1.6651120858245467,
          0.5744064112949149,
          1.9128949821715222,
          1.7976417392441149,
          0.4582994336429656,
          1.377266254458147,
          2.5135953303809684
         ],
         "xaxis": "x12",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y12"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.8391268998756262,
          0.8384090290478076,
          0.9874188903547395,
          0.5503861112186494,
          0.5065896071904618,
          0.5001952017791316,
          0.638145839512903,
          0.6533676066838329,
          0.6203538805551276,
          0.501170563141212,
          0.739013540248122,
          0.5542541483470574,
          0.5808893289142647,
          0.5843517282049606,
          0.6571580651481883,
          0.5027292876886564,
          0.5871319248742302,
          0.6879619031245297,
          0.573039207150036,
          0.7002982254737011,
          0.6132678622291264,
          0.6886496250940006,
          0.5517973584943614,
          0.5586740000560421,
          0.5355036556887023,
          0.6008966970449205,
          0.5282116926663798,
          0.525334087331987,
          0.5973329060181136,
          0.532189491987094,
          0.5759335895652518,
          0.5345578757825197,
          0.5723569975135155,
          0.6240653287601755,
          0.5748295655645715,
          0.5209474308429427,
          0.7964863498961815,
          0.5545944687755313,
          0.6454090401612174,
          0.5004654809287296,
          0.6139304696516282,
          0.5518568505361754,
          0.525689335656851,
          0.5227672692123647,
          0.570492172725747,
          0.5989995908421104,
          0.5000332351173018,
          0.539660781250809,
          0.5192035601191084,
          0.5652246973357207,
          0.6325948471328068,
          0.543277532679266,
          0.587005770973366,
          0.5849019613572705,
          0.5145624668961253,
          0.5557266598205487,
          0.6010841207032018,
          0.5818394208788348,
          0.6528646194019916,
          0.5387799435564415,
          0.5118017363162963,
          0.5524468236615281,
          0.5643301395983217,
          0.5358726815783836,
          0.5901895533700969,
          0.615676598497345,
          0.5885059229628221,
          0.5161214118439114,
          0.6313730245268122,
          0.5653670921957025,
          0.6640346761127407,
          0.5468608798937488,
          0.5313730434404595,
          0.5725235868539632,
          0.6046593954466568,
          0.5894493346195435,
          0.51012635028062,
          0.5265214887557811,
          0.5541651706888973,
          0.5776795961520191,
          0.5411956064281873,
          0.5637416121033391,
          0.563814633390657,
          0.5639527142223846,
          0.6226163533750867,
          0.5287715438871721,
          0.6043051423098943,
          0.6226993669919783,
          0.5757901185847916,
          0.5439886056665619,
          0.5081610735614605,
          0.5069581883238962,
          0.5233075354219932,
          0.544849466412835,
          0.5447271821004331,
          0.5474469437486429,
          0.5117915315660707,
          0.5038133559497314,
          0.5297341857359618,
          0.5480827941538589,
          0.5212342602810116,
          0.544510209358754,
          0.5374281166254927,
          0.557017320902077,
          0.556487365902615,
          0.5183768831124896,
          0.5474917107796456,
          0.5361032700554857,
          0.5001161000540493,
          0.5244339823317133,
          0.5364964216980868,
          0.5588818960308941,
          0.5303094273225931,
          0.5147093000330795,
          0.5481318742292343,
          0.5404965301686333,
          0.5685049435349091,
          0.5570685101691655,
          0.5823044575675224,
          0.5111797418087576,
          0.5304514935505432,
          0.5587757355015744,
          0.5586693758005612,
          0.5646038732282053,
          0.5533279125992562,
          0.519720460763633,
          0.5573183949971409,
          0.5705210106269067,
          0.5349118300472421,
          0.5079537926157309,
          0.577268712622058,
          0.5432547212371166,
          0.5554821261110083,
          0.5970466634956187,
          0.526075383312836,
          0.5273946920897674,
          0.5003334745996265,
          0.5241109901360211,
          0.5153138949075132,
          0.5373509516543816,
          0.5630265646500123,
          0.5484248658337575,
          0.584832698723333,
          0.5360465804549953,
          0.5187349990120218,
          0.5343949315692096,
          0.5446104955582063,
          0.5070489719425385,
          0.5609806263202401,
          0.5268749039598298,
          0.5718235394906204,
          0.5169895738415854,
          0.5156289110673236,
          0.5368376562279861,
          0.5496593969012878,
          0.5260178682802742,
          0.500546611205402,
          0.5415207705416921,
          0.5132925999101059,
          0.556200909262427,
          0.5323083442403738,
          0.5186788284535033,
          0.5197397787591281,
          0.509833089161573,
          0.5472496555977365,
          0.5345564023156412,
          0.5341606711509158,
          0.5658091094460412,
          0.5377616614101621,
          0.7415420766444714,
          0.5522342476629515,
          0.5302883952075357,
          0.5285472620571924,
          0.5419563905215883,
          0.5726549018485142,
          0.5561171381368648,
          0.5290636193447638,
          0.712559550937911,
          0.5382773073924114,
          0.5588275438906957,
          0.5473028548888654,
          0.5207237739239565,
          0.5226779531224006,
          0.53363258291755,
          0.5252246786829002,
          0.5469732820307387,
          0.7924602029464155,
          0.5130327550779127,
          0.5347441664542855,
          0.5647509276525292,
          0.5795008078785187,
          0.5195339859574262,
          0.5195155263957234,
          0.5072537167968878,
          0.5407194586795868,
          0.5262391067621929,
          0.5514219034175462,
          0.5310893521302763,
          0.5001652472951511,
          0.5162918935818765,
          0.5424132310460824,
          0.5098675306245453,
          0.6466499320486537,
          0.5228082263165504,
          0.6679458769343087,
          0.8971174296293818,
          0.534765441570343,
          0.5099301961124358,
          0.5555807357000143,
          0.6126121538601874,
          0.5188209786313331,
          0.5174091039108232,
          0.5275429126882542,
          0.5171308894463056,
          0.5420600312439035,
          0.5322749591806765,
          0.5666607512586797,
          0.5655277836517807,
          0.5711833071012741,
          0.5651481232945131,
          0.5495695276360951,
          0.5588168863850448,
          0.5870168362292099,
          0.5928203189073409,
          0.5841539529948823,
          0.5684579794179603,
          0.5769549751049318,
          0.5462188624040863,
          0.5382215954277817,
          0.5553118859845922,
          0.5313895629851241,
          0.5619885765801446,
          0.5646071583845538,
          0.5765488640940762,
          0.5470983280209839,
          0.5550328105163123,
          0.5949449922106336,
          0.5252408102204364,
          0.5396466537677269,
          0.6364554727790718,
          0.5000146412491189,
          0.5613523281957908,
          0.5705784078682131,
          0.5493684387514872,
          0.5486444700760219,
          0.5321450295329502,
          0.5195700592026341,
          0.5419945960138378,
          0.5811424402097959,
          0.6854917426816498,
          0.6102298612613218,
          0.5900511429262458,
          0.608379443916427,
          0.5138925283706621,
          0.6000120632707683,
          0.5253185425202757,
          0.5332588682711231,
          0.549140784365918,
          0.5392840835077888,
          0.5099656702088439,
          0.5698678342493315,
          0.5231886789015541,
          0.5571853155896472,
          0.5368853603052656,
          0.5787043675976488,
          0.54941817698787,
          0.5890600736310865,
          0.5154794283415394,
          0.5615894810219049,
          0.5632199891178044,
          0.5697556740382382,
          0.5596014665506788,
          0.6326441705187609,
          0.6242777127809973,
          0.6162983806231607,
          0.633620189408723,
          0.5951920338442888,
          0.6081102422593029,
          0.6224700021515498,
          0.5798282327298946,
          0.640096252233623,
          0.6014913868042638,
          0.7123529303534778,
          0.5523440225965836,
          0.5738872138839533,
          0.5867804691692756,
          0.543110053357288,
          0.5620490015272609,
          0.5641927014551485,
          0.5677532710223696,
          0.5534297058611787,
          0.5854036441692182,
          0.5735925698352984,
          0.6130787045976854,
          0.66189931570148,
          0.6459607902443818,
          0.559378681200603,
          0.7636671819661973,
          0.5081281215733515,
          0.5459815176856258,
          0.5275606067338722,
          0.5538490086933594,
          0.6688311341906557,
          0.6026405251616588,
          0.8415002636665916,
          0.5805044935156658,
          0.5621782221076325,
          0.542534786317215,
          0.5762647144791538,
          0.6279450463703858,
          0.5217780906850982,
          0.5771204223288919,
          0.5063309360355646,
          0.5198221645138739,
          0.580318658136653,
          0.5912686117040656,
          0.6580899747063379,
          0.6457643563192975,
          0.6286506643302108,
          0.6347903066192724,
          0.6142301614825284,
          0.6071896575278755,
          0.6056440807674236,
          0.6182998778359149,
          0.6086163732858537,
          0.609535459521988,
          0.6057350656917471,
          0.6159527049825235,
          0.6253620106829123,
          0.5943531186295218,
          0.6192736227150514,
          0.6049049318737894,
          0.6174469264940462,
          0.6145141096851445,
          0.6380508820770819,
          0.6345997813565343,
          0.625669320970335,
          0.653736998956946,
          0.5966342293476035,
          0.6270446039905293,
          0.6472560317415227,
          0.6152851730181519,
          0.5940585804304168,
          0.9980639127854269,
          0.5818130203115239,
          0.6709798608715154,
          0.6020191335609549,
          0.6789787837676109,
          0.7112470969216472,
          0.6383505374081672,
          0.6783755691888996,
          0.7225135072904281,
          0.6497420516467022,
          0.6225134681803689,
          0.5691778087255066,
          0.6634790493218516,
          0.6537365252627452,
          0.5031004324268137,
          0.527869531170581,
          0.9476213855531406,
          0.7003442470837631,
          0.5859664607439655,
          0.5463896311403943,
          0.7597411668371109,
          0.5156303925508091,
          0.5717403350389288,
          0.6592580387880288,
          0.5377006349343301,
          0.6126939272746206,
          0.5966005591738086,
          0.5220829080212843,
          0.5541369926865753,
          0.6315551461739761,
          0.577393957893666,
          0.5005516268153352,
          0.5311414806824268,
          0.545555909780188,
          0.7405658144718987,
          0.5636370842523305,
          0.5909550858743601,
          0.5115177721747464,
          0.5508474410233362,
          0.617048523337726,
          0.6857953923636435,
          0.524674635264781,
          0.5377596916081928,
          0.5698799372552886,
          0.6039532167731974,
          0.788909719807389,
          0.6360323566726372,
          0.5151625616641339,
          0.5168013427676376,
          0.6989471545567193,
          0.508285883290043,
          0.5117007568137777,
          0.5076394804388692,
          0.5180111993785399,
          0.5013112473199781,
          0.510080717080228,
          0.5113116096265542,
          0.5083519478537231,
          0.5036703687872737,
          0.5206275730775767,
          0.5030790553708047,
          0.7269293926969175,
          0.5210825216426387,
          0.51758899512184,
          0.5017172914629434,
          0.5270606380454002,
          0.6233534987968252,
          0.5291457947928458,
          0.6515435757879275,
          0.5002866096044071,
          0.6137229776258013,
          0.5986348017167458,
          0.5181135261074012,
          0.8406945181625209,
          0.6727391314181843,
          0.7991712492229511,
          0.9615300924921812,
          0.860038548370866,
          0.6871308102943007,
          0.6413179760535505,
          0.5879694451557956,
          0.772745714784584,
          0.7484191534036269,
          0.8203859315630622,
          0.7698184896849174,
          0.6286601592098539,
          0.8031183963139876,
          0.8821398139902554,
          0.8467876267097518,
          0.5132053378867427,
          0.809246577044009,
          0.7354112494432896,
          0.7699092204897281,
          0.8220697291488875,
          0.8187451760980051,
          0.860012588438951,
          0.8227473952312717,
          0.7500932839601757,
          0.837658449714763,
          0.8059180093404705,
          0.8273583061708762,
          0.8158969195498614,
          0.804802652754722,
          0.781472472124534,
          0.8069383358408556,
          0.810239011031228,
          0.8102548708735572,
          0.8330570178973189,
          0.7917062579893016,
          0.8144902062560792,
          0.8287711232060306,
          0.8268276397408365,
          0.8278278959198442,
          0.8341199431531566,
          0.8404353004405407,
          0.8415255677170282,
          0.8458031178248968,
          0.8422329367093615,
          0.830243808176751,
          0.8216017288713625,
          0.83171073221273,
          0.8393356299928464,
          0.8566862929275029,
          0.8240459955982647,
          0.815712347997652,
          0.7970367483165639,
          0.8518936711301689,
          0.8389076253467019,
          0.8524415854443773,
          0.8322073036018862,
          0.8159259274881009,
          0.8464059539813259,
          0.7834458275003819,
          0.8259012992610504,
          0.8422439710275806,
          0.7965719288859432,
          0.8025728130510824,
          0.8266896449033837,
          0.783576206951414,
          0.8631049838599878,
          0.8115115726624401,
          0.8405604635736912,
          0.8359190519723804,
          0.8391598938281017,
          0.8501732522549268,
          0.8217379480080226,
          0.8742622829452188,
          0.8506340279554065,
          0.8382299133813017,
          0.8292540141547676,
          0.6574114349779923,
          0.8707588634367288,
          0.8450976766973956,
          0.6951020302211487,
          0.8110026168354595,
          0.8610278088434911,
          0.8301393905141536
         ],
         "xaxis": "x13",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y13"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Slice Plot"
        },
        "width": 3900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.06272189349112425
         ],
         "title": {
          "text": "fs_mb__threshold"
         }
        },
        "xaxis10": {
         "anchor": "y10",
         "domain": [
          0.7029585798816567,
          0.7656804733727809
         ],
         "title": {
          "text": "xgboost__n_estimators"
         }
        },
        "xaxis11": {
         "anchor": "y11",
         "domain": [
          0.7810650887573962,
          0.8437869822485204
         ],
         "title": {
          "text": "xgboost__reg_alpha"
         }
        },
        "xaxis12": {
         "anchor": "y12",
         "domain": [
          0.8591715976331358,
          0.92189349112426
         ],
         "title": {
          "text": "xgboost__reg_lambda"
         }
        },
        "xaxis13": {
         "anchor": "y13",
         "domain": [
          0.9372781065088754,
          0.9999999999999997
         ],
         "title": {
          "text": "xgboost__subsample"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.07810650887573964,
          0.1408284023668639
         ],
         "title": {
          "text": "fs_mb_xgboost__max_depth"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.15621301775147928,
          0.21893491124260353
         ],
         "title": {
          "text": "fs_mb_xgboost__n_estimators"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.23431952662721892,
          0.29704142011834317
         ],
         "title": {
          "text": "knn_imputer__n_neighbors"
         }
        },
        "xaxis5": {
         "anchor": "y5",
         "categoryarray": [
          "distance",
          "uniform"
         ],
         "categoryorder": "array",
         "domain": [
          0.31242603550295855,
          0.3751479289940828
         ],
         "title": {
          "text": "knn_imputer__weights"
         },
         "type": "category"
        },
        "xaxis6": {
         "anchor": "y6",
         "categoryarray": [
          "project.packages.modelling.transformers.scaler.NotScalerTransformer",
          "sklearn.preprocessing.PowerTransformer",
          "sklearn.preprocessing.QuantileTransformer"
         ],
         "categoryorder": "array",
         "domain": [
          0.39053254437869817,
          0.45325443786982245
         ],
         "title": {
          "text": "scaler__transformer"
         },
         "type": "category"
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0.4686390532544378,
          0.531360946745562
         ],
         "title": {
          "text": "xgboost__learning_rate"
         }
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.5467455621301773,
          0.6094674556213016
         ],
         "title": {
          "text": "xgboost__max_depth"
         }
        },
        "xaxis9": {
         "anchor": "y9",
         "domain": [
          0.624852071005917,
          0.6875739644970412
         ],
         "title": {
          "text": "xgboost__min_child_weight"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Objective Value"
         }
        },
        "yaxis10": {
         "anchor": "x10",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis11": {
         "anchor": "x11",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis12": {
         "anchor": "x12",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis13": {
         "anchor": "x13",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis9": {
         "anchor": "x9",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = optuna_visualization.plot_slice(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": true
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          450,
          482,
          354,
          24,
          0,
          24,
          184,
          180,
          126,
          309,
          102,
          12,
          0,
          93,
          248,
          76,
          177,
          1,
          66,
          149,
          268,
          51,
          1,
          53,
          129,
          43,
          3,
          401,
          221,
          95,
          38,
          10,
          2,
          67,
          454,
          32,
          127,
          354,
          29,
          85,
          493,
          0,
          0,
          35,
          25,
          59,
          111,
          19,
          76,
          17,
          54,
          0,
          2,
          23,
          41,
          65,
          112,
          18,
          155,
          295,
          215,
          14,
          4,
          46,
          4,
          81,
          38,
          58,
          14,
          30,
          73,
          2,
          1,
          46,
          25,
          14,
          375,
          37,
          52,
          28,
          87,
          0,
          11,
          13,
          12,
          25,
          41,
          14,
          67,
          0,
          0,
          30,
          23,
          1,
          0,
          0,
          54,
          40,
          18,
          30,
          48,
          2,
          8,
          0,
          22,
          10,
          34,
          1,
          20,
          62,
          432,
          7,
          0,
          10,
          34,
          21,
          45,
          0,
          203,
          257,
          20,
          1,
          0,
          10,
          30,
          11,
          21,
          0,
          39,
          0,
          28,
          11,
          321,
          16,
          0,
          0,
          20,
          9,
          32,
          9,
          25,
          10,
          18,
          0,
          0,
          39,
          18,
          9,
          148,
          28,
          49,
          1,
          9,
          18,
          4,
          0,
          0,
          28,
          16,
          36,
          11,
          0,
          24,
          8,
          16,
          0,
          0,
          23,
          11,
          34,
          0,
          0,
          13,
          9,
          0,
          24,
          17,
          9,
          22,
          0,
          10,
          0,
          16,
          0,
          9,
          28,
          18,
          0,
          9,
          32,
          19,
          7,
          0,
          9,
          0,
          17,
          9,
          0,
          24,
          17,
          10,
          466,
          0,
          0,
          10,
          26,
          16,
          9,
          0,
          19,
          0,
          0,
          9,
          235,
          9,
          18,
          0,
          0,
          292,
          28,
          9,
          0,
          0,
          12,
          10,
          20,
          7,
          0,
          17,
          10,
          24,
          0,
          1,
          9,
          8,
          17,
          0,
          9,
          0,
          0,
          18,
          9,
          8,
          0,
          16,
          1,
          419,
          16,
          181,
          0,
          0,
          28,
          10,
          0,
          21,
          11,
          350,
          0,
          13,
          25,
          161,
          11,
          34,
          9,
          0,
          19,
          9,
          19,
          0,
          0,
          28,
          9,
          0,
          18,
          0,
          14,
          9,
          27,
          0,
          38,
          17,
          10,
          9,
          21,
          0,
          9,
          23,
          0,
          10,
          0,
          16,
          29,
          0,
          9,
          18,
          9,
          195,
          35,
          0,
          18,
          9,
          25,
          0,
          16,
          9,
          0,
          24,
          11,
          0,
          9,
          0,
          99,
          17,
          40,
          30,
          8,
          0,
          125,
          18,
          10,
          0,
          0,
          23,
          11,
          0,
          22,
          8,
          16,
          32,
          495,
          0,
          10,
          0,
          17,
          8,
          24,
          0,
          15,
          8,
          0,
          32,
          20,
          15,
          10,
          44,
          0,
          27,
          9,
          0,
          18,
          384,
          10,
          10,
          326,
          0,
          27,
          18,
          9,
          0,
          267,
          21,
          10,
          8,
          36,
          0,
          19,
          9,
          0,
          27,
          237,
          15,
          0,
          15,
          9,
          25,
          0,
          9,
          19,
          9,
          37,
          0,
          17,
          9,
          27,
          0,
          481,
          17,
          9,
          49,
          24,
          0,
          0,
          9,
          0,
          17,
          9,
          31,
          0,
          17,
          0,
          0,
          9,
          23,
          116,
          289,
          140,
          9,
          17,
          0,
          9,
          34,
          163,
          0,
          16,
          25,
          10,
          0,
          9,
          0,
          17,
          8,
          27,
          0,
          17,
          0,
          9,
          36,
          19,
          10,
          0,
          27,
          10,
          0,
          18,
          9,
          46,
          0,
          19,
          217,
          441,
          11,
          87,
          25,
          0,
          9,
          16,
          35,
          9,
          0,
          24,
          9,
          16,
          8,
          22,
          0,
          0,
          16,
          0,
          0,
          31,
          9,
          0,
          16,
          0,
          8,
          25,
          10,
          0,
          17,
          38,
          10,
          0,
          26,
          17,
          9,
          9,
          21,
          0,
          0,
          200,
          17,
          356,
          29,
          8,
          0,
          9,
          17,
          0,
          40,
          9,
          23,
          9,
          410,
          70,
          17,
          0,
          32,
          9,
          17,
          0
         ],
         "xaxis": "x",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.17668140036133317,
          0.13158502776480327,
          0.913602585940464,
          0.09351215387535233,
          0.009028922472964163,
          0.472122575176048,
          0.3989769322753984,
          0.0005638470121471194,
          0.3221359376429537,
          0.6440462010743564,
          0.2825137975289682,
          0.0041163567188945635,
          0.015054508683232045,
          0.2398120467786177,
          0.11891956062116638,
          0.021483474167786527,
          0.21569913852152844,
          0.38820793912377927,
          0.12677254593379284,
          0.23422242655205705,
          0.08933334027391757,
          0.36914761975252075,
          0.502219383112168,
          0.5988764510512964,
          0.28825020618703107,
          0.5010063085178752,
          0.18469376812638083,
          0.07208311701368508,
          0.20692980778151573,
          0.1956243486240699,
          0.15591396906091895,
          0.03579215626219987,
          0.07492823837362163,
          0.15018415565474572,
          0.07005540163304,
          0.06073856003865589,
          0.14918229815925418,
          0.09102710060931962,
          0.01306028148334632,
          0.1687619641003985,
          0.06168622080873945,
          0.11596778735262611,
          0.007256746728667054,
          0.0026392367745679685,
          0.05070970040789198,
          0.10942485525356102,
          0.0038815651856069187,
          0.050147902881687086,
          0.17624268259690481,
          0.10363704973185037,
          0.035647439106766196,
          0.1216158307393172,
          0.2433889115331292,
          0.25735330470583667,
          0.1918802759758429,
          0.093636446507182,
          0.0011696836313633795,
          0.14373071945855093,
          0.04087945821724466,
          0.22501956362900233,
          0.08130105596976628,
          0.2701922059101109,
          0.3304728798031194,
          0.17819684005400496,
          0.03598891611872926,
          0.035176841472679424,
          0.08148429594497394,
          0.1317587164572712,
          0.030532772863675086,
          0.059186941325378516,
          0.13718594948826845,
          0.08530158995862551,
          0.029780442346103487,
          0.2136969148450148,
          0.4479099122539749,
          0.06893349229969868,
          0.11094908543404372,
          0.0005027340309045752,
          0.15693285113089872,
          0.02385822994725011,
          0.05673710673595566,
          0.10933186881444022,
          0.1305580815596914,
          0.10533945226221758,
          0.09876970488496699,
          0.0984588400413131,
          0.18068158447950966,
          0.16014974349153344,
          0.19849803713578237,
          0.11888648825831313,
          0.24445369673755163,
          0.23347478825600587,
          0.06345472384597542,
          0.2506885874967713,
          0.29588623368215106,
          0.2594044479035313,
          0.2523521900444002,
          0.2420472306270971,
          0.2897693942833424,
          0.2834343102863981,
          0.2204321499974159,
          0.19952974935454015,
          0.3171937927880314,
          0.20622460906232637,
          0.21930560126127685,
          0.20315537238862288,
          0.26004848213690984,
          0.18535543610800848,
          0.172647883025976,
          0.1899943162076544,
          0.2314516293019275,
          0.24223233866449584,
          0.20229881126691773,
          0.15939309965065313,
          0.3044110092502297,
          0.25892580017811323,
          0.2150430319652019,
          0.27397163119444445,
          0.27069144789215416,
          0.14670906206156642,
          0.18915132908946777,
          0.33277378412638237,
          0.2727095516673191,
          0.27340089369331283,
          0.3429943760010984,
          0.25084015432990164,
          0.27703753144747967,
          0.30630160225213443,
          0.23190804171831955,
          0.3422343256059678,
          0.17524655198371936,
          0.2442057445613054,
          0.21661775731097066,
          0.2947925625972008,
          0.26822568030414673,
          0.2689181336363511,
          0.19947932495431342,
          0.327572677174729,
          0.2911309952621127,
          0.25904888212663135,
          0.1402017879024977,
          0.22117331672382806,
          0.3144990101940274,
          0.2432877890133881,
          0.1838640913593657,
          0.27693103655327084,
          0.24057362417042488,
          0.1664123533460142,
          0.20190545844449165,
          0.2299236549196764,
          0.36077286768428085,
          0.1900746160249565,
          0.2543480596634139,
          0.209105563706654,
          0.020111253406634645,
          0.15653684773079676,
          0.19025222069277983,
          0.12728838387705177,
          0.3042257941346706,
          0.23053714973882428,
          0.28256792021966115,
          0.18114706659215823,
          0.17868824712467507,
          0.20528578260395183,
          0.14436232961130224,
          0.2555182177332379,
          0.2622297802855267,
          0.2667689848888556,
          0.31937087102503076,
          0.2547518965709726,
          0.04509184400013737,
          0.21478678198603218,
          0.2241264546682709,
          0.2939466703051136,
          0.2148436135793518,
          0.24243404832204157,
          0.27617679923631855,
          0.16384076764743882,
          0.0190355091524241,
          0.07596276083169241,
          0.24490453103977441,
          0.19051249453054436,
          0.1979435303407255,
          0.22318257237180333,
          0.26491383271294877,
          0.10642273341106367,
          0.16705336895384146,
          0.19222492458443652,
          0.12524628126345233,
          0.20967064558478277,
          0.22977761842773878,
          0.17736197517145955,
          0.15337746913339315,
          0.2521003486433405,
          0.17983051575029807,
          0.39643654221678576,
          0.2814795263623535,
          0.2026410918726689,
          0.0006680897531336442,
          0.3043976043211016,
          0.13373711507255853,
          0.23468992380706255,
          0.257676041729184,
          0.21212651295001794,
          0.24234077061859333,
          0.2799378737267619,
          0.22702230088478742,
          0.04923737682529418,
          0.18472623811365613,
          0.2567098661348072,
          0.15495400190394354,
          0.15319472684090876,
          0.15074420973609926,
          0.15833389588615623,
          0.1870100117680451,
          0.08953923506444944,
          0.13858206400757805,
          0.1076052096653588,
          0.12003326775665346,
          0.10647915264976528,
          0.13359771350502966,
          0.14019006388824004,
          0.08395951006392777,
          0.08660503867461794,
          0.11567999537256056,
          0.07226505136052869,
          0.06265458188656747,
          0.16575690392366582,
          0.5175018807159101,
          0.028838400471877017,
          0.09539945309147921,
          0.1479549899308707,
          0.1252447534112712,
          0.14854043050109217,
          0.16597024079797396,
          0.1980278250672745,
          0.10306997020688397,
          0.04000989395206785,
          0.14334624860592513,
          0.019204432997009843,
          0.16992691520342917,
          0.20988011248472457,
          0.3292798732587537,
          0.36312106505123687,
          0.30313634039104564,
          0.3594990116957632,
          0.9156931940386867,
          0.18941927771692357,
          0.12035493832635775,
          0.36672704008881446,
          0.34230387139667023,
          0.3920199996319459,
          0.83792941959159,
          0.4117254532835532,
          0.21901677177951717,
          0.0020131806706350005,
          0.1527049200754613,
          0.29040627532217306,
          0.24101110016654875,
          0.05463227328219635,
          0.17684014648583068,
          0.2637376051428995,
          0.20423710801066822,
          0.0817090113279563,
          0.34417457478655333,
          0.13678471617656085,
          0.10915955362344985,
          0.22870217423371375,
          0.1897831171679617,
          0.19356836148318524,
          0.16708358502856485,
          0.20863479374407007,
          0.17777052877783986,
          0.1789115521059387,
          0.15452373853142257,
          0.18998440276661577,
          0.13526873707436698,
          0.15614322565576247,
          0.21899779260282032,
          0.1782677637441045,
          0.11977149649857552,
          0.19763263495604247,
          0.3770149823161018,
          0.4136550504314719,
          0.31080994800954903,
          0.16648609082398408,
          0.23479461489510856,
          0.13914339597038614,
          0.0898490508300077,
          0.1295558338021007,
          0.1463520018346043,
          0.10538718813350338,
          0.4361560818495976,
          0.27898929644585274,
          0.2482855381870737,
          0.33230252245539493,
          0.4856224074866434,
          0.13712563861417632,
          0.07288076486418867,
          0.21037279806711948,
          0.16530244729831217,
          0.22224958572679215,
          0.11142250410469531,
          0.35189711590227907,
          0.3138065981937931,
          0.18987012625938904,
          0.19131616215320735,
          0.24467845556864548,
          0.17598211062914615,
          0.1748077156217706,
          0.15666753885860543,
          0.1606819582911032,
          0.14876508266319208,
          0.1902204557153022,
          0.17083655834758835,
          0.20407940146460674,
          0.1410496144219892,
          0.15886261070135457,
          0.14023930506228907,
          0.18528603945205896,
          0.13014866825404875,
          0.1254238672716365,
          0.12721008253815128,
          0.12516716639974387,
          0.14711614006493057,
          0.14174151842612873,
          0.11974742395365497,
          0.14741515442087985,
          0.3786574946186514,
          0.16123067334502972,
          0.11985135831133756,
          0.13718700113314197,
          0.10737683205319622,
          0.05290019746931092,
          0.45568543316224164,
          0.17390336133966483,
          0.0983750208426758,
          0.09189748475802303,
          0.5258959609344256,
          0.1724158169740299,
          0.35642580658671735,
          0.20522737097629798,
          0.07249153382405057,
          0.10597895470791478,
          0.1444857942152481,
          0.029657701271299616,
          0.22613399634703263,
          0.18438500903792907,
          0.16152133554358059,
          0.20176233428591106,
          0.10202497972701141,
          0.1493626080867401,
          0.40463409946329,
          0.3237766378985528,
          0.17537079996754557,
          0.2885601820582483,
          0.686220208811904,
          0.2257641552813076,
          0.13187072124840032,
          0.19862613920416008,
          0.39058536474376426,
          0.043831017598937594,
          0.07226102083527763,
          0.1560475996126038,
          0.42261739146671606,
          0.3703583606355775,
          0.26032405165851763,
          0.12273586670139469,
          0.9975959522361048,
          0.1839568589720777,
          0.21423829051762702,
          0.10407863613658284,
          0.23513100673478332,
          0.15218298243279224,
          0.1812968054376742,
          0.45843083783851396,
          0.2957391027449086,
          0.13649017457853405,
          0.16748584774414096,
          0.012228239606809927,
          0.2142531171495371,
          0.3473886639038759,
          0.245009570178846,
          0.08880222739586796,
          0.06243107681801581,
          0.425400355645025,
          0.1934668449553769,
          0.16291417852350681,
          0.2686176266827675,
          0.11861299546550949,
          0.33107385768725933,
          0.14170876550505118,
          0.33373819022470513,
          0.3363766289209027,
          0.3192945898230074,
          0.3408001094865294,
          0.36575621337455566,
          0.3795839280768579,
          0.3486304273689617,
          0.37679011104368515,
          0.3870672159212267,
          0.3132000507869724,
          0.3600785812229612,
          0.13497281140197992,
          0.10924414838479433,
          0.3263212827800344,
          0.39727251143662223,
          0.3384767988031069,
          0.35404504591863,
          0.13683307161079164,
          0.29968369110156523,
          0.03197153972887422,
          0.37911424920849557,
          0.0858063095195983,
          0.14396980985795624,
          0.11374144332601,
          0.15743707577849123,
          0.15375994026288947,
          0.12249941947921657,
          0.09430642358104671,
          0.1575707924198102,
          0.002578884547478769,
          0.3188694011998149,
          0.1370620055591674,
          0.16909974987336776,
          0.40431479134278986,
          0.11609510211040931,
          0.06459415162920953,
          0.3419023444388201,
          0.44114837169370463,
          0.4533843580738168,
          0.40872493747144145,
          0.4200402308979201,
          0.48941117417029656,
          0.37334373059911585,
          0.43971555417992836,
          0.38278918255818173,
          0.4784223111381582,
          0.4421482278066167,
          0.045775694419472115,
          0.3548431148789036,
          0.17133869803333784,
          0.3940693583965638,
          0.15060641954577492,
          0.29993754102086306,
          0.5354388755374224,
          0.32798844017629214,
          0.672391181442081,
          0.42974588677200287,
          0.39383113846221857,
          0.4290623537908563,
          0.4601009683652987,
          0.3644931038607279,
          0.4119785824796522,
          0.4656720031974771,
          0.46273669024070396,
          0.17732306677405282,
          0.48740033703104,
          0.5038070229224714,
          0.4894117251598074,
          0.4737506588611171,
          0.5035314506732268,
          0.5044464795069025,
          0.4941963053058755,
          0.47115908482537333,
          0.5072542820500179,
          0.5378449430392158,
          0.44465146036662295,
          0.4940868481462815,
          0.5168380813875243,
          0.5499825693394665,
          0.4716224712366672,
          0.4331911613140172,
          0.5060955001526449,
          0.45839808057876613,
          0.4776498317118943,
          0.4282515511357844,
          0.44538084686908747,
          0.5540528692065865,
          0.522864728972355,
          0.4620933861507906,
          0.4857515624142177,
          0.44955761443102205,
          0.5057130100373368,
          0.5599188745850596,
          0.5962834622168038,
          0.5568131063287681,
          0.42181225498406194,
          0.5136337393717221,
          0.48658261731720814,
          0.5592490617803696,
          0.5251501844491939,
          0.5680912865956373,
          0.5821941563143126,
          0.6151059767989773,
          0.5380143334656552,
          0.4722761510850056,
          0.39706969149204857,
          0.438917872499998,
          0.49734683564327076
         ],
         "xaxis": "x2",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          2.749217162380866,
          2.6981005340139887,
          4.766112898831798,
          0.8084330541961959,
          0.04830223610325324,
          0.05723293938418124,
          1.2586840182459347,
          0.14823564560792188,
          1.3553024871268937,
          1.8208878340125199,
          2.0120003222547718,
          0.5924999861874596,
          0.09496068781222433,
          0.027596547537860977,
          0.8004838377910559,
          0.005044278267082619,
          0.6742041322880156,
          1.0834752241589507,
          1.695993574738367,
          0.536369471561255,
          2.2764764950819503,
          1.1816131390693498,
          0.4478516419400229,
          0.37036421417710486,
          0.4096899581394158,
          0.4061816486492399,
          0.9349623154068951,
          0.851340680237374,
          1.4762034293341464,
          0.9281365889320669,
          1.1134590576246999,
          0.32725214320777407,
          0.33539746996900455,
          0.03678939439261438,
          0.6809425374088,
          3.0958710716965854,
          0.255570928884599,
          0.9457712579118638,
          0.21159168895198188,
          0.6764817027815124,
          0.20354165009142502,
          0.545136822009628,
          0.43920429417740203,
          0.0176953592468093,
          0.30858931303559217,
          0.871912145432317,
          0.6226729712963195,
          0.1694172354508062,
          1.3653968305497524,
          0.4969469115066075,
          0.014110273731066714,
          0.44879347063610653,
          0.7433807263636762,
          0.7494450583889963,
          1.0564538017050211,
          0.2322232402396433,
          0.6952774434717373,
          0.9615203037658789,
          0.5718949884043096,
          1.243499682725161,
          0.1574803906591009,
          0.397976029157703,
          0.4538450654764631,
          0.7883647022461272,
          0.3737646792585824,
          0.16583389927248626,
          0.2914080583665652,
          0.005778335969591375,
          0.556586192256318,
          0.3397275305120982,
          1.0024717120456312,
          0.7463445944856895,
          0.4232349960896449,
          0.13129283152468307,
          0.5655135703010049,
          0.8310133669469144,
          0.3109367240220147,
          0.11127404450374315,
          1.1434866272260928,
          0.6225019811136354,
          0.428882707594188,
          0.5037803380643738,
          0.28195609247882997,
          0.26893588837923305,
          0.09721986414489145,
          0.09633004177053414,
          0.20776349539307945,
          0.5162271280911654,
          0.6626478883106773,
          0.9119559025955679,
          0.8901586261578441,
          0.8909725845548656,
          1.0742348614990334,
          0.8346497294425419,
          0.8128339586735718,
          0.8032378156443282,
          0.7843033190800361,
          1.0070717047037263,
          1.2498858848904235,
          0.6914426243147704,
          1.153364936770646,
          0.8938875711561692,
          0.9754363124689487,
          0.8044416777857577,
          0.8666501297944706,
          0.7947445071416279,
          1.088140707786165,
          1.3243583067718994,
          1.310783046095909,
          1.419803442278109,
          0.6345264422204906,
          0.7464782073281211,
          0.9161151890616623,
          1.2106777908035138,
          0.5217519880163107,
          0.9944537042269209,
          0.8336945809317998,
          1.081490507279175,
          1.4868692634658993,
          0.6129625283253216,
          1.0679473603252145,
          0.7836245198275714,
          0.9425205127180785,
          1.1770890894159198,
          0.9002569002481497,
          0.6904936448780676,
          1.0065188661599214,
          0.4667661725962851,
          1.111110063815111,
          1.3062984320883337,
          0.634691888952148,
          0.7075006952824888,
          0.767925286718436,
          0.8890388385165517,
          0.5506812540431445,
          0.5424614844508855,
          0.9693377237981379,
          0.39598087967129425,
          0.5372565447373807,
          0.8601481447790258,
          1.03698868973178,
          0.770086260610427,
          0.6115241490086005,
          0.714543524361391,
          0.4782349814109363,
          0.6878325648624358,
          1.1721162342972222,
          0.9507578882864456,
          0.353604161635593,
          0.7895249544470513,
          1.0737453866587157,
          0.6076001862512522,
          0.5602341499858772,
          0.8481721216890087,
          0.6902711997984814,
          0.23753246156389696,
          0.43763866608715235,
          0.935775594095748,
          0.643545945906215,
          0.7867347557372181,
          1.2420979729570945,
          0.4747060877138816,
          0.36330019595542684,
          0.4956191201820739,
          0.6064331306111542,
          0.735914166915784,
          0.706477920831927,
          0.7414273115714721,
          0.8631651470379007,
          0.5925832122343451,
          1.0047259484839968,
          0.31175756497193885,
          0.14571764183126473,
          1.9832144568634344,
          0.27680828636317334,
          0.705122692968297,
          0.39638250157498706,
          0.7887227045565258,
          2.455039316184349,
          0.5388863142923868,
          0.031241842345695478,
          0.4960559381392161,
          0.6458757183345468,
          0.2910850293209999,
          0.9351814776200781,
          0.4662148538971199,
          0.835724652961733,
          0.6901576497854816,
          1.042454306844694,
          0.5771600779820154,
          0.3653018836646696,
          0.4824339897895702,
          1.638640763905094,
          0.7158173596347503,
          0.48630287454046317,
          0.21186192017630118,
          1.1424909862346349,
          0.828330722615938,
          0.5950219973526635,
          0.3739006975529982,
          0.9428733931742839,
          0.8764450229987559,
          0.7698490800661362,
          0.6798073191929217,
          0.8987623286877073,
          0.9960726850683513,
          0.5496246792979563,
          1.0894115808136797,
          0.13699703906635508,
          3.231038998779977,
          0.7955209143551796,
          0.7532023554263942,
          0.7151865110929473,
          0.6220328115046229,
          0.7807039098200867,
          0.5130873591502731,
          0.4208931991837074,
          0.2426992798764932,
          0.2661118574627397,
          0.2011553162728601,
          0.3252695553376158,
          0.8268942139761695,
          0.6584605232656248,
          0.659302580908541,
          0.4325057998477156,
          0.5815090588831606,
          0.7337510859042237,
          0.10009326834128818,
          0.41461671575101944,
          0.6332826246256333,
          0.808696114783109,
          0.9096694916771184,
          0.742248361073252,
          0.8721847036377578,
          0.026398400797590177,
          0.9284414550383955,
          0.5298309062419799,
          0.31005104096493524,
          0.7023692897769808,
          1.034016305260546,
          0.8463447541831074,
          1.0098440912527376,
          0.9405263544267655,
          0.8108607619064578,
          0.7492799999066665,
          0.6145852606743305,
          0.8085735611281759,
          1.3605057502951574,
          0.4147627200988209,
          0.6556559345501773,
          0.5319280291804067,
          0.515269369803175,
          0.24629947049879727,
          0.4521652242217738,
          0.5729472982243216,
          0.3586785369539395,
          0.16225020043335608,
          0.7132332312962838,
          1.2068439612311908,
          0.8831457246312475,
          0.5845942814960233,
          0.6421243327451731,
          0.4922031774857398,
          1.0969359930820608,
          0.3187040330360263,
          0.7596508462196684,
          0.9556128748509636,
          0.8455678977713083,
          1.5946584782856026,
          1.292655288973198,
          1.079888161827171,
          1.6174763202891684,
          1.1632177006493891,
          1.3467082469406966,
          1.4820366295509446,
          1.194890187712644,
          1.8624303312800525,
          1.1549185239994486,
          1.4630388144488142,
          1.2419844825779598,
          0.9975730037773519,
          1.1135167234767906,
          1.570301126272946,
          0.9186530698279255,
          2.177815526062727,
          2.772291738955607,
          1.3100928703100005,
          1.036462963576902,
          0.9940279427901342,
          0.8439458735854385,
          0.7958147054892434,
          4.631246690665893,
          1.0374838363309935,
          1.810515744245055,
          0.10907223191328558,
          0.6696567331260878,
          0.9293856233959119,
          0.5498870211636626,
          0.20011371849607557,
          0.4391753921861713,
          0.7642516042639639,
          0.8730759197713918,
          0.6228322018109921,
          1.0468256761834356,
          0.3469843436949646,
          0.7570927284954254,
          0.7880234687275721,
          0.9332158721836087,
          1.1767648359962473,
          1.1986596053459169,
          0.01884598643476665,
          0.25857847859266986,
          0.022593367332130385,
          0.05546494174594967,
          0.0052695767268836,
          0.16455830866727697,
          1.7270061505257428,
          1.430979367872213,
          1.7433285779671037,
          1.5112037993169498,
          1.08316565883607,
          1.127625553364406,
          1.1777464188746014,
          1.020477265391678,
          1.0890542355058588,
          1.1475039074522553,
          1.2983509405069047,
          1.078825954390164,
          1.2830539961300402,
          1.2074421294860522,
          1.068553784696065,
          0.9367845873337115,
          1.1152280230600773,
          0.9724373813869649,
          0.8575162192015808,
          1.3438031210559114,
          1.953688494296242,
          2.154732671324502,
          1.429417566981435,
          1.0304182700151518,
          1.1283274819005589,
          1.239049939625161,
          0.8803971437641809,
          0.109625990869252,
          0.9536802673917459,
          1.7611345070839557,
          1.1413086623587254,
          1.0024993411372363,
          1.3843615740891115,
          0.8326357335956224,
          0.6891652876606343,
          1.2379539762349634,
          1.9005786462931755,
          2.097438892791105,
          0.8999294740422787,
          1.7255903572740148,
          1.5604676525271153,
          0.19927182755317552,
          0.5385797826391339,
          1.0673412494475607,
          1.6590979540245145,
          0.7766313283867338,
          0.4112502794269988,
          0.9721042653925117,
          0.6882112539427042,
          0.008060929142955572,
          0.8289755349717768,
          0.5739194166820643,
          1.0773690529011049,
          1.1631899646582553,
          2.062491687604142,
          0.2780961129882993,
          1.852752804520542,
          1.9532086929198518,
          0.8695130129427123,
          0.9858034516367302,
          0.09246058088173725,
          0.7555788996768114,
          1.3575748606554157,
          0.45948835597855836,
          2.21277561232131,
          0.620984550962544,
          0.9051085785183752,
          0.7332232695392604,
          1.6906310262570667,
          1.242512286568485,
          1.4597453244909575,
          0.16215528384171302,
          1.0399073750176349,
          0.34658849364871935,
          0.5033231724666085,
          0.38092870661532746,
          0.38444302799771934,
          0.22124947163657022,
          0.2450137521915663,
          0.24002455358061156,
          0.4547530252405061,
          0.14675092067607767,
          0.14401575568808545,
          0.12518527937500348,
          0.0000836503149915166,
          0.3808924339126987,
          0.2894697519617897,
          0.19909111994016984,
          0.12229751835020161,
          0.2992495430166132,
          0.4769219217764169,
          0.2375242258007783,
          0.4105231866396034,
          0.3295160124313187,
          0.08097481569417886,
          0.5144945642546122,
          1.1429558397811828,
          2.303661125282903,
          0.00011221366877113559,
          0.2015187404284933,
          1.5687002267031263,
          1.381801579802935,
          1.8419877865923342,
          2.0184251250506726,
          1.297916969963996,
          2.7266427270673783,
          2.4194330786728204,
          1.323193475968198,
          1.209461790454628,
          0.12425268943261533,
          3.078391497323703,
          1.4293830157413656,
          1.455952048791202,
          1.6780373724821627,
          1.576001672247564,
          1.6647092620492088,
          1.6610373838943489,
          1.9425391282459847,
          1.5986771062755945,
          0.37112441191327783,
          1.919734912050462,
          1.91498995858112,
          1.840091834695434,
          1.748677700010777,
          1.551824546972363,
          1.8807628438814614,
          1.6759694995963024,
          1.555123670768693,
          1.684578833922342,
          1.768237873358033,
          1.8164667754849058,
          1.5656850680417729,
          0.5441384392468354,
          1.5221603781385886,
          0.5429834746700338,
          1.7860599839314177,
          1.9879893272586093,
          2.1220542600028702,
          0.5911982968628058,
          2.5803315142438237,
          0.6402435906577091,
          2.10503360161923,
          2.2809266397140653,
          2.032920547493833,
          1.8940780850762136,
          1.7700128286299404,
          2.3331893450283956,
          1.9844272971234778,
          2.1581212871410287,
          2.06105355474409,
          2.2031199250178415,
          2.0101276978073663,
          1.74735434392878,
          2.1021685175368705,
          2.20951898991592,
          2.2894952035082645,
          1.7252585811445886,
          1.8314376786287747,
          4.390443726249137,
          1.9199823181227387,
          2.327171153158762,
          3.8079321386596328,
          1.6412373529323812,
          2.143765367736446,
          2.5887409859255146,
          2.4501836525448977,
          1.7981784663993259,
          2.0485288305830567,
          0.5159611339146439,
          0.48826550879003133,
          2.2493858544233922,
          0.4264735149392428,
          0.524342160907104,
          4.8143581771709485,
          1.505575211736158,
          0.3313810232008661,
          2.3921537259684924,
          1.6651120858245467,
          0.5744064112949149,
          1.9128949821715222,
          1.7976417392441149,
          0.4582994336429656,
          1.377266254458147,
          2.5135953303809684
         ],
         "xaxis": "x3",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445,
           446,
           447,
           448,
           449,
           450,
           451,
           452,
           453,
           454,
           455,
           456,
           457,
           458,
           459,
           460,
           461,
           462,
           463,
           464,
           465,
           466,
           467,
           468,
           469,
           470,
           471,
           472,
           473,
           474,
           475,
           476,
           477,
           478,
           479,
           480,
           481,
           482,
           483,
           484,
           485,
           486,
           487,
           488,
           489,
           490,
           491,
           492,
           493,
           494,
           495,
           496,
           497,
           498,
           499
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.8391268998756262,
          0.8384090290478076,
          0.9874188903547395,
          0.5503861112186494,
          0.5065896071904618,
          0.5001952017791316,
          0.638145839512903,
          0.6533676066838329,
          0.6203538805551276,
          0.501170563141212,
          0.739013540248122,
          0.5542541483470574,
          0.5808893289142647,
          0.5843517282049606,
          0.6571580651481883,
          0.5027292876886564,
          0.5871319248742302,
          0.6879619031245297,
          0.573039207150036,
          0.7002982254737011,
          0.6132678622291264,
          0.6886496250940006,
          0.5517973584943614,
          0.5586740000560421,
          0.5355036556887023,
          0.6008966970449205,
          0.5282116926663798,
          0.525334087331987,
          0.5973329060181136,
          0.532189491987094,
          0.5759335895652518,
          0.5345578757825197,
          0.5723569975135155,
          0.6240653287601755,
          0.5748295655645715,
          0.5209474308429427,
          0.7964863498961815,
          0.5545944687755313,
          0.6454090401612174,
          0.5004654809287296,
          0.6139304696516282,
          0.5518568505361754,
          0.525689335656851,
          0.5227672692123647,
          0.570492172725747,
          0.5989995908421104,
          0.5000332351173018,
          0.539660781250809,
          0.5192035601191084,
          0.5652246973357207,
          0.6325948471328068,
          0.543277532679266,
          0.587005770973366,
          0.5849019613572705,
          0.5145624668961253,
          0.5557266598205487,
          0.6010841207032018,
          0.5818394208788348,
          0.6528646194019916,
          0.5387799435564415,
          0.5118017363162963,
          0.5524468236615281,
          0.5643301395983217,
          0.5358726815783836,
          0.5901895533700969,
          0.615676598497345,
          0.5885059229628221,
          0.5161214118439114,
          0.6313730245268122,
          0.5653670921957025,
          0.6640346761127407,
          0.5468608798937488,
          0.5313730434404595,
          0.5725235868539632,
          0.6046593954466568,
          0.5894493346195435,
          0.51012635028062,
          0.5265214887557811,
          0.5541651706888973,
          0.5776795961520191,
          0.5411956064281873,
          0.5637416121033391,
          0.563814633390657,
          0.5639527142223846,
          0.6226163533750867,
          0.5287715438871721,
          0.6043051423098943,
          0.6226993669919783,
          0.5757901185847916,
          0.5439886056665619,
          0.5081610735614605,
          0.5069581883238962,
          0.5233075354219932,
          0.544849466412835,
          0.5447271821004331,
          0.5474469437486429,
          0.5117915315660707,
          0.5038133559497314,
          0.5297341857359618,
          0.5480827941538589,
          0.5212342602810116,
          0.544510209358754,
          0.5374281166254927,
          0.557017320902077,
          0.556487365902615,
          0.5183768831124896,
          0.5474917107796456,
          0.5361032700554857,
          0.5001161000540493,
          0.5244339823317133,
          0.5364964216980868,
          0.5588818960308941,
          0.5303094273225931,
          0.5147093000330795,
          0.5481318742292343,
          0.5404965301686333,
          0.5685049435349091,
          0.5570685101691655,
          0.5823044575675224,
          0.5111797418087576,
          0.5304514935505432,
          0.5587757355015744,
          0.5586693758005612,
          0.5646038732282053,
          0.5533279125992562,
          0.519720460763633,
          0.5573183949971409,
          0.5705210106269067,
          0.5349118300472421,
          0.5079537926157309,
          0.577268712622058,
          0.5432547212371166,
          0.5554821261110083,
          0.5970466634956187,
          0.526075383312836,
          0.5273946920897674,
          0.5003334745996265,
          0.5241109901360211,
          0.5153138949075132,
          0.5373509516543816,
          0.5630265646500123,
          0.5484248658337575,
          0.584832698723333,
          0.5360465804549953,
          0.5187349990120218,
          0.5343949315692096,
          0.5446104955582063,
          0.5070489719425385,
          0.5609806263202401,
          0.5268749039598298,
          0.5718235394906204,
          0.5169895738415854,
          0.5156289110673236,
          0.5368376562279861,
          0.5496593969012878,
          0.5260178682802742,
          0.500546611205402,
          0.5415207705416921,
          0.5132925999101059,
          0.556200909262427,
          0.5323083442403738,
          0.5186788284535033,
          0.5197397787591281,
          0.509833089161573,
          0.5472496555977365,
          0.5345564023156412,
          0.5341606711509158,
          0.5658091094460412,
          0.5377616614101621,
          0.7415420766444714,
          0.5522342476629515,
          0.5302883952075357,
          0.5285472620571924,
          0.5419563905215883,
          0.5726549018485142,
          0.5561171381368648,
          0.5290636193447638,
          0.712559550937911,
          0.5382773073924114,
          0.5588275438906957,
          0.5473028548888654,
          0.5207237739239565,
          0.5226779531224006,
          0.53363258291755,
          0.5252246786829002,
          0.5469732820307387,
          0.7924602029464155,
          0.5130327550779127,
          0.5347441664542855,
          0.5647509276525292,
          0.5795008078785187,
          0.5195339859574262,
          0.5195155263957234,
          0.5072537167968878,
          0.5407194586795868,
          0.5262391067621929,
          0.5514219034175462,
          0.5310893521302763,
          0.5001652472951511,
          0.5162918935818765,
          0.5424132310460824,
          0.5098675306245453,
          0.6466499320486537,
          0.5228082263165504,
          0.6679458769343087,
          0.8971174296293818,
          0.534765441570343,
          0.5099301961124358,
          0.5555807357000143,
          0.6126121538601874,
          0.5188209786313331,
          0.5174091039108232,
          0.5275429126882542,
          0.5171308894463056,
          0.5420600312439035,
          0.5322749591806765,
          0.5666607512586797,
          0.5655277836517807,
          0.5711833071012741,
          0.5651481232945131,
          0.5495695276360951,
          0.5588168863850448,
          0.5870168362292099,
          0.5928203189073409,
          0.5841539529948823,
          0.5684579794179603,
          0.5769549751049318,
          0.5462188624040863,
          0.5382215954277817,
          0.5553118859845922,
          0.5313895629851241,
          0.5619885765801446,
          0.5646071583845538,
          0.5765488640940762,
          0.5470983280209839,
          0.5550328105163123,
          0.5949449922106336,
          0.5252408102204364,
          0.5396466537677269,
          0.6364554727790718,
          0.5000146412491189,
          0.5613523281957908,
          0.5705784078682131,
          0.5493684387514872,
          0.5486444700760219,
          0.5321450295329502,
          0.5195700592026341,
          0.5419945960138378,
          0.5811424402097959,
          0.6854917426816498,
          0.6102298612613218,
          0.5900511429262458,
          0.608379443916427,
          0.5138925283706621,
          0.6000120632707683,
          0.5253185425202757,
          0.5332588682711231,
          0.549140784365918,
          0.5392840835077888,
          0.5099656702088439,
          0.5698678342493315,
          0.5231886789015541,
          0.5571853155896472,
          0.5368853603052656,
          0.5787043675976488,
          0.54941817698787,
          0.5890600736310865,
          0.5154794283415394,
          0.5615894810219049,
          0.5632199891178044,
          0.5697556740382382,
          0.5596014665506788,
          0.6326441705187609,
          0.6242777127809973,
          0.6162983806231607,
          0.633620189408723,
          0.5951920338442888,
          0.6081102422593029,
          0.6224700021515498,
          0.5798282327298946,
          0.640096252233623,
          0.6014913868042638,
          0.7123529303534778,
          0.5523440225965836,
          0.5738872138839533,
          0.5867804691692756,
          0.543110053357288,
          0.5620490015272609,
          0.5641927014551485,
          0.5677532710223696,
          0.5534297058611787,
          0.5854036441692182,
          0.5735925698352984,
          0.6130787045976854,
          0.66189931570148,
          0.6459607902443818,
          0.559378681200603,
          0.7636671819661973,
          0.5081281215733515,
          0.5459815176856258,
          0.5275606067338722,
          0.5538490086933594,
          0.6688311341906557,
          0.6026405251616588,
          0.8415002636665916,
          0.5805044935156658,
          0.5621782221076325,
          0.542534786317215,
          0.5762647144791538,
          0.6279450463703858,
          0.5217780906850982,
          0.5771204223288919,
          0.5063309360355646,
          0.5198221645138739,
          0.580318658136653,
          0.5912686117040656,
          0.6580899747063379,
          0.6457643563192975,
          0.6286506643302108,
          0.6347903066192724,
          0.6142301614825284,
          0.6071896575278755,
          0.6056440807674236,
          0.6182998778359149,
          0.6086163732858537,
          0.609535459521988,
          0.6057350656917471,
          0.6159527049825235,
          0.6253620106829123,
          0.5943531186295218,
          0.6192736227150514,
          0.6049049318737894,
          0.6174469264940462,
          0.6145141096851445,
          0.6380508820770819,
          0.6345997813565343,
          0.625669320970335,
          0.653736998956946,
          0.5966342293476035,
          0.6270446039905293,
          0.6472560317415227,
          0.6152851730181519,
          0.5940585804304168,
          0.9980639127854269,
          0.5818130203115239,
          0.6709798608715154,
          0.6020191335609549,
          0.6789787837676109,
          0.7112470969216472,
          0.6383505374081672,
          0.6783755691888996,
          0.7225135072904281,
          0.6497420516467022,
          0.6225134681803689,
          0.5691778087255066,
          0.6634790493218516,
          0.6537365252627452,
          0.5031004324268137,
          0.527869531170581,
          0.9476213855531406,
          0.7003442470837631,
          0.5859664607439655,
          0.5463896311403943,
          0.7597411668371109,
          0.5156303925508091,
          0.5717403350389288,
          0.6592580387880288,
          0.5377006349343301,
          0.6126939272746206,
          0.5966005591738086,
          0.5220829080212843,
          0.5541369926865753,
          0.6315551461739761,
          0.577393957893666,
          0.5005516268153352,
          0.5311414806824268,
          0.545555909780188,
          0.7405658144718987,
          0.5636370842523305,
          0.5909550858743601,
          0.5115177721747464,
          0.5508474410233362,
          0.617048523337726,
          0.6857953923636435,
          0.524674635264781,
          0.5377596916081928,
          0.5698799372552886,
          0.6039532167731974,
          0.788909719807389,
          0.6360323566726372,
          0.5151625616641339,
          0.5168013427676376,
          0.6989471545567193,
          0.508285883290043,
          0.5117007568137777,
          0.5076394804388692,
          0.5180111993785399,
          0.5013112473199781,
          0.510080717080228,
          0.5113116096265542,
          0.5083519478537231,
          0.5036703687872737,
          0.5206275730775767,
          0.5030790553708047,
          0.7269293926969175,
          0.5210825216426387,
          0.51758899512184,
          0.5017172914629434,
          0.5270606380454002,
          0.6233534987968252,
          0.5291457947928458,
          0.6515435757879275,
          0.5002866096044071,
          0.6137229776258013,
          0.5986348017167458,
          0.5181135261074012,
          0.8406945181625209,
          0.6727391314181843,
          0.7991712492229511,
          0.9615300924921812,
          0.860038548370866,
          0.6871308102943007,
          0.6413179760535505,
          0.5879694451557956,
          0.772745714784584,
          0.7484191534036269,
          0.8203859315630622,
          0.7698184896849174,
          0.6286601592098539,
          0.8031183963139876,
          0.8821398139902554,
          0.8467876267097518,
          0.5132053378867427,
          0.809246577044009,
          0.7354112494432896,
          0.7699092204897281,
          0.8220697291488875,
          0.8187451760980051,
          0.860012588438951,
          0.8227473952312717,
          0.7500932839601757,
          0.837658449714763,
          0.8059180093404705,
          0.8273583061708762,
          0.8158969195498614,
          0.804802652754722,
          0.781472472124534,
          0.8069383358408556,
          0.810239011031228,
          0.8102548708735572,
          0.8330570178973189,
          0.7917062579893016,
          0.8144902062560792,
          0.8287711232060306,
          0.8268276397408365,
          0.8278278959198442,
          0.8341199431531566,
          0.8404353004405407,
          0.8415255677170282,
          0.8458031178248968,
          0.8422329367093615,
          0.830243808176751,
          0.8216017288713625,
          0.83171073221273,
          0.8393356299928464,
          0.8566862929275029,
          0.8240459955982647,
          0.815712347997652,
          0.7970367483165639,
          0.8518936711301689,
          0.8389076253467019,
          0.8524415854443773,
          0.8322073036018862,
          0.8159259274881009,
          0.8464059539813259,
          0.7834458275003819,
          0.8259012992610504,
          0.8422439710275806,
          0.7965719288859432,
          0.8025728130510824,
          0.8266896449033837,
          0.783576206951414,
          0.8631049838599878,
          0.8115115726624401,
          0.8405604635736912,
          0.8359190519723804,
          0.8391598938281017,
          0.8501732522549268,
          0.8217379480080226,
          0.8742622829452188,
          0.8506340279554065,
          0.8382299133813017,
          0.8292540141547676,
          0.6574114349779923,
          0.8707588634367288,
          0.8450976766973956,
          0.6951020302211487,
          0.8110026168354595,
          0.8610278088434911,
          0.8301393905141536
         ],
         "xaxis": "x4",
         "y": [
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7800069208288982,
          0.8413588024167761,
          0.7796750574528353,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.7812045968135162,
          0.8308032291810925,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8021892735454892,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6963154217692574,
          0.811783766244153,
          0.46982323232323225,
          0.46982323232323225,
          0.7012596424822131,
          0.8429887004244362,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.6715094130188469,
          0.7933100827545888,
          0.8295478121798622,
          0.46982323232323225,
          0.46982323232323225,
          0.7685707448808669,
          0.46982323232323225,
          0.46982323232323225,
          0.7878658646178112,
          0.46982323232323225,
          0.46982323232323225,
          0.8043560406210365,
          0.8354586886799922,
          0.7165032826893035,
          0.7935324950920709,
          0.46982323232323225,
          0.46982323232323225,
          0.7862163442693051,
          0.46982323232323225,
          0.8117584992659643,
          0.6715644416675345,
          0.8037475645929483,
          0.8325339299822528,
          0.7866882684100401,
          0.6966718493681404,
          0.46982323232323225,
          0.46982323232323225,
          0.8001997466627692,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8042674952526491,
          0.7834710743801652,
          0.680573159356752,
          0.8134557596619184,
          0.46982323232323225,
          0.7259997607205729,
          0.46982323232323225,
          0.7989816941882802,
          0.7772342003021679,
          0.46982323232323225,
          0.8038930178052333,
          0.7924486559632626,
          0.6986925532380078,
          0.7812216903838729,
          0.8105637360798874,
          0.46982323232323225,
          0.7053254380714565,
          0.46982323232323225,
          0.7813748046389238,
          0.46982323232323225,
          0.8373954428871773,
          0.8125263643590556,
          0.8148126282083353,
          0.816648245033724,
          0.7872096232162156,
          0.7027651674149189,
          0.8126816960122869,
          0.46982323232323225,
          0.8305059115104432,
          0.8338389897782109,
          0.7693602693602694,
          0.7925573540945532,
          0.8400485931075474,
          0.8322935911263063,
          0.8390924995941588,
          0.46982323232323225,
          0.46982323232323225,
          0.7887606220939554,
          0.7728101208090659,
          0.46982323232323225,
          0.8401671416794099,
          0.819214294258781,
          0.8392088147427575,
          0.7842178397733954,
          0.7984548038086549,
          0.7620269289270186,
          0.8358704241809264,
          0.782305825372625,
          0.46982323232323225,
          0.46982323232323225,
          0.8123627144460477,
          0.8314615624133674,
          0.8158751977103262,
          0.7654031726196674,
          0.7848568647966473,
          0.7003033097473328,
          0.8370600399827325,
          0.46982323232323225,
          0.46982323232323225,
          0.7892338374965742,
          0.8352462922355396,
          0.8349124038963612,
          0.8105637360798874,
          0.7795307549382281,
          0.8058701213218245,
          0.7859121296890962,
          0.8010220219829349,
          0.7007279727586345,
          0.8307324920228146,
          0.7848568647966473,
          0.817713032248934,
          0.46982323232323225,
          0.7994843354738276,
          0.8412421078146687,
          0.8313427117445381,
          0.7848568647966473,
          0.8042000592910578,
          0.7700951091672742,
          0.811783766244153,
          0.7847012318513391,
          0.8105637360798874,
          0.8020521706197269,
          0.841805517409747,
          0.8328786496340432,
          0.7015128504607095,
          0.7920872514528102,
          0.8256167082827834,
          0.46982323232323225,
          0.7824227995661613,
          0.6633756289176245,
          0.8392088147427575,
          0.7653783156366818,
          0.7881776097982062,
          0.8325339299822528,
          0.8253707636039312,
          0.8316929234765538,
          0.7861413909431137,
          0.7976678855122432,
          0.720211054325194,
          0.8193851559068951,
          0.8342789943602194,
          0.7896518518105313,
          0.8116177266000588,
          0.7945871837010827,
          0.8373954428871773,
          0.8355618605618605,
          0.7987479879484543,
          0.8042000592910578,
          0.7848568647966473,
          0.8286967169819097,
          0.8378144378144378,
          0.793915523120999,
          0.8085986838613808,
          0.7892338374965742,
          0.7908705949302469,
          0.7861413909431137,
          0.8217637955995697,
          0.7848568647966473,
          0.8282459903305827,
          0.8110302897809047,
          0.8430936814106018,
          0.7800263052194589,
          0.8258665082194494,
          0.8187781478232847,
          0.7873774620169777,
          0.7970354259972238,
          0.831578295761588,
          0.8055700900518964,
          0.7848568647966473,
          0.7841037214125053,
          0.816648245033724,
          0.8307324920228146,
          0.7980953128800914,
          0.8308426398386515,
          0.797369828801211,
          0.7653783156366818,
          0.7782441434430467,
          0.7824349290287218,
          0.7868648656789576,
          0.8088460333753942,
          0.46982323232323225,
          0.8332046981139647,
          0.8259860691507218,
          0.8244252915439678,
          0.8037166422032569,
          0.8016258850630973,
          0.8122437851907783,
          0.8324148209994937,
          0.7873778177760505,
          0.842016992554627,
          0.8378144378144378,
          0.8237623623277424,
          0.46982323232323225,
          0.816648245033724,
          0.7975312513403748,
          0.841143726891318,
          0.8441706327668782,
          0.46982323232323225,
          0.7899764470440789,
          0.8221598114348577,
          0.8298773245431845,
          0.836320746795232,
          0.7971283942905023,
          0.8019325823785515,
          0.7905395983113641,
          0.8343143860458349,
          0.7705691213173758,
          0.8058345909773162,
          0.8181483434176061,
          0.7887606220939554,
          0.8424166030139313,
          0.8301881376171062,
          0.7890443887760493,
          0.8265643452265937,
          0.8069317513761957,
          0.8336108941149343,
          0.8181483434176061,
          0.8322348731670277,
          0.8299829922699407,
          0.7848568647966473,
          0.8125381575871466,
          0.830450448445006,
          0.8430936814106018,
          0.7836640737002963,
          0.8294337680869773,
          0.46982323232323225,
          0.7793318132586108,
          0.46982323232323225,
          0.8199046891587786,
          0.8422206603780747,
          0.7812216903838729,
          0.8107217582139212,
          0.46982323232323225,
          0.7854577251989087,
          0.8266849834247955,
          0.46982323232323225,
          0.8271746126974008,
          0.7879171507698155,
          0.7763949608443991,
          0.46982323232323225,
          0.8117584992659643,
          0.7680266197086469,
          0.8241668931324104,
          0.7980953128800914,
          0.7906392011470801,
          0.8158751977103262,
          0.7919443994310305,
          0.8377126792460198,
          0.8339520788661303,
          0.7854577251989087,
          0.816294439042688,
          0.8419122361403112,
          0.8054162864704432,
          0.8314615624133674,
          0.8113012273027473,
          0.8230983487077738,
          0.7847609833004587,
          0.8316929234765538,
          0.698604409616048,
          0.8072225594892407,
          0.8199916193458224,
          0.818288707177596,
          0.7926485741831626,
          0.7961645174882984,
          0.7685704913749558,
          0.7895358849776961,
          0.8413588024167761,
          0.8193549518567049,
          0.8288041288041289,
          0.8037475645929483,
          0.7868648656789576,
          0.8062783562783562,
          0.76699311085276,
          0.7825352736490705,
          0.8073805470574537,
          0.46982323232323225,
          0.7920877747784719,
          0.7747051016887347,
          0.7872728299774563,
          0.8032096761263428,
          0.7833282360534863,
          0.8309507075479371,
          0.8051010269042874,
          0.7874839707995865,
          0.8413588024167761,
          0.7848568647966473,
          0.8063200967644926,
          0.8483753149839316,
          0.8175631404471531,
          0.8494535614900911,
          0.46982323232323225,
          0.7887689710746011,
          0.7014478973121837,
          0.7819464486131154,
          0.7653783156366818,
          0.842772866949383,
          0.46982323232323225,
          0.8031404535636645,
          0.7918684719810437,
          0.8408360365388119,
          0.8389741379263068,
          0.46982323232323225,
          0.7653783156366818,
          0.8438492049834518,
          0.7848568647966473,
          0.780804034440973,
          0.8085986838613808,
          0.7826579574026585,
          0.46982323232323225,
          0.7810087406047,
          0.8231908107142042,
          0.847709043969658,
          0.7984269526147151,
          0.8164453086732879,
          0.7774731941267188,
          0.8303894560579054,
          0.8143705834813479,
          0.8307162756393022,
          0.7786883458613796,
          0.7848568647966473,
          0.7845364992459607,
          0.7975214730294302,
          0.8233561626751421,
          0.6715094130188469,
          0.7797203838600735,
          0.7851599776733467,
          0.46982323232323225,
          0.7885189129650848,
          0.8029822757194673,
          0.46982323232323225,
          0.812846100705431,
          0.8102658928306273,
          0.46982323232323225,
          0.7789616925097669,
          0.7824349290287218,
          0.8054162864704432,
          0.8161920989962648,
          0.7972347107966655,
          0.46982323232323225,
          0.7937664431418092,
          0.7975276488053207,
          0.7842255075173541,
          0.46982323232323225,
          0.7954168863448068,
          0.7711471826879223,
          0.8266907716530778,
          0.7903450085268269,
          0.7848568647966473,
          0.46982323232323225,
          0.8169392336059003,
          0.8298773245431845,
          0.7975776801974926,
          0.8174108299565179,
          0.7889696773040504,
          0.8275148716810447,
          0.8146662261898195,
          0.8048087287663259,
          0.8078441240863773,
          0.7194876734718031,
          0.8336065679627324,
          0.7779023233834869,
          0.8208303788194118,
          0.7838017311624617,
          0.7631318487097914,
          0.46982323232323225,
          0.7716899636091555,
          0.8044241500852451,
          0.7295452029262502,
          0.7848568647966473,
          0.8440654385896077,
          0.8419122361403112,
          0.8171910913846397,
          0.8474031538779488,
          0.8058345909773162,
          0.8204214891248859,
          0.76334028879367,
          0.8410431170393942,
          0.8058505135238087,
          0.8322348731670277,
          0.8355618605618605,
          0.8199916193458224,
          0.7884315322994929,
          0.46982323232323225,
          0.46982323232323225,
          0.46982323232323225,
          0.8014401000799581,
          0.7948244868366892,
          0.8319159077887337,
          0.8026581306681119,
          0.7264134624261489,
          0.46982323232323225,
          0.7893163064052107,
          0.7870487729045014,
          0.7890788003823456,
          0.8167954510043351,
          0.8464290293934451,
          0.8333657434530016,
          0.8372856750500254,
          0.8209094018201942,
          0.8100852572440833,
          0.793915523120999,
          0.7789770516018327,
          0.759341490549321,
          0.8085309335309335,
          0.8229660563229467,
          0.783488823126009,
          0.8054979357062689,
          0.8268273806364874,
          0.8422206603780747,
          0.8143201139265568,
          0.8271053382232415,
          0.8255855757210772,
          0.8031404535636645,
          0.8227748775644926,
          0.7490679541867842,
          0.8465307927673519,
          0.7688374473893754,
          0.46982323232323225,
          0.46982323232323225,
          0.7967237981561263,
          0.46982323232323225,
          0.8090139694518717,
          0.8387884094796694,
          0.7610742721682778,
          0.7827354187720035,
          0.7794295615476956,
          0.8305059115104432,
          0.8489826320761573,
          0.7978461867350758,
          0.8229660563229467,
          0.806630970381257,
          0.8276342884844975,
          0.8095023573501426,
          0.8419122361403112,
          0.7653163634304182,
          0.8125381575871466,
          0.8498666160259712,
          0.8461122599836918,
          0.7867926615575213,
          0.8295140719540057,
          0.8419122361403112,
          0.8122052341501838,
          0.8396538395137442,
          0.8290788555263442,
          0.810411171115466,
          0.8094772112032455,
          0.8333092833092834,
          0.825325410847382,
          0.7822748907172601,
          0.8261717461262633,
          0.8353535027762874,
          0.7881776097982062,
          0.818475426959044,
          0.8356328761951377,
          0.8271053382232415,
          0.8084272832895052,
          0.8322348731670277,
          0.7737497403099242,
          0.46982323232323225,
          0.7971467104808033,
          0.46982323232323225,
          0.807993628074108,
          0.7847340856534633,
          0.842016992554627,
          0.827885491837318,
          0.8016221960311848,
          0.822155880544294,
          0.7894801186467854,
          0.8336065679627324,
          0.7763130894349799,
          0.7614219387981903,
          0.46982323232323225,
          0.46982323232323225,
          0.8155837767741358,
          0.8197629470001856,
          0.7843817352651274,
          0.7960949514711082,
          0.811783766244153,
          0.8084108018876622
         ],
         "yaxis": "y4"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Slice Plot"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.2125
         ],
         "title": {
          "text": "xgboost__min_child_weight"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.2625,
          0.475
         ],
         "title": {
          "text": "xgboost__reg_alpha"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.525,
          0.7375
         ],
         "title": {
          "text": "xgboost__reg_lambda"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.7875,
          1
         ],
         "title": {
          "text": "xgboost__subsample"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Objective Value"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_importance = pd.DataFrame.from_dict(\n",
    "    optuna.importance.get_param_importances(study),\n",
    "    orient=\"index\",\n",
    "    columns=[\"param_importance\"],\n",
    ").sort_values(by=\"param_importance\", ascending=False)\n",
    "\n",
    "\n",
    "fig = optuna.visualization.plot_slice(\n",
    "    study,\n",
    "    params=[\n",
    "        param_importance.index[0],\n",
    "        param_importance.index[1],\n",
    "        param_importance.index[2],\n",
    "        param_importance.index[3],\n",
    "    ],\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions are in another readme, but we can see clairly the dependency on the search space and the min_child_weight parameter of xgboost, model performance is very restrictive to this parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.98991597\u001b[0m, \u001b[1;36m0.01008401\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.02167255\u001b[0m, \u001b[1;36m0.97832745\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.2049759\u001b[0m , \u001b[1;36m0.7950241\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[33m...\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98532516\u001b[0m, \u001b[1;36m0.01467485\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.08064389\u001b[0m, \u001b[1;36m0.9193561\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9418847\u001b[0m , \u001b[1;36m0.05811528\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mfloat32\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs = model.predict_proba(data)\n",
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All ml process in a single sklearn Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-306f45e9-d515-4250-b07b-5061d4881909 {color: black;background-color: white;}#sk-306f45e9-d515-4250-b07b-5061d4881909 pre{padding: 0;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-toggleable {background-color: white;}#sk-306f45e9-d515-4250-b07b-5061d4881909 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-306f45e9-d515-4250-b07b-5061d4881909 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-306f45e9-d515-4250-b07b-5061d4881909 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-306f45e9-d515-4250-b07b-5061d4881909 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-306f45e9-d515-4250-b07b-5061d4881909 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-306f45e9-d515-4250-b07b-5061d4881909 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-estimator:hover {background-color: #d4ebff;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-item {z-index: 1;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-parallel-item:only-child::after {width: 0;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-306f45e9-d515-4250-b07b-5061d4881909 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-306f45e9-d515-4250-b07b-5061d4881909\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;raw_transformations&#x27;,\n",
       "                 RawDataProcessor(params={&#x27;index&#x27;: &#x27;passenger_id&#x27;,\n",
       "                                          &#x27;schemas&#x27;: {&#x27;Age&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                                              &#x27;name&#x27;: &#x27;passenger_age&#x27;},\n",
       "                                                      &#x27;Cabin&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                                &#x27;name&#x27;: &#x27;passenger_cabin&#x27;},\n",
       "                                                      &#x27;Embarked&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                                   &#x27;name&#x27;: &#x27;passenger_embarked_port&#x27;},\n",
       "                                                      &#x27;Fare&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                                               &#x27;name&#x27;: &#x27;passenger_fare&#x27;},\n",
       "                                                      &#x27;Name&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                               &#x27;name&#x27;: &#x27;name...\n",
       "                                                                                                            &#x27;&quot;sklearn.preprocessing.QuantileTransformer&quot;])&#x27;,\n",
       "                                                                                                   &#x27;kwargs&#x27;: {}}}}},\n",
       "                                                 scoring_metrics=[&#x27;accuracy&#x27;,\n",
       "                                                                  &#x27;balanced_accuracy&#x27;,\n",
       "                                                                  &#x27;f1&#x27;,\n",
       "                                                                  &#x27;f1_micro&#x27;,\n",
       "                                                                  &#x27;f1_macro&#x27;,\n",
       "                                                                  &#x27;f1_weighted&#x27;,\n",
       "                                                                  &#x27;precision&#x27;,\n",
       "                                                                  &#x27;precision_micro&#x27;,\n",
       "                                                                  &#x27;precision_macro&#x27;,\n",
       "                                                                  &#x27;precision_weighted&#x27;,\n",
       "                                                                  &#x27;recall&#x27;,\n",
       "                                                                  &#x27;recall_micro&#x27;,\n",
       "                                                                  &#x27;recall_macro&#x27;,\n",
       "                                                                  &#x27;recall_weighted&#x27;,\n",
       "                                                                  &#x27;roc_auc&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovr&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovo&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovr_weighted&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovo_weighted&#x27;],\n",
       "                                                 target=&#x27;survived&#x27;))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"15525eeb-b7db-4c3f-88c5-8ac8605b895b\" type=\"checkbox\" ><label for=\"15525eeb-b7db-4c3f-88c5-8ac8605b895b\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;raw_transformations&#x27;,\n",
       "                 RawDataProcessor(params={&#x27;index&#x27;: &#x27;passenger_id&#x27;,\n",
       "                                          &#x27;schemas&#x27;: {&#x27;Age&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                                              &#x27;name&#x27;: &#x27;passenger_age&#x27;},\n",
       "                                                      &#x27;Cabin&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                                &#x27;name&#x27;: &#x27;passenger_cabin&#x27;},\n",
       "                                                      &#x27;Embarked&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                                   &#x27;name&#x27;: &#x27;passenger_embarked_port&#x27;},\n",
       "                                                      &#x27;Fare&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                                               &#x27;name&#x27;: &#x27;passenger_fare&#x27;},\n",
       "                                                      &#x27;Name&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                               &#x27;name&#x27;: &#x27;name...\n",
       "                                                                                                            &#x27;&quot;sklearn.preprocessing.QuantileTransformer&quot;])&#x27;,\n",
       "                                                                                                   &#x27;kwargs&#x27;: {}}}}},\n",
       "                                                 scoring_metrics=[&#x27;accuracy&#x27;,\n",
       "                                                                  &#x27;balanced_accuracy&#x27;,\n",
       "                                                                  &#x27;f1&#x27;,\n",
       "                                                                  &#x27;f1_micro&#x27;,\n",
       "                                                                  &#x27;f1_macro&#x27;,\n",
       "                                                                  &#x27;f1_weighted&#x27;,\n",
       "                                                                  &#x27;precision&#x27;,\n",
       "                                                                  &#x27;precision_micro&#x27;,\n",
       "                                                                  &#x27;precision_macro&#x27;,\n",
       "                                                                  &#x27;precision_weighted&#x27;,\n",
       "                                                                  &#x27;recall&#x27;,\n",
       "                                                                  &#x27;recall_micro&#x27;,\n",
       "                                                                  &#x27;recall_macro&#x27;,\n",
       "                                                                  &#x27;recall_weighted&#x27;,\n",
       "                                                                  &#x27;roc_auc&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovr&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovo&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovr_weighted&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovo_weighted&#x27;],\n",
       "                                                 target=&#x27;survived&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"cdd59300-a006-4c94-aa5d-362768612822\" type=\"checkbox\" ><label for=\"cdd59300-a006-4c94-aa5d-362768612822\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RawDataProcessor</label><div class=\"sk-toggleable__content\"><pre>RawDataProcessor(params={&#x27;index&#x27;: &#x27;passenger_id&#x27;,\n",
       "                         &#x27;schemas&#x27;: {&#x27;Age&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                             &#x27;name&#x27;: &#x27;passenger_age&#x27;},\n",
       "                                     &#x27;Cabin&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                               &#x27;name&#x27;: &#x27;passenger_cabin&#x27;},\n",
       "                                     &#x27;Embarked&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                  &#x27;name&#x27;: &#x27;passenger_embarked_port&#x27;},\n",
       "                                     &#x27;Fare&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                              &#x27;name&#x27;: &#x27;passenger_fare&#x27;},\n",
       "                                     &#x27;Name&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                              &#x27;name&#x27;: &#x27;name&#x27;},\n",
       "                                     &#x27;Parch&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                               &#x27;name&#x27;: &#x27;passenger_parch&#x27;},\n",
       "                                     &#x27;PassengerId&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                                     &#x27;name&#x27;: &#x27;passenger_id&#x27;},\n",
       "                                     &#x27;Pclass&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                                &#x27;name&#x27;: &#x27;passenger_class&#x27;},\n",
       "                                     &#x27;Sex&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                             &#x27;name&#x27;: &#x27;passenger_sex&#x27;},\n",
       "                                     &#x27;SibSp&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                               &#x27;name&#x27;: &#x27;passenger_siblings&#x27;},\n",
       "                                     &#x27;Survived&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                                  &#x27;name&#x27;: &#x27;survived&#x27;},\n",
       "                                     &#x27;Ticket&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                &#x27;name&#x27;: &#x27;passenger_ticket&#x27;}},\n",
       "                         &#x27;target&#x27;: &#x27;Survived&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"62fa3693-6224-4bfd-91b9-4d9a0e4cf843\" type=\"checkbox\" ><label for=\"62fa3693-6224-4bfd-91b9-4d9a0e4cf843\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IntermediateDataProcessor</label><div class=\"sk-toggleable__content\"><pre>IntermediateDataProcessor(params={&#x27;categorical_features&#x27;: [&#x27;passenger_sex&#x27;,\n",
       "                                                           &#x27;passenger_ticket&#x27;,\n",
       "                                                           &#x27;passenger_cabin&#x27;,\n",
       "                                                           &#x27;passenger_embarked_port&#x27;],\n",
       "                                  &#x27;drop_columns&#x27;: [&#x27;name&#x27;],\n",
       "                                  &#x27;outlier_params&#x27;: {&#x27;iqr_alpha&#x27;: 2.5,\n",
       "                                                     &#x27;q1_quantile&#x27;: 0.25,\n",
       "                                                     &#x27;q3_quantile&#x27;: 0.75},\n",
       "                                  &#x27;target&#x27;: &#x27;survived&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3511bfe3-33d2-439e-ba3b-2c2970177c94\" type=\"checkbox\" ><label for=\"3511bfe3-33d2-439e-ba3b-2c2970177c94\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PrimaryDataProcessor</label><div class=\"sk-toggleable__content\"><pre>PrimaryDataProcessor(params={&#x27;categorical_columns_fillna&#x27;: {&#x27;passenger_cabin&#x27;: &#x27;unknown&#x27;,\n",
       "                                                            &#x27;passenger_embarked_port&#x27;: &#x27;unknown&#x27;},\n",
       "                             &#x27;target&#x27;: &#x27;supervised&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"50118a15-defc-48f0-b095-0cc656748bb6\" type=\"checkbox\" ><label for=\"50118a15-defc-48f0-b095-0cc656748bb6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureDataProcessor</label><div class=\"sk-toggleable__content\"><pre>FeatureDataProcessor(params={&#x27;encoding_transform&#x27;: {&#x27;one_hot_encoder&#x27;: [&#x27;passenger_cabin_level&#x27;,\n",
       "                                                                        &#x27;passenger_embarked_port&#x27;,\n",
       "                                                                        &#x27;passenger_sex&#x27;],\n",
       "                                                    &#x27;similarity_based_encoder&#x27;: None},\n",
       "                             &#x27;target&#x27;: &#x27;survived&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ba46db23-8cd8-4676-9473-9f7e63dc4eb8\" type=\"checkbox\" ><label for=\"ba46db23-8cd8-4676-9473-9f7e63dc4eb8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeansClusteringFeatures</label><div class=\"sk-toggleable__content\"><pre>KMeansClusteringFeatures(feature_params={&#x27;passenger_cabin_cluster_feature&#x27;: [&#x27;passenger_cabin_level_a&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_b&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_c&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_d&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_e&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_f&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_g&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_t&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_unknown&#x27;],\n",
       "                                         &#x27;passenger_embarked_port_cluster_...\n",
       "                                                                                  &#x27;weights&#x27;: &#x27;distance&#x27;}}}},\n",
       "                         model_params={&#x27;class&#x27;: &#x27;project.packages.modelling.models.unsupervised.segmentation.KMeansElbowSelector&#x27;,\n",
       "                                       &#x27;kwargs&#x27;: {&#x27;max_clusters&#x27;: 15,\n",
       "                                                  &#x27;min_clusters&#x27;: 1}},\n",
       "                         scaler_params={&#x27;class&#x27;: &#x27;project.packages.modelling.transformers.scaler.ColumnsPreserverScaler&#x27;,\n",
       "                                        &#x27;kwargs&#x27;: {&#x27;scaler_params&#x27;: {&#x27;class&#x27;: &#x27;sklearn.preprocessing.MinMaxScaler&#x27;,\n",
       "                                                                     &#x27;kwargs&#x27;: {}}}})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4b83f552-0a2d-4cbd-add0-d0d0dfea1f7a\" type=\"checkbox\" ><label for=\"4b83f552-0a2d-4cbd-add0-d0d0dfea1f7a\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BinaryClassifierSklearnPipeline</label><div class=\"sk-toggleable__content\"><pre>BinaryClassifierSklearnPipeline(cv_score={&#x27;class&#x27;: &#x27;sklearn.model_selection.cross_val_predict&#x27;,\n",
       "                                          &#x27;kwargs&#x27;: {&#x27;X&#x27;: None, &#x27;cv&#x27;: None,\n",
       "                                                     &#x27;estimator&#x27;: None,\n",
       "                                                     &#x27;method&#x27;: &#x27;predict&#x27;,\n",
       "                                                     &#x27;n_jobs&#x27;: -1, &#x27;y&#x27;: None},\n",
       "                                          &#x27;scoring&#x27;: &#x27;f1_weighted&#x27;},\n",
       "                                cv_strategy={&#x27;class&#x27;: &#x27;sklearn.model_selection.StratifiedKFold&#x27;,\n",
       "                                             &#x27;kwargs&#x27;: {&#x27;n_splits&#x27;: 5,\n",
       "                                                        &#x27;random_state&#x27;: 42,\n",
       "                                                        &#x27;shuffle&#x27;: True}},\n",
       "                                features=[&#x27;passenger_cl...\n",
       "                                                                                           &#x27;&quot;sklearn.preprocessing.QuantileTransformer&quot;])&#x27;,\n",
       "                                                                                  &#x27;kwargs&#x27;: {}}}}},\n",
       "                                scoring_metrics=[&#x27;accuracy&#x27;,\n",
       "                                                 &#x27;balanced_accuracy&#x27;, &#x27;f1&#x27;,\n",
       "                                                 &#x27;f1_micro&#x27;, &#x27;f1_macro&#x27;,\n",
       "                                                 &#x27;f1_weighted&#x27;, &#x27;precision&#x27;,\n",
       "                                                 &#x27;precision_micro&#x27;,\n",
       "                                                 &#x27;precision_macro&#x27;,\n",
       "                                                 &#x27;precision_weighted&#x27;, &#x27;recall&#x27;,\n",
       "                                                 &#x27;recall_micro&#x27;, &#x27;recall_macro&#x27;,\n",
       "                                                 &#x27;recall_weighted&#x27;, &#x27;roc_auc&#x27;,\n",
       "                                                 &#x27;roc_auc_ovr&#x27;, &#x27;roc_auc_ovo&#x27;,\n",
       "                                                 &#x27;roc_auc_ovr_weighted&#x27;,\n",
       "                                                 &#x27;roc_auc_ovo_weighted&#x27;],\n",
       "                                target=&#x27;survived&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('raw_transformations',\n",
       "                 RawDataProcessor(params={'index': 'passenger_id',\n",
       "                                          'schemas': {'Age': {'dtype': 'float64',\n",
       "                                                              'name': 'passenger_age'},\n",
       "                                                      'Cabin': {'dtype': 'object',\n",
       "                                                                'name': 'passenger_cabin'},\n",
       "                                                      'Embarked': {'dtype': 'object',\n",
       "                                                                   'name': 'passenger_embarked_port'},\n",
       "                                                      'Fare': {'dtype': 'float64',\n",
       "                                                               'name': 'passenger_fare'},\n",
       "                                                      'Name': {'dtype': 'object',\n",
       "                                                               'name': 'name...\n",
       "                                                                                                            '\"sklearn.preprocessing.QuantileTransformer\"])',\n",
       "                                                                                                   'kwargs': {}}}}},\n",
       "                                                 scoring_metrics=['accuracy',\n",
       "                                                                  'balanced_accuracy',\n",
       "                                                                  'f1',\n",
       "                                                                  'f1_micro',\n",
       "                                                                  'f1_macro',\n",
       "                                                                  'f1_weighted',\n",
       "                                                                  'precision',\n",
       "                                                                  'precision_micro',\n",
       "                                                                  'precision_macro',\n",
       "                                                                  'precision_weighted',\n",
       "                                                                  'recall',\n",
       "                                                                  'recall_micro',\n",
       "                                                                  'recall_macro',\n",
       "                                                                  'recall_weighted',\n",
       "                                                                  'roc_auc',\n",
       "                                                                  'roc_auc_ovr',\n",
       "                                                                  'roc_auc_ovo',\n",
       "                                                                  'roc_auc_ovr_weighted',\n",
       "                                                                  'roc_auc_ovo_weighted'],\n",
       "                                                 target='survived'))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"raw_transformations\", RawDataProcessor(raw_params)),\n",
    "        (\n",
    "            \"intermediate_transformations\",\n",
    "            IntermediateDataProcessor(intermediate_params),\n",
    "        ),\n",
    "        (\"primary_transformations\", PrimaryDataProcessor(primary_params)),\n",
    "        (\"feature_transformations\", FeatureDataProcessor(feature_params)),\n",
    "        (\n",
    "            \"cluster_feature_transformations\",\n",
    "            KMeansClusteringFeatures(\n",
    "                model_params=cluster_model_params,\n",
    "                scaler_params=cluster_scaler_params,\n",
    "                feature_params=cluster_feature_params,\n",
    "                imputer_params=cluster_imputer_params,\n",
    "            ),\n",
    "        ),\n",
    "        (\"model\", BinaryClassifierSklearnPipeline(model_params)),\n",
    "    ],\n",
    ")\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-01-07 21:21:46,656 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 21:21:46,670 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 31, 'cluster_id_1': 0, 'cluster_id_2': 1}\u001b[0m\n",
      "\u001b[34m2024-01-07 21:21:47,586 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 21:21:47,603 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 1, 'cluster_id_1': 0, 'cluster_id_2': 5}\u001b[0m\n",
      "\u001b[34m2024-01-07 21:21:48,433 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 21:21:48,448 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 427, 'cluster_id_1': 594, 'cluster_id_2': 816}\u001b[0m\n",
      "\u001b[34m2024-01-07 21:21:49,564 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 21:21:49,585 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 889, 'cluster_id_1': 68, 'cluster_id_2': 128}\u001b[0m\n",
      "\u001b[34m2024-01-07 21:21:50,961 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 21:21:50,982 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 390, 'cluster_id_1': 146, 'cluster_id_2': 312}\u001b[0m\n",
      "\u001b[34m2024-01-07 21:21:51,803 - project.packages.modelling.reproducibility.set_seed - INFO - Seeding sklearn, numpy and random libraries with the seed 42\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 21:21:51,805] A new study created in memory with name: xgboost\n",
      "[I 2024-01-07 21:22:00,883] Trial 0 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.08718230210027886, 'xgboost__n_estimators': 20, 'xgboost__learning_rate': 0.3925136468134222, 'xgboost__min_child_weight': 450, 'xgboost__max_depth': 1, 'xgboost__subsample': 0.8391268998756262, 'xgboost__reg_lambda': 2.749217162380866, 'xgboost__reg_alpha': 0.17668140036133317}. Best is trial 0 with value: 0.46982323232323225.\n",
      "[I 2024-01-07 21:22:02,208] Trial 1 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.09380113636694212, 'xgboost__n_estimators': 10, 'xgboost__learning_rate': 0.38208404980070293, 'xgboost__min_child_weight': 482, 'xgboost__max_depth': 1, 'xgboost__subsample': 0.8384090290478076, 'xgboost__reg_lambda': 2.6981005340139887, 'xgboost__reg_alpha': 0.13158502776480327}. Best is trial 0 with value: 0.46982323232323225.\n",
      "[I 2024-01-07 21:22:03,252] Trial 2 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 140, 'fs_mb_xgboost__max_depth': 10, 'fs_mb__threshold': 0.061004164780424926, 'xgboost__n_estimators': 125, 'xgboost__learning_rate': 0.8733243417622814, 'xgboost__min_child_weight': 354, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.9874188903547395, 'xgboost__reg_lambda': 4.766112898831798, 'xgboost__reg_alpha': 0.913602585940464}. Best is trial 0 with value: 0.46982323232323225.\n",
      "[I 2024-01-07 21:22:03,729] Trial 3 finished with value: 0.7800069208288982 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.015779496404363325, 'xgboost__n_estimators': 455, 'xgboost__learning_rate': 0.04544733852500937, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5503861112186494, 'xgboost__reg_lambda': 0.8084330541961959, 'xgboost__reg_alpha': 0.09351215387535233}. Best is trial 3 with value: 0.7800069208288982.\n",
      "[I 2024-01-07 21:22:04,792] Trial 4 finished with value: 0.8413588024167761 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0018425789560252565, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.021583189959284575, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5065896071904618, 'xgboost__reg_lambda': 0.04830223610325324, 'xgboost__reg_alpha': 0.009028922472964163}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:05,316] Trial 5 finished with value: 0.7796750574528353 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.004594176509979703, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.01802189559897557, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5001952017791316, 'xgboost__reg_lambda': 0.05723293938418124, 'xgboost__reg_alpha': 0.472122575176048}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:05,637] Trial 6 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 340, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02632946441403268, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.2081591517438272, 'xgboost__min_child_weight': 184, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.638145839512903, 'xgboost__reg_lambda': 1.2586840182459347, 'xgboost__reg_alpha': 0.3989769322753984}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:06,051] Trial 7 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 330, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.032626011572554764, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.7115318813056645, 'xgboost__min_child_weight': 180, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.6533676066838329, 'xgboost__reg_lambda': 0.14823564560792188, 'xgboost__reg_alpha': 0.0005638470121471194}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:06,463] Trial 8 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 390, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.004231905875396498, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.542087215834471, 'xgboost__min_child_weight': 126, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6203538805551276, 'xgboost__reg_lambda': 1.3553024871268937, 'xgboost__reg_alpha': 0.3221359376429537}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:06,761] Trial 9 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 200, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04229864213651614, 'xgboost__n_estimators': 215, 'xgboost__learning_rate': 0.15746253681106132, 'xgboost__min_child_weight': 309, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.501170563141212, 'xgboost__reg_lambda': 1.8208878340125199, 'xgboost__reg_alpha': 0.6440462010743564}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:07,207] Trial 10 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 420, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.05730662636754405, 'xgboost__n_estimators': 210, 'xgboost__learning_rate': 0.2510642047739566, 'xgboost__min_child_weight': 102, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.739013540248122, 'xgboost__reg_lambda': 2.0120003222547718, 'xgboost__reg_alpha': 0.2825137975289682}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:07,817] Trial 11 finished with value: 0.7812045968135162 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.015824715165500554, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.005660842721502891, 'xgboost__min_child_weight': 12, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5542541483470574, 'xgboost__reg_lambda': 0.5924999861874596, 'xgboost__reg_alpha': 0.0041163567188945635}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:09,174] Trial 12 finished with value: 0.8308032291810925 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 260, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.003753012603709645, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.002795035258286264, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5808893289142647, 'xgboost__reg_lambda': 0.09496068781222433, 'xgboost__reg_alpha': 0.015054508683232045}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:09,618] Trial 13 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 240, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.010437597330985454, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.17895476181477427, 'xgboost__min_child_weight': 93, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5843517282049606, 'xgboost__reg_lambda': 0.027596547537860977, 'xgboost__reg_alpha': 0.2398120467786177}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:10,153] Trial 14 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.002238682929788773, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.10592433178880975, 'xgboost__min_child_weight': 248, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.6571580651481883, 'xgboost__reg_lambda': 0.8004838377910559, 'xgboost__reg_alpha': 0.11891956062116638}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:10,636] Trial 15 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 300, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.023817480501919695, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.2879058972572614, 'xgboost__min_child_weight': 76, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5027292876886564, 'xgboost__reg_lambda': 0.005044278267082619, 'xgboost__reg_alpha': 0.021483474167786527}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:11,265] Trial 16 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 400, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.0013749669723765415, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.0013785709153815197, 'xgboost__min_child_weight': 177, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5871319248742302, 'xgboost__reg_lambda': 0.6742041322880156, 'xgboost__reg_alpha': 0.21569913852152844}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:11,776] Trial 17 finished with value: 0.8021892735454892 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 190, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.01801495125845802, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.14872972534672188, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.6879619031245297, 'xgboost__reg_lambda': 1.0834752241589507, 'xgboost__reg_alpha': 0.38820793912377927}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:12,239] Trial 18 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 270, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.035323821756859206, 'xgboost__n_estimators': 270, 'xgboost__learning_rate': 0.3197538572713865, 'xgboost__min_child_weight': 66, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.573039207150036, 'xgboost__reg_lambda': 1.695993574738367, 'xgboost__reg_alpha': 0.12677254593379284}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:12,480] Trial 19 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.012433566504255297, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.1067719251711543, 'xgboost__min_child_weight': 149, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.7002982254737011, 'xgboost__reg_lambda': 0.536369471561255, 'xgboost__reg_alpha': 0.23422242655205705}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:12,852] Trial 20 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 440, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.02484362394973338, 'xgboost__n_estimators': 135, 'xgboost__learning_rate': 0.5147294730511498, 'xgboost__min_child_weight': 268, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.6132678622291264, 'xgboost__reg_lambda': 2.2764764950819503, 'xgboost__reg_alpha': 0.08933334027391757}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:13,256] Trial 21 finished with value: 0.6963154217692574 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 180, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.014669301728109561, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.11428846476752014, 'xgboost__min_child_weight': 51, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.6886496250940006, 'xgboost__reg_lambda': 1.1816131390693498, 'xgboost__reg_alpha': 0.36914761975252075}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:13,657] Trial 22 finished with value: 0.811783766244153 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 220, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.019972848063234728, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.103298419415503, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5517973584943614, 'xgboost__reg_lambda': 0.4478516419400229, 'xgboost__reg_alpha': 0.502219383112168}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:14,009] Trial 23 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 240, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.008684311032796068, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.07980963763839456, 'xgboost__min_child_weight': 53, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5586740000560421, 'xgboost__reg_lambda': 0.37036421417710486, 'xgboost__reg_alpha': 0.5988764510512964}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:14,333] Trial 24 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 340, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0018517800243709648, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.22076185761995487, 'xgboost__min_child_weight': 129, 'xgboost__max_depth': 2, 'xgboost__subsample': 0.5355036556887023, 'xgboost__reg_lambda': 0.4096899581394158, 'xgboost__reg_alpha': 0.28825020618703107}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:14,640] Trial 25 finished with value: 0.7012596424822131 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.02031350392418601, 'xgboost__n_estimators': 465, 'xgboost__learning_rate': 0.0032642485777751723, 'xgboost__min_child_weight': 43, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.6008966970449205, 'xgboost__reg_lambda': 0.4061816486492399, 'xgboost__reg_alpha': 0.5010063085178752}. Best is trial 4 with value: 0.8413588024167761.\n",
      "[I 2024-01-07 21:22:15,282] Trial 26 finished with value: 0.8429887004244362 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.010452924839967244, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.09695821118980388, 'xgboost__min_child_weight': 3, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5282116926663798, 'xgboost__reg_lambda': 0.9349623154068951, 'xgboost__reg_alpha': 0.18469376812638083}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:15,664] Trial 27 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 300, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00967725928278656, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.18624912303145144, 'xgboost__min_child_weight': 401, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.525334087331987, 'xgboost__reg_lambda': 0.851340680237374, 'xgboost__reg_alpha': 0.07208311701368508}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:16,057] Trial 28 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 360, 'fs_mb_xgboost__max_depth': 10, 'fs_mb__threshold': 0.009453924996714061, 'xgboost__n_estimators': 460, 'xgboost__learning_rate': 0.06932341348876517, 'xgboost__min_child_weight': 221, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5973329060181136, 'xgboost__reg_lambda': 1.4762034293341464, 'xgboost__reg_alpha': 0.20692980778151573}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:16,423] Trial 29 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 290, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.07060902348485489, 'xgboost__n_estimators': 120, 'xgboost__learning_rate': 0.3478863018689504, 'xgboost__min_child_weight': 95, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.532189491987094, 'xgboost__reg_lambda': 0.9281365889320669, 'xgboost__reg_alpha': 0.1956243486240699}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:16,698] Trial 30 finished with value: 0.6715094130188469 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 9, 'fs_mb__threshold': 0.04284372413081557, 'xgboost__n_estimators': 80, 'xgboost__learning_rate': 0.264087905412473, 'xgboost__min_child_weight': 38, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5759335895652518, 'xgboost__reg_lambda': 1.1134590576246999, 'xgboost__reg_alpha': 0.15591396906091895}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:17,074] Trial 31 finished with value: 0.7933100827545888 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 210, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.01968467899714859, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.08613936732511664, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5345578757825197, 'xgboost__reg_lambda': 0.32725214320777407, 'xgboost__reg_alpha': 0.03579215626219987}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:17,479] Trial 32 finished with value: 0.8295478121798622 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 160, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.007972034818125842, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.1574703613526946, 'xgboost__min_child_weight': 2, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5723569975135155, 'xgboost__reg_lambda': 0.33539746996900455, 'xgboost__reg_alpha': 0.07492823837362163}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:17,791] Trial 33 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 160, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.0075595770130936785, 'xgboost__n_estimators': 470, 'xgboost__learning_rate': 0.4326548252557329, 'xgboost__min_child_weight': 67, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6240653287601755, 'xgboost__reg_lambda': 0.03678939439261438, 'xgboost__reg_alpha': 0.15018415565474572}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:18,048] Trial 34 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.0010592450217726057, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.1493458999420411, 'xgboost__min_child_weight': 454, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5748295655645715, 'xgboost__reg_lambda': 0.6809425374088, 'xgboost__reg_alpha': 0.07005540163304}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:18,349] Trial 35 finished with value: 0.7685707448808669 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.013837033857309054, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.05870749181133461, 'xgboost__min_child_weight': 32, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5209474308429427, 'xgboost__reg_lambda': 3.0958710716965854, 'xgboost__reg_alpha': 0.06073856003865589}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:18,648] Trial 36 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 160, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.006770821793576385, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.21379045187237478, 'xgboost__min_child_weight': 127, 'xgboost__max_depth': 1, 'xgboost__subsample': 0.7964863498961815, 'xgboost__reg_lambda': 0.255570928884599, 'xgboost__reg_alpha': 0.14918229815925418}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:18,966] Trial 37 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 270, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.013331523610813592, 'xgboost__n_estimators': 440, 'xgboost__learning_rate': 0.05363103932763263, 'xgboost__min_child_weight': 354, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5545944687755313, 'xgboost__reg_lambda': 0.9457712579118638, 'xgboost__reg_alpha': 0.09102710060931962}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:19,369] Trial 38 finished with value: 0.7878658646178112 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 460, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.006566819469195532, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.046309948956956226, 'xgboost__min_child_weight': 29, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6454090401612174, 'xgboost__reg_lambda': 0.21159168895198188, 'xgboost__reg_alpha': 0.01306028148334632}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:19,662] Trial 39 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 360, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.029826681797419874, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.14065253668764427, 'xgboost__min_child_weight': 85, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5004654809287296, 'xgboost__reg_lambda': 0.6764817027815124, 'xgboost__reg_alpha': 0.1687619641003985}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:20,062] Trial 40 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 320, 'fs_mb_xgboost__max_depth': 9, 'fs_mb__threshold': 0.0257642995847268, 'xgboost__n_estimators': 260, 'xgboost__learning_rate': 0.230312824310655, 'xgboost__min_child_weight': 493, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6139304696516282, 'xgboost__reg_lambda': 0.20354165009142502, 'xgboost__reg_alpha': 0.06168622080873945}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:20,507] Trial 41 finished with value: 0.8043560406210365 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.019709023923116267, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.11904778442892265, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5518568505361754, 'xgboost__reg_lambda': 0.545136822009628, 'xgboost__reg_alpha': 0.11596778735262611}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:21,166] Trial 42 finished with value: 0.8354586886799922 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 210, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.006184121940246942, 'xgboost__n_estimators': 450, 'xgboost__learning_rate': 0.03369788320825845, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.525689335656851, 'xgboost__reg_lambda': 0.43920429417740203, 'xgboost__reg_alpha': 0.007256746728667054}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:21,524] Trial 43 finished with value: 0.7165032826893035 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 160, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.006172635503219647, 'xgboost__n_estimators': 450, 'xgboost__learning_rate': 0.02946045528017524, 'xgboost__min_child_weight': 35, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5227672692123647, 'xgboost__reg_lambda': 0.0176953592468093, 'xgboost__reg_alpha': 0.0026392367745679685}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:21,856] Trial 44 finished with value: 0.7935324950920709 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.012189448054549714, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.17451807273682798, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.570492172725747, 'xgboost__reg_lambda': 0.30858931303559217, 'xgboost__reg_alpha': 0.05070970040789198}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:22,178] Trial 45 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 260, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004944192869380757, 'xgboost__n_estimators': 220, 'xgboost__learning_rate': 0.002376979401198076, 'xgboost__min_child_weight': 59, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5989995908421104, 'xgboost__reg_lambda': 0.871912145432317, 'xgboost__reg_alpha': 0.10942485525356102}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:22,671] Trial 46 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 200, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.0011501189773531646, 'xgboost__n_estimators': 450, 'xgboost__learning_rate': 0.057038868280316624, 'xgboost__min_child_weight': 111, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5000332351173018, 'xgboost__reg_lambda': 0.6226729712963195, 'xgboost__reg_alpha': 0.0038815651856069187}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:23,173] Trial 47 finished with value: 0.7862163442693051 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.014387837055800766, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.17804920486505854, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.539660781250809, 'xgboost__reg_lambda': 0.1694172354508062, 'xgboost__reg_alpha': 0.050147902881687086}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:23,687] Trial 48 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 380, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.006718579061736793, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.033521145315927044, 'xgboost__min_child_weight': 76, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5192035601191084, 'xgboost__reg_lambda': 1.3653968305497524, 'xgboost__reg_alpha': 0.17624268259690481}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:23,994] Trial 49 finished with value: 0.8117584992659643 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 180, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.016821238128795435, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.1369800103483166, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5652246973357207, 'xgboost__reg_lambda': 0.4969469115066075, 'xgboost__reg_alpha': 0.10363704973185037}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:24,255] Trial 50 finished with value: 0.6715644416675345 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010237202921350084, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.2714586912996223, 'xgboost__min_child_weight': 54, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.6325948471328068, 'xgboost__reg_lambda': 0.014110273731066714, 'xgboost__reg_alpha': 0.035647439106766196}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:24,666] Trial 51 finished with value: 0.8037475645929483 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 220, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.02135788805511181, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.10476861193195351, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.543277532679266, 'xgboost__reg_lambda': 0.44879347063610653, 'xgboost__reg_alpha': 0.1216158307393172}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:25,124] Trial 52 finished with value: 0.8325339299822528 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 250, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.004659554323147086, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.09511184312630586, 'xgboost__min_child_weight': 2, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.587005770973366, 'xgboost__reg_lambda': 0.7433807263636762, 'xgboost__reg_alpha': 0.2433889115331292}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:25,528] Trial 53 finished with value: 0.7866882684100401 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 250, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.00477719136230287, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.0687184541160669, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5849019613572705, 'xgboost__reg_lambda': 0.7494450583889963, 'xgboost__reg_alpha': 0.25735330470583667}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:25,947] Trial 54 finished with value: 0.6966718493681404 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.010787890295906735, 'xgboost__n_estimators': 485, 'xgboost__learning_rate': 0.03130133681172803, 'xgboost__min_child_weight': 41, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5145624668961253, 'xgboost__reg_lambda': 1.0564538017050211, 'xgboost__reg_alpha': 0.1918802759758429}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:26,321] Trial 55 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 310, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.016742934105846652, 'xgboost__n_estimators': 445, 'xgboost__learning_rate': 0.002654857500227512, 'xgboost__min_child_weight': 65, 'xgboost__max_depth': 2, 'xgboost__subsample': 0.5557266598205487, 'xgboost__reg_lambda': 0.2322232402396433, 'xgboost__reg_alpha': 0.093636446507182}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:26,752] Trial 56 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 420, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.004665021105211804, 'xgboost__n_estimators': 460, 'xgboost__learning_rate': 0.09940821397517936, 'xgboost__min_child_weight': 112, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6010841207032018, 'xgboost__reg_lambda': 0.6952774434717373, 'xgboost__reg_alpha': 0.0011696836313633795}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:27,180] Trial 57 finished with value: 0.8001997466627692 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 250, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.0015248868038557064, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.19209872336491335, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5818394208788348, 'xgboost__reg_lambda': 0.9615203037658789, 'xgboost__reg_alpha': 0.14373071945855093}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:27,462] Trial 58 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 180, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.010711074910401033, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.14349422377768845, 'xgboost__min_child_weight': 155, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.6528646194019916, 'xgboost__reg_lambda': 0.5718949884043096, 'xgboost__reg_alpha': 0.04087945821724466}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:27,783] Trial 59 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.016280756660455767, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.08343602252389945, 'xgboost__min_child_weight': 295, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5387799435564415, 'xgboost__reg_lambda': 1.243499682725161, 'xgboost__reg_alpha': 0.22501956362900233}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:28,164] Trial 60 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 200, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.004342055836424161, 'xgboost__n_estimators': 495, 'xgboost__learning_rate': 0.03919824688220737, 'xgboost__min_child_weight': 215, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.5118017363162963, 'xgboost__reg_lambda': 0.1574803906591009, 'xgboost__reg_alpha': 0.08130105596976628}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:28,743] Trial 61 finished with value: 0.8042674952526491 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 210, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.00854982625639402, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.10846891871986851, 'xgboost__min_child_weight': 14, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5524468236615281, 'xgboost__reg_lambda': 0.397976029157703, 'xgboost__reg_alpha': 0.2701922059101109}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:29,172] Trial 62 finished with value: 0.7834710743801652 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.022396502997840587, 'xgboost__n_estimators': 465, 'xgboost__learning_rate': 0.08265057814391658, 'xgboost__min_child_weight': 4, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.5643301395983217, 'xgboost__reg_lambda': 0.4538450654764631, 'xgboost__reg_alpha': 0.3304728798031194}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:29,488] Trial 63 finished with value: 0.680573159356752 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 150, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.01244135820327687, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.16420029205415032, 'xgboost__min_child_weight': 46, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5358726815783836, 'xgboost__reg_lambda': 0.7883647022461272, 'xgboost__reg_alpha': 0.17819684005400496}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:29,914] Trial 64 finished with value: 0.8134557596619184 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.018356303295584558, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.12339135252130617, 'xgboost__min_child_weight': 4, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5901895533700969, 'xgboost__reg_lambda': 0.3737646792585824, 'xgboost__reg_alpha': 0.03598891611872926}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:30,290] Trial 65 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.004416634615095572, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.2097218385042754, 'xgboost__min_child_weight': 81, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.615676598497345, 'xgboost__reg_lambda': 0.16583389927248626, 'xgboost__reg_alpha': 0.035176841472679424}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:30,692] Trial 66 finished with value: 0.7259997607205729 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 260, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00851314234456364, 'xgboost__n_estimators': 470, 'xgboost__learning_rate': 0.1349735793698032, 'xgboost__min_child_weight': 38, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5885059229628221, 'xgboost__reg_lambda': 0.2914080583665652, 'xgboost__reg_alpha': 0.08148429594497394}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:31,133] Trial 67 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 330, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.017178762938009316, 'xgboost__n_estimators': 450, 'xgboost__learning_rate': 0.2425985255279689, 'xgboost__min_child_weight': 58, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5161214118439114, 'xgboost__reg_lambda': 0.005778335969591375, 'xgboost__reg_alpha': 0.1317587164572712}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:31,494] Trial 68 finished with value: 0.7989816941882802 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 180, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.013730460338220177, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.03210504012585935, 'xgboost__min_child_weight': 14, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6313730245268122, 'xgboost__reg_lambda': 0.556586192256318, 'xgboost__reg_alpha': 0.030532772863675086}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:31,975] Trial 69 finished with value: 0.7772342003021679 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0029590577709611146, 'xgboost__n_estimators': 485, 'xgboost__learning_rate': 0.07442890884022613, 'xgboost__min_child_weight': 30, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5653670921957025, 'xgboost__reg_lambda': 0.3397275305120982, 'xgboost__reg_alpha': 0.059186941325378516}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:32,287] Trial 70 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 240, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.008060186257384052, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.12355704564156837, 'xgboost__min_child_weight': 73, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6640346761127407, 'xgboost__reg_lambda': 1.0024717120456312, 'xgboost__reg_alpha': 0.13718594948826845}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:32,658] Trial 71 finished with value: 0.8038930178052333 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 210, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.019600795860615673, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.09315310831561932, 'xgboost__min_child_weight': 2, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5468608798937488, 'xgboost__reg_lambda': 0.7463445944856895, 'xgboost__reg_alpha': 0.08530158995862551}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:33,014] Trial 72 finished with value: 0.7924486559632626 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.023683463178001095, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.055138385495521344, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5313730434404595, 'xgboost__reg_lambda': 0.4232349960896449, 'xgboost__reg_alpha': 0.029780442346103487}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:33,337] Trial 73 finished with value: 0.6986925532380078 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 300, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.011722243917945274, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.015624752362376784, 'xgboost__min_child_weight': 46, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5725235868539632, 'xgboost__reg_lambda': 0.13129283152468307, 'xgboost__reg_alpha': 0.2136969148450148}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:33,598] Trial 74 finished with value: 0.7812216903838729 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 220, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.015139050848548236, 'xgboost__n_estimators': 50, 'xgboost__learning_rate': 0.19220648232990167, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.6046593954466568, 'xgboost__reg_lambda': 0.5655135703010049, 'xgboost__reg_alpha': 0.4479099122539749}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:33,910] Trial 75 finished with value: 0.8105637360798874 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 190, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.0037832670149783717, 'xgboost__n_estimators': 440, 'xgboost__learning_rate': 0.15821624861662245, 'xgboost__min_child_weight': 14, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5894493346195435, 'xgboost__reg_lambda': 0.8310133669469144, 'xgboost__reg_alpha': 0.06893349229969868}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:34,206] Trial 76 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 240, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.0074863001803212505, 'xgboost__n_estimators': 155, 'xgboost__learning_rate': 0.1124557261176794, 'xgboost__min_child_weight': 375, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.51012635028062, 'xgboost__reg_lambda': 0.3109367240220147, 'xgboost__reg_alpha': 0.11094908543404372}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:34,583] Trial 77 finished with value: 0.7053254380714565 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 140, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.010348172324609111, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.056673900634027476, 'xgboost__min_child_weight': 37, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5265214887557811, 'xgboost__reg_lambda': 0.11127404450374315, 'xgboost__reg_alpha': 0.0005027340309045752}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:34,871] Trial 78 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 170, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.0010558128775755896, 'xgboost__n_estimators': 470, 'xgboost__learning_rate': 0.0017513833854317568, 'xgboost__min_child_weight': 52, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5541651706888973, 'xgboost__reg_lambda': 1.1434866272260928, 'xgboost__reg_alpha': 0.15693285113089872}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:35,171] Trial 79 finished with value: 0.7813748046389238 and parameters: {'knn_imputer__n_neighbors': 4, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 260, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.018498103694496393, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.025969161396300226, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.5776795961520191, 'xgboost__reg_lambda': 0.6225019811136354, 'xgboost__reg_alpha': 0.02385822994725011}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:35,460] Trial 80 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 350, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.029236832903506458, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.07807654594544283, 'xgboost__min_child_weight': 87, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5411956064281873, 'xgboost__reg_lambda': 0.428882707594188, 'xgboost__reg_alpha': 0.05673710673595566}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:35,907] Trial 81 finished with value: 0.8373954428871773 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 180, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.016080768478582114, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.13116349031515723, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5637416121033391, 'xgboost__reg_lambda': 0.5037803380643738, 'xgboost__reg_alpha': 0.10933186881444022}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:36,144] Trial 82 finished with value: 0.8125263643590556 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.013869847924493115, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.12831843495280276, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.563814633390657, 'xgboost__reg_lambda': 0.28195609247882997, 'xgboost__reg_alpha': 0.1305580815596914}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:36,375] Trial 83 finished with value: 0.8148126282083353 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.013259186916423242, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.16201340421636665, 'xgboost__min_child_weight': 13, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5639527142223846, 'xgboost__reg_lambda': 0.26893588837923305, 'xgboost__reg_alpha': 0.10533945226221758}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:36,598] Trial 84 finished with value: 0.816648245033724 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006735509862264435, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.1637659299491418, 'xgboost__min_child_weight': 12, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.6226163533750867, 'xgboost__reg_lambda': 0.09721986414489145, 'xgboost__reg_alpha': 0.09876970488496699}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:36,798] Trial 85 finished with value: 0.7872096232162156 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006835260541589224, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.229459516787624, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5287715438871721, 'xgboost__reg_lambda': 0.09633004177053414, 'xgboost__reg_alpha': 0.0984588400413131}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:36,969] Trial 86 finished with value: 0.7027651674149189 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0033866563401443815, 'xgboost__n_estimators': 240, 'xgboost__learning_rate': 0.17166946968899557, 'xgboost__min_child_weight': 41, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6043051423098943, 'xgboost__reg_lambda': 0.20776349539307945, 'xgboost__reg_alpha': 0.18068158447950966}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:37,197] Trial 87 finished with value: 0.8126816960122869 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006139834610837431, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.2977517594013833, 'xgboost__min_child_weight': 14, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.6226993669919783, 'xgboost__reg_lambda': 0.5162271280911654, 'xgboost__reg_alpha': 0.16014974349153344}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:37,396] Trial 88 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.009604992820438384, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.2023518248528616, 'xgboost__min_child_weight': 67, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5757901185847916, 'xgboost__reg_lambda': 0.6626478883106773, 'xgboost__reg_alpha': 0.19849803713578237}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:38,028] Trial 89 finished with value: 0.8305059115104432 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012066622831893577, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.15789294411972743, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5439886056665619, 'xgboost__reg_lambda': 0.9119559025955679, 'xgboost__reg_alpha': 0.11888648825831313}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:38,669] Trial 90 finished with value: 0.8338389897782109 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0029679732623081496, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.0411875585262903, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5081610735614605, 'xgboost__reg_lambda': 0.8901586261578441, 'xgboost__reg_alpha': 0.24445369673755163}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:38,870] Trial 91 finished with value: 0.7693602693602694 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003118091941542451, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.04705659735451254, 'xgboost__min_child_weight': 30, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5069581883238962, 'xgboost__reg_lambda': 0.8909725845548656, 'xgboost__reg_alpha': 0.23347478825600587}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:39,080] Trial 92 finished with value: 0.7925573540945532 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005729790405944412, 'xgboost__n_estimators': 275, 'xgboost__learning_rate': 0.08790448618465348, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5233075354219932, 'xgboost__reg_lambda': 1.0742348614990334, 'xgboost__reg_alpha': 0.06345472384597542}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:39,430] Trial 93 finished with value: 0.8400485931075474 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009019213863804196, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.02714478880339107, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.544849466412835, 'xgboost__reg_lambda': 0.8346497294425419, 'xgboost__reg_alpha': 0.2506885874967713}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:40,104] Trial 94 finished with value: 0.8322935911263063 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010548245617894731, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.015073233515108371, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5447271821004331, 'xgboost__reg_lambda': 0.8128339586735718, 'xgboost__reg_alpha': 0.29588623368215106}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:40,655] Trial 95 finished with value: 0.8390924995941588 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01107236309881927, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.021857083176411024, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5474469437486429, 'xgboost__reg_lambda': 0.8032378156443282, 'xgboost__reg_alpha': 0.2594044479035313}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:40,835] Trial 96 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009894124931407908, 'xgboost__n_estimators': 245, 'xgboost__learning_rate': 0.026505021997506612, 'xgboost__min_child_weight': 54, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5117915315660707, 'xgboost__reg_lambda': 0.7843033190800361, 'xgboost__reg_alpha': 0.2523521900444002}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:41,002] Trial 97 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015400987785516386, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.0014461450788252578, 'xgboost__min_child_weight': 40, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5038133559497314, 'xgboost__reg_lambda': 1.0070717047037263, 'xgboost__reg_alpha': 0.2420472306270971}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:41,193] Trial 98 finished with value: 0.7887606220939554 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0026657901253285257, 'xgboost__n_estimators': 260, 'xgboost__learning_rate': 0.05953818507401997, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5297341857359618, 'xgboost__reg_lambda': 1.2498858848904235, 'xgboost__reg_alpha': 0.2897693942833424}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:41,383] Trial 99 finished with value: 0.7728101208090659 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.00888889716059283, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.02323559691034341, 'xgboost__min_child_weight': 30, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5480827941538589, 'xgboost__reg_lambda': 0.6914426243147704, 'xgboost__reg_alpha': 0.2834343102863981}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:41,571] Trial 100 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004798615167721501, 'xgboost__n_estimators': 275, 'xgboost__learning_rate': 0.04973771193672388, 'xgboost__min_child_weight': 48, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5212342602810116, 'xgboost__reg_lambda': 1.153364936770646, 'xgboost__reg_alpha': 0.2204321499974159}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:41,906] Trial 101 finished with value: 0.8401671416794099 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011787413780252866, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.06845953028501071, 'xgboost__min_child_weight': 2, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.544510209358754, 'xgboost__reg_lambda': 0.8938875711561692, 'xgboost__reg_alpha': 0.19952974935454015}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:42,132] Trial 102 finished with value: 0.819214294258781 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01066640012418881, 'xgboost__n_estimators': 225, 'xgboost__learning_rate': 0.06889291631359776, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5374281166254927, 'xgboost__reg_lambda': 0.9754363124689487, 'xgboost__reg_alpha': 0.3171937927880314}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:42,905] Trial 103 finished with value: 0.8392088147427575 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011856388228632213, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.023207687460771755, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.557017320902077, 'xgboost__reg_lambda': 0.8044416777857577, 'xgboost__reg_alpha': 0.20622460906232637}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:43,118] Trial 104 finished with value: 0.7842178397733954 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01226934326818412, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.040549009674363604, 'xgboost__min_child_weight': 22, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.556487365902615, 'xgboost__reg_lambda': 0.8666501297944706, 'xgboost__reg_alpha': 0.21930560126127685}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:43,354] Trial 105 finished with value: 0.7984548038086549 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015967457121980715, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.018124530345835485, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5183768831124896, 'xgboost__reg_lambda': 0.7947445071416279, 'xgboost__reg_alpha': 0.20315537238862288}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:43,571] Trial 106 finished with value: 0.7620269289270186 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008308550496625553, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.09424190510551955, 'xgboost__min_child_weight': 34, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5474917107796456, 'xgboost__reg_lambda': 1.088140707786165, 'xgboost__reg_alpha': 0.26004848213690984}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:44,009] Trial 107 finished with value: 0.8358704241809264 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0010793640362217367, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.0680286510319928, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5361032700554857, 'xgboost__reg_lambda': 1.3243583067718994, 'xgboost__reg_alpha': 0.18535543610800848}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:44,235] Trial 108 finished with value: 0.782305825372625 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.001941064967923698, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.07047133759173595, 'xgboost__min_child_weight': 20, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5001161000540493, 'xgboost__reg_lambda': 1.310783046095909, 'xgboost__reg_alpha': 0.172647883025976}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:44,410] Trial 109 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.005693894864716545, 'xgboost__n_estimators': 265, 'xgboost__learning_rate': 0.10196609735209243, 'xgboost__min_child_weight': 62, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5244339823317133, 'xgboost__reg_lambda': 1.419803442278109, 'xgboost__reg_alpha': 0.1899943162076544}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:44,759] Trial 110 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 440, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004383783591962267, 'xgboost__n_estimators': 490, 'xgboost__learning_rate': 0.03989883600531212, 'xgboost__min_child_weight': 432, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5364964216980868, 'xgboost__reg_lambda': 0.6345264422204906, 'xgboost__reg_alpha': 0.2314516293019275}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:45,011] Trial 111 finished with value: 0.8123627144460477 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011370006119370614, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.018013293681194024, 'xgboost__min_child_weight': 7, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5588818960308941, 'xgboost__reg_lambda': 0.7464782073281211, 'xgboost__reg_alpha': 0.24223233866449584}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:45,768] Trial 112 finished with value: 0.8314615624133674 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008566354843018998, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.06332186820325321, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5303094273225931, 'xgboost__reg_lambda': 0.9161151890616623, 'xgboost__reg_alpha': 0.20229881126691773}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:45,991] Trial 113 finished with value: 0.8158751977103262 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014498530957097421, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.04241458374021852, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5147093000330795, 'xgboost__reg_lambda': 1.2106777908035138, 'xgboost__reg_alpha': 0.15939309965065313}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:46,195] Trial 114 finished with value: 0.7654031726196674 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.002971776850357422, 'xgboost__n_estimators': 250, 'xgboost__learning_rate': 0.08631379494056049, 'xgboost__min_child_weight': 34, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5481318742292343, 'xgboost__reg_lambda': 0.5217519880163107, 'xgboost__reg_alpha': 0.3044110092502297}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:46,409] Trial 115 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005845293868617517, 'xgboost__n_estimators': 235, 'xgboost__learning_rate': 0.015943023404588787, 'xgboost__min_child_weight': 21, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5404965301686333, 'xgboost__reg_lambda': 0.9944537042269209, 'xgboost__reg_alpha': 0.25892580017811323}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:46,600] Trial 116 finished with value: 0.7003033097473328 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0015043756234750514, 'xgboost__n_estimators': 270, 'xgboost__learning_rate': 0.10100862512557704, 'xgboost__min_child_weight': 45, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5685049435349091, 'xgboost__reg_lambda': 0.8336945809317998, 'xgboost__reg_alpha': 0.2150430319652019}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:47,355] Trial 117 finished with value: 0.8370600399827325 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007140167607081473, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.12463501782860002, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5570685101691655, 'xgboost__reg_lambda': 1.081490507279175, 'xgboost__reg_alpha': 0.27397163119444445}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:47,580] Trial 118 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.007728368488470772, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.12577865599738802, 'xgboost__min_child_weight': 203, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5823044575675224, 'xgboost__reg_lambda': 1.4868692634658993, 'xgboost__reg_alpha': 0.27069144789215416}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:47,813] Trial 119 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 150, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.012611908261314423, 'xgboost__n_estimators': 455, 'xgboost__learning_rate': 0.13796033530307147, 'xgboost__min_child_weight': 257, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5111797418087576, 'xgboost__reg_lambda': 0.6129625283253216, 'xgboost__reg_alpha': 0.14670906206156642}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:48,012] Trial 120 finished with value: 0.7892338374965742 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0011665437032156445, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.11475601653558656, 'xgboost__min_child_weight': 20, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5304514935505432, 'xgboost__reg_lambda': 1.0679473603252145, 'xgboost__reg_alpha': 0.18915132908946777}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:48,397] Trial 121 finished with value: 0.8352462922355396 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 380, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009994498162132597, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.07654759002758964, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5587757355015744, 'xgboost__reg_lambda': 0.7836245198275714, 'xgboost__reg_alpha': 0.33277378412638237}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:49,182] Trial 122 finished with value: 0.8349124038963612 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006654447789531205, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.06929302483102834, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5586693758005612, 'xgboost__reg_lambda': 0.9425205127180785, 'xgboost__reg_alpha': 0.2727095516673191}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:49,475] Trial 123 finished with value: 0.8105637360798874 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 370, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007255250421098237, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.06977993902540108, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5646038732282053, 'xgboost__reg_lambda': 1.1770890894159198, 'xgboost__reg_alpha': 0.27340089369331283}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:49,785] Trial 124 finished with value: 0.7795307549382281 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.017425514126456394, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.04633369085317361, 'xgboost__min_child_weight': 30, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5533279125992562, 'xgboost__reg_lambda': 0.9002569002481497, 'xgboost__reg_alpha': 0.3429943760010984}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:50,094] Trial 125 finished with value: 0.8058701213218245 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009629136450812564, 'xgboost__n_estimators': 190, 'xgboost__learning_rate': 0.07978131387863346, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.519720460763633, 'xgboost__reg_lambda': 0.6904936448780676, 'xgboost__reg_alpha': 0.25084015432990164}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:50,391] Trial 126 finished with value: 0.7859121296890962 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.021476775288328705, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.05793778484292664, 'xgboost__min_child_weight': 21, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5573183949971409, 'xgboost__reg_lambda': 1.0065188661599214, 'xgboost__reg_alpha': 0.27703753144747967}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:50,937] Trial 127 finished with value: 0.8010220219829349 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 460, 'fs_mb_xgboost__max_depth': 9, 'fs_mb__threshold': 0.01430987140067019, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.038062422511082404, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5705210106269067, 'xgboost__reg_lambda': 0.4667661725962851, 'xgboost__reg_alpha': 0.30630160225213443}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:51,231] Trial 128 finished with value: 0.7007279727586345 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 410, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0038523871025551867, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.11271189246714025, 'xgboost__min_child_weight': 39, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5349118300472421, 'xgboost__reg_lambda': 1.111110063815111, 'xgboost__reg_alpha': 0.23190804171831955}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:51,901] Trial 129 finished with value: 0.8307324920228146 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 440, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011324923100626633, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.07887305993277706, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5079537926157309, 'xgboost__reg_lambda': 1.3062984320883337, 'xgboost__reg_alpha': 0.3422343256059678}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:52,300] Trial 130 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005650946255819444, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.003503525591432341, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.577268712622058, 'xgboost__reg_lambda': 0.634691888952148, 'xgboost__reg_alpha': 0.17524655198371936}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:52,572] Trial 131 finished with value: 0.817713032248934 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007772764010724102, 'xgboost__n_estimators': 475, 'xgboost__learning_rate': 0.0998052700088293, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5432547212371166, 'xgboost__reg_lambda': 0.7075006952824888, 'xgboost__reg_alpha': 0.2442057445613054}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:52,909] Trial 132 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 400, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.00408075397234178, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.14181686167047153, 'xgboost__min_child_weight': 321, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5554821261110083, 'xgboost__reg_lambda': 0.767925286718436, 'xgboost__reg_alpha': 0.21661775731097066}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:53,129] Trial 133 finished with value: 0.7994843354738276 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006251240281429087, 'xgboost__n_estimators': 260, 'xgboost__learning_rate': 0.030931066892498665, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5970466634956187, 'xgboost__reg_lambda': 0.8890388385165517, 'xgboost__reg_alpha': 0.2947925625972008}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:53,729] Trial 134 finished with value: 0.8412421078146687 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009286390368331243, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.0898383961925743, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.526075383312836, 'xgboost__reg_lambda': 0.5506812540431445, 'xgboost__reg_alpha': 0.26822568030414673}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:54,402] Trial 135 finished with value: 0.8313427117445381 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012976603241813732, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.060330229335726, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5273946920897674, 'xgboost__reg_lambda': 0.5424614844508855, 'xgboost__reg_alpha': 0.2689181336363511}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:54,621] Trial 136 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009327431963780511, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.0014037460339173559, 'xgboost__min_child_weight': 20, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5003334745996265, 'xgboost__reg_lambda': 0.9693377237981379, 'xgboost__reg_alpha': 0.19947932495431342}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:54,859] Trial 137 finished with value: 0.8042000592910578 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 140, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.017129549146066722, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.08570899708927411, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5241109901360211, 'xgboost__reg_lambda': 0.39598087967129425, 'xgboost__reg_alpha': 0.327572677174729}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:55,086] Trial 138 finished with value: 0.7700951091672742 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011436896437076275, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.12337671110598947, 'xgboost__min_child_weight': 32, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5153138949075132, 'xgboost__reg_lambda': 0.5372565447373807, 'xgboost__reg_alpha': 0.2911309952621127}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:55,352] Trial 139 finished with value: 0.811783766244153 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 170, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015129998116238627, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.052711681747293376, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5373509516543816, 'xgboost__reg_lambda': 0.8601481447790258, 'xgboost__reg_alpha': 0.25904888212663135}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:55,663] Trial 140 finished with value: 0.7847012318513391 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 460, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.009104841210560655, 'xgboost__n_estimators': 275, 'xgboost__learning_rate': 0.023976705915834937, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5630265646500123, 'xgboost__reg_lambda': 1.03698868973178, 'xgboost__reg_alpha': 0.1402017879024977}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:55,922] Trial 141 finished with value: 0.8105637360798874 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 200, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003539877790339818, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.09386557962255314, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5484248658337575, 'xgboost__reg_lambda': 0.770086260610427, 'xgboost__reg_alpha': 0.22117331672382806}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:56,125] Trial 142 finished with value: 0.8020521706197269 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005885221135422768, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.06862929564328595, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.584832698723333, 'xgboost__reg_lambda': 0.6115241490086005, 'xgboost__reg_alpha': 0.3144990101940274}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:56,739] Trial 143 finished with value: 0.841805517409747 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007976356588350993, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.038345382110852394, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5360465804549953, 'xgboost__reg_lambda': 0.714543524361391, 'xgboost__reg_alpha': 0.2432877890133881}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:57,314] Trial 144 finished with value: 0.8328786496340432 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00818710527806147, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.04089287187666972, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5187349990120218, 'xgboost__reg_lambda': 0.4782349814109363, 'xgboost__reg_alpha': 0.1838640913593657}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:57,540] Trial 145 finished with value: 0.7015128504607095 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013088120547422252, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.026697649664492007, 'xgboost__min_child_weight': 39, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5343949315692096, 'xgboost__reg_lambda': 0.6878325648624358, 'xgboost__reg_alpha': 0.27693103655327084}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:57,732] Trial 146 finished with value: 0.7920872514528102 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0011327999203598876, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.0675311448683333, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5446104955582063, 'xgboost__reg_lambda': 1.1721162342972222, 'xgboost__reg_alpha': 0.24057362417042488}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:58,001] Trial 147 finished with value: 0.8256167082827834 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 150, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.010988250753267162, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.11029188420102434, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5070489719425385, 'xgboost__reg_lambda': 0.9507578882864456, 'xgboost__reg_alpha': 0.1664123533460142}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:58,232] Trial 148 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006618405730754787, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.05075401126530049, 'xgboost__min_child_weight': 148, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5609806263202401, 'xgboost__reg_lambda': 0.353604161635593, 'xgboost__reg_alpha': 0.20190545844449165}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:58,523] Trial 149 finished with value: 0.7824227995661613 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010029163530841002, 'xgboost__n_estimators': 255, 'xgboost__learning_rate': 0.018768275439158, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5268749039598298, 'xgboost__reg_lambda': 0.7895249544470513, 'xgboost__reg_alpha': 0.2299236549196764}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:58,708] Trial 150 finished with value: 0.6633756289176245 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.018392196309074984, 'xgboost__n_estimators': 270, 'xgboost__learning_rate': 0.1478007433793952, 'xgboost__min_child_weight': 49, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5718235394906204, 'xgboost__reg_lambda': 1.0737453866587157, 'xgboost__reg_alpha': 0.36077286768428085}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:59,072] Trial 151 finished with value: 0.8392088147427575 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.008209303899845862, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.04267921715792768, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5169895738415854, 'xgboost__reg_lambda': 0.6076001862512522, 'xgboost__reg_alpha': 0.1900746160249565}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:59,359] Trial 152 finished with value: 0.7653783156366818 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0034466835318024136, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.0012647949014405607, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5156289110673236, 'xgboost__reg_lambda': 0.5602341499858772, 'xgboost__reg_alpha': 0.2543480596634139}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:59,585] Trial 153 finished with value: 0.7881776097982062 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007275564863010534, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.038141160962920556, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5368376562279861, 'xgboost__reg_lambda': 0.8481721216890087, 'xgboost__reg_alpha': 0.209105563706654}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:22:59,872] Trial 154 finished with value: 0.8325339299822528 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.005273083131204998, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.06981695988560331, 'xgboost__min_child_weight': 4, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5496593969012878, 'xgboost__reg_lambda': 0.6902711997984814, 'xgboost__reg_alpha': 0.020111253406634645}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:00,536] Trial 155 finished with value: 0.8253707636039312 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.013716616870945695, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.08553747695935246, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5260178682802742, 'xgboost__reg_lambda': 0.23753246156389696, 'xgboost__reg_alpha': 0.15653684773079676}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:01,299] Trial 156 finished with value: 0.8316929234765538 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00983948570993784, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.04998629525553129, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.500546611205402, 'xgboost__reg_lambda': 0.43763866608715235, 'xgboost__reg_alpha': 0.19025222069277983}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:01,574] Trial 157 finished with value: 0.7861413909431137 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 330, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.002781734605920987, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.39299481727041724, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5415207705416921, 'xgboost__reg_lambda': 0.935775594095748, 'xgboost__reg_alpha': 0.12728838387705177}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:01,808] Trial 158 finished with value: 0.7976678855122432 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01590646356032722, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.025291831110239277, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5132925999101059, 'xgboost__reg_lambda': 0.643545945906215, 'xgboost__reg_alpha': 0.3042257941346706}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:02,111] Trial 159 finished with value: 0.720211054325194 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 430, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008041940454282066, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.12411172653926371, 'xgboost__min_child_weight': 36, 'xgboost__max_depth': 1, 'xgboost__subsample': 0.556200909262427, 'xgboost__reg_lambda': 0.7867347557372181, 'xgboost__reg_alpha': 0.23053714973882428}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:02,522] Trial 160 finished with value: 0.8193851559068951 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.004939362767832158, 'xgboost__n_estimators': 265, 'xgboost__learning_rate': 0.18620804565807186, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5323083442403738, 'xgboost__reg_lambda': 1.2420979729570945, 'xgboost__reg_alpha': 0.28256792021966115}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:03,098] Trial 161 finished with value: 0.8342789943602194 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007769048103789704, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.041963150969737885, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5186788284535033, 'xgboost__reg_lambda': 0.4747060877138816, 'xgboost__reg_alpha': 0.18114706659215823}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:03,354] Trial 162 finished with value: 0.7896518518105313 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.012337275494685896, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.08187383600287193, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5197397787591281, 'xgboost__reg_lambda': 0.36330019595542684, 'xgboost__reg_alpha': 0.17868824712467507}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:03,640] Trial 163 finished with value: 0.8116177266000588 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00912231928836255, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.053774821611847406, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.509833089161573, 'xgboost__reg_lambda': 0.4956191201820739, 'xgboost__reg_alpha': 0.20528578260395183}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:03,891] Trial 164 finished with value: 0.7945871837010827 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.006777877253860358, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.03566075048529262, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5472496555977365, 'xgboost__reg_lambda': 0.6064331306111542, 'xgboost__reg_alpha': 0.14436232961130224}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:04,536] Trial 165 finished with value: 0.8373954428871773 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.01078564809545394, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.09993725559957642, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5345564023156412, 'xgboost__reg_lambda': 0.735914166915784, 'xgboost__reg_alpha': 0.2555182177332379}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:05,150] Trial 166 finished with value: 0.8355618605618605 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.011379323534364853, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.09711762629272945, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5341606711509158, 'xgboost__reg_lambda': 0.706477920831927, 'xgboost__reg_alpha': 0.2622297802855267}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:05,420] Trial 167 finished with value: 0.7987479879484543 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.011612597746060653, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.10547696775480449, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5658091094460412, 'xgboost__reg_lambda': 0.7414273115714721, 'xgboost__reg_alpha': 0.2667689848888556}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:05,709] Trial 168 finished with value: 0.8042000592910578 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.015214474549646795, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.132589020004473, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5377616614101621, 'xgboost__reg_lambda': 0.8631651470379007, 'xgboost__reg_alpha': 0.31937087102503076}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:05,893] Trial 169 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.04217253051496733, 'xgboost__n_estimators': 10, 'xgboost__learning_rate': 0.10067384330682513, 'xgboost__min_child_weight': 34, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.7415420766444714, 'xgboost__reg_lambda': 0.5925832122343451, 'xgboost__reg_alpha': 0.2547518965709726}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:06,873] Trial 170 finished with value: 0.8286967169819097 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.010782862218698976, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.07237820976850959, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5522342476629515, 'xgboost__reg_lambda': 1.0047259484839968, 'xgboost__reg_alpha': 0.04509184400013737}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:07,426] Trial 171 finished with value: 0.8378144378144378 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.013347496723962678, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.08671912109779704, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5302883952075357, 'xgboost__reg_lambda': 0.31175756497193885, 'xgboost__reg_alpha': 0.21478678198603218}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:07,696] Trial 172 finished with value: 0.793915523120999 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.013087762938640229, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.5907491874402411, 'xgboost__min_child_weight': 13, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5285472620571924, 'xgboost__reg_lambda': 0.14571764183126473, 'xgboost__reg_alpha': 0.2241264546682709}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:07,966] Trial 173 finished with value: 0.8085986838613808 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.016226052801143434, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.09174080767634342, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5419563905215883, 'xgboost__reg_lambda': 1.9832144568634344, 'xgboost__reg_alpha': 0.2939466703051136}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:08,379] Trial 174 finished with value: 0.7892338374965742 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 380, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.019297618663794515, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.11418076258991988, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5726549018485142, 'xgboost__reg_lambda': 0.27680828636317334, 'xgboost__reg_alpha': 0.2148436135793518}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:08,636] Trial 175 finished with value: 0.7908705949302469 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.010511766721777428, 'xgboost__n_estimators': 460, 'xgboost__learning_rate': 0.06924133377509836, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5561171381368648, 'xgboost__reg_lambda': 0.705122692968297, 'xgboost__reg_alpha': 0.24243404832204157}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:08,874] Trial 176 finished with value: 0.7861413909431137 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.013058702871436872, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.1536030537449734, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5290636193447638, 'xgboost__reg_lambda': 0.39638250157498706, 'xgboost__reg_alpha': 0.27617679923631855}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:09,179] Trial 177 finished with value: 0.8217637955995697 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 10, 'fs_mb__threshold': 0.008992154890881149, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.08459834063460403, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.712559550937911, 'xgboost__reg_lambda': 0.7887227045565258, 'xgboost__reg_alpha': 0.16384076764743882}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:09,633] Trial 178 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 350, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.02270738115457746, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.0196795924105434, 'xgboost__min_child_weight': 22, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5382773073924114, 'xgboost__reg_lambda': 2.455039316184349, 'xgboost__reg_alpha': 0.0190355091524241}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:10,359] Trial 179 finished with value: 0.8282459903305827 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.011785079099043208, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.14122164333908144, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5588275438906957, 'xgboost__reg_lambda': 0.5388863142923868, 'xgboost__reg_alpha': 0.07596276083169241}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:10,633] Trial 180 finished with value: 0.8110302897809047 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.014621226776416436, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.05805516788448084, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5473028548888654, 'xgboost__reg_lambda': 0.031241842345695478, 'xgboost__reg_alpha': 0.24490453103977441}. Best is trial 26 with value: 0.8429887004244362.\n",
      "[I 2024-01-07 21:23:11,489] Trial 181 finished with value: 0.8430936814106018 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007080520935267898, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.03964636103580148, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5207237739239565, 'xgboost__reg_lambda': 0.4960559381392161, 'xgboost__reg_alpha': 0.19051249453054436}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:12,041] Trial 182 finished with value: 0.7800263052194589 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00559365309625885, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.002517633870496045, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5226779531224006, 'xgboost__reg_lambda': 0.6458757183345468, 'xgboost__reg_alpha': 0.1979435303407255}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:12,746] Trial 183 finished with value: 0.8258665082194494 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009527570468478385, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.06440055903333004, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.53363258291755, 'xgboost__reg_lambda': 0.2910850293209999, 'xgboost__reg_alpha': 0.22318257237180333}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:13,203] Trial 184 finished with value: 0.8187781478232847 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 450, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007356049564158338, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.10370739099416461, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5252246786829002, 'xgboost__reg_lambda': 0.9351814776200781, 'xgboost__reg_alpha': 0.26491383271294877}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:13,714] Trial 185 finished with value: 0.7873774620169777 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.005035312950855432, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.3236771019662027, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5469732820307387, 'xgboost__reg_lambda': 0.4662148538971199, 'xgboost__reg_alpha': 0.10642273341106367}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:14,007] Trial 186 finished with value: 0.7970354259972238 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011392555069658169, 'xgboost__n_estimators': 270, 'xgboost__learning_rate': 0.023863083472672752, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7924602029464155, 'xgboost__reg_lambda': 0.835724652961733, 'xgboost__reg_alpha': 0.16705336895384146}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:15,272] Trial 187 finished with value: 0.831578295761588 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014167602685073244, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.08325848803567273, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5130327550779127, 'xgboost__reg_lambda': 0.6901576497854816, 'xgboost__reg_alpha': 0.19222492458443652}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:15,639] Trial 188 finished with value: 0.8055700900518964 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008879919220556472, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.05170672024504776, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5347441664542855, 'xgboost__reg_lambda': 1.042454306844694, 'xgboost__reg_alpha': 0.12524628126345233}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:15,855] Trial 189 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.07050956084056825, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.1256224132235575, 'xgboost__min_child_weight': 32, 'xgboost__max_depth': 2, 'xgboost__subsample': 0.5647509276525292, 'xgboost__reg_lambda': 0.5771600779820154, 'xgboost__reg_alpha': 0.20967064558478277}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:16,148] Trial 190 finished with value: 0.7841037214125053 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 190, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.025946966821577114, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.24082729666099278, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5795008078785187, 'xgboost__reg_lambda': 0.3653018836646696, 'xgboost__reg_alpha': 0.22977761842773878}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:16,470] Trial 191 finished with value: 0.816648245033724 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007731662374409664, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.036936579328518584, 'xgboost__min_child_weight': 7, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5195339859574262, 'xgboost__reg_lambda': 0.4824339897895702, 'xgboost__reg_alpha': 0.17736197517145955}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:17,386] Trial 192 finished with value: 0.8307324920228146 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0065813580984450115, 'xgboost__n_estimators': 445, 'xgboost__learning_rate': 0.045978151822003634, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5195155263957234, 'xgboost__reg_lambda': 1.638640763905094, 'xgboost__reg_alpha': 0.15337746913339315}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:17,751] Trial 193 finished with value: 0.7980953128800914 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0029203178270867007, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.02290770805959834, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5072537167968878, 'xgboost__reg_lambda': 0.7158173596347503, 'xgboost__reg_alpha': 0.2521003486433405}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:18,350] Trial 194 finished with value: 0.8308426398386515 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.010056919121465136, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.07156165326738438, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5407194586795868, 'xgboost__reg_lambda': 0.48630287454046317, 'xgboost__reg_alpha': 0.17983051575029807}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:18,560] Trial 195 finished with value: 0.797369828801211 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007694820102612427, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.09100566538919233, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5262391067621929, 'xgboost__reg_lambda': 0.21186192017630118, 'xgboost__reg_alpha': 0.39643654221678576}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:18,841] Trial 196 finished with value: 0.7653783156366818 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.01196988467509794, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.0012862858487309795, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5514219034175462, 'xgboost__reg_lambda': 1.1424909862346349, 'xgboost__reg_alpha': 0.2814795263623535}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:19,200] Trial 197 finished with value: 0.7782441434430467 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.028285069461199696, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.2703161581157103, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5310893521302763, 'xgboost__reg_lambda': 0.828330722615938, 'xgboost__reg_alpha': 0.2026410918726689}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:19,403] Trial 198 finished with value: 0.7824349290287218 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03476796372222836, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.038910377343723865, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5001652472951511, 'xgboost__reg_lambda': 0.5950219973526635, 'xgboost__reg_alpha': 0.0006680897531336442}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:19,704] Trial 199 finished with value: 0.7868648656789576 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0049175532169241035, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.054990544946636716, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5162918935818765, 'xgboost__reg_lambda': 0.3739006975529982, 'xgboost__reg_alpha': 0.3043976043211016}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:19,934] Trial 200 finished with value: 0.8088460333753942 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01756405212941496, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.019415517465968892, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5424132310460824, 'xgboost__reg_lambda': 0.9428733931742839, 'xgboost__reg_alpha': 0.13373711507255853}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:20,161] Trial 201 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.001601610127777481, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.035698881020444675, 'xgboost__min_child_weight': 466, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5098675306245453, 'xgboost__reg_lambda': 0.8764450229987559, 'xgboost__reg_alpha': 0.23468992380706255}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:20,789] Trial 202 finished with value: 0.8332046981139647 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004331644701541895, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.061349404361546456, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6466499320486537, 'xgboost__reg_lambda': 0.7698490800661362, 'xgboost__reg_alpha': 0.257676041729184}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:21,337] Trial 203 finished with value: 0.8259860691507218 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0011164126222576894, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.20938745862990643, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5228082263165504, 'xgboost__reg_lambda': 0.6798073191929217, 'xgboost__reg_alpha': 0.21212651295001794}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:21,693] Trial 204 finished with value: 0.8244252915439678 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008699174068017186, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.11050530513358013, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6679458769343087, 'xgboost__reg_lambda': 0.8987623286877073, 'xgboost__reg_alpha': 0.24234077061859333}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:21,905] Trial 205 finished with value: 0.8037166422032569 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00334409621790965, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.07847501511331637, 'xgboost__min_child_weight': 26, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.8971174296293818, 'xgboost__reg_lambda': 0.9960726850683513, 'xgboost__reg_alpha': 0.2799378737267619}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:22,119] Trial 206 finished with value: 0.8016258850630973 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006766676678207484, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.04292072802680402, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.534765441570343, 'xgboost__reg_lambda': 0.5496246792979563, 'xgboost__reg_alpha': 0.22702230088478742}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:22,450] Trial 207 finished with value: 0.8122437851907783 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 170, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.01099245897123751, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.08834177565028309, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5099301961124358, 'xgboost__reg_lambda': 1.0894115808136797, 'xgboost__reg_alpha': 0.04923737682529418}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:22,975] Trial 208 finished with value: 0.8324148209994937 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012885520896030242, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.17087525419809252, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5555807357000143, 'xgboost__reg_lambda': 0.13699703906635508, 'xgboost__reg_alpha': 0.18472623811365613}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:23,202] Trial 209 finished with value: 0.7873778177760505 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006227190553245347, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.022016662743310145, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6126121538601874, 'xgboost__reg_lambda': 3.231038998779977, 'xgboost__reg_alpha': 0.2567098661348072}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:23,785] Trial 210 finished with value: 0.842016992554627 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009135912398802471, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.06102144894681829, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5188209786313331, 'xgboost__reg_lambda': 0.7955209143551796, 'xgboost__reg_alpha': 0.15495400190394354}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:24,358] Trial 211 finished with value: 0.8378144378144378 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009445657881914165, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.058444206714420875, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5174091039108232, 'xgboost__reg_lambda': 0.7532023554263942, 'xgboost__reg_alpha': 0.15319472684090876}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:24,655] Trial 212 finished with value: 0.8237623623277424 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009696327111072876, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.06567777273407405, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5275429126882542, 'xgboost__reg_lambda': 0.7151865110929473, 'xgboost__reg_alpha': 0.15074420973609926}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:24,895] Trial 213 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.008512899068323646, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.1033883774343542, 'xgboost__min_child_weight': 235, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5171308894463056, 'xgboost__reg_lambda': 0.6220328115046229, 'xgboost__reg_alpha': 0.15833389588615623}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:25,268] Trial 214 finished with value: 0.816648245033724 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 290, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.014110713451405589, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.05470775266676766, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5420600312439035, 'xgboost__reg_lambda': 0.7807039098200867, 'xgboost__reg_alpha': 0.1870100117680451}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:25,515] Trial 215 finished with value: 0.7975312513403748 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.010675015430210825, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.07603646523965402, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5322749591806765, 'xgboost__reg_lambda': 0.5130873591502731, 'xgboost__reg_alpha': 0.08953923506444944}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:26,135] Trial 216 finished with value: 0.841143726891318 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007632774266929996, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.12312491750905097, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5666607512586797, 'xgboost__reg_lambda': 0.4208931991837074, 'xgboost__reg_alpha': 0.13858206400757805}. Best is trial 181 with value: 0.8430936814106018.\n",
      "[I 2024-01-07 21:23:26,778] Trial 217 finished with value: 0.8441706327668782 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.012448856495061443, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.13178100232377266, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5655277836517807, 'xgboost__reg_lambda': 0.2426992798764932, 'xgboost__reg_alpha': 0.1076052096653588}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:27,104] Trial 218 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.015604577478567663, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.12563218901995454, 'xgboost__min_child_weight': 292, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5711833071012741, 'xgboost__reg_lambda': 0.2661118574627397, 'xgboost__reg_alpha': 0.12003326775665346}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:27,417] Trial 219 finished with value: 0.7899764470440789 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.012109971966934151, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.14396485846821405, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5651481232945131, 'xgboost__reg_lambda': 0.2011553162728601, 'xgboost__reg_alpha': 0.10647915264976528}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:27,764] Trial 220 finished with value: 0.8221598114348577 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.013529280214955003, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.1837386707000177, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5495695276360951, 'xgboost__reg_lambda': 0.3252695553376158, 'xgboost__reg_alpha': 0.13359771350502966}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:28,409] Trial 221 finished with value: 0.8298773245431845 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009985358572355366, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.12594182727220882, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5588168863850448, 'xgboost__reg_lambda': 0.8268942139761695, 'xgboost__reg_alpha': 0.14019006388824004}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:29,185] Trial 222 finished with value: 0.836320746795232 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 310, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00873277939974594, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.10165541777385478, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5870168362292099, 'xgboost__reg_lambda': 0.6584605232656248, 'xgboost__reg_alpha': 0.08395951006392777}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:29,590] Trial 223 finished with value: 0.7971283942905023 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 270, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.02435776370761611, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.10584000942171223, 'xgboost__min_child_weight': 12, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5928203189073409, 'xgboost__reg_lambda': 0.659302580908541, 'xgboost__reg_alpha': 0.08660503867461794}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:30,014] Trial 224 finished with value: 0.8019325823785515 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 300, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.02071332261648614, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.14747792704629129, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5841539529948823, 'xgboost__reg_lambda': 0.4325057998477156, 'xgboost__reg_alpha': 0.11567999537256056}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:30,333] Trial 225 finished with value: 0.7905395983113641 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.010907400782308703, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.9033814012149844, 'xgboost__min_child_weight': 20, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5684579794179603, 'xgboost__reg_lambda': 0.5815090588831606, 'xgboost__reg_alpha': 0.07226505136052869}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:30,683] Trial 226 finished with value: 0.8343143860458349 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00883161244857282, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.09450154596197818, 'xgboost__min_child_weight': 7, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5769549751049318, 'xgboost__reg_lambda': 0.7337510859042237, 'xgboost__reg_alpha': 0.06265458188656747}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:31,112] Trial 227 finished with value: 0.7705691213173758 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 250, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.05334635360428579, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.11197257153309886, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5462188624040863, 'xgboost__reg_lambda': 0.10009326834128818, 'xgboost__reg_alpha': 0.16575690392366582}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:31,482] Trial 228 finished with value: 0.8058345909773162 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 220, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.012409064427875198, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.3825501219109471, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5382215954277817, 'xgboost__reg_lambda': 0.41461671575101944, 'xgboost__reg_alpha': 0.5175018807159101}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:31,839] Trial 229 finished with value: 0.8181483434176061 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.007683967372414358, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.09143302099845318, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5553118859845922, 'xgboost__reg_lambda': 0.6332826246256333, 'xgboost__reg_alpha': 0.028838400471877017}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:32,135] Trial 230 finished with value: 0.7887606220939554 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.014803832145147484, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.12198078723606005, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5313895629851241, 'xgboost__reg_lambda': 0.808696114783109, 'xgboost__reg_alpha': 0.09539945309147921}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:32,729] Trial 231 finished with value: 0.8424166030139313 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 320, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.00561334480203614, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.2600631882030452, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5619885765801446, 'xgboost__reg_lambda': 0.9096694916771184, 'xgboost__reg_alpha': 0.1479549899308707}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:33,144] Trial 232 finished with value: 0.8301881376171062 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.005676836628039986, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.2594931505785489, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5646071583845538, 'xgboost__reg_lambda': 0.742248361073252, 'xgboost__reg_alpha': 0.1252447534112712}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:33,468] Trial 233 finished with value: 0.7890443887760493 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 310, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0404418161482457, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.15125172366807754, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5765488640940762, 'xgboost__reg_lambda': 0.8721847036377578, 'xgboost__reg_alpha': 0.14854043050109217}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:33,826] Trial 234 finished with value: 0.8265643452265937 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 330, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009846560677302767, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.19842034514171014, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5470983280209839, 'xgboost__reg_lambda': 0.026398400797590177, 'xgboost__reg_alpha': 0.16597024079797396}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:34,186] Trial 235 finished with value: 0.8069317513761957 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 310, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.005170706522620819, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.28157417439497834, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5550328105163123, 'xgboost__reg_lambda': 0.9284414550383955, 'xgboost__reg_alpha': 0.1980278250672745}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:34,771] Trial 236 finished with value: 0.8336108941149343 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 340, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.008082581133979373, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.352866023975816, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5949449922106336, 'xgboost__reg_lambda': 0.5298309062419799, 'xgboost__reg_alpha': 0.10306997020688397}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:35,142] Trial 237 finished with value: 0.8181483434176061 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 290, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.011521335744044757, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.16369126992721064, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5252408102204364, 'xgboost__reg_lambda': 0.31005104096493524, 'xgboost__reg_alpha': 0.04000989395206785}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:35,834] Trial 238 finished with value: 0.8322348731670277 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 400, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.003699254144764589, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.13364518757261173, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5396466537677269, 'xgboost__reg_lambda': 0.7023692897769808, 'xgboost__reg_alpha': 0.14334624860592513}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:36,378] Trial 239 finished with value: 0.8299829922699407 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.009432536211169794, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.23614052757203757, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6364554727790718, 'xgboost__reg_lambda': 1.034016305260546, 'xgboost__reg_alpha': 0.019204432997009843}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:36,719] Trial 240 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 360, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.09536296494222007, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.06987777193070116, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5000146412491189, 'xgboost__reg_lambda': 0.8463447541831074, 'xgboost__reg_alpha': 0.16992691520342917}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:36,953] Trial 241 finished with value: 0.8125381575871466 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006663372345539977, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.2159558217599315, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5613523281957908, 'xgboost__reg_lambda': 1.0098440912527376, 'xgboost__reg_alpha': 0.20988011248472457}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:37,331] Trial 242 finished with value: 0.830450448445006 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 320, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.006975878884995731, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.08407128975960569, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5705784078682131, 'xgboost__reg_lambda': 0.9405263544267655, 'xgboost__reg_alpha': 0.3292798732587537}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:38,174] Trial 243 finished with value: 0.8430936814106018 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010910623277215068, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.04687401412359843, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5493684387514872, 'xgboost__reg_lambda': 0.8108607619064578, 'xgboost__reg_alpha': 0.36312106505123687}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:38,399] Trial 244 finished with value: 0.7836640737002963 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.031468248530167685, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.034343049023243824, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5486444700760219, 'xgboost__reg_lambda': 0.7492799999066665, 'xgboost__reg_alpha': 0.30313634039104564}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:38,715] Trial 245 finished with value: 0.8294337680869773 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012744671790122305, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.45786609360952346, 'xgboost__min_child_weight': 1, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5321450295329502, 'xgboost__reg_lambda': 0.6145852606743305, 'xgboost__reg_alpha': 0.3594990116957632}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:38,959] Trial 246 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.010547692700550854, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.053175107849922604, 'xgboost__min_child_weight': 419, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5195700592026341, 'xgboost__reg_lambda': 0.8085735611281759, 'xgboost__reg_alpha': 0.9156931940386867}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:39,186] Trial 247 finished with value: 0.7793318132586108 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009185108481827405, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.015283518746350738, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5419945960138378, 'xgboost__reg_lambda': 1.3605057502951574, 'xgboost__reg_alpha': 0.18941927771692357}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:39,492] Trial 248 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 270, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.04563990687306094, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.10525994069061094, 'xgboost__min_child_weight': 181, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5811424402097959, 'xgboost__reg_lambda': 0.4147627200988209, 'xgboost__reg_alpha': 0.12035493832635775}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:40,181] Trial 249 finished with value: 0.8199046891587786 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 380, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013527902210104227, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.05681913170653289, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6854917426816498, 'xgboost__reg_lambda': 0.6556559345501773, 'xgboost__reg_alpha': 0.36672704008881446}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:40,694] Trial 250 finished with value: 0.8422206603780747 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01137302812312973, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.07519535954177065, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6102298612613218, 'xgboost__reg_lambda': 0.5319280291804067, 'xgboost__reg_alpha': 0.34230387139667023}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:40,929] Trial 251 finished with value: 0.7812216903838729 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.011802470084523857, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.027157099288057637, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5900511429262458, 'xgboost__reg_lambda': 0.515269369803175, 'xgboost__reg_alpha': 0.3920199996319459}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:41,178] Trial 252 finished with value: 0.8107217582139212 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 9, 'fs_mb__threshold': 0.016762153692022125, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.09574779713902956, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.608379443916427, 'xgboost__reg_lambda': 0.24629947049879727, 'xgboost__reg_alpha': 0.83792941959159}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:41,642] Trial 253 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008030901784821368, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.00043210186598976325, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5138925283706621, 'xgboost__reg_lambda': 0.4521652242217738, 'xgboost__reg_alpha': 0.4117254532835532}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:42,001] Trial 254 finished with value: 0.7854577251989087 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.004322939863824003, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.04503064291761955, 'xgboost__min_child_weight': 21, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6000120632707683, 'xgboost__reg_lambda': 0.5729472982243216, 'xgboost__reg_alpha': 0.21901677177951717}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:42,267] Trial 255 finished with value: 0.8266849834247955 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01543599708258022, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.07251355817322086, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5253185425202757, 'xgboost__reg_lambda': 0.3586785369539395, 'xgboost__reg_alpha': 0.0020131806706350005}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:42,564] Trial 256 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 210, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.011194434978893851, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.12264760518427997, 'xgboost__min_child_weight': 350, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5332588682711231, 'xgboost__reg_lambda': 0.16225020043335608, 'xgboost__reg_alpha': 0.1527049200754613}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:42,973] Trial 257 finished with value: 0.8271746126974008 and parameters: {'knn_imputer__n_neighbors': 2, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00603338395308114, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.16908832178355926, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.549140784365918, 'xgboost__reg_lambda': 0.7132332312962838, 'xgboost__reg_alpha': 0.29040627532217306}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:43,213] Trial 258 finished with value: 0.7879171507698155 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.01890035566076452, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.03392908501851056, 'xgboost__min_child_weight': 13, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5392840835077888, 'xgboost__reg_lambda': 1.2068439612311908, 'xgboost__reg_alpha': 0.24101110016654875}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:43,528] Trial 259 finished with value: 0.7763949608443991 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013687554930972377, 'xgboost__n_estimators': 455, 'xgboost__learning_rate': 0.776483084125839, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5099656702088439, 'xgboost__reg_lambda': 0.8831457246312475, 'xgboost__reg_alpha': 0.05463227328219635}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:43,764] Trial 260 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.08654501089975572, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.06224763332314075, 'xgboost__min_child_weight': 161, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5698678342493315, 'xgboost__reg_lambda': 0.5845942814960233, 'xgboost__reg_alpha': 0.17684014648583068}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:44,046] Trial 261 finished with value: 0.8117584992659643 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.008610861863614434, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.2977118336327346, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5231886789015541, 'xgboost__reg_lambda': 0.6421243327451731, 'xgboost__reg_alpha': 0.2637376051428995}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:44,320] Trial 262 finished with value: 0.7680266197086469 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0029519318192181955, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.0870380926114164, 'xgboost__min_child_weight': 34, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5571853155896472, 'xgboost__reg_lambda': 0.4922031774857398, 'xgboost__reg_alpha': 0.20423710801066822}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:44,606] Trial 263 finished with value: 0.8241668931324104 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 190, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.0106021737183383, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.11075402437126662, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5368853603052656, 'xgboost__reg_lambda': 1.0969359930820608, 'xgboost__reg_alpha': 0.0817090113279563}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:45,281] Trial 264 finished with value: 0.7980953128800914 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.023388126336685588, 'xgboost__n_estimators': 465, 'xgboost__learning_rate': 0.013712178679100732, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5787043675976488, 'xgboost__reg_lambda': 0.3187040330360263, 'xgboost__reg_alpha': 0.34417457478655333}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:45,506] Trial 265 finished with value: 0.7906392011470801 and parameters: {'knn_imputer__n_neighbors': 7, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012839793618878492, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.13455428445949613, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.54941817698787, 'xgboost__reg_lambda': 0.7596508462196684, 'xgboost__reg_alpha': 0.13678471617656085}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:45,880] Trial 266 finished with value: 0.8158751977103262 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.006980851997480077, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.05063971317612747, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5890600736310865, 'xgboost__reg_lambda': 0.9556128748509636, 'xgboost__reg_alpha': 0.10915955362344985}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:46,132] Trial 267 finished with value: 0.7919443994310305 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 150, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0051125637849104705, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.07845903135491505, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5154794283415394, 'xgboost__reg_lambda': 0.8455678977713083, 'xgboost__reg_alpha': 0.22870217423371375}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:46,796] Trial 268 finished with value: 0.8377126792460198 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009333219892574275, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.1882521109712161, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5615894810219049, 'xgboost__reg_lambda': 1.5946584782856026, 'xgboost__reg_alpha': 0.1897831171679617}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:47,410] Trial 269 finished with value: 0.8339520788661303 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00902758656994226, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.22030854535629987, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5632199891178044, 'xgboost__reg_lambda': 1.292655288973198, 'xgboost__reg_alpha': 0.19356836148318524}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:47,625] Trial 270 finished with value: 0.7854577251989087 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0010370712776251777, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.15366841290894884, 'xgboost__min_child_weight': 28, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5697556740382382, 'xgboost__reg_lambda': 1.079888161827171, 'xgboost__reg_alpha': 0.16708358502856485}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:47,864] Trial 271 finished with value: 0.816294439042688 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0148281047712465, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.258033438510866, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5596014665506788, 'xgboost__reg_lambda': 1.6174763202891684, 'xgboost__reg_alpha': 0.20863479374407007}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:48,580] Trial 272 finished with value: 0.8419122361403112 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011539790789436188, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.11304242185353798, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6326441705187609, 'xgboost__reg_lambda': 1.1632177006493891, 'xgboost__reg_alpha': 0.17777052877783986}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:48,806] Trial 273 finished with value: 0.8054162864704432 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010269255866297271, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.18832714468069892, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6242777127809973, 'xgboost__reg_lambda': 1.3467082469406966, 'xgboost__reg_alpha': 0.1789115521059387}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:49,524] Trial 274 finished with value: 0.8314615624133674 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.017247163260461093, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.11956382835506629, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6162983806231607, 'xgboost__reg_lambda': 1.4820366295509446, 'xgboost__reg_alpha': 0.15452373853142257}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:49,748] Trial 275 finished with value: 0.8113012273027473 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01245944301564713, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.14010540163510646, 'xgboost__min_child_weight': 14, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.633620189408723, 'xgboost__reg_lambda': 1.194890187712644, 'xgboost__reg_alpha': 0.18998440276661577}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:50,034] Trial 276 finished with value: 0.8230983487077738 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007590599788785324, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.17519245914518952, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5951920338442888, 'xgboost__reg_lambda': 1.8624303312800525, 'xgboost__reg_alpha': 0.13526873707436698}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:50,261] Trial 277 finished with value: 0.7847609833004587 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009523848978505816, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.11051392431070588, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6081102422593029, 'xgboost__reg_lambda': 1.1549185239994486, 'xgboost__reg_alpha': 0.15614322565576247}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:50,593] Trial 278 finished with value: 0.8316929234765538 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02082908176806015, 'xgboost__n_estimators': 95, 'xgboost__learning_rate': 0.19622833377629134, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6224700021515498, 'xgboost__reg_lambda': 1.4630388144488142, 'xgboost__reg_alpha': 0.21899779260282032}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:50,996] Trial 279 finished with value: 0.698604409616048 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.0253059024193115, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.09220603799861832, 'xgboost__min_child_weight': 38, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5798282327298946, 'xgboost__reg_lambda': 1.2419844825779598, 'xgboost__reg_alpha': 0.1782677637441045}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:51,225] Trial 280 finished with value: 0.8072225594892407 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01465969788843274, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.5863883842511539, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.640096252233623, 'xgboost__reg_lambda': 0.9975730037773519, 'xgboost__reg_alpha': 0.11977149649857552}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:51,545] Trial 281 finished with value: 0.8199916193458224 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011866637185919023, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.1561385662488388, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6014913868042638, 'xgboost__reg_lambda': 1.1135167234767906, 'xgboost__reg_alpha': 0.19763263495604247}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:51,812] Trial 282 finished with value: 0.818288707177596 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008151675684346759, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.06047523530434459, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.7123529303534778, 'xgboost__reg_lambda': 1.570301126272946, 'xgboost__reg_alpha': 0.3770149823161018}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:52,016] Trial 283 finished with value: 0.7926485741831626 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003722285847005919, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.1327395431466635, 'xgboost__min_child_weight': 21, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5523440225965836, 'xgboost__reg_lambda': 0.9186530698279255, 'xgboost__reg_alpha': 0.4136550504314719}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:52,584] Trial 284 finished with value: 0.7961645174882984 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03744532120197562, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.033895313409187805, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5738872138839533, 'xgboost__reg_lambda': 2.177815526062727, 'xgboost__reg_alpha': 0.31080994800954903}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:52,800] Trial 285 finished with value: 0.7685704913749558 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.046649972012846756, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.07644330888735552, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5867804691692756, 'xgboost__reg_lambda': 2.772291738955607, 'xgboost__reg_alpha': 0.16648609082398408}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:53,037] Trial 286 finished with value: 0.7895358849776961 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005410324665028993, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.23567043340715968, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.543110053357288, 'xgboost__reg_lambda': 1.3100928703100005, 'xgboost__reg_alpha': 0.23479461489510856}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:53,301] Trial 287 finished with value: 0.8413588024167761 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010481803502830359, 'xgboost__n_estimators': 45, 'xgboost__learning_rate': 0.10809738869063583, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5620490015272609, 'xgboost__reg_lambda': 1.036462963576902, 'xgboost__reg_alpha': 0.13914339597038614}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:53,571] Trial 288 finished with value: 0.8193549518567049 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011252036311418282, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.10788072270882676, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5641927014551485, 'xgboost__reg_lambda': 0.9940279427901342, 'xgboost__reg_alpha': 0.0898490508300077}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:54,124] Trial 289 finished with value: 0.8288041288041289 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.013621586585054388, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.1372951446636852, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5677532710223696, 'xgboost__reg_lambda': 0.8439458735854385, 'xgboost__reg_alpha': 0.1295558338021007}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:54,350] Trial 290 finished with value: 0.8037475645929483 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009695533109029607, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.1224856062322622, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5534297058611787, 'xgboost__reg_lambda': 0.7958147054892434, 'xgboost__reg_alpha': 0.1463520018346043}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:54,641] Trial 291 finished with value: 0.7868648656789576 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.008316040739441071, 'xgboost__n_estimators': 145, 'xgboost__learning_rate': 0.42351313624156606, 'xgboost__min_child_weight': 29, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5854036441692182, 'xgboost__reg_lambda': 4.631246690665893, 'xgboost__reg_alpha': 0.10538718813350338}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:54,894] Trial 292 finished with value: 0.8062783562783562 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02935553769882141, 'xgboost__n_estimators': 125, 'xgboost__learning_rate': 0.3226872758444521, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5735925698352984, 'xgboost__reg_lambda': 1.0374838363309935, 'xgboost__reg_alpha': 0.4361560818495976}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:55,153] Trial 293 finished with value: 0.76699311085276 and parameters: {'knn_imputer__n_neighbors': 8, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 100, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.06304025779204867, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.9683642581373981, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6130787045976854, 'xgboost__reg_lambda': 1.810515744245055, 'xgboost__reg_alpha': 0.27898929644585274}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:55,483] Trial 294 finished with value: 0.7825352736490705 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 290, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0343705196092702, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.097338839900326, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.66189931570148, 'xgboost__reg_lambda': 0.10907223191328558, 'xgboost__reg_alpha': 0.2482855381870737}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:55,663] Trial 295 finished with value: 0.8073805470574537 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012412191788674962, 'xgboost__n_estimators': 60, 'xgboost__learning_rate': 0.1786778239942558, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6459607902443818, 'xgboost__reg_lambda': 0.6696567331260878, 'xgboost__reg_alpha': 0.33230252245539493}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:55,926] Trial 296 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 120, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.026516448491991022, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.04665770231114884, 'xgboost__min_child_weight': 195, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.559378681200603, 'xgboost__reg_lambda': 0.9293856233959119, 'xgboost__reg_alpha': 0.4856224074866434}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:56,249] Trial 297 finished with value: 0.7920877747784719 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 240, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.01623416128342146, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.49189414519632557, 'xgboost__min_child_weight': 35, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.7636671819661973, 'xgboost__reg_lambda': 0.5498870211636626, 'xgboost__reg_alpha': 0.13712563861417632}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:56,575] Trial 298 finished with value: 0.7747051016887347 and parameters: {'knn_imputer__n_neighbors': 9, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 110, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0312669542273283, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.15930431481506457, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5081281215733515, 'xgboost__reg_lambda': 0.20011371849607557, 'xgboost__reg_alpha': 0.07288076486418867}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:56,839] Trial 299 finished with value: 0.7872728299774563 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.010260436598409129, 'xgboost__n_estimators': 175, 'xgboost__learning_rate': 0.08205361585647122, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5459815176856258, 'xgboost__reg_lambda': 0.4391753921861713, 'xgboost__reg_alpha': 0.21037279806711948}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:57,190] Trial 300 finished with value: 0.8032096761263428 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006626117921869568, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.021078672022101053, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5275606067338722, 'xgboost__reg_lambda': 0.7642516042639639, 'xgboost__reg_alpha': 0.16530244729831217}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:57,361] Trial 301 finished with value: 0.7833282360534863 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.013836356878641468, 'xgboost__n_estimators': 45, 'xgboost__learning_rate': 0.29538926925930825, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5538490086933594, 'xgboost__reg_lambda': 0.8730759197713918, 'xgboost__reg_alpha': 0.22224958572679215}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:58,258] Trial 302 finished with value: 0.8309507075479371 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 140, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.011037748103663206, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.10289084422051856, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6688311341906557, 'xgboost__reg_lambda': 0.6228322018109921, 'xgboost__reg_alpha': 0.11142250410469531}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:58,560] Trial 303 finished with value: 0.8051010269042874 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 320, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008260659417731776, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.06246900715172729, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6026405251616588, 'xgboost__reg_lambda': 1.0468256761834356, 'xgboost__reg_alpha': 0.35189711590227907}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:58,964] Trial 304 finished with value: 0.7874839707995865 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.018714679942832275, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.12136159195218844, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.8415002636665916, 'xgboost__reg_lambda': 0.3469843436949646, 'xgboost__reg_alpha': 0.3138065981937931}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:59,437] Trial 305 finished with value: 0.8413588024167761 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012538830220671695, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.013504638125174159, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5805044935156658, 'xgboost__reg_lambda': 0.7570927284954254, 'xgboost__reg_alpha': 0.18987012625938904}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:59,641] Trial 306 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.016186942106493366, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.004362214171176056, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 2, 'xgboost__subsample': 0.5621782221076325, 'xgboost__reg_lambda': 0.7880234687275721, 'xgboost__reg_alpha': 0.19131616215320735}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:23:59,885] Trial 307 finished with value: 0.8063200967644926 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013019729519517603, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.024042447704748608, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.542534786317215, 'xgboost__reg_lambda': 0.9332158721836087, 'xgboost__reg_alpha': 0.24467845556864548}. Best is trial 217 with value: 0.8441706327668782.\n",
      "[I 2024-01-07 21:24:00,364] Trial 308 finished with value: 0.8483753149839316 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014786397422246855, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.042289699821556635, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5762647144791538, 'xgboost__reg_lambda': 1.1767648359962473, 'xgboost__reg_alpha': 0.17598211062914615}. Best is trial 308 with value: 0.8483753149839316.\n",
      "[I 2024-01-07 21:24:00,596] Trial 309 finished with value: 0.8175631404471531 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014573628773102443, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.03860975853795915, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6279450463703858, 'xgboost__reg_lambda': 1.1986596053459169, 'xgboost__reg_alpha': 0.1748077156217706}. Best is trial 308 with value: 0.8483753149839316.\n",
      "[I 2024-01-07 21:24:01,078] Trial 310 finished with value: 0.8494535614900911 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014895086882852264, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.01989443319536055, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5217780906850982, 'xgboost__reg_lambda': 0.01884598643476665, 'xgboost__reg_alpha': 0.15666753885860543}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:01,270] Trial 311 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.020629581874102243, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.011913145505008202, 'xgboost__min_child_weight': 99, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5771204223288919, 'xgboost__reg_lambda': 0.25857847859266986, 'xgboost__reg_alpha': 0.1606819582911032}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:01,500] Trial 312 finished with value: 0.7887689710746011 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01771804299140449, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.03398839251604778, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5063309360355646, 'xgboost__reg_lambda': 0.022593367332130385, 'xgboost__reg_alpha': 0.14876508266319208}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:01,707] Trial 313 finished with value: 0.7014478973121837 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015029830688143151, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.017605773238403448, 'xgboost__min_child_weight': 40, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5198221645138739, 'xgboost__reg_lambda': 0.05546494174594967, 'xgboost__reg_alpha': 0.1902204557153022}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:01,925] Trial 314 finished with value: 0.7819464486131154 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01548807088587929, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.04987017296184043, 'xgboost__min_child_weight': 30, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.580318658136653, 'xgboost__reg_lambda': 0.0052695767268836, 'xgboost__reg_alpha': 0.17083655834758835}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:02,246] Trial 315 finished with value: 0.7653783156366818 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012764750867125942, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.0009550794691439782, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5912686117040656, 'xgboost__reg_lambda': 0.16455830866727697, 'xgboost__reg_alpha': 0.20407940146460674}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:02,783] Trial 316 finished with value: 0.842772866949383 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01850516445652279, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.03653244038313204, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6580899747063379, 'xgboost__reg_lambda': 1.7270061505257428, 'xgboost__reg_alpha': 0.1410496144219892}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:02,986] Trial 317 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01702627911736749, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.03201045708993177, 'xgboost__min_child_weight': 125, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6457643563192975, 'xgboost__reg_lambda': 1.430979367872213, 'xgboost__reg_alpha': 0.15886261070135457}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:03,203] Trial 318 finished with value: 0.8031404535636645 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011482355997812504, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.04961017423322252, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6286506643302108, 'xgboost__reg_lambda': 1.7433285779671037, 'xgboost__reg_alpha': 0.14023930506228907}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:03,417] Trial 319 finished with value: 0.7918684719810437 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.018690224868945324, 'xgboost__n_estimators': 210, 'xgboost__learning_rate': 0.01833676854376334, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6347903066192724, 'xgboost__reg_lambda': 1.5112037993169498, 'xgboost__reg_alpha': 0.18528603945205896}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:03,927] Trial 320 finished with value: 0.8408360365388119 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01391200089081485, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.040328020964385446, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6142301614825284, 'xgboost__reg_lambda': 1.08316565883607, 'xgboost__reg_alpha': 0.13014866825404875}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:04,223] Trial 321 finished with value: 0.8389741379263068 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014117719662893526, 'xgboost__n_estimators': 100, 'xgboost__learning_rate': 0.034734137576739293, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6071896575278755, 'xgboost__reg_lambda': 1.127625553364406, 'xgboost__reg_alpha': 0.1254238672716365}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:04,452] Trial 322 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014448719733617204, 'xgboost__n_estimators': 110, 'xgboost__learning_rate': 0.00042667494124380874, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6056440807674236, 'xgboost__reg_lambda': 1.1777464188746014, 'xgboost__reg_alpha': 0.12721008253815128}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:04,662] Trial 323 finished with value: 0.7653783156366818 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.016856362831423992, 'xgboost__n_estimators': 35, 'xgboost__learning_rate': 0.030138125258075948, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6182998778359149, 'xgboost__reg_lambda': 1.020477265391678, 'xgboost__reg_alpha': 0.12516716639974387}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:05,240] Trial 324 finished with value: 0.8438492049834518 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013677707377188061, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.03720404831289152, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6086163732858537, 'xgboost__reg_lambda': 1.0890542355058588, 'xgboost__reg_alpha': 0.14711614006493057}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:05,446] Trial 325 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01967183886364995, 'xgboost__n_estimators': 60, 'xgboost__learning_rate': 0.03995690223320449, 'xgboost__min_child_weight': 22, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.609535459521988, 'xgboost__reg_lambda': 1.1475039074522553, 'xgboost__reg_alpha': 0.14174151842612873}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:05,665] Trial 326 finished with value: 0.780804034440973 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013501578160259398, 'xgboost__n_estimators': 70, 'xgboost__learning_rate': 0.02296357094719637, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6057350656917471, 'xgboost__reg_lambda': 1.2983509405069047, 'xgboost__reg_alpha': 0.11974742395365497}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:05,936] Trial 327 finished with value: 0.8085986838613808 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.021765046807067107, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.05065002534641873, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6159527049825235, 'xgboost__reg_lambda': 1.078825954390164, 'xgboost__reg_alpha': 0.14741515442087985}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:06,206] Trial 328 finished with value: 0.7826579574026585 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01605430883169054, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.023728679148590025, 'xgboost__min_child_weight': 32, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6253620106829123, 'xgboost__reg_lambda': 1.2830539961300402, 'xgboost__reg_alpha': 0.3786574946186514}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:06,414] Trial 329 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011781023763017092, 'xgboost__n_estimators': 35, 'xgboost__learning_rate': 0.0001314817271862584, 'xgboost__min_child_weight': 495, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5943531186295218, 'xgboost__reg_lambda': 1.2074421294860522, 'xgboost__reg_alpha': 0.16123067334502972}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:06,708] Trial 330 finished with value: 0.7810087406047 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.05544428546685071, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.04260466892504977, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6192736227150514, 'xgboost__reg_lambda': 1.068553784696065, 'xgboost__reg_alpha': 0.11985135831133756}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:06,981] Trial 331 finished with value: 0.8231908107142042 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015109264378214044, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.06315189640557219, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6049049318737894, 'xgboost__reg_lambda': 0.9367845873337115, 'xgboost__reg_alpha': 0.13718700113314197}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:07,535] Trial 332 finished with value: 0.847709043969658 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012342921069559814, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.018246075872017473, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6174469264940462, 'xgboost__reg_lambda': 1.1152280230600773, 'xgboost__reg_alpha': 0.10737683205319622}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:07,805] Trial 333 finished with value: 0.7984269526147151 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011756925628695453, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.022271545816076755, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6145141096851445, 'xgboost__reg_lambda': 0.9724373813869649, 'xgboost__reg_alpha': 0.05290019746931092}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:08,086] Trial 334 finished with value: 0.8164453086732879 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012634956232510819, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.014677973996866354, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6380508820770819, 'xgboost__reg_lambda': 0.8575162192015808, 'xgboost__reg_alpha': 0.45568543316224164}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:08,319] Trial 335 finished with value: 0.7774731941267188 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03226692090102471, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.06254053725128986, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6345997813565343, 'xgboost__reg_lambda': 1.3438031210559114, 'xgboost__reg_alpha': 0.17390336133966483}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:08,968] Trial 336 finished with value: 0.8303894560579054 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 460, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010197952857616412, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.3130778939485399, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.625669320970335, 'xgboost__reg_lambda': 1.953688494296242, 'xgboost__reg_alpha': 0.0983750208426758}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:09,225] Trial 337 finished with value: 0.8143705834813479 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005804727889749519, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.044273204406163495, 'xgboost__min_child_weight': 15, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.653736998956946, 'xgboost__reg_lambda': 2.154732671324502, 'xgboost__reg_alpha': 0.09189748475802303}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:09,462] Trial 338 finished with value: 0.8307162756393022 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.017687706642617634, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.071722552484179, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5966342293476035, 'xgboost__reg_lambda': 1.429417566981435, 'xgboost__reg_alpha': 0.5258959609344256}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:09,931] Trial 339 finished with value: 0.7786883458613796 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 420, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03520167092162116, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.023628055421889525, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6270446039905293, 'xgboost__reg_lambda': 1.0304182700151518, 'xgboost__reg_alpha': 0.1724158169740299}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:10,185] Trial 340 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011269938098533005, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.00221373401083055, 'xgboost__min_child_weight': 32, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6472560317415227, 'xgboost__reg_lambda': 1.1283274819005589, 'xgboost__reg_alpha': 0.35642580658671735}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:10,439] Trial 341 finished with value: 0.7845364992459607 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04922244264208889, 'xgboost__n_estimators': 270, 'xgboost__learning_rate': 0.051737405081343786, 'xgboost__min_child_weight': 20, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6152851730181519, 'xgboost__reg_lambda': 1.239049939625161, 'xgboost__reg_alpha': 0.20522737097629798}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:10,755] Trial 342 finished with value: 0.7975214730294302 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03998086871692631, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.03891685673591862, 'xgboost__min_child_weight': 15, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5940585804304168, 'xgboost__reg_lambda': 0.8803971437641809, 'xgboost__reg_alpha': 0.07249153382405057}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:11,046] Trial 343 finished with value: 0.8233561626751421 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014377782885873781, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.26611690145626765, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.9980639127854269, 'xgboost__reg_lambda': 0.109625990869252, 'xgboost__reg_alpha': 0.10597895470791478}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:11,284] Trial 344 finished with value: 0.6715094130188469 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.037497309117896865, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.06449908222201374, 'xgboost__min_child_weight': 44, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5818130203115239, 'xgboost__reg_lambda': 0.9536802673917459, 'xgboost__reg_alpha': 0.1444857942152481}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:11,818] Trial 345 finished with value: 0.7797203838600735 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04408257829810083, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.02086133879762249, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6709798608715154, 'xgboost__reg_lambda': 1.7611345070839557, 'xgboost__reg_alpha': 0.029657701271299616}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:12,107] Trial 346 finished with value: 0.7851599776733467 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007341042327352528, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.07027454428155777, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6020191335609549, 'xgboost__reg_lambda': 1.1413086623587254, 'xgboost__reg_alpha': 0.22613399634703263}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:12,444] Trial 347 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010228717590694394, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.00030120272422801825, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6789787837676109, 'xgboost__reg_lambda': 1.0024993411372363, 'xgboost__reg_alpha': 0.18438500903792907}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:12,919] Trial 348 finished with value: 0.7885189129650848 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02808621629157223, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.2204314818934126, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7112470969216472, 'xgboost__reg_lambda': 1.3843615740891115, 'xgboost__reg_alpha': 0.16152133554358059}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:13,184] Trial 349 finished with value: 0.8029822757194673 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0126826599726803, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.0430360669047643, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6383505374081672, 'xgboost__reg_lambda': 0.8326357335956224, 'xgboost__reg_alpha': 0.20176233428591106}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:13,444] Trial 350 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004014276298538239, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.07954863138191956, 'xgboost__min_child_weight': 384, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6783755691888996, 'xgboost__reg_lambda': 0.6891652876606343, 'xgboost__reg_alpha': 0.10202497972701141}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:13,716] Trial 351 finished with value: 0.812846100705431 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00844990562356882, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.03149308735305227, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7225135072904281, 'xgboost__reg_lambda': 1.2379539762349634, 'xgboost__reg_alpha': 0.1493626080867401}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:14,052] Trial 352 finished with value: 0.8102658928306273 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.022801522152070923, 'xgboost__n_estimators': 280, 'xgboost__learning_rate': 0.253048521660342, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6497420516467022, 'xgboost__reg_lambda': 1.9005786462931755, 'xgboost__reg_alpha': 0.40463409946329}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:14,312] Trial 353 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.016866599885454123, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.3425273767399237, 'xgboost__min_child_weight': 326, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6225134681803689, 'xgboost__reg_lambda': 2.097438892791105, 'xgboost__reg_alpha': 0.3237766378985528}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:14,605] Trial 354 finished with value: 0.7789616925097669 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.060245786197554815, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.052764758164750736, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5691778087255066, 'xgboost__reg_lambda': 0.8999294740422787, 'xgboost__reg_alpha': 0.17537079996754557}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:14,881] Trial 355 finished with value: 0.7824349290287218 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012938308650734257, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.018620274700475253, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6634790493218516, 'xgboost__reg_lambda': 1.7255903572740148, 'xgboost__reg_alpha': 0.2885601820582483}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:15,256] Trial 356 finished with value: 0.8054162864704432 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 440, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009762763522766891, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.07860156941979972, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6537365252627452, 'xgboost__reg_lambda': 1.5604676525271153, 'xgboost__reg_alpha': 0.686220208811904}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:15,570] Trial 357 finished with value: 0.8161920989962648 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.005781274565593372, 'xgboost__n_estimators': 295, 'xgboost__learning_rate': 0.05205161639745791, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5031004324268137, 'xgboost__reg_lambda': 0.19927182755317552, 'xgboost__reg_alpha': 0.2257641552813076}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:16,286] Trial 358 finished with value: 0.7972347107966655 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015434243922183025, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.3687029565820086, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.527869531170581, 'xgboost__reg_lambda': 0.5385797826391339, 'xgboost__reg_alpha': 0.13187072124840032}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:16,521] Trial 359 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010711234816099065, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.03324327245747095, 'xgboost__min_child_weight': 267, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.9476213855531406, 'xgboost__reg_lambda': 1.0673412494475607, 'xgboost__reg_alpha': 0.19862613920416008}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:16,849] Trial 360 finished with value: 0.7937664431418092 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 260, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007624351271174383, 'xgboost__n_estimators': 330, 'xgboost__learning_rate': 0.5635743175239643, 'xgboost__min_child_weight': 21, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.7003442470837631, 'xgboost__reg_lambda': 1.6590979540245145, 'xgboost__reg_alpha': 0.39058536474376426}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:17,209] Trial 361 finished with value: 0.7975276488053207 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02400817719233475, 'xgboost__n_estimators': 255, 'xgboost__learning_rate': 0.5095664748379056, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5859664607439655, 'xgboost__reg_lambda': 0.7766313283867338, 'xgboost__reg_alpha': 0.043831017598937594}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:17,433] Trial 362 finished with value: 0.7842255075173541 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.052275041132701705, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.6650880167327308, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5463896311403943, 'xgboost__reg_lambda': 0.4112502794269988, 'xgboost__reg_alpha': 0.07226102083527763}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:17,676] Trial 363 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.0029121365667962454, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.0007136417145930732, 'xgboost__min_child_weight': 36, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7597411668371109, 'xgboost__reg_lambda': 0.9721042653925117, 'xgboost__reg_alpha': 0.1560475996126038}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:18,099] Trial 364 finished with value: 0.7954168863448068 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02999951989937747, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.06930819323352137, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5156303925508091, 'xgboost__reg_lambda': 0.6882112539427042, 'xgboost__reg_alpha': 0.42261739146671606}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:18,476] Trial 365 finished with value: 0.7711471826879223 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 10, 'fs_mb__threshold': 0.02009192161971113, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.03652445573938532, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 3, 'xgboost__subsample': 0.5717403350389288, 'xgboost__reg_lambda': 0.008060929142955572, 'xgboost__reg_alpha': 0.3703583606355775}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:18,700] Trial 366 finished with value: 0.8266907716530778 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013196162049561071, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.4886525929162133, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6592580387880288, 'xgboost__reg_lambda': 0.8289755349717768, 'xgboost__reg_alpha': 0.26032405165851763}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:19,181] Trial 367 finished with value: 0.7903450085268269 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.03377420003927692, 'xgboost__n_estimators': 320, 'xgboost__learning_rate': 0.08709247312052035, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5377006349343301, 'xgboost__reg_lambda': 0.5739194166820643, 'xgboost__reg_alpha': 0.12273586670139469}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:19,592] Trial 368 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.08995475114300967, 'xgboost__n_estimators': 335, 'xgboost__learning_rate': 0.2857730601451093, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 1, 'xgboost__subsample': 0.6126939272746206, 'xgboost__reg_lambda': 1.0773690529011049, 'xgboost__reg_alpha': 0.9975959522361048}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:19,973] Trial 369 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.011414696689830956, 'xgboost__n_estimators': 310, 'xgboost__learning_rate': 0.015976017916771276, 'xgboost__min_child_weight': 237, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5966005591738086, 'xgboost__reg_lambda': 1.1631899646582553, 'xgboost__reg_alpha': 0.1839568589720777}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:20,268] Trial 370 finished with value: 0.8169392336059003 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00876273580317855, 'xgboost__n_estimators': 230, 'xgboost__learning_rate': 0.4564135307182422, 'xgboost__min_child_weight': 15, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5220829080212843, 'xgboost__reg_lambda': 2.062491687604142, 'xgboost__reg_alpha': 0.21423829051762702}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:21,000] Trial 371 finished with value: 0.8298773245431845 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006637546378952921, 'xgboost__n_estimators': 485, 'xgboost__learning_rate': 0.3869790215562393, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5541369926865753, 'xgboost__reg_lambda': 0.2780961129882993, 'xgboost__reg_alpha': 0.10407863613658284}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:21,231] Trial 372 finished with value: 0.7975776801974926 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04783257812967895, 'xgboost__n_estimators': 195, 'xgboost__learning_rate': 0.20754461820809578, 'xgboost__min_child_weight': 15, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6315551461739761, 'xgboost__reg_lambda': 1.852752804520542, 'xgboost__reg_alpha': 0.23513100673478332}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:21,558] Trial 373 finished with value: 0.8174108299565179 and parameters: {'knn_imputer__n_neighbors': 10, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015333612460380924, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.06316319270453015, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.577393957893666, 'xgboost__reg_lambda': 1.9532086929198518, 'xgboost__reg_alpha': 0.15218298243279224}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:21,831] Trial 374 finished with value: 0.7889696773040504 and parameters: {'knn_imputer__n_neighbors': 15, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00484618535591233, 'xgboost__n_estimators': 285, 'xgboost__learning_rate': 0.396869871087452, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5005516268153352, 'xgboost__reg_lambda': 0.8695130129427123, 'xgboost__reg_alpha': 0.1812968054376742}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:22,489] Trial 375 finished with value: 0.8275148716810447 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012191067396902977, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.2340225356069876, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5311414806824268, 'xgboost__reg_lambda': 0.9858034516367302, 'xgboost__reg_alpha': 0.45843083783851396}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:22,746] Trial 376 finished with value: 0.8146662261898195 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.018163552630911448, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.04925690547597453, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.545555909780188, 'xgboost__reg_lambda': 0.09246058088173725, 'xgboost__reg_alpha': 0.2957391027449086}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:23,178] Trial 377 finished with value: 0.8048087287663259 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009730903737440285, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.4080121259279034, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7405658144718987, 'xgboost__reg_lambda': 0.7555788996768114, 'xgboost__reg_alpha': 0.13649017457853405}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:23,522] Trial 378 finished with value: 0.8078441240863773 and parameters: {'knn_imputer__n_neighbors': 13, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.013372501907155101, 'xgboost__n_estimators': 340, 'xgboost__learning_rate': 0.025137041314202673, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5636370842523305, 'xgboost__reg_lambda': 1.3575748606554157, 'xgboost__reg_alpha': 0.16748584774414096}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:23,752] Trial 379 finished with value: 0.7194876734718031 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04190121327959192, 'xgboost__n_estimators': 300, 'xgboost__learning_rate': 0.08366315240592646, 'xgboost__min_child_weight': 37, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5909550858743601, 'xgboost__reg_lambda': 0.45948835597855836, 'xgboost__reg_alpha': 0.012228239606809927}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:24,946] Trial 380 finished with value: 0.8336065679627324 and parameters: {'knn_imputer__n_neighbors': 11, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007616871537572531, 'xgboost__n_estimators': 445, 'xgboost__learning_rate': 0.05195430760948036, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5115177721747464, 'xgboost__reg_lambda': 2.21277561232131, 'xgboost__reg_alpha': 0.2142531171495371}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:25,258] Trial 381 finished with value: 0.7779023233834869 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010689789686061487, 'xgboost__n_estimators': 315, 'xgboost__learning_rate': 0.016456140136182854, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5508474410233362, 'xgboost__reg_lambda': 0.620984550962544, 'xgboost__reg_alpha': 0.3473886639038759}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:25,492] Trial 382 finished with value: 0.8208303788194118 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014987486095022411, 'xgboost__n_estimators': 245, 'xgboost__learning_rate': 0.34923849862987255, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.617048523337726, 'xgboost__reg_lambda': 0.9051085785183752, 'xgboost__reg_alpha': 0.245009570178846}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:25,723] Trial 383 finished with value: 0.7838017311624617 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.037639738892599084, 'xgboost__n_estimators': 275, 'xgboost__learning_rate': 0.03595880084353681, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.6857953923636435, 'xgboost__reg_lambda': 0.7332232695392604, 'xgboost__reg_alpha': 0.08880222739586796}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:26,013] Trial 384 finished with value: 0.7631318487097914 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 9, 'fs_mb__threshold': 0.05161712760293857, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.28043923505825297, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.524674635264781, 'xgboost__reg_lambda': 1.6906310262570667, 'xgboost__reg_alpha': 0.06243107681801581}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:26,385] Trial 385 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 450, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.04963010383134978, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.06937549001872212, 'xgboost__min_child_weight': 481, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.5377596916081928, 'xgboost__reg_lambda': 1.242512286568485, 'xgboost__reg_alpha': 0.425400355645025}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:26,596] Trial 386 finished with value: 0.7716899636091555 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0978893139355095, 'xgboost__n_estimators': 325, 'xgboost__learning_rate': 0.09095432376614548, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5698799372552886, 'xgboost__reg_lambda': 1.4597453244909575, 'xgboost__reg_alpha': 0.1934668449553769}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:26,853] Trial 387 finished with value: 0.8044241500852451 and parameters: {'knn_imputer__n_neighbors': 14, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04438905679409591, 'xgboost__n_estimators': 290, 'xgboost__learning_rate': 0.3362032077820579, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.6039532167731974, 'xgboost__reg_lambda': 0.16215528384171302, 'xgboost__reg_alpha': 0.16291417852350681}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:27,080] Trial 388 finished with value: 0.7295452029262502 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009242228291198548, 'xgboost__n_estimators': 305, 'xgboost__learning_rate': 0.018016630989650798, 'xgboost__min_child_weight': 49, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.788909719807389, 'xgboost__reg_lambda': 1.0399073750176349, 'xgboost__reg_alpha': 0.2686176266827675}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:27,517] Trial 389 finished with value: 0.7848568647966473 and parameters: {'knn_imputer__n_neighbors': 12, 'knn_imputer__weights': 'distance', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.07104367563519659, 'xgboost__n_estimators': 350, 'xgboost__learning_rate': 0.7890219017068782, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6360323566726372, 'xgboost__reg_lambda': 0.34658849364871935, 'xgboost__reg_alpha': 0.11861299546550949}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:28,176] Trial 390 finished with value: 0.8440654385896077 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.002521171130845293, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.0541676651410419, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 7, 'xgboost__subsample': 0.5151625616641339, 'xgboost__reg_lambda': 0.5033231724666085, 'xgboost__reg_alpha': 0.33107385768725933}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:28,715] Trial 391 finished with value: 0.8419122361403112 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005727796673308964, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.06231811687820659, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5168013427676376, 'xgboost__reg_lambda': 0.38092870661532746, 'xgboost__reg_alpha': 0.14170876550505118}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:28,964] Trial 392 finished with value: 0.8171910913846397 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0013722755672748062, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.3662684977415544, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.6989471545567193, 'xgboost__reg_lambda': 0.38444302799771934, 'xgboost__reg_alpha': 0.33373819022470513}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:29,501] Trial 393 finished with value: 0.8474031538779488 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0032287739398997543, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.09417844166661929, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.508285883290043, 'xgboost__reg_lambda': 0.22124947163657022, 'xgboost__reg_alpha': 0.3363766289209027}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:29,772] Trial 394 finished with value: 0.8058345909773162 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004308612895758549, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.08452970227207589, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5117007568137777, 'xgboost__reg_lambda': 0.2450137521915663, 'xgboost__reg_alpha': 0.3192945898230074}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:30,051] Trial 395 finished with value: 0.8204214891248859 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0018087062760320715, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.11546982341394688, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5076394804388692, 'xgboost__reg_lambda': 0.24002455358061156, 'xgboost__reg_alpha': 0.3408001094865294}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:30,326] Trial 396 finished with value: 0.76334028879367 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003282687677102594, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.10365373481073697, 'xgboost__min_child_weight': 31, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5180111993785399, 'xgboost__reg_lambda': 0.4547530252405061, 'xgboost__reg_alpha': 0.36575621337455566}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:30,918] Trial 397 finished with value: 0.8410431170393942 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 350, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003076798859611507, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.15081918044528198, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5013112473199781, 'xgboost__reg_lambda': 0.14675092067607767, 'xgboost__reg_alpha': 0.3795839280768579}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:31,259] Trial 398 finished with value: 0.8058505135238087 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 330, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.002603236912684458, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.14499206975832696, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.510080717080228, 'xgboost__reg_lambda': 0.14401575568808545, 'xgboost__reg_alpha': 0.3486304273689617}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:31,850] Trial 399 finished with value: 0.8322348731670277 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 360, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0043306730287459155, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.1563207845650961, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5113116096265542, 'xgboost__reg_lambda': 0.12518527937500348, 'xgboost__reg_alpha': 0.37679011104368515}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:32,432] Trial 400 finished with value: 0.8355618605618605 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 340, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0030271743204965166, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.1295609097022458, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5083519478537231, 'xgboost__reg_lambda': 8.36503149915166e-05, 'xgboost__reg_alpha': 0.3870672159212267}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:32,719] Trial 401 finished with value: 0.8199916193458224 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004961788709021246, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.10140094962282738, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5036703687872737, 'xgboost__reg_lambda': 0.3808924339126987, 'xgboost__reg_alpha': 0.3132000507869724}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:33,034] Trial 402 finished with value: 0.7884315322994929 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 290, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.002173858330362605, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.12266080308978702, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5206275730775767, 'xgboost__reg_lambda': 0.2894697519617897, 'xgboost__reg_alpha': 0.3600785812229612}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:33,355] Trial 403 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 410, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005794489153340146, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.17296960453190885, 'xgboost__min_child_weight': 116, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5030790553708047, 'xgboost__reg_lambda': 0.19909111994016984, 'xgboost__reg_alpha': 0.13497281140197992}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:33,678] Trial 404 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 300, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003584838868786591, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.07579994460538807, 'xgboost__min_child_weight': 289, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7269293926969175, 'xgboost__reg_lambda': 0.12229751835020161, 'xgboost__reg_alpha': 0.10924414838479433}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:34,061] Trial 405 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.0011028323487191423, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.10630114688514988, 'xgboost__min_child_weight': 140, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5210825216426387, 'xgboost__reg_lambda': 0.2992495430166132, 'xgboost__reg_alpha': 0.3263212827800344}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:34,343] Trial 406 finished with value: 0.8014401000799581 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.025692021040163722, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.14711775744746833, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.51758899512184, 'xgboost__reg_lambda': 0.4769219217764169, 'xgboost__reg_alpha': 0.39727251143662223}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:34,674] Trial 407 finished with value: 0.7948244868366892 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 270, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.005667258058273693, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.06463850089870143, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5017172914629434, 'xgboost__reg_lambda': 0.2375242258007783, 'xgboost__reg_alpha': 0.3384767988031069}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:35,117] Trial 408 finished with value: 0.8319159077887337 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0062470224853368094, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.42958258257017146, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5270606380454002, 'xgboost__reg_lambda': 0.4105231866396034, 'xgboost__reg_alpha': 0.35404504591863}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:35,404] Trial 409 finished with value: 0.8026581306681119 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 70, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.027247222692540936, 'xgboost__n_estimators': 360, 'xgboost__learning_rate': 0.09038313737205966, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6233534987968252, 'xgboost__reg_lambda': 0.3295160124313187, 'xgboost__reg_alpha': 0.13683307161079164}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:35,739] Trial 410 finished with value: 0.7264134624261489 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 390, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0037385467798249986, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.11684417575869072, 'xgboost__min_child_weight': 34, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5291457947928458, 'xgboost__reg_lambda': 0.08097481569417886, 'xgboost__reg_alpha': 0.29968369110156523}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:36,071] Trial 411 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 320, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006665124580513603, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.06462226547044261, 'xgboost__min_child_weight': 163, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6515435757879275, 'xgboost__reg_lambda': 0.5144945642546122, 'xgboost__reg_alpha': 0.03197153972887422}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:36,683] Trial 412 finished with value: 0.7893163064052107 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.018539978009458124, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.09026841247351686, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5002866096044071, 'xgboost__reg_lambda': 1.1429558397811828, 'xgboost__reg_alpha': 0.37911424920849557}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:36,994] Trial 413 finished with value: 0.7870487729045014 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.032700683611820845, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.21826664329235518, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6137229776258013, 'xgboost__reg_lambda': 2.303661125282903, 'xgboost__reg_alpha': 0.0858063095195983}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:37,343] Trial 414 finished with value: 0.7890788003823456 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 350, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0010842383307033238, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.6247792596767632, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5986348017167458, 'xgboost__reg_lambda': 0.00011221366877113559, 'xgboost__reg_alpha': 0.14396980985795624}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:37,665] Trial 415 finished with value: 0.8167954510043351 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.004782702692742713, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.2045147416506926, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.5181135261074012, 'xgboost__reg_lambda': 0.2015187404284933, 'xgboost__reg_alpha': 0.11374144332601}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:38,354] Trial 416 finished with value: 0.8464290293934451 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.00677867288202685, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.1656549862659517, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8406945181625209, 'xgboost__reg_lambda': 1.5687002267031263, 'xgboost__reg_alpha': 0.15743707577849123}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:38,735] Trial 417 finished with value: 0.8333657434530016 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.002985143436956077, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.16595408128403194, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6727391314181843, 'xgboost__reg_lambda': 1.381801579802935, 'xgboost__reg_alpha': 0.15375994026288947}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:39,542] Trial 418 finished with value: 0.8372856750500254 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.006519255518713438, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.1367966193745351, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7991712492229511, 'xgboost__reg_lambda': 1.8419877865923342, 'xgboost__reg_alpha': 0.12249941947921657}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:39,930] Trial 419 finished with value: 0.8209094018201942 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.007723333454272926, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.3179564391156555, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.9615300924921812, 'xgboost__reg_lambda': 2.0184251250506726, 'xgboost__reg_alpha': 0.09430642358104671}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:40,338] Trial 420 finished with value: 0.8100852572440833 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.02123866304603226, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.1719903171558833, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.860038548370866, 'xgboost__reg_lambda': 1.297916969963996, 'xgboost__reg_alpha': 0.1575707924198102}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:40,656] Trial 421 finished with value: 0.793915523120999 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 450, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004776075455424586, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.10856864138800346, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6871308102943007, 'xgboost__reg_lambda': 2.7266427270673783, 'xgboost__reg_alpha': 0.002578884547478769}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:40,997] Trial 422 finished with value: 0.7789770516018327 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.028234172340892746, 'xgboost__n_estimators': 355, 'xgboost__learning_rate': 0.18634897556523877, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 4, 'xgboost__subsample': 0.6413179760535505, 'xgboost__reg_lambda': 2.4194330786728204, 'xgboost__reg_alpha': 0.3188694011998149}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:41,425] Trial 423 finished with value: 0.759341490549321 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.04794653333157578, 'xgboost__n_estimators': 370, 'xgboost__learning_rate': 0.2549623583645914, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5879694451557956, 'xgboost__reg_lambda': 1.323193475968198, 'xgboost__reg_alpha': 0.1370620055591674}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:42,069] Trial 424 finished with value: 0.8085309335309335 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.016476405658083355, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.14491332377532504, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.772745714784584, 'xgboost__reg_lambda': 1.209461790454628, 'xgboost__reg_alpha': 0.16909974987336776}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:42,412] Trial 425 finished with value: 0.8229660563229467 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 480, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.007267832700968685, 'xgboost__n_estimators': 345, 'xgboost__learning_rate': 0.13321064258313978, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7484191534036269, 'xgboost__reg_lambda': 0.12425268943261533, 'xgboost__reg_alpha': 0.40431479134278986}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:42,645] Trial 426 finished with value: 0.783488823126009 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00239875412225415, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.5296352017588648, 'xgboost__min_child_weight': 36, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8203859315630622, 'xgboost__reg_lambda': 3.078391497323703, 'xgboost__reg_alpha': 0.11609510211040931}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:43,076] Trial 427 finished with value: 0.8054979357062689 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 350, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.005154909371259412, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.24094671352524005, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7698184896849174, 'xgboost__reg_lambda': 1.4293830157413656, 'xgboost__reg_alpha': 0.06459415162920953}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:43,369] Trial 428 finished with value: 0.8268273806364874 and parameters: {'knn_imputer__n_neighbors': 3, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 300, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.008312542120562531, 'xgboost__n_estimators': 165, 'xgboost__learning_rate': 0.29249860433596797, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6286601592098539, 'xgboost__reg_lambda': 1.455952048791202, 'xgboost__reg_alpha': 0.3419023444388201}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:44,007] Trial 429 finished with value: 0.8422206603780747 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.004176654610802289, 'xgboost__n_estimators': 495, 'xgboost__learning_rate': 0.1581666385541394, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8031183963139876, 'xgboost__reg_lambda': 1.6780373724821627, 'xgboost__reg_alpha': 0.44114837169370463}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:44,403] Trial 430 finished with value: 0.8143201139265568 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 250, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.003602617308079406, 'xgboost__n_estimators': 495, 'xgboost__learning_rate': 0.19182417195930743, 'xgboost__min_child_weight': 27, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8821398139902554, 'xgboost__reg_lambda': 1.576001672247564, 'xgboost__reg_alpha': 0.4533843580738168}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:44,780] Trial 431 finished with value: 0.8271053382232415 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 470, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006034165014283704, 'xgboost__n_estimators': 490, 'xgboost__learning_rate': 0.16041755266726057, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8467876267097518, 'xgboost__reg_lambda': 1.6647092620492088, 'xgboost__reg_alpha': 0.40872493747144145}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:45,407] Trial 432 finished with value: 0.8255855757210772 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.0014000866388465456, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.15336985775130588, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.5132053378867427, 'xgboost__reg_lambda': 1.6610373838943489, 'xgboost__reg_alpha': 0.4200402308979201}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:45,808] Trial 433 finished with value: 0.8031404535636645 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 500, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.004341366928949277, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.5617829749687088, 'xgboost__min_child_weight': 18, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.809246577044009, 'xgboost__reg_lambda': 1.9425391282459847, 'xgboost__reg_alpha': 0.48941117417029656}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:46,146] Trial 434 finished with value: 0.8227748775644926 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 280, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006727080894740665, 'xgboost__n_estimators': 500, 'xgboost__learning_rate': 0.3080014395437322, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7354112494432896, 'xgboost__reg_lambda': 1.5986771062755945, 'xgboost__reg_alpha': 0.37334373059911585}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:46,422] Trial 435 finished with value: 0.7490679541867842 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.PowerTransformer', 'fs_mb_xgboost__n_estimators': 190, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.022318294734313748, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.12562524825593588, 'xgboost__min_child_weight': 46, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.7699092204897281, 'xgboost__reg_lambda': 0.37112441191327783, 'xgboost__reg_alpha': 0.43971555417992836}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:47,053] Trial 436 finished with value: 0.8465307927673519 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 170, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.00897145574396178, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.14404597560830273, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8220697291488875, 'xgboost__reg_lambda': 1.919734912050462, 'xgboost__reg_alpha': 0.38278918255818173}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:47,357] Trial 437 finished with value: 0.7688374473893754 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 170, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.03602625396287615, 'xgboost__n_estimators': 465, 'xgboost__learning_rate': 0.26689358228817783, 'xgboost__min_child_weight': 19, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8187451760980051, 'xgboost__reg_lambda': 1.91498995858112, 'xgboost__reg_alpha': 0.4784223111381582}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:47,621] Trial 438 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 180, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.009225082817879869, 'xgboost__n_estimators': 495, 'xgboost__learning_rate': 0.10481137330133977, 'xgboost__min_child_weight': 217, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.860012588438951, 'xgboost__reg_lambda': 1.840091834695434, 'xgboost__reg_alpha': 0.4421482278066167}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:47,861] Trial 439 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 160, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.010134000930206938, 'xgboost__n_estimators': 485, 'xgboost__learning_rate': 0.41418616652685025, 'xgboost__min_child_weight': 441, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8227473952312717, 'xgboost__reg_lambda': 1.748677700010777, 'xgboost__reg_alpha': 0.045775694419472115}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:48,168] Trial 440 finished with value: 0.7967237981561263 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 220, 'fs_mb_xgboost__max_depth': 5, 'fs_mb__threshold': 0.025057822777439315, 'xgboost__n_estimators': 485, 'xgboost__learning_rate': 0.1750484418687343, 'xgboost__min_child_weight': 11, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7500932839601757, 'xgboost__reg_lambda': 1.551824546972363, 'xgboost__reg_alpha': 0.3548431148789036}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:48,480] Trial 441 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 490, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.031973295547193414, 'xgboost__n_estimators': 465, 'xgboost__learning_rate': 0.19804114500747544, 'xgboost__min_child_weight': 87, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.837658449714763, 'xgboost__reg_lambda': 1.8807628438814614, 'xgboost__reg_alpha': 0.17133869803333784}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:48,755] Trial 442 finished with value: 0.8090139694518717 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 150, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008042789113362757, 'xgboost__n_estimators': 455, 'xgboost__learning_rate': 0.12802784918154575, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8059180093404705, 'xgboost__reg_lambda': 1.6759694995963024, 'xgboost__reg_alpha': 0.3940693583965638}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:49,562] Trial 443 finished with value: 0.8387884094796694 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 210, 'fs_mb_xgboost__max_depth': 8, 'fs_mb__threshold': 0.011141763369988724, 'xgboost__n_estimators': 485, 'xgboost__learning_rate': 0.07626909559768452, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8273583061708762, 'xgboost__reg_lambda': 1.555123670768693, 'xgboost__reg_alpha': 0.15060641954577492}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:49,849] Trial 444 finished with value: 0.7610742721682778 and parameters: {'knn_imputer__n_neighbors': 5, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 130, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.055910788244709866, 'xgboost__n_estimators': 470, 'xgboost__learning_rate': 0.08962564209521366, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8158969195498614, 'xgboost__reg_lambda': 1.684578833922342, 'xgboost__reg_alpha': 0.29993754102086306}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:50,096] Trial 445 finished with value: 0.7827354187720035 and parameters: {'knn_imputer__n_neighbors': 6, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 140, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.04508247125070647, 'xgboost__n_estimators': 480, 'xgboost__learning_rate': 0.44049864201246, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.804802652754722, 'xgboost__reg_lambda': 1.768237873358033, 'xgboost__reg_alpha': 0.5354388755374224}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:50,371] Trial 446 finished with value: 0.7794295615476956 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 240, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.008842510325875571, 'xgboost__n_estimators': 440, 'xgboost__learning_rate': 0.5255602408585054, 'xgboost__min_child_weight': 35, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.781472472124534, 'xgboost__reg_lambda': 1.8164667754849058, 'xgboost__reg_alpha': 0.32798844017629214}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:50,683] Trial 447 finished with value: 0.8305059115104432 and parameters: {'knn_imputer__n_neighbors': 16, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 200, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.006585360156867813, 'xgboost__n_estimators': 470, 'xgboost__learning_rate': 0.22584424251314303, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8069383358408556, 'xgboost__reg_lambda': 1.5656850680417729, 'xgboost__reg_alpha': 0.672391181442081}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:51,262] Trial 448 finished with value: 0.8489826320761573 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012034862193472334, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.05297428580541784, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.810239011031228, 'xgboost__reg_lambda': 0.5441384392468354, 'xgboost__reg_alpha': 0.42974588677200287}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:51,491] Trial 449 finished with value: 0.7978461867350758 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012862357475739564, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.05252688147824316, 'xgboost__min_child_weight': 24, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8102548708735572, 'xgboost__reg_lambda': 1.5221603781385886, 'xgboost__reg_alpha': 0.39383113846221857}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:51,782] Trial 450 finished with value: 0.8229660563229467 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015109446661130344, 'xgboost__n_estimators': 475, 'xgboost__learning_rate': 0.04934749633126069, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8330570178973189, 'xgboost__reg_lambda': 0.5429834746700338, 'xgboost__reg_alpha': 0.4290623537908563}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:52,114] Trial 451 finished with value: 0.806630970381257 and parameters: {'knn_imputer__n_neighbors': 17, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.019753683939898507, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.06665897050378207, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7917062579893016, 'xgboost__reg_lambda': 1.7860599839314177, 'xgboost__reg_alpha': 0.4601009683652987}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:52,397] Trial 452 finished with value: 0.8276342884844975 and parameters: {'knn_imputer__n_neighbors': 18, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.029865089531844972, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.041434504891151996, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 8, 'xgboost__subsample': 0.8144902062560792, 'xgboost__reg_lambda': 1.9879893272586093, 'xgboost__reg_alpha': 0.3644931038607279}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:52,620] Trial 453 finished with value: 0.8095023573501426 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01172111325754225, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.0810583716444533, 'xgboost__min_child_weight': 22, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8287711232060306, 'xgboost__reg_lambda': 2.1220542600028702, 'xgboost__reg_alpha': 0.4119785824796522}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:53,166] Trial 454 finished with value: 0.8419122361403112 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.016363194845968564, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.05248855192291661, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8268276397408365, 'xgboost__reg_lambda': 0.5911982968628058, 'xgboost__reg_alpha': 0.4656720031974771}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:53,770] Trial 455 finished with value: 0.7653163634304182 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01922624929718744, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.0013854741318752375, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8278278959198442, 'xgboost__reg_lambda': 2.5803315142438237, 'xgboost__reg_alpha': 0.46273669024070396}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:54,048] Trial 456 finished with value: 0.8125381575871466 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01709864919008509, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.36867163205563325, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8341199431531566, 'xgboost__reg_lambda': 0.6402435906577091, 'xgboost__reg_alpha': 0.17732306677405282}. Best is trial 310 with value: 0.8494535614900911.\n",
      "[I 2024-01-07 21:24:54,698] Trial 457 finished with value: 0.8498666160259712 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014506382657943451, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.05778333213062965, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8404353004405407, 'xgboost__reg_lambda': 2.10503360161923, 'xgboost__reg_alpha': 0.48740033703104}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:24:55,308] Trial 458 finished with value: 0.8461122599836918 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01631696661872629, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.05664951801129591, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8415255677170282, 'xgboost__reg_lambda': 2.2809266397140653, 'xgboost__reg_alpha': 0.5038070229224714}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:24:55,612] Trial 459 finished with value: 0.7867926615575213 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.016057691535473, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.4883374590270426, 'xgboost__min_child_weight': 31, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8458031178248968, 'xgboost__reg_lambda': 2.032920547493833, 'xgboost__reg_alpha': 0.4894117251598074}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:24:55,905] Trial 460 finished with value: 0.8295140719540057 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01810236814661036, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.05295600136673907, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8422329367093615, 'xgboost__reg_lambda': 1.8940780850762136, 'xgboost__reg_alpha': 0.4737506588611171}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:24:56,598] Trial 461 finished with value: 0.8419122361403112 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02292764724607782, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.06218819081304285, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.830243808176751, 'xgboost__reg_lambda': 1.7700128286299404, 'xgboost__reg_alpha': 0.5035314506732268}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:24:56,961] Trial 462 finished with value: 0.8122052341501838 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.021107441839859437, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.0644383223054098, 'xgboost__min_child_weight': 16, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8216017288713625, 'xgboost__reg_lambda': 2.3331893450283956, 'xgboost__reg_alpha': 0.5044464795069025}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:24:57,630] Trial 463 finished with value: 0.8396538395137442 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01692815005816456, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.05948926839335072, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.83171073221273, 'xgboost__reg_lambda': 1.9844272971234778, 'xgboost__reg_alpha': 0.4941963053058755}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:24:57,984] Trial 464 finished with value: 0.8290788555263442 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01792617492815952, 'xgboost__n_estimators': 440, 'xgboost__learning_rate': 0.07527042816348141, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8393356299928464, 'xgboost__reg_lambda': 2.1581212871410287, 'xgboost__reg_alpha': 0.47115908482537333}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:24:58,298] Trial 465 finished with value: 0.810411171115466 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.022884512281302324, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.34444217535657384, 'xgboost__min_child_weight': 25, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8566862929275029, 'xgboost__reg_lambda': 2.06105355474409, 'xgboost__reg_alpha': 0.5072542820500179}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:24:58,614] Trial 466 finished with value: 0.8094772112032455 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.019019156136304283, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.7614204488990758, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8240459955982647, 'xgboost__reg_lambda': 2.2031199250178415, 'xgboost__reg_alpha': 0.5378449430392158}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:24:59,104] Trial 467 finished with value: 0.8333092833092834 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01484879699107677, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.3971791997366901, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.815712347997652, 'xgboost__reg_lambda': 2.0101276978073663, 'xgboost__reg_alpha': 0.44465146036662295}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:24:59,419] Trial 468 finished with value: 0.825325410847382 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.020530954763025105, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.03944906098495236, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7970367483165639, 'xgboost__reg_lambda': 1.74735434392878, 'xgboost__reg_alpha': 0.4940868481462815}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:24:59,744] Trial 469 finished with value: 0.7822748907172601 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 250, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.016338707971156944, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.060092046503238475, 'xgboost__min_child_weight': 38, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8518936711301689, 'xgboost__reg_lambda': 2.1021685175368705, 'xgboost__reg_alpha': 0.5168380813875243}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:00,041] Trial 470 finished with value: 0.8261717461262633 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013990189774423185, 'xgboost__n_estimators': 440, 'xgboost__learning_rate': 0.09130193293257709, 'xgboost__min_child_weight': 10, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8389076253467019, 'xgboost__reg_lambda': 2.20951898991592, 'xgboost__reg_alpha': 0.5499825693394665}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:00,730] Trial 471 finished with value: 0.8353535027762874 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.014895825868185416, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.3297351678378755, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8524415854443773, 'xgboost__reg_lambda': 2.2894952035082645, 'xgboost__reg_alpha': 0.4716224712366672}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:00,966] Trial 472 finished with value: 0.7881776097982062 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.027159588326548918, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.6948607333236224, 'xgboost__min_child_weight': 26, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8322073036018862, 'xgboost__reg_lambda': 1.7252585811445886, 'xgboost__reg_alpha': 0.4331911613140172}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:01,207] Trial 473 finished with value: 0.818475426959044 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.017483669666919086, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.03583546033324149, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8159259274881009, 'xgboost__reg_lambda': 1.8314376786287747, 'xgboost__reg_alpha': 0.5060955001526449}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:01,475] Trial 474 finished with value: 0.8356328761951377 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.024427741559183695, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.07671880910102438, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8464059539813259, 'xgboost__reg_lambda': 4.390443726249137, 'xgboost__reg_alpha': 0.45839808057876613}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:01,747] Trial 475 finished with value: 0.8271053382232415 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.019710736612954822, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.0531439189482054, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.7834458275003819, 'xgboost__reg_lambda': 1.9199823181227387, 'xgboost__reg_alpha': 0.4776498317118943}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:01,988] Trial 476 finished with value: 0.8084272832895052 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013714540690706491, 'xgboost__n_estimators': 450, 'xgboost__learning_rate': 0.6279764737211979, 'xgboost__min_child_weight': 21, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8259012992610504, 'xgboost__reg_lambda': 2.327171153158762, 'xgboost__reg_alpha': 0.4282515511357844}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:02,485] Trial 477 finished with value: 0.8322348731670277 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.015505028302050793, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.302926557273099, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8422439710275806, 'xgboost__reg_lambda': 3.8079321386596328, 'xgboost__reg_alpha': 0.44538084686908747}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:02,795] Trial 478 finished with value: 0.7737497403099242 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 260, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0753122782044342, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.029337821127786802, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.7965719288859432, 'xgboost__reg_lambda': 1.6412373529323812, 'xgboost__reg_alpha': 0.5540528692065865}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:03,101] Trial 479 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01293457289672582, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.20441832420419073, 'xgboost__min_child_weight': 200, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8025728130510824, 'xgboost__reg_lambda': 2.143765367736446, 'xgboost__reg_alpha': 0.522864728972355}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:03,313] Trial 480 finished with value: 0.7971467104808033 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.03935264505239296, 'xgboost__n_estimators': 395, 'xgboost__learning_rate': 0.8133276991670046, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8266896449033837, 'xgboost__reg_lambda': 2.5887409859255146, 'xgboost__reg_alpha': 0.4620933861507906}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:03,529] Trial 481 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.02279127530578855, 'xgboost__n_estimators': 400, 'xgboost__learning_rate': 0.276785975275546, 'xgboost__min_child_weight': 356, 'xgboost__max_depth': 2, 'xgboost__subsample': 0.783576206951414, 'xgboost__reg_lambda': 2.4501836525448977, 'xgboost__reg_alpha': 0.4857515624142177}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:03,753] Trial 482 finished with value: 0.807993628074108 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0167656058936117, 'xgboost__n_estimators': 385, 'xgboost__learning_rate': 0.24407169054639882, 'xgboost__min_child_weight': 29, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8631049838599878, 'xgboost__reg_lambda': 1.7981784663993259, 'xgboost__reg_alpha': 0.44955761443102205}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:04,012] Trial 483 finished with value: 0.7847340856534633 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 230, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.04063549141979267, 'xgboost__n_estimators': 405, 'xgboost__learning_rate': 0.09968081586039539, 'xgboost__min_child_weight': 8, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8115115726624401, 'xgboost__reg_lambda': 2.0485288305830567, 'xgboost__reg_alpha': 0.5057130100373368}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:04,570] Trial 484 finished with value: 0.842016992554627 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.013847981921031864, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.0753244484486097, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8405604635736912, 'xgboost__reg_lambda': 0.5159611339146439, 'xgboost__reg_alpha': 0.5599188745850596}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:04,833] Trial 485 finished with value: 0.827885491837318 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 30, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.014058453345479859, 'xgboost__n_estimators': 425, 'xgboost__learning_rate': 0.08147211142309614, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8359190519723804, 'xgboost__reg_lambda': 0.48826550879003133, 'xgboost__reg_alpha': 0.5962834622168038}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:05,066] Trial 486 finished with value: 0.8016221960311848 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03865313394884087, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.06862273951363602, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8391598938281017, 'xgboost__reg_lambda': 2.2493858544233922, 'xgboost__reg_alpha': 0.5568131063287681}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:05,411] Trial 487 finished with value: 0.822155880544294 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 6, 'fs_mb__threshold': 0.018350349213469685, 'xgboost__n_estimators': 415, 'xgboost__learning_rate': 0.9363803460778297, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8501732522549268, 'xgboost__reg_lambda': 0.4264735149392428, 'xgboost__reg_alpha': 0.42181225498406194}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:05,654] Trial 488 finished with value: 0.7894801186467854 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 10, 'fs_mb__threshold': 0.015945609064403295, 'xgboost__n_estimators': 435, 'xgboost__learning_rate': 0.47458833821136304, 'xgboost__min_child_weight': 40, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8217379480080226, 'xgboost__reg_lambda': 0.524342160907104, 'xgboost__reg_alpha': 0.5136337393717221}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:05,908] Trial 489 finished with value: 0.8336065679627324 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.012200271488560241, 'xgboost__n_estimators': 445, 'xgboost__learning_rate': 0.09794317568761002, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8742622829452188, 'xgboost__reg_lambda': 4.8143581771709485, 'xgboost__reg_alpha': 0.48658261731720814}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:06,109] Trial 490 finished with value: 0.7763130894349799 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 40, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.055237775368485835, 'xgboost__n_estimators': 380, 'xgboost__learning_rate': 0.053921499437926027, 'xgboost__min_child_weight': 23, 'xgboost__max_depth': 5, 'xgboost__subsample': 0.8506340279554065, 'xgboost__reg_lambda': 1.505575211736158, 'xgboost__reg_alpha': 0.5592490617803696}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:06,372] Trial 491 finished with value: 0.7614219387981903 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 60, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.0789180953226469, 'xgboost__n_estimators': 410, 'xgboost__learning_rate': 0.5310036829190526, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8382299133813017, 'xgboost__reg_lambda': 0.3313810232008661, 'xgboost__reg_alpha': 0.5251501844491939}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:06,614] Trial 492 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 50, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.049221855488831984, 'xgboost__n_estimators': 430, 'xgboost__learning_rate': 0.17552001867354394, 'xgboost__min_child_weight': 410, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8292540141547676, 'xgboost__reg_lambda': 2.3921537259684924, 'xgboost__reg_alpha': 0.5680912865956373}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:06,846] Trial 493 finished with value: 0.46982323232323225 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 20, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.060738359215624184, 'xgboost__n_estimators': 450, 'xgboost__learning_rate': 0.5486511807647825, 'xgboost__min_child_weight': 70, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6574114349779923, 'xgboost__reg_lambda': 1.6651120858245467, 'xgboost__reg_alpha': 0.5821941563143126}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:07,174] Trial 494 finished with value: 0.8155837767741358 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 90, 'fs_mb_xgboost__max_depth': 3, 'fs_mb__threshold': 0.014037910794639927, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.1190219754231662, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8707588634367288, 'xgboost__reg_lambda': 0.5744064112949149, 'xgboost__reg_alpha': 0.6151059767989773}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:07,872] Trial 495 finished with value: 0.8197629470001856 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 200, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.01943785476860161, 'xgboost__n_estimators': 420, 'xgboost__learning_rate': 0.08683656667764089, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8450976766973956, 'xgboost__reg_lambda': 1.9128949821715222, 'xgboost__reg_alpha': 0.5380143334656552}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:08,195] Trial 496 finished with value: 0.7843817352651274 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'sklearn.preprocessing.QuantileTransformer', 'fs_mb_xgboost__n_estimators': 80, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.03248098509520933, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.07169054984273843, 'xgboost__min_child_weight': 32, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.6951020302211487, 'xgboost__reg_lambda': 1.7976417392441149, 'xgboost__reg_alpha': 0.4722761510850056}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:08,436] Trial 497 finished with value: 0.7960949514711082 and parameters: {'knn_imputer__n_neighbors': 19, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 10, 'fs_mb_xgboost__max_depth': 4, 'fs_mb__threshold': 0.04552278871966443, 'xgboost__n_estimators': 365, 'xgboost__learning_rate': 0.14141178828637402, 'xgboost__min_child_weight': 9, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8110026168354595, 'xgboost__reg_lambda': 0.4582994336429656, 'xgboost__reg_alpha': 0.39706969149204857}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:08,745] Trial 498 finished with value: 0.811783766244153 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 270, 'fs_mb_xgboost__max_depth': 2, 'fs_mb__threshold': 0.011433617594268097, 'xgboost__n_estimators': 390, 'xgboost__learning_rate': 0.044128645090439865, 'xgboost__min_child_weight': 17, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8610278088434911, 'xgboost__reg_lambda': 1.377266254458147, 'xgboost__reg_alpha': 0.438917872499998}. Best is trial 457 with value: 0.8498666160259712.\n",
      "[I 2024-01-07 21:25:09,323] Trial 499 finished with value: 0.8084108018876622 and parameters: {'knn_imputer__n_neighbors': 20, 'knn_imputer__weights': 'uniform', 'scaler__transformer': 'project.packages.modelling.transformers.scaler.NotScalerTransformer', 'fs_mb_xgboost__n_estimators': 170, 'fs_mb_xgboost__max_depth': 7, 'fs_mb__threshold': 0.016647145242973477, 'xgboost__n_estimators': 375, 'xgboost__learning_rate': 0.11296574315432267, 'xgboost__min_child_weight': 0, 'xgboost__max_depth': 6, 'xgboost__subsample': 0.8301393905141536, 'xgboost__reg_lambda': 2.5135953303809684, 'xgboost__reg_alpha': 0.49734683564327076}. Best is trial 457 with value: 0.8498666160259712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-01-07 21:25:10,776 - project.packages.modelling.models.supervised.sklearn - INFO - final estimator: Pipeline(steps=[('columns_selector',\n",
      "                 ColumnsSelector(columns=['passenger_class', 'passenger_age',\n",
      "                                          'passenger_siblings',\n",
      "                                          'passenger_parch', 'passenger_fare',\n",
      "                                          'passenger_ticket_number',\n",
      "                                          'passenger_ticket_unknown_base',\n",
      "                                          'passenger_cabin_number',\n",
      "                                          'passenger_number_of_family_onboard',\n",
      "                                          'passenger_is_single',\n",
      "                                          'passenger_has_childs',\n",
      "                                          'passenger_cabin_level_a',\n",
      "                                          'passeng...\n",
      "                               feature_types=None, gamma=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.05778333213062965, max_bin=None,\n",
      "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               max_leaves=None, min_child_weight=0, missing=nan,\n",
      "                               monotone_constraints=None, multi_strategy=None,\n",
      "                               n_estimators=430, n_jobs=None,\n",
      "                               num_parallel_tree=None, random_state=42, ...))])\u001b[0m\n",
      "\u001b[34m2024-01-07 21:25:10,777 - project.packages.modelling.models.supervised.sklearn - INFO - final estimator f1_weighted: 0.8498666160259712\u001b[0m\n",
      "\u001b[34m2024-01-07 21:25:11,065 - project.packages.modelling.feature_selection.feature_selectors.model_based - INFO - Model based feature selection drops the following features: ['passenger_ticket_unknown_base', 'passenger_is_single', 'passenger_cabin_level_d', 'passenger_embarked_port_cluster_feature', 'passenger_family_cluster_feature', 'passenger_embarked_port_c', 'passenger_embarked_port_q', 'passenger_cabin_level_b', 'passenger_ticket_number_cluster_feature', 'passenger_cabin_level_c', 'passenger_cabin_level_a', 'passenger_has_childs', 'passenger_parch', 'passenger_social_status_cluster_feature']\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 {color: black;background-color: white;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 pre{padding: 0;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-toggleable {background-color: white;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-estimator:hover {background-color: #d4ebff;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-item {z-index: 1;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-parallel-item:only-child::after {width: 0;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-37735f9b-dd77-49cb-b0d9-ab8cb4494255\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;raw_transformations&#x27;,\n",
       "                 RawDataProcessor(params={&#x27;index&#x27;: &#x27;passenger_id&#x27;,\n",
       "                                          &#x27;schemas&#x27;: {&#x27;Age&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                                              &#x27;name&#x27;: &#x27;passenger_age&#x27;},\n",
       "                                                      &#x27;Cabin&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                                &#x27;name&#x27;: &#x27;passenger_cabin&#x27;},\n",
       "                                                      &#x27;Embarked&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                                   &#x27;name&#x27;: &#x27;passenger_embarked_port&#x27;},\n",
       "                                                      &#x27;Fare&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                                               &#x27;name&#x27;: &#x27;passenger_fare&#x27;},\n",
       "                                                      &#x27;Name&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                               &#x27;name&#x27;: &#x27;name...\n",
       "                                                                                                            &#x27;&quot;sklearn.preprocessing.QuantileTransformer&quot;])&#x27;,\n",
       "                                                                                                   &#x27;kwargs&#x27;: {}}}}},\n",
       "                                                 scoring_metrics=[&#x27;accuracy&#x27;,\n",
       "                                                                  &#x27;balanced_accuracy&#x27;,\n",
       "                                                                  &#x27;f1&#x27;,\n",
       "                                                                  &#x27;f1_micro&#x27;,\n",
       "                                                                  &#x27;f1_macro&#x27;,\n",
       "                                                                  &#x27;f1_weighted&#x27;,\n",
       "                                                                  &#x27;precision&#x27;,\n",
       "                                                                  &#x27;precision_micro&#x27;,\n",
       "                                                                  &#x27;precision_macro&#x27;,\n",
       "                                                                  &#x27;precision_weighted&#x27;,\n",
       "                                                                  &#x27;recall&#x27;,\n",
       "                                                                  &#x27;recall_micro&#x27;,\n",
       "                                                                  &#x27;recall_macro&#x27;,\n",
       "                                                                  &#x27;recall_weighted&#x27;,\n",
       "                                                                  &#x27;roc_auc&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovr&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovo&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovr_weighted&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovo_weighted&#x27;],\n",
       "                                                 target=&#x27;survived&#x27;))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2948f8b3-5628-463d-877d-385e33b9bedc\" type=\"checkbox\" ><label for=\"2948f8b3-5628-463d-877d-385e33b9bedc\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;raw_transformations&#x27;,\n",
       "                 RawDataProcessor(params={&#x27;index&#x27;: &#x27;passenger_id&#x27;,\n",
       "                                          &#x27;schemas&#x27;: {&#x27;Age&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                                              &#x27;name&#x27;: &#x27;passenger_age&#x27;},\n",
       "                                                      &#x27;Cabin&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                                &#x27;name&#x27;: &#x27;passenger_cabin&#x27;},\n",
       "                                                      &#x27;Embarked&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                                   &#x27;name&#x27;: &#x27;passenger_embarked_port&#x27;},\n",
       "                                                      &#x27;Fare&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                                               &#x27;name&#x27;: &#x27;passenger_fare&#x27;},\n",
       "                                                      &#x27;Name&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                               &#x27;name&#x27;: &#x27;name...\n",
       "                                                                                                            &#x27;&quot;sklearn.preprocessing.QuantileTransformer&quot;])&#x27;,\n",
       "                                                                                                   &#x27;kwargs&#x27;: {}}}}},\n",
       "                                                 scoring_metrics=[&#x27;accuracy&#x27;,\n",
       "                                                                  &#x27;balanced_accuracy&#x27;,\n",
       "                                                                  &#x27;f1&#x27;,\n",
       "                                                                  &#x27;f1_micro&#x27;,\n",
       "                                                                  &#x27;f1_macro&#x27;,\n",
       "                                                                  &#x27;f1_weighted&#x27;,\n",
       "                                                                  &#x27;precision&#x27;,\n",
       "                                                                  &#x27;precision_micro&#x27;,\n",
       "                                                                  &#x27;precision_macro&#x27;,\n",
       "                                                                  &#x27;precision_weighted&#x27;,\n",
       "                                                                  &#x27;recall&#x27;,\n",
       "                                                                  &#x27;recall_micro&#x27;,\n",
       "                                                                  &#x27;recall_macro&#x27;,\n",
       "                                                                  &#x27;recall_weighted&#x27;,\n",
       "                                                                  &#x27;roc_auc&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovr&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovo&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovr_weighted&#x27;,\n",
       "                                                                  &#x27;roc_auc_ovo_weighted&#x27;],\n",
       "                                                 target=&#x27;survived&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5249b9f9-fe9b-463a-a6ec-f98e7ea99606\" type=\"checkbox\" ><label for=\"5249b9f9-fe9b-463a-a6ec-f98e7ea99606\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RawDataProcessor</label><div class=\"sk-toggleable__content\"><pre>RawDataProcessor(params={&#x27;index&#x27;: &#x27;passenger_id&#x27;,\n",
       "                         &#x27;schemas&#x27;: {&#x27;Age&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                             &#x27;name&#x27;: &#x27;passenger_age&#x27;},\n",
       "                                     &#x27;Cabin&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                               &#x27;name&#x27;: &#x27;passenger_cabin&#x27;},\n",
       "                                     &#x27;Embarked&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                  &#x27;name&#x27;: &#x27;passenger_embarked_port&#x27;},\n",
       "                                     &#x27;Fare&#x27;: {&#x27;dtype&#x27;: &#x27;float64&#x27;,\n",
       "                                              &#x27;name&#x27;: &#x27;passenger_fare&#x27;},\n",
       "                                     &#x27;Name&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                              &#x27;name&#x27;: &#x27;name&#x27;},\n",
       "                                     &#x27;Parch&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                               &#x27;name&#x27;: &#x27;passenger_parch&#x27;},\n",
       "                                     &#x27;PassengerId&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                                     &#x27;name&#x27;: &#x27;passenger_id&#x27;},\n",
       "                                     &#x27;Pclass&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                                &#x27;name&#x27;: &#x27;passenger_class&#x27;},\n",
       "                                     &#x27;Sex&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                             &#x27;name&#x27;: &#x27;passenger_sex&#x27;},\n",
       "                                     &#x27;SibSp&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                               &#x27;name&#x27;: &#x27;passenger_siblings&#x27;},\n",
       "                                     &#x27;Survived&#x27;: {&#x27;dtype&#x27;: &#x27;int64&#x27;,\n",
       "                                                  &#x27;name&#x27;: &#x27;survived&#x27;},\n",
       "                                     &#x27;Ticket&#x27;: {&#x27;dtype&#x27;: &#x27;object&#x27;,\n",
       "                                                &#x27;name&#x27;: &#x27;passenger_ticket&#x27;}},\n",
       "                         &#x27;target&#x27;: &#x27;Survived&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d0003dff-5c00-489e-85e8-3339414f76cf\" type=\"checkbox\" ><label for=\"d0003dff-5c00-489e-85e8-3339414f76cf\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IntermediateDataProcessor</label><div class=\"sk-toggleable__content\"><pre>IntermediateDataProcessor(params={&#x27;categorical_features&#x27;: [&#x27;passenger_sex&#x27;,\n",
       "                                                           &#x27;passenger_ticket&#x27;,\n",
       "                                                           &#x27;passenger_cabin&#x27;,\n",
       "                                                           &#x27;passenger_embarked_port&#x27;],\n",
       "                                  &#x27;drop_columns&#x27;: [&#x27;name&#x27;],\n",
       "                                  &#x27;outlier_params&#x27;: {&#x27;iqr_alpha&#x27;: 2.5,\n",
       "                                                     &#x27;q1_quantile&#x27;: 0.25,\n",
       "                                                     &#x27;q3_quantile&#x27;: 0.75},\n",
       "                                  &#x27;target&#x27;: &#x27;survived&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"bba84623-9100-4bbc-8529-48bcfcb06c95\" type=\"checkbox\" ><label for=\"bba84623-9100-4bbc-8529-48bcfcb06c95\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PrimaryDataProcessor</label><div class=\"sk-toggleable__content\"><pre>PrimaryDataProcessor(params={&#x27;categorical_columns_fillna&#x27;: {&#x27;passenger_cabin&#x27;: &#x27;unknown&#x27;,\n",
       "                                                            &#x27;passenger_embarked_port&#x27;: &#x27;unknown&#x27;},\n",
       "                             &#x27;target&#x27;: &#x27;supervised&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a05c7b8a-1196-4034-b04c-3babbfcb4105\" type=\"checkbox\" ><label for=\"a05c7b8a-1196-4034-b04c-3babbfcb4105\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureDataProcessor</label><div class=\"sk-toggleable__content\"><pre>FeatureDataProcessor(params={&#x27;encoding_transform&#x27;: {&#x27;one_hot_encoder&#x27;: [&#x27;passenger_cabin_level&#x27;,\n",
       "                                                                        &#x27;passenger_embarked_port&#x27;,\n",
       "                                                                        &#x27;passenger_sex&#x27;],\n",
       "                                                    &#x27;similarity_based_encoder&#x27;: None},\n",
       "                             &#x27;target&#x27;: &#x27;survived&#x27;})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e9d13879-762e-489e-a5b8-33c51a982ffb\" type=\"checkbox\" ><label for=\"e9d13879-762e-489e-a5b8-33c51a982ffb\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeansClusteringFeatures</label><div class=\"sk-toggleable__content\"><pre>KMeansClusteringFeatures(feature_params={&#x27;passenger_cabin_cluster_feature&#x27;: [&#x27;passenger_cabin_level_a&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_b&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_c&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_d&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_e&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_f&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_g&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_t&#x27;,\n",
       "                                                                             &#x27;passenger_cabin_level_unknown&#x27;],\n",
       "                                         &#x27;passenger_embarked_port_cluster_...\n",
       "                                                                                  &#x27;weights&#x27;: &#x27;distance&#x27;}}}},\n",
       "                         model_params={&#x27;class&#x27;: &#x27;project.packages.modelling.models.unsupervised.segmentation.KMeansElbowSelector&#x27;,\n",
       "                                       &#x27;kwargs&#x27;: {&#x27;max_clusters&#x27;: 15,\n",
       "                                                  &#x27;min_clusters&#x27;: 1}},\n",
       "                         scaler_params={&#x27;class&#x27;: &#x27;project.packages.modelling.transformers.scaler.ColumnsPreserverScaler&#x27;,\n",
       "                                        &#x27;kwargs&#x27;: {&#x27;scaler_params&#x27;: {&#x27;class&#x27;: &#x27;sklearn.preprocessing.MinMaxScaler&#x27;,\n",
       "                                                                     &#x27;kwargs&#x27;: {}}}})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5f738a9f-c1a0-40a5-a53c-460b0e24dbc3\" type=\"checkbox\" ><label for=\"5f738a9f-c1a0-40a5-a53c-460b0e24dbc3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BinaryClassifierSklearnPipeline</label><div class=\"sk-toggleable__content\"><pre>BinaryClassifierSklearnPipeline(cv_score={&#x27;class&#x27;: &#x27;sklearn.model_selection.cross_val_predict&#x27;,\n",
       "                                          &#x27;kwargs&#x27;: {&#x27;X&#x27;: None, &#x27;cv&#x27;: None,\n",
       "                                                     &#x27;estimator&#x27;: None,\n",
       "                                                     &#x27;method&#x27;: &#x27;predict&#x27;,\n",
       "                                                     &#x27;n_jobs&#x27;: -1, &#x27;y&#x27;: None},\n",
       "                                          &#x27;scoring&#x27;: &#x27;f1_weighted&#x27;},\n",
       "                                cv_strategy={&#x27;class&#x27;: &#x27;sklearn.model_selection.StratifiedKFold&#x27;,\n",
       "                                             &#x27;kwargs&#x27;: {&#x27;n_splits&#x27;: 5,\n",
       "                                                        &#x27;random_state&#x27;: 42,\n",
       "                                                        &#x27;shuffle&#x27;: True}},\n",
       "                                features=[&#x27;passenger_cl...\n",
       "                                                                                           &#x27;&quot;sklearn.preprocessing.QuantileTransformer&quot;])&#x27;,\n",
       "                                                                                  &#x27;kwargs&#x27;: {}}}}},\n",
       "                                scoring_metrics=[&#x27;accuracy&#x27;,\n",
       "                                                 &#x27;balanced_accuracy&#x27;, &#x27;f1&#x27;,\n",
       "                                                 &#x27;f1_micro&#x27;, &#x27;f1_macro&#x27;,\n",
       "                                                 &#x27;f1_weighted&#x27;, &#x27;precision&#x27;,\n",
       "                                                 &#x27;precision_micro&#x27;,\n",
       "                                                 &#x27;precision_macro&#x27;,\n",
       "                                                 &#x27;precision_weighted&#x27;, &#x27;recall&#x27;,\n",
       "                                                 &#x27;recall_micro&#x27;, &#x27;recall_macro&#x27;,\n",
       "                                                 &#x27;recall_weighted&#x27;, &#x27;roc_auc&#x27;,\n",
       "                                                 &#x27;roc_auc_ovr&#x27;, &#x27;roc_auc_ovo&#x27;,\n",
       "                                                 &#x27;roc_auc_ovr_weighted&#x27;,\n",
       "                                                 &#x27;roc_auc_ovo_weighted&#x27;],\n",
       "                                target=&#x27;survived&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('raw_transformations',\n",
       "                 RawDataProcessor(params={'index': 'passenger_id',\n",
       "                                          'schemas': {'Age': {'dtype': 'float64',\n",
       "                                                              'name': 'passenger_age'},\n",
       "                                                      'Cabin': {'dtype': 'object',\n",
       "                                                                'name': 'passenger_cabin'},\n",
       "                                                      'Embarked': {'dtype': 'object',\n",
       "                                                                   'name': 'passenger_embarked_port'},\n",
       "                                                      'Fare': {'dtype': 'float64',\n",
       "                                                               'name': 'passenger_fare'},\n",
       "                                                      'Name': {'dtype': 'object',\n",
       "                                                               'name': 'name...\n",
       "                                                                                                            '\"sklearn.preprocessing.QuantileTransformer\"])',\n",
       "                                                                                                   'kwargs': {}}}}},\n",
       "                                                 scoring_metrics=['accuracy',\n",
       "                                                                  'balanced_accuracy',\n",
       "                                                                  'f1',\n",
       "                                                                  'f1_micro',\n",
       "                                                                  'f1_macro',\n",
       "                                                                  'f1_weighted',\n",
       "                                                                  'precision',\n",
       "                                                                  'precision_micro',\n",
       "                                                                  'precision_macro',\n",
       "                                                                  'precision_weighted',\n",
       "                                                                  'recall',\n",
       "                                                                  'recall_micro',\n",
       "                                                                  'recall_macro',\n",
       "                                                                  'recall_weighted',\n",
       "                                                                  'roc_auc',\n",
       "                                                                  'roc_auc_ovr',\n",
       "                                                                  'roc_auc_ovo',\n",
       "                                                                  'roc_auc_ovr_weighted',\n",
       "                                                                  'roc_auc_ovo_weighted'],\n",
       "                                                 target='survived'))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/01_raw/titanic_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.9585429\u001b[0m , \u001b[1;36m0.04145713\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98495734\u001b[0m, \u001b[1;36m0.01504268\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.91867673\u001b[0m, \u001b[1;36m0.08132327\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.6080147\u001b[0m , \u001b[1;36m0.39198533\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.17216593\u001b[0m, \u001b[1;36m0.82783407\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9740399\u001b[0m , \u001b[1;36m0.02596007\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.72623605\u001b[0m, \u001b[1;36m0.27376395\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.97367996\u001b[0m, \u001b[1;36m0.02632004\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00956863\u001b[0m, \u001b[1;36m0.99043137\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9916237\u001b[0m , \u001b[1;36m0.00837629\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9882268\u001b[0m , \u001b[1;36m0.01177321\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.86152005\u001b[0m, \u001b[1;36m0.13847995\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00699151\u001b[0m, \u001b[1;36m0.9930085\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9706892\u001b[0m , \u001b[1;36m0.02931079\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.14146829\u001b[0m, \u001b[1;36m0.8585317\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01628315\u001b[0m, \u001b[1;36m0.98371685\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8891957\u001b[0m , \u001b[1;36m0.11080433\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9486027\u001b[0m , \u001b[1;36m0.05139732\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.26580322\u001b[0m, \u001b[1;36m0.7341968\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.80220866\u001b[0m, \u001b[1;36m0.19779137\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.91840005\u001b[0m, \u001b[1;36m0.08159994\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.20409274\u001b[0m, \u001b[1;36m0.79590726\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01105571\u001b[0m, \u001b[1;36m0.9889443\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8981447\u001b[0m , \u001b[1;36m0.10185529\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00979137\u001b[0m, \u001b[1;36m0.9902086\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98926014\u001b[0m, \u001b[1;36m0.01073986\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00382644\u001b[0m, \u001b[1;36m0.99617356\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.94552654\u001b[0m, \u001b[1;36m0.05447348\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.2559877\u001b[0m , \u001b[1;36m0.7440123\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.863664\u001b[0m  , \u001b[1;36m0.13633603\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.81370026\u001b[0m, \u001b[1;36m0.18629973\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9540689\u001b[0m , \u001b[1;36m0.04593109\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.27872813\u001b[0m, \u001b[1;36m0.7212719\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98532516\u001b[0m, \u001b[1;36m0.01467485\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.75228554\u001b[0m, \u001b[1;36m0.24771444\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8935895\u001b[0m , \u001b[1;36m0.10641051\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9083948\u001b[0m , \u001b[1;36m0.09160521\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9241837\u001b[0m , \u001b[1;36m0.07581625\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.97202814\u001b[0m, \u001b[1;36m0.02797185\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.31910086\u001b[0m, \u001b[1;36m0.68089914\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.99368936\u001b[0m, \u001b[1;36m0.00631062\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.656176\u001b[0m  , \u001b[1;36m0.34382403\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9823035\u001b[0m , \u001b[1;36m0.01769651\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.05677992\u001b[0m, \u001b[1;36m0.9432201\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00204062\u001b[0m, \u001b[1;36m0.9979594\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.6739298\u001b[0m , \u001b[1;36m0.32607022\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.43687475\u001b[0m, \u001b[1;36m0.56312525\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.935495\u001b[0m  , \u001b[1;36m0.06450497\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.0026632\u001b[0m , \u001b[1;36m0.9973368\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.12787575\u001b[0m, \u001b[1;36m0.87212425\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.52128595\u001b[0m, \u001b[1;36m0.47871405\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9316171\u001b[0m , \u001b[1;36m0.06838292\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.02001923\u001b[0m, \u001b[1;36m0.97998077\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.07323086\u001b[0m, \u001b[1;36m0.92676914\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.764352\u001b[0m  , \u001b[1;36m0.23564798\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.985264\u001b[0m  , \u001b[1;36m0.01473602\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9878834\u001b[0m , \u001b[1;36m0.01211658\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.84678775\u001b[0m, \u001b[1;36m0.15321226\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.97071797\u001b[0m, \u001b[1;36m0.02928202\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00430167\u001b[0m, \u001b[1;36m0.99569833\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9810555\u001b[0m , \u001b[1;36m0.01894453\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.7962371\u001b[0m , \u001b[1;36m0.20376286\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.982554\u001b[0m  , \u001b[1;36m0.017446\u001b[0m  \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.06308579\u001b[0m, \u001b[1;36m0.9369142\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.55808324\u001b[0m, \u001b[1;36m0.44191676\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.04890776\u001b[0m, \u001b[1;36m0.95109224\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.06206357\u001b[0m, \u001b[1;36m0.9379364\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98241884\u001b[0m, \u001b[1;36m0.01758117\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.30024832\u001b[0m, \u001b[1;36m0.6997517\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.05936724\u001b[0m, \u001b[1;36m0.94063276\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.5652952\u001b[0m , \u001b[1;36m0.4347048\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9932724\u001b[0m , \u001b[1;36m0.00672758\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.18019468\u001b[0m, \u001b[1;36m0.8198053\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.18606067\u001b[0m, \u001b[1;36m0.81393933\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.02428937\u001b[0m, \u001b[1;36m0.97571063\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8291065\u001b[0m , \u001b[1;36m0.17089348\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.92857283\u001b[0m, \u001b[1;36m0.07142716\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.05010796\u001b[0m, \u001b[1;36m0.94989204\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8209335\u001b[0m , \u001b[1;36m0.17906646\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.641899\u001b[0m  , \u001b[1;36m0.35810104\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.17343265\u001b[0m, \u001b[1;36m0.82656735\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8221767\u001b[0m , \u001b[1;36m0.1778233\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9451519\u001b[0m , \u001b[1;36m0.05484806\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9766088\u001b[0m , \u001b[1;36m0.0233912\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.50781214\u001b[0m, \u001b[1;36m0.4921879\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.30376595\u001b[0m, \u001b[1;36m0.69623405\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01517791\u001b[0m, \u001b[1;36m0.9848221\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.11356992\u001b[0m, \u001b[1;36m0.8864301\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8995439\u001b[0m , \u001b[1;36m0.1004561\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01679337\u001b[0m, \u001b[1;36m0.9832066\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9168523\u001b[0m , \u001b[1;36m0.0831477\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9209877\u001b[0m , \u001b[1;36m0.07901226\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.02387041\u001b[0m, \u001b[1;36m0.9761296\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9693251\u001b[0m , \u001b[1;36m0.03067487\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.76684123\u001b[0m, \u001b[1;36m0.23315875\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.81695306\u001b[0m, \u001b[1;36m0.18304697\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.1386097\u001b[0m , \u001b[1;36m0.8613903\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.6011548\u001b[0m , \u001b[1;36m0.3988452\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.41863376\u001b[0m, \u001b[1;36m0.58136624\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9761014\u001b[0m , \u001b[1;36m0.0238986\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00893337\u001b[0m, \u001b[1;36m0.99106663\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.90562207\u001b[0m, \u001b[1;36m0.09437792\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9428025\u001b[0m , \u001b[1;36m0.05719752\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.91014206\u001b[0m, \u001b[1;36m0.08985797\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.29187173\u001b[0m, \u001b[1;36m0.7081283\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9733101\u001b[0m , \u001b[1;36m0.02668991\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9270433\u001b[0m , \u001b[1;36m0.07295671\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9831421\u001b[0m , \u001b[1;36m0.01685794\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9882576\u001b[0m , \u001b[1;36m0.01174242\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.62580776\u001b[0m, \u001b[1;36m0.3741922\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9818235\u001b[0m , \u001b[1;36m0.01817648\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.16739744\u001b[0m, \u001b[1;36m0.83260256\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00187272\u001b[0m, \u001b[1;36m0.9981273\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.17532551\u001b[0m, \u001b[1;36m0.8246745\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.02306688\u001b[0m, \u001b[1;36m0.9769331\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.94195926\u001b[0m, \u001b[1;36m0.05804077\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.92200065\u001b[0m, \u001b[1;36m0.07799938\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.03546226\u001b[0m, \u001b[1;36m0.96453774\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.661625\u001b[0m  , \u001b[1;36m0.338375\u001b[0m  \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.04086262\u001b[0m, \u001b[1;36m0.9591374\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00455427\u001b[0m, \u001b[1;36m0.9954457\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.77465004\u001b[0m, \u001b[1;36m0.22534996\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00379384\u001b[0m, \u001b[1;36m0.99620616\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9253034\u001b[0m , \u001b[1;36m0.07469658\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.81857324\u001b[0m, \u001b[1;36m0.1814268\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.06601769\u001b[0m, \u001b[1;36m0.9339823\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.7350466\u001b[0m , \u001b[1;36m0.2649534\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01647198\u001b[0m, \u001b[1;36m0.983528\u001b[0m  \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9807061\u001b[0m , \u001b[1;36m0.01929391\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9948889\u001b[0m , \u001b[1;36m0.00511111\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9485461\u001b[0m , \u001b[1;36m0.05145387\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9622728\u001b[0m , \u001b[1;36m0.03772719\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.96646535\u001b[0m, \u001b[1;36m0.03353468\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.79164404\u001b[0m, \u001b[1;36m0.20835596\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9940349\u001b[0m , \u001b[1;36m0.00596511\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9815899\u001b[0m , \u001b[1;36m0.01841011\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.74764687\u001b[0m, \u001b[1;36m0.25235313\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9203031\u001b[0m , \u001b[1;36m0.07969688\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.90921617\u001b[0m, \u001b[1;36m0.09078385\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9768407\u001b[0m , \u001b[1;36m0.0231593\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9860233\u001b[0m , \u001b[1;36m0.01397669\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00647736\u001b[0m, \u001b[1;36m0.99352264\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.63474476\u001b[0m, \u001b[1;36m0.36525524\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9788676\u001b[0m , \u001b[1;36m0.02113241\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.72017443\u001b[0m, \u001b[1;36m0.27982554\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9516678\u001b[0m , \u001b[1;36m0.04833219\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.54639226\u001b[0m, \u001b[1;36m0.45360774\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.99613446\u001b[0m, \u001b[1;36m0.00386556\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8900875\u001b[0m , \u001b[1;36m0.10991252\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.99254096\u001b[0m, \u001b[1;36m0.00745904\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00742847\u001b[0m, \u001b[1;36m0.99257153\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9085397\u001b[0m , \u001b[1;36m0.09146031\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8602593\u001b[0m , \u001b[1;36m0.13974068\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.5224005\u001b[0m , \u001b[1;36m0.47759953\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9575969\u001b[0m , \u001b[1;36m0.04240308\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.4429387\u001b[0m , \u001b[1;36m0.5570613\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.03514254\u001b[0m, \u001b[1;36m0.96485746\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.6548687\u001b[0m , \u001b[1;36m0.34513125\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.123321\u001b[0m  , \u001b[1;36m0.876679\u001b[0m  \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.13408613\u001b[0m, \u001b[1;36m0.86591387\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.34971434\u001b[0m, \u001b[1;36m0.65028566\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.06614327\u001b[0m, \u001b[1;36m0.9338567\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.04039961\u001b[0m, \u001b[1;36m0.9596004\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9932128\u001b[0m , \u001b[1;36m0.0067872\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9328539\u001b[0m , \u001b[1;36m0.06714614\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8530908\u001b[0m , \u001b[1;36m0.14690919\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.6822126\u001b[0m , \u001b[1;36m0.31778744\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.987473\u001b[0m  , \u001b[1;36m0.012527\u001b[0m  \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.0295859\u001b[0m , \u001b[1;36m0.9704141\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.95063305\u001b[0m, \u001b[1;36m0.04936692\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9724453\u001b[0m , \u001b[1;36m0.02755472\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8711684\u001b[0m , \u001b[1;36m0.1288316\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9895251\u001b[0m , \u001b[1;36m0.0104749\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9543041\u001b[0m , \u001b[1;36m0.04569589\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9557578\u001b[0m , \u001b[1;36m0.04424222\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.0032866\u001b[0m , \u001b[1;36m0.9967134\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01021451\u001b[0m, \u001b[1;36m0.9897855\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.4443606\u001b[0m , \u001b[1;36m0.5556394\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01814771\u001b[0m, \u001b[1;36m0.9818523\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.03149724\u001b[0m, \u001b[1;36m0.96850276\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8987724\u001b[0m , \u001b[1;36m0.1012276\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.3538224\u001b[0m , \u001b[1;36m0.6461776\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00948793\u001b[0m, \u001b[1;36m0.9905121\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.83862776\u001b[0m, \u001b[1;36m0.16137226\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.0151763\u001b[0m , \u001b[1;36m0.9848237\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8997534\u001b[0m , \u001b[1;36m0.10024662\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.25928986\u001b[0m, \u001b[1;36m0.74071014\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8356004\u001b[0m , \u001b[1;36m0.1643996\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9850431\u001b[0m , \u001b[1;36m0.0149569\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.99347115\u001b[0m, \u001b[1;36m0.00652884\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8425419\u001b[0m , \u001b[1;36m0.15745813\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.6152197\u001b[0m , \u001b[1;36m0.38478032\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.5183617\u001b[0m , \u001b[1;36m0.48163828\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.97346824\u001b[0m, \u001b[1;36m0.02653178\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.06177866\u001b[0m, \u001b[1;36m0.93822134\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9298488\u001b[0m , \u001b[1;36m0.07015121\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.03607762\u001b[0m, \u001b[1;36m0.9639224\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.7940514\u001b[0m , \u001b[1;36m0.20594856\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9953416\u001b[0m , \u001b[1;36m0.00465841\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.09138423\u001b[0m, \u001b[1;36m0.90861577\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.12217373\u001b[0m, \u001b[1;36m0.8778263\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.07511103\u001b[0m, \u001b[1;36m0.92488897\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.7920245\u001b[0m , \u001b[1;36m0.20797552\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00495386\u001b[0m, \u001b[1;36m0.99504614\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.99279404\u001b[0m, \u001b[1;36m0.00720596\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.97178\u001b[0m   , \u001b[1;36m0.02822003\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.09255898\u001b[0m, \u001b[1;36m0.907441\u001b[0m  \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.99185973\u001b[0m, \u001b[1;36m0.00814026\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00592315\u001b[0m, \u001b[1;36m0.99407685\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.99232745\u001b[0m, \u001b[1;36m0.00767252\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8390908\u001b[0m , \u001b[1;36m0.16090915\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9567087\u001b[0m , \u001b[1;36m0.04329127\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.94624925\u001b[0m, \u001b[1;36m0.05375078\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.02787507\u001b[0m, \u001b[1;36m0.97212493\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8831793\u001b[0m , \u001b[1;36m0.11682072\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.79566133\u001b[0m, \u001b[1;36m0.2043387\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.06725216\u001b[0m, \u001b[1;36m0.93274784\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9366718\u001b[0m , \u001b[1;36m0.06332819\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.12808049\u001b[0m, \u001b[1;36m0.8719195\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.96077746\u001b[0m, \u001b[1;36m0.03922255\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.07192647\u001b[0m, \u001b[1;36m0.9280735\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98963153\u001b[0m, \u001b[1;36m0.01036848\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.02197677\u001b[0m, \u001b[1;36m0.97802323\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8631025\u001b[0m , \u001b[1;36m0.13689752\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.07352167\u001b[0m, \u001b[1;36m0.9264783\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.1497432\u001b[0m , \u001b[1;36m0.8502568\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.97465503\u001b[0m, \u001b[1;36m0.02534494\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.14930266\u001b[0m, \u001b[1;36m0.85069734\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.99570405\u001b[0m, \u001b[1;36m0.00429594\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.7221557\u001b[0m , \u001b[1;36m0.27784428\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9187002\u001b[0m , \u001b[1;36m0.08129976\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00533366\u001b[0m, \u001b[1;36m0.99466634\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9676449\u001b[0m , \u001b[1;36m0.03235514\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.87878335\u001b[0m, \u001b[1;36m0.12121663\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9427269\u001b[0m , \u001b[1;36m0.05727312\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9585171\u001b[0m , \u001b[1;36m0.04148291\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9440045\u001b[0m , \u001b[1;36m0.0559955\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9094413\u001b[0m , \u001b[1;36m0.09055871\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.154073\u001b[0m  , \u001b[1;36m0.845927\u001b[0m  \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.03580374\u001b[0m, \u001b[1;36m0.96419626\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.06215763\u001b[0m, \u001b[1;36m0.93784237\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.14678627\u001b[0m, \u001b[1;36m0.8532137\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.12281215\u001b[0m, \u001b[1;36m0.87718785\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9909677\u001b[0m , \u001b[1;36m0.0090323\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.99693066\u001b[0m, \u001b[1;36m0.00306932\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.09964371\u001b[0m, \u001b[1;36m0.9003563\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01752436\u001b[0m, \u001b[1;36m0.98247564\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.91896105\u001b[0m, \u001b[1;36m0.08103897\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.0122543\u001b[0m , \u001b[1;36m0.9877457\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.39189303\u001b[0m, \u001b[1;36m0.608107\u001b[0m  \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.0164625\u001b[0m , \u001b[1;36m0.9835375\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9591275\u001b[0m , \u001b[1;36m0.0408725\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.84169513\u001b[0m, \u001b[1;36m0.15830487\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.99121296\u001b[0m, \u001b[1;36m0.00878703\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.68786424\u001b[0m, \u001b[1;36m0.31213576\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.99002916\u001b[0m, \u001b[1;36m0.00997082\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9870486\u001b[0m , \u001b[1;36m0.0129514\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.97597015\u001b[0m, \u001b[1;36m0.02402983\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.02771598\u001b[0m, \u001b[1;36m0.972284\u001b[0m  \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9640698\u001b[0m , \u001b[1;36m0.03593021\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9828934\u001b[0m , \u001b[1;36m0.01710662\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.93813956\u001b[0m, \u001b[1;36m0.06186042\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.0173912\u001b[0m , \u001b[1;36m0.9826088\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.06820911\u001b[0m, \u001b[1;36m0.9317909\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9556103\u001b[0m , \u001b[1;36m0.04438969\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9842788\u001b[0m , \u001b[1;36m0.01572117\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98891217\u001b[0m, \u001b[1;36m0.01108786\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98898876\u001b[0m, \u001b[1;36m0.01101125\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.7966061\u001b[0m , \u001b[1;36m0.20339388\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98003536\u001b[0m, \u001b[1;36m0.01996462\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.52877843\u001b[0m, \u001b[1;36m0.47122157\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.81857324\u001b[0m, \u001b[1;36m0.1814268\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.05161786\u001b[0m, \u001b[1;36m0.94838214\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.11565131\u001b[0m, \u001b[1;36m0.8843487\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9611156\u001b[0m , \u001b[1;36m0.03888438\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.08149582\u001b[0m, \u001b[1;36m0.9185042\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98092663\u001b[0m, \u001b[1;36m0.01907334\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.7776981\u001b[0m , \u001b[1;36m0.22230189\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9943121\u001b[0m , \u001b[1;36m0.00568791\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9812857\u001b[0m , \u001b[1;36m0.01871429\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9667189\u001b[0m , \u001b[1;36m0.03328106\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.04715794\u001b[0m, \u001b[1;36m0.95284206\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8995439\u001b[0m , \u001b[1;36m0.1004561\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.23237824\u001b[0m, \u001b[1;36m0.76762176\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.05777758\u001b[0m, \u001b[1;36m0.9422224\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.99886054\u001b[0m, \u001b[1;36m0.00113948\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9587633\u001b[0m , \u001b[1;36m0.04123671\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.7229589\u001b[0m , \u001b[1;36m0.27704105\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.29620504\u001b[0m, \u001b[1;36m0.70379496\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.92683685\u001b[0m, \u001b[1;36m0.07316315\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9880839\u001b[0m , \u001b[1;36m0.01191609\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.4377219\u001b[0m , \u001b[1;36m0.5622781\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.5392022\u001b[0m , \u001b[1;36m0.4607978\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8167612\u001b[0m , \u001b[1;36m0.18323882\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9338815\u001b[0m , \u001b[1;36m0.06611845\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98811436\u001b[0m, \u001b[1;36m0.01188566\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.09560806\u001b[0m, \u001b[1;36m0.90439194\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.863664\u001b[0m  , \u001b[1;36m0.13633603\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.89404345\u001b[0m, \u001b[1;36m0.10595657\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.5560745\u001b[0m , \u001b[1;36m0.4439255\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.92053735\u001b[0m, \u001b[1;36m0.07946263\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.4896536\u001b[0m , \u001b[1;36m0.5103464\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.837464\u001b[0m  , \u001b[1;36m0.16253603\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.992631\u001b[0m  , \u001b[1;36m0.00736895\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.6663691\u001b[0m , \u001b[1;36m0.3336309\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.0234195\u001b[0m , \u001b[1;36m0.9765805\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.88932353\u001b[0m, \u001b[1;36m0.11067646\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.02172446\u001b[0m, \u001b[1;36m0.97827554\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8378527\u001b[0m , \u001b[1;36m0.16214725\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9757388\u001b[0m , \u001b[1;36m0.02426119\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9852877\u001b[0m , \u001b[1;36m0.01471225\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.5379182\u001b[0m , \u001b[1;36m0.46208176\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.7633008\u001b[0m , \u001b[1;36m0.23669924\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.7950446\u001b[0m , \u001b[1;36m0.20495541\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.03112084\u001b[0m, \u001b[1;36m0.96887916\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01942092\u001b[0m, \u001b[1;36m0.9805791\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.84451634\u001b[0m, \u001b[1;36m0.15548366\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98054147\u001b[0m, \u001b[1;36m0.01945855\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.5025984\u001b[0m , \u001b[1;36m0.49740157\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.96546865\u001b[0m, \u001b[1;36m0.03453137\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.91014206\u001b[0m, \u001b[1;36m0.08985797\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.5003864\u001b[0m , \u001b[1;36m0.49961358\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.4810422\u001b[0m , \u001b[1;36m0.5189578\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.16886562\u001b[0m, \u001b[1;36m0.8311344\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00843656\u001b[0m, \u001b[1;36m0.99156344\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9924745\u001b[0m , \u001b[1;36m0.00752549\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00775313\u001b[0m, \u001b[1;36m0.99224687\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.97293717\u001b[0m, \u001b[1;36m0.02706281\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.91670555\u001b[0m, \u001b[1;36m0.08329444\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.990494\u001b[0m  , \u001b[1;36m0.00950602\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01291347\u001b[0m, \u001b[1;36m0.98708653\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.15946871\u001b[0m, \u001b[1;36m0.8405313\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9472753\u001b[0m , \u001b[1;36m0.05272471\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01885146\u001b[0m, \u001b[1;36m0.98114854\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9101174\u001b[0m , \u001b[1;36m0.08988264\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.39770812\u001b[0m, \u001b[1;36m0.6022919\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.28640395\u001b[0m, \u001b[1;36m0.71359605\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.990858\u001b[0m  , \u001b[1;36m0.00914201\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9507697\u001b[0m , \u001b[1;36m0.0492303\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.7644984\u001b[0m , \u001b[1;36m0.23550159\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9010812\u001b[0m , \u001b[1;36m0.09891878\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98966366\u001b[0m, \u001b[1;36m0.01033635\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98770815\u001b[0m, \u001b[1;36m0.01229184\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00674224\u001b[0m, \u001b[1;36m0.99325776\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9083417\u001b[0m , \u001b[1;36m0.09165828\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.6361722\u001b[0m , \u001b[1;36m0.36382782\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.96552587\u001b[0m, \u001b[1;36m0.0344741\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.85779893\u001b[0m, \u001b[1;36m0.14220108\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.97270596\u001b[0m, \u001b[1;36m0.02729404\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.02250797\u001b[0m, \u001b[1;36m0.97749203\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00574803\u001b[0m, \u001b[1;36m0.99425197\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.97746307\u001b[0m, \u001b[1;36m0.02253694\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.96546686\u001b[0m, \u001b[1;36m0.03453317\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9302212\u001b[0m , \u001b[1;36m0.06977877\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.09537995\u001b[0m, \u001b[1;36m0.90462005\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9141008\u001b[0m , \u001b[1;36m0.08589916\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01168829\u001b[0m, \u001b[1;36m0.9883117\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.85954124\u001b[0m, \u001b[1;36m0.14045878\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.81857324\u001b[0m, \u001b[1;36m0.1814268\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.48756182\u001b[0m, \u001b[1;36m0.5124382\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9909415\u001b[0m , \u001b[1;36m0.00905849\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.02144635\u001b[0m, \u001b[1;36m0.97855365\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.0125649\u001b[0m , \u001b[1;36m0.9874351\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.6153436\u001b[0m , \u001b[1;36m0.3846564\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00261575\u001b[0m, \u001b[1;36m0.99738425\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9804866\u001b[0m , \u001b[1;36m0.0195134\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9513554\u001b[0m , \u001b[1;36m0.04864459\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.43404877\u001b[0m, \u001b[1;36m0.5659512\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01242691\u001b[0m, \u001b[1;36m0.9875731\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.83238924\u001b[0m, \u001b[1;36m0.16761075\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9931442\u001b[0m , \u001b[1;36m0.00685582\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00270015\u001b[0m, \u001b[1;36m0.99729985\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98960817\u001b[0m, \u001b[1;36m0.01039182\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9352381\u001b[0m , \u001b[1;36m0.0647619\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00663298\u001b[0m, \u001b[1;36m0.993367\u001b[0m  \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01494908\u001b[0m, \u001b[1;36m0.9850509\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.90559083\u001b[0m, \u001b[1;36m0.09440915\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9963231\u001b[0m , \u001b[1;36m0.00367689\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.96252316\u001b[0m, \u001b[1;36m0.03747683\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.47677332\u001b[0m, \u001b[1;36m0.5232267\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.5509759\u001b[0m , \u001b[1;36m0.44902405\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.778527\u001b[0m  , \u001b[1;36m0.22147298\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.5796828\u001b[0m , \u001b[1;36m0.42031717\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.09547484\u001b[0m, \u001b[1;36m0.90452516\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.84323496\u001b[0m, \u001b[1;36m0.15676503\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.0307287\u001b[0m , \u001b[1;36m0.9692713\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9604195\u001b[0m , \u001b[1;36m0.03958054\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.920996\u001b[0m  , \u001b[1;36m0.07900399\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.97215354\u001b[0m, \u001b[1;36m0.02784644\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98399204\u001b[0m, \u001b[1;36m0.01600797\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.46407008\u001b[0m, \u001b[1;36m0.5359299\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01059067\u001b[0m, \u001b[1;36m0.9894093\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.8416346\u001b[0m , \u001b[1;36m0.15836541\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9376056\u001b[0m , \u001b[1;36m0.0623944\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.98917097\u001b[0m, \u001b[1;36m0.01082901\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00915694\u001b[0m, \u001b[1;36m0.99084306\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9879201\u001b[0m , \u001b[1;36m0.01207989\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00189412\u001b[0m, \u001b[1;36m0.9981059\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9681394\u001b[0m , \u001b[1;36m0.0318606\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9945079\u001b[0m , \u001b[1;36m0.00549211\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.02214003\u001b[0m, \u001b[1;36m0.97786\u001b[0m   \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9832423\u001b[0m , \u001b[1;36m0.01675774\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00315475\u001b[0m, \u001b[1;36m0.99684525\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.952319\u001b[0m  , \u001b[1;36m0.04768098\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.6895947\u001b[0m , \u001b[1;36m0.3104053\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.58342123\u001b[0m, \u001b[1;36m0.41657874\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9917438\u001b[0m , \u001b[1;36m0.00825619\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9693912\u001b[0m , \u001b[1;36m0.03060877\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.5609031\u001b[0m , \u001b[1;36m0.4390969\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.05075341\u001b[0m, \u001b[1;36m0.9492466\u001b[0m \u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.7043196\u001b[0m , \u001b[1;36m0.29568043\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.00874156\u001b[0m, \u001b[1;36m0.99125844\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.39370173\u001b[0m, \u001b[1;36m0.60629827\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9884715\u001b[0m , \u001b[1;36m0.01152848\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.01483464\u001b[0m, \u001b[1;36m0.98516536\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.9963682\u001b[0m , \u001b[1;36m0.00363176\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.92857283\u001b[0m, \u001b[1;36m0.07142716\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[1m[\u001b[0m\u001b[1;36m0.69028807\u001b[0m, \u001b[1;36m0.30971193\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mfloat32\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package CLI\n",
    "\n",
    "\n",
    "The Package CLI simplifies complex machine learning workflows by breaking them down into modular pipelines. It seamlessly integrates with Kedro, a data engineering framework, to provide a structured approach to ML project development.\n",
    "\n",
    "## 2. Package Structure\n",
    "\n",
    "The package is organized as follows:\n",
    "\n",
    "### Pipelines\n",
    "\n",
    "- Pipelines are the backbone of the Package CLI. Each step in the ML workflow is broken down into separate pipelines. This modular approach improves code readability and maintainability.\n",
    "\n",
    "### Logging and Tracking\n",
    "\n",
    "- The Package CLI utilizes MLflow for logging and tracking experiments. This integration enables comprehensive monitoring of your ML projects, including model performance, data lineage, and hyperparameter optimization.\n",
    "\n",
    "## 3. Logging and Tracking\n",
    "\n",
    "MLflow is at the core of our logging and tracking system:\n",
    "\n",
    "- **Data**: Input data, transformed data, and data splits are logged to ensure complete traceability.\n",
    "- **Model Artifacts**: Serialized model files are logged, simplifying model replication and deployment.\n",
    "- **Metrics**: Key performance metrics, such as accuracy, precision, recall, and F1-score, are tracked.\n",
    "- **Hyperparameters**: Detailed information about the hyperparameters used during training is recorded.\n",
    "- **Experiment Parameters**: Parameters set for each experiment run are logged for easy reproducibility.\n",
    "- **Models reprotign**: All html files that reports, performance reports, hyperparameters study, model predictive control exploration and global model optimization reports are logged as artifacts.\n",
    "\n",
    "## 4. Custom Pipelines\n",
    "\n",
    "The Package CLI provides a collection of custom Kedro pipelines, making it easy to integrate into your ML projects. These pipelines cover fundamental steps in the ML workflow, including:\n",
    "\n",
    "- Data preprocessing and feature engineering.\n",
    "- Model training and evaluation.\n",
    "- Model deployment and serving.\n",
    "\n",
    "These pipelines are designed to be highly modular, allowing you to extend or customize them to meet your specific project requirements.\n",
    "\n",
    "## 5. Model Compatibility\n",
    "\n",
    "The Package CLI includes the `BinaryClassifierSklearnPipeline` class, which is compatible with any machine learning model adhering to the scikit-learn API. This flexibility empowers you to experiment with a wide variety of models, including:\n",
    "\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- Support Vector Machines\n",
    "- Gradient Boosting\n",
    "- Neural Networks\n",
    "- Xgboost\n",
    "- SVM\n",
    "- k-NN\n",
    "\n",
    "And all compatible models\n",
    "\n",
    "## 6. Hyperparameter Tuning\n",
    "\n",
    "Using the kedro cli. You can explore different hyperparameter settings for different models to optimize its performance, using **StratifiedKFold** cross validation strategy. Hyperparameter tuning is seamlessly integrated into the pipeline, simplifying the search for the best model configurations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data engineering CLI<a name=\"data-engineering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m[01/07/24 21:27:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/Users/Matheus_Pinto/anaconda3/envs\u001b[0m \u001b]8;id=173221;file:///Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=616096;file:///Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35m/distelsa/lib/python3.10/site-packa\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35mges/kedro/io/\u001b[0m\u001b[95m__init__.py\u001b[0m:\u001b[1;36m44\u001b[0m:        \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         KedroDeprecationWarning:            \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[32m'AbstractDataSet'\u001b[0m has been renamed  \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         to \u001b[32m'AbstractDataset'\u001b[0m, and the alias \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         will be removed in Kedro \u001b[1;36m0.19\u001b[0m.\u001b[1;36m0\u001b[0m     \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m           return \u001b[1;35mgetattr\u001b[0m\u001b[1m(\u001b[0mkedro.io.core,     \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         name\u001b[1m)\u001b[0m                               \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m                                             \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/Users/Matheus_Pinto/anaconda3/envs\u001b[0m \u001b]8;id=356568;file:///Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=737489;file:///Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35m/distelsa/lib/python3.10/site-packa\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35mges/kedro/io/\u001b[0m\u001b[95m__init__.py\u001b[0m:\u001b[1;36m44\u001b[0m:        \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         KedroDeprecationWarning:            \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[32m'DataSetError'\u001b[0m has been renamed to  \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[32m'DatasetError'\u001b[0m, and the alias will  \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         be removed in Kedro \u001b[1;36m0.19\u001b[0m.\u001b[1;36m0\u001b[0m          \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m           return \u001b[1;35mgetattr\u001b[0m\u001b[1m(\u001b[0mkedro.io.core,     \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         name\u001b[1m)\u001b[0m                               \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m                                             \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/Users/Matheus_Pinto/anaconda3/envs\u001b[0m \u001b]8;id=127402;file:///Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=54731;file:///Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35m/distelsa/lib/python3.10/site-packa\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35mges/kedro/extras/logging/\u001b[0m\u001b[95m__init__.p\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[95my\u001b[0m:\u001b[1;36m11\u001b[0m: KedroDeprecationWarning:      \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         Support for ColorHandler will be    \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         removed in Kedro \u001b[1;36m0.19\u001b[0m.\u001b[1;36m0\u001b[0m.            \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m           \u001b[1;35mwarnings.warn\u001b[0m\u001b[1m(\u001b[0m                    \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m                                             \u001b[2m               \u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:04,180 - kedro.framework.session.session - INFO - Kedro project titanic-dataset\u001b[0m\n",
      "\u001b[33m2024-01-07 21:27:04,196 - py.warnings - WARNING - /Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/site-packages/kedro/framework/session/session.py:267: KedroDeprecationWarning: TemplatedConfigLoader will be deprecated in Kedro 0.19. Please use the OmegaConfigLoader instead. To consult the documentation for OmegaConfigLoader, see here: https://docs.kedro.org/en/stable/configuration/advanced_configuration.html#omegaconfigloader\n",
      "  warnings.warn(\n",
      "\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:04,208 - kedro_mlflow.config.kedro_mlflow_config - INFO - The 'tracking_uri' key in mlflow.yml is relative ('server.mlflow_(tracking|registry)_uri = mlruns'). It is converted to a valid uri: 'file:///Users/Matheus_Pinto/Desktop/quantumblack/titanic-dataset/mlruns'\u001b[0m\n",
      "\u001b[34m2024-01-07 21:27:07,148 - project.packages.modelling.reproducibility.set_seed - INFO - Seeding sklearn, numpy and random libraries with the seed 42\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:08,747 - kedro.io.data_catalog - INFO - Loading data from 'origin_titanic_train' (CSVDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:08,769 - kedro.io.data_catalog - INFO - Loading data from 'origin_titanic_test' (CSVDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:08,777 - kedro.io.data_catalog - INFO - Loading data from 'params:raw_transform' (MemoryDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:08,825 - kedro.pipeline.node - INFO - Running node: raw_data_process: raw_data_process([origin_titanic_train,origin_titanic_test,params:raw_transform]) -> [raw_titanic_train,raw_titanic_test,raw_preprocessor]\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:08,857 - kedro.io.data_catalog - INFO - Saving data to 'raw_titanic_train' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:08,947 - kedro.io.data_catalog - INFO - Saving data to 'raw_titanic_test' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:08,959 - kedro.io.data_catalog - INFO - Saving data to 'raw_preprocessor' (MlflowPickleDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:08,975 - kedro.runner.sequential_runner - INFO - Completed 1 out of 5 tasks\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:08,975 - kedro.io.data_catalog - INFO - Loading data from 'raw_titanic_train' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,039 - kedro.io.data_catalog - INFO - Loading data from 'raw_titanic_test' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,048 - kedro.io.data_catalog - INFO - Loading data from 'params:intermediate_transform' (MemoryDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,062 - kedro.pipeline.node - INFO - Running node: intermediate_data_process: intermediate_data_process([raw_titanic_train,raw_titanic_test,params:intermediate_transform]) -> [int_titanic_train,int_titanic_test,int_preprocessor]\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,092 - kedro.io.data_catalog - INFO - Saving data to 'int_titanic_train' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,107 - kedro.io.data_catalog - INFO - Saving data to 'int_titanic_test' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,132 - kedro.io.data_catalog - INFO - Saving data to 'int_preprocessor' (MlflowPickleDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,166 - kedro.runner.sequential_runner - INFO - Completed 2 out of 5 tasks\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,166 - kedro.io.data_catalog - INFO - Loading data from 'int_titanic_train' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,175 - kedro.io.data_catalog - INFO - Loading data from 'int_titanic_test' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,185 - kedro.io.data_catalog - INFO - Loading data from 'params:primary_transform' (MemoryDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,204 - kedro.pipeline.node - INFO - Running node: primary_data_process: primary_data_process([int_titanic_train,int_titanic_test,params:primary_transform]) -> [prm_titanic_train,prm_titanic_test,prm_preprocessor]\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,237 - kedro.io.data_catalog - INFO - Saving data to 'prm_titanic_train' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,251 - kedro.io.data_catalog - INFO - Saving data to 'prm_titanic_test' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,260 - kedro.io.data_catalog - INFO - Saving data to 'prm_preprocessor' (MlflowPickleDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,264 - kedro.runner.sequential_runner - INFO - Completed 3 out of 5 tasks\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,264 - kedro.io.data_catalog - INFO - Loading data from 'prm_titanic_train' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,274 - kedro.io.data_catalog - INFO - Loading data from 'prm_titanic_test' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,287 - kedro.io.data_catalog - INFO - Loading data from 'params:feature_transform' (MemoryDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,334 - kedro.pipeline.node - INFO - Running node: pre_feature_data_process: feature_data_process([prm_titanic_train,prm_titanic_test,params:feature_transform]) -> [pre_feat_titanic_train,pre_feat_titanic_test,feat_preprocessor]\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,400 - kedro.io.data_catalog - INFO - Saving data to 'pre_feat_titanic_train' (MemoryDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,424 - kedro.io.data_catalog - INFO - Saving data to 'pre_feat_titanic_test' (MemoryDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,438 - kedro.io.data_catalog - INFO - Saving data to 'feat_preprocessor' (MlflowPickleDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,445 - kedro.runner.sequential_runner - INFO - Completed 4 out of 5 tasks\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,445 - kedro.io.data_catalog - INFO - Loading data from 'pre_feat_titanic_train' (MemoryDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,458 - kedro.io.data_catalog - INFO - Loading data from 'pre_feat_titanic_test' (MemoryDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,470 - kedro.io.data_catalog - INFO - Loading data from 'params:feature_transform.clustering_features' (MemoryDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:09,512 - kedro.pipeline.node - INFO - Running node: feature_data_process: clustering_feature_process([pre_feat_titanic_train,pre_feat_titanic_test,params:feature_transform.clustering_features]) -> [feat_titanic_train,feat_titanic_test,cluster_preprocessor]\u001b[0m\n",
      "\u001b[34m2024-01-07 21:27:10,545 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 21:27:10,558 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 31, 'cluster_id_1': 0, 'cluster_id_2': 1}\u001b[0m\n",
      "\u001b[34m2024-01-07 21:27:11,448 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 21:27:11,461 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 1, 'cluster_id_1': 0, 'cluster_id_2': 5}\u001b[0m\n",
      "\u001b[34m2024-01-07 21:27:12,261 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 21:27:12,275 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 427, 'cluster_id_1': 594, 'cluster_id_2': 816}\u001b[0m\n",
      "\u001b[34m2024-01-07 21:27:13,445 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 21:27:13,465 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 889, 'cluster_id_1': 68, 'cluster_id_2': 128}\u001b[0m\n",
      "\u001b[34m2024-01-07 21:27:14,730 - project.packages.modelling.models.unsupervised.segmentation - INFO - Optimal number of clusters: 3\u001b[0m\n",
      "\u001b[34m2024-01-07 21:27:14,749 - project.packages.modelling.models.unsupervised.segmentation - INFO - Centroids dictionary -> {'cluster_id_0': 390, 'cluster_id_1': 146, 'cluster_id_2': 312}\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:15,968 - kedro.io.data_catalog - INFO - Saving data to 'feat_titanic_train' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:16,076 - kedro.io.data_catalog - INFO - Saving data to 'feat_titanic_test' (ParquetDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:16,105 - kedro.io.data_catalog - INFO - Saving data to 'cluster_preprocessor' (MlflowPickleDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:16,125 - kedro.runner.sequential_runner - INFO - Completed 5 out of 5 tasks\u001b[0m\n",
      "\u001b[35m2024-01-07 21:27:16,125 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kedro run --pipeline data_engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data engineering pipelines ends running from raw to cluster transformers and save train and test datasets ready to be used by models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Pipelines\n",
    "\n",
    "The Data Science Pipelines project comprises 9 modular pipelines, each uniquely designed to optimize different machine learning models. These pipelines are thoughtfully constructed to leverage the full potential of your data and to achieve the highest possible model performance.\n",
    "\n",
    "## Model Optimization\n",
    "\n",
    "### Model Selection\n",
    "\n",
    "Our pipelines explore a diverse range of models, including:\n",
    "\n",
    "- Bagging Models\n",
    "- Boosting Models\n",
    "- Support Vector Machines (SVM)\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Neural Network Models\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "To ensure that these models perform at their best, we employ hyperparameter tuning using cross-validation strategies. This rigorous process fine-tunes the model parameters to maximize predictive accuracy and generalization.\n",
    "\n",
    "### Saving Trained Models\n",
    "\n",
    "Once the models are optimized, they are trained on the entire dataset. These trained models are diligently saved for future use, facilitating easy inference on new data and seamless deployment in production environments.\n",
    "\n",
    "## Out-of-Sample Predictions\n",
    "\n",
    "To evaluate model performance, we generate out-of-sample predictions using the `cross_val_predict` class from scikit-learn. These predictions provide invaluable insights into how well the models generalize to unseen data.\n",
    "\n",
    "## Metrics Reporting\n",
    "\n",
    "The final segment of the pipelines involves the creation of a comprehensive metrics report. This report encompasses key performance metrics, enabling you to thoroughly assess the models' effectiveness. Commonly included metrics are accuracy, precision, recall, F1-score, and more.\n",
    "\n",
    "## Production Deployment with MLflow\n",
    "\n",
    "One of the standout features of these pipelines is their seamless integration with MLflow. The best-performing model is automatically registered in a production environment within MLflow. This production-ready model is primed for deployment and can be employed to perform inference on a test dataset. It plays a pivotal role in ranking models based on their performance, ensuring that only the top-performing models are deployed in production.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b><Execution Time Alert/b>\n",
    "\n",
    "> The data science pipeline execution can take 1/2 hours to complete. The data science pipeline evaluates several models\n",
    "\n",
    "> If you want to speed up the execution you can run this command instead:\n",
    "\n",
    "!kedro run --pipeline data_science --namespace xgboost  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kedro run --pipeline data_science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow exploration\n",
    "\n",
    "\n",
    "After running data engineering and data science pipelines you can access to the mlflow UI using the following command you should be able to see this url:\n",
    "\n",
    "- **http://127.0.0.1:3001** \n",
    "\n",
    "Open it in a browser and navigate to the artifacts, metrics, models and registered models folder.\n",
    "\n",
    "**Artifacts**: This section houses a variety of assets, including input data, transformed data, model files, and other relevant files. It provides a comprehensive view of the artifacts generated during your experiments.\n",
    "\n",
    "**Metrics**: In the \"Metrics\" section, you can review key performance metrics recorded during your experiments. These metrics are crucial for assessing the effectiveness of your models and pipelines. Commonly logged metrics include accuracy, precision, recall, F1-score, and more.\n",
    "\n",
    "**Models**: Explore the models that have been trained and logged during your experiments in the \"Models\" section. You can access detailed information about each model, including its hyperparameters, performance metrics, and any associated artifacts.\n",
    "\n",
    "**Registered** Models: The \"Registered Models\" folder contains the best-performing models that have been specifically registered for production deployment. These models have undergone rigorous evaluation and are deemed ready for use in real-world applications. This section provides a streamlined view of models that meet the highest quality standards.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kedro mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model productionalization\n",
    "\n",
    "After reviweing MLflow models, next step is put these model on production through an API, so package also contains API version to the production model and transformers used to create these model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the API on production\n",
    "\n",
    "Excecute the following command to have a POST endpoint with the production model.\n",
    "\n",
    "!python src/project/api/model_serving/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flask --app src/project/apis/model_serving run --port=5000 --debug\n",
      "\u001b[35m2024-01-07 21:34:24,093 - kedro_mlflow.config.kedro_mlflow_config - INFO - The 'tracking_uri' key in mlflow.yml is relative ('server.mlflow_(tracking|registry)_uri = mlruns'). It is converted to a valid uri: 'file:///Users/Matheus_Pinto/Desktop/quantumblack/titanic-dataset/mlruns'\u001b[0m\n",
      "\u001b[33m2024-01-07 21:34:24,127 - py.warnings - WARNING - /Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/site-packages/kedro/io/data_catalog.py:302: KedroDeprecationWarning: Defining the 'layer' attribute at the top level is deprecated and will be removed in Kedro 0.19.0. Please move 'layer' inside the 'metadata' -> 'kedro-viz' attributes. See https://docs.kedro.org/en/latest/visualisation/kedro-viz_visualisation.html#visualise-layers for more information.\n",
      "  warnings.warn(\n",
      "\u001b[0m\n",
      "\u001b[33m2024-01-07 21:34:24,130 - py.warnings - WARNING - /Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/site-packages/kedro/io/__init__.py:44: KedroDeprecationWarning: 'AbstractVersionedDataSet' has been renamed to 'AbstractVersionedDataset', and the alias will be removed in Kedro 0.19.0\n",
      "  return getattr(kedro.io.core, name)\n",
      "\u001b[0m\n",
      "\u001b[33m2024-01-07 21:34:24,132 - py.warnings - WARNING - /Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/site-packages/lazy_loader/__init__.py:78: KedroDeprecationWarning: 'PickleDataSet' has been renamed to 'PickleDataset', and the alias will be removed in Kedro-Datasets 2.0.0\n",
      "  attr = getattr(submod, name)\n",
      "\u001b[0m\n",
      "\u001b[33m2024-01-07 21:34:24,134 - py.warnings - WARNING - /Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/site-packages/lazy_loader/__init__.py:78: KedroDeprecationWarning: 'CSVDataSet' has been renamed to 'CSVDataset', and the alias will be removed in Kedro-Datasets 2.0.0\n",
      "  attr = getattr(submod, name)\n",
      "\u001b[0m\n",
      "\u001b[33m2024-01-07 21:34:24,136 - py.warnings - WARNING - /Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/site-packages/kedro_mlflow/io/models/mlflow_model_logger_dataset.py:4: KedroDeprecationWarning: 'DataSetError' has been renamed to 'DatasetError', and the alias will be removed in Kedro 0.19.0\n",
      "  from kedro.io.core import DataSetError\n",
      "\u001b[0m\n",
      "\u001b[33m2024-01-07 21:34:24,137 - py.warnings - WARNING - /Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/site-packages/kedro_mlflow/io/models/mlflow_abstract_model_dataset.py:7: KedroDeprecationWarning: 'DataSetError' has been renamed to 'DatasetError', and the alias will be removed in Kedro 0.19.0\n",
      "  from kedro.io.core import DataSetError\n",
      "\u001b[0m\n",
      "\u001b[33m2024-01-07 21:34:24,146 - py.warnings - WARNING - /Users/Matheus_Pinto/anaconda3/envs/distelsa/lib/python3.10/site-packages/lazy_loader/__init__.py:78: KedroDeprecationWarning: 'TextDataSet' has been renamed to 'TextDataset', and the alias will be removed in Kedro-Datasets 2.0.0\n",
      "  attr = getattr(submod, name)\n",
      "\u001b[0m\n",
      "\u001b[35m2024-01-07 21:34:24,307 - kedro.io.data_catalog - INFO - Loading data from 'raw_preprocessor' (MlflowPickleDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:34:24,674 - kedro.io.data_catalog - INFO - Loading data from 'int_preprocessor' (MlflowPickleDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:34:24,675 - kedro.io.data_catalog - INFO - Loading data from 'prm_preprocessor' (MlflowPickleDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:34:24,678 - kedro.io.data_catalog - INFO - Loading data from 'feat_preprocessor' (MlflowPickleDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:34:24,693 - kedro.io.data_catalog - INFO - Loading data from 'cluster_preprocessor' (MlflowPickleDataset)...\u001b[0m\n",
      "\u001b[35m2024-01-07 21:34:25,000 - kedro.io.data_catalog - INFO - Loading data from 'prd' (MlflowMlflowModelSaverDataSet)...\u001b[0m\n",
      "\u001b[34m2024-01-07 21:34:25,143 - project.packages.modelling.reproducibility.set_seed - INFO - Seeding sklearn, numpy and random libraries with the seed 42\u001b[0m\n",
      "\u001b[35m2024-01-07 21:34:25,174 - kedro.io.data_catalog - INFO - Loading data from 'params:raw_transform' (MemoryDataset)...\u001b[0m\n",
      " * Serving Flask app 'src/project/apis/model_serving'\n",
      " * Debug mode: on\n",
      "Address already in use\n",
      "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
      "On macOS, try disabling the 'AirPlay Receiver' service from System Preferences -> General -> AirDrop & Handoff.\n",
      "make: *** [deploy-model-service-api-dev] Error 1\n"
     ]
    }
   ],
   "source": [
    "# In a unix system run / sorry if you're using a different system, but you should not XD\n",
    "!make deploy-model-service-api-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model API\n",
    "\n",
    "!python src/project/api/model_serving/ping_api.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matheus Pinto Arratia has a survival probability of 16.013 [%]\n"
     ]
    }
   ],
   "source": [
    "!python src/project/apis/model_serving/ping_api.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing the API you should recieve this text on the terminal\n",
    "\n",
    "\n",
    "**Model response: Matheus Pinto Arratia has a survival probability of XX [%]**\n",
    "\n",
    "So, I would probably die ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package testing \n",
    "\n",
    "You can test the whole package using the following command\n",
    "\n",
    "!kedro test src/project/packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see the hole package testing and modules that are missing to be tested\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About CI/CD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application Deployment and Software Architecture\n",
    "\n",
    "\n",
    "When considering deploying these applications into production, there are several architectural options to choose from, each with its own set of advantages and disadvantages.\n",
    "\n",
    "## Gitflow\n",
    "\n",
    "**Pros:**\n",
    "- Ensures a well-structured development process with clear branching strategies.\n",
    "- Continuous Integration (CI) pipeline ensures code quality and functionality.\n",
    "- Integration tests and unit tests provide end-to-end testing coverage.\n",
    "- Code versioning and history tracking.\n",
    "\n",
    "## Docker\n",
    "\n",
    "API, pipelines and packages should be containarized using docker, in order to maintain reproducibility\n",
    "\n",
    "**Pros:**\n",
    "- Enables containerization, ensuring reproducibility across different environments.\n",
    "- Simplifies deployment and scaling as containers can run consistently in various environments.\n",
    "- Supports microservices architecture, allowing for modularization of applications.\n",
    "- Easier management of dependencies within containers.\n",
    "\n",
    "\n",
    "## Deployment\n",
    "\n",
    "Using azure function, lambda functions --> API Gateway\n",
    "\n",
    "### Serverless\n",
    "\n",
    "**Pros:**\n",
    "- Cost-effective as you only pay for actual usage.\n",
    "- Auto-scaling and automatic resource management.\n",
    "- Low operational overhead as the cloud provider handles infrastructure.\n",
    "- Well-suited for event-driven applications and microservices.\n",
    "\n",
    "**Cons:**\n",
    "- Limited control over infrastructure, which may be a limitation for specific requirements.\n",
    "- Cold start latency can impact response times for some functions.\n",
    "- Debugging and monitoring can be more challenging in a serverless environment.\n",
    "\n",
    "\n",
    "### Load Balancer and Server Deployment\n",
    "\n",
    "**Pros:**\n",
    "- Provides control over the underlying infrastructure.\n",
    "- Suitable for applications with specific hardware requirements.\n",
    "- Can be cost-effective for steady-state workloads.\n",
    "- Greater flexibility in configuring load balancing algorithms.\n",
    "\n",
    "\n",
    "**Cons:**\n",
    "- Increased operational complexity compared to serverless or containerized approaches.\n",
    "- Limited scalability during traffic spikes without proper automation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marcimex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
