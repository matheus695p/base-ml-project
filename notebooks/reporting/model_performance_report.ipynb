{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "os.chdir(\"../../\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "\n",
    "%load_ext kedro.ipython\n",
    "%reload_kedro .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# namespace = \"xgboost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = catalog.load(f\"{namespace}.model_artifact\")\n",
    "class_names = [\"class_die\", \"class_survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model metrics \n",
    "\n",
    "### All metrics and predictions are out of sample using **cross_val_predict** method from sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.scores\n",
    "metrics = {\n",
    "    metric.capitalize().replace(\"_\", \" \"): str(round(value * 100, 2)) + \" [%]\" for metric, value in metrics.items()\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names=[\"class1\", \"class2\",]):\n",
    "    \"\"\"\n",
    "    Create an interactive confusion matrix plot using Plotly.\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): True classes.\n",
    "        y_pred (array-like): Predicted classes.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Get unique classes from true and predicted labels\n",
    "    classes = np.unique(np.concatenate([y_true, y_pred]))\n",
    "\n",
    "    # Create confusion matrix\n",
    "    n_classes = len(classes)\n",
    "    confusion_matrix = np.zeros((n_classes, n_classes), dtype=int) # Confusion matrix initialized with zeros\n",
    "\n",
    "    for i in range(len(y_true)):\n",
    "        confusion_matrix[np.where(classes == y_true[i]), np.where(classes == y_pred[i])] += 1 # Fill the confusion matrix\n",
    "\n",
    "    trace = go.Heatmap(\n",
    "        z=confusion_matrix,\n",
    "        x= class_names,\n",
    "        y= class_names,\n",
    "        text=confusion_matrix,\n",
    "        colorscale='Blues',\n",
    "        showscale=True,\n",
    "        hoverinfo='text',\n",
    "        colorbar=dict(title='Count'),\n",
    "        )\n",
    "\n",
    "    # Add annotations to each cell\n",
    "    annotations = []\n",
    "    for i in range(len(confusion_matrix)):\n",
    "        for j in range(len(confusion_matrix)):\n",
    "            annotations.append(\n",
    "                dict(\n",
    "                    x=j,\n",
    "                    y=i,\n",
    "                    text=str(confusion_matrix[i][j]),\n",
    "                    showarrow=False,\n",
    "                    font=dict(color='white' if confusion_matrix[i][j] > (0.5 * confusion_matrix.max()) else 'black')\n",
    "                )\n",
    "            )\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=f'Confusion Matrix {namespace} model',\n",
    "        xaxis=dict(title='Predicted'),\n",
    "        yaxis=dict(title='Actual'),\n",
    "        annotations=annotations,\n",
    "        template='plotly_dark',  # Choose a plotly template (e.g., dark mode)\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "y_pred = model.y_pred\n",
    "y_true = model.y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(np.array(y_true).ravel(), np.array(y_pred).ravel(), class_names=class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report on *out of sample predictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "# Extract the metrics and class labels from the report\n",
    "class_labels = list(report.keys())\n",
    "class_labels.remove('accuracy')\n",
    "\n",
    "metric_names = ['precision', 'recall', 'f1-score']\n",
    "\n",
    "# Create an empty numpy array to store the metric values\n",
    "metrics_array = np.zeros((len(class_labels), len(metric_names)), dtype=float)\n",
    "\n",
    "# Populate the metrics array with the metric values\n",
    "for idx, label in enumerate(class_labels):\n",
    "    for metric_idx, metric_name in enumerate(metric_names):\n",
    "        metrics_array[idx, metric_idx] = round(report[label][metric_name], 2)\n",
    "\n",
    "# Create the heatmap using Plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=metrics_array,\n",
    "    x=metric_names,\n",
    "    y=class_labels,\n",
    "    colorscale='Bluered',\n",
    "    colorbar=dict(title='Metric Values'),\n",
    "    hovertemplate='Class: %{y}<br>Metric: %{x}<br>Value: %{z:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Classification Report {namespace} model',\n",
    "    xaxis=dict(title='Metrics'),\n",
    "    yaxis=dict(title='Class Labels'),\n",
    "    template='plotly_dark',  # Choose a plotly template (e.g., dark mode)\n",
    ")\n",
    "\n",
    "# Add annotations to each cell\n",
    "for i in range(len(class_labels)):\n",
    "    for j in range(len(metric_names)):\n",
    "        fig.add_annotation(\n",
    "            x=metric_names[j],\n",
    "            y=(class_labels[i]),\n",
    "            text=str(metrics_array[i, j]),\n",
    "            showarrow=False,\n",
    "            font=dict(color='white' if metrics_array[i, j] > (0.5 * metrics_array.max()) else 'black')\n",
    "        )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_score = model.y_score\n",
    "y_score.columns = class_names\n",
    "\n",
    "y_probs = y_score[y_score.columns[1]].ravel()\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_true[model.target].ravel(), y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add ROC curve to the figure\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=fpr,\n",
    "        y=tpr,\n",
    "        mode='lines',\n",
    "        name=f'ROC Curve (AUC={roc_auc:.2f})',\n",
    "        line=dict(width=2),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title=f'ROC Curve {namespace} model',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    xaxis_range=[0, 1],\n",
    "    yaxis_range=[0, 1],\n",
    "    legend=dict(x=0.7, y=0.2),\n",
    "    template='plotly_dark',  # Choose a plotly template (e.g., dark mode)\n",
    ")\n",
    "\n",
    "# Add diagonal reference line\n",
    "fig.add_shape(\n",
    "    type='line',\n",
    "    x0=0,\n",
    "    y0=0,\n",
    "    x1=1,\n",
    "    y1=1,\n",
    "    line=dict(dash='dash', color='gray'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_true, y_probs, n_bins=10,)\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the perfectly calibrated line\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', line=dict(dash='dash'), name=\"Perfectly Calibrated\"))\n",
    "\n",
    "# Add the calibration curve\n",
    "fig.add_trace(go.Scatter(x=prob_pred, y=prob_true, mode='lines+markers', name=f'{namespace} Calibration', line=dict(width=2)))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title=f'Calibration Curve for {namespace}',\n",
    "    xaxis_title='Mean Predicted Probability',\n",
    "    yaxis_title='Fraction of Positives',\n",
    "    xaxis_range=[0, 1],\n",
    "    yaxis_range=[0, 1],\n",
    "    legend=dict(x=0.7, y=0.2),\n",
    "    template='plotly_dark',  # Choose a plotly template (e.g., dark mode)\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative gain plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sort the data by predicted probabilities in descending order\n",
    "sorted_indices = np.argsort(y_probs)[::-1]\n",
    "y_true_sorted = y_true[model.target].ravel()[sorted_indices]\n",
    "\n",
    "# Calculate cumulative gain\n",
    "cumulative_gain = np.cumsum(y_true_sorted) / np.sum(y_true_sorted)\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Calculate the fraction of the dataset examined in percentage\n",
    "fraction_examined_percentage = np.arange(1, len(cumulative_gain) + 1) / len(cumulative_gain) * 100\n",
    "\n",
    "# Calculate the Gain in percentage\n",
    "cumulative_gain_percentage = cumulative_gain * 100\n",
    "\n",
    "fig.add_trace(go.Scatter(x=fraction_examined_percentage, y=cumulative_gain_percentage, mode='lines', name='Cumulative Gain Curve'))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title=f'Cumulative Gain Curve for {namespace} Model',\n",
    "    xaxis_title='Fraction of Dataset Examined (%)',\n",
    "    yaxis_title='Gain (%)',\n",
    "    xaxis_range=[0, 100],  # Set the x-axis range to 0-100%\n",
    "    yaxis_range=[0, 100],  # Set the y-axis range to 0-100%\n",
    "    legend=dict(x=0.7, y=0.2),\n",
    "    template='plotly_dark',  # Choose a plotly template (e.g., dark mode)\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities plot through the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "class_name_str = \"/ \".join(class_names)\n",
    "\n",
    "fig = px.line(y_score.reset_index(), x=y_score.index.name, y=[col for col in y_score.columns if \"class\" in col]).update_traces(line_width=3.5)\n",
    "fig.update_layout(\n",
    "    # template=\"plotly_dark\",\n",
    "    title=dict(\n",
    "        text=f'{namespace} Model' + \"<br>\" + f\"{class_name_str}\",\n",
    "        y=.93,\n",
    "        font=dict(\n",
    "            family=\"Courier New\",\n",
    "            size=32,\n",
    "        ),\n",
    "    ),\n",
    "    font_size=20,\n",
    "    xaxis_title=y_score.index.name,\n",
    "    yaxis_title=f'{class_name_str}',\n",
    "    template='plotly_dark',  # Choose a plotly template (e.g., dark mode)\n",
    "    boxgroupgap=0,\n",
    "    legend=dict(\n",
    "        title=\"\",\n",
    "        orientation=\"v\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1,\n",
    "    ),\n",
    "    height=1080,\n",
    "    width=1920,\n",
    "    margin=dict(l=150, r=75, t=270, b=15),\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marcimex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
